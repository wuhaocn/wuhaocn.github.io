{"meta":{"title":"wuhaocn","subtitle":"","description":"","author":"wuhao","url":"https://wuhaocn.github.io","root":"/"},"pages":[{"title":"关于","date":"2021-07-26T01:33:15.069Z","updated":"2021-07-26T01:33:15.069Z","comments":false,"path":"about/index.html","permalink":"https://wuhaocn.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2021-07-26T01:33:15.070Z","updated":"2021-07-26T01:33:15.070Z","comments":false,"path":"books/index.html","permalink":"https://wuhaocn.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-07-26T01:33:15.071Z","updated":"2021-07-26T01:33:15.071Z","comments":true,"path":"links/index.html","permalink":"https://wuhaocn.github.io/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-07-26T02:15:38.649Z","updated":"2021-07-26T02:15:38.649Z","comments":false,"path":"categories/index.html","permalink":"https://wuhaocn.github.io/categories/index.html","excerpt":"","text":"1.编程语言1.1.java1.1.c1.1.go2.技术中间件3.devops4.算法4.1.常见算法4.2.分布式算法5.计算机基础5.1.网络"},{"title":"标签","date":"2021-07-26T01:33:15.071Z","updated":"2021-07-26T01:33:15.071Z","comments":false,"path":"tags/index.html","permalink":"https://wuhaocn.github.io/tags/index.html","excerpt":"","text":""},{"title":"git仓库","date":"2021-07-26T01:33:15.071Z","updated":"2021-07-26T01:33:15.071Z","comments":false,"path":"repository/index.html","permalink":"https://wuhaocn.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux定时任务用法与实例","slug":"language/shell/Linux定时任务用法与实例","date":"2021-10-18T03:19:43.244Z","updated":"2021-10-18T03:35:26.285Z","comments":true,"path":"2021/10/18/language/shell/Linux定时任务用法与实例/","link":"","permalink":"https://wuhaocn.github.io/2021/10/18/language/shell/Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%94%A8%E6%B3%95%E4%B8%8E%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"1.简介** 在**Linux系统的实际使用中，可能会经常碰到让系统在某个特定时间执行某些任务的情况，比如定时采集服务器的状态信息、负载状况；定时执行某些任务/脚本来对远端进行数据采集等。这里将介绍下crontab的配置参数以及一些使用实例。​ crontab配置文件Linux下的任务调度分为两类：系统任务调度和用户任务调度。Linux系统任务是由 cron (crond) 这个系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用crontab 命令。 2.常见配置2.1 配置详情1cat /etc/crontab 1234567891011121314# /etc/crontab: system-wide crontab# Unlike any other crontab you don&#x27;t have to run the `crontab&#x27;# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin# m h dom mon dow user command17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 2.2 crontab格式 在以上各个字段中，还可以使用以下特殊字符： 12345&quot;*&quot;代表所有的取值范围内的数字，如月份字段为*，则表示1到12个月；&quot;/&quot;代表每一定时间间隔的意思，如分钟字段为*/10，表示每10分钟执行1次。&quot;-&quot;代表从某个区间范围，是闭区间。如“2-5”表示“2,3,4,5”，小时字段中0-23/2表示在0~23点范围内每2个小时执行一次。&quot;,&quot;分散的数字（不一定连续），如1,2,3,4,7,9。注：由于各个地方每周第一天不一样，因此Sunday=0（第一天）或Sunday=7（最后1天）。 crontab命令详解 2.3 配置文件​ 其一：/var/spool/cron/该目录下存放的是每个用户（包括root）的crontab任务，文件名以用户名命名 其二：/etc/cron.d/这个目录用来存放任何要执行的crontab文件或脚本。3.服务状态​ 启动服务 sudo service cron start 关闭服务 sudo service cron stop 重启服务 sudo service cron restart 重新载入配置 sudo service cron reload 查看服务状态 sudo service cron status 4.常见命令 重新指定crontab定时任务列表文件 crontab $filepath 查看crontab定时任务 crontab -l 编辑定时任务【删除-添加-修改】 crontab -e 添加定时任务【推荐】Step-One : 编辑任务脚本【分目录存放】【ex: backup.sh】Step-Two : 编辑定时文件【命名规则:backup.cron】Step-Three : crontab命令添加到系统crontab backup.cronStep-Four : 查看crontab列表 crontab -l 5.crontab时间举例规则1234567891011121314151617181920212223242526每一分钟执行一次command（因cron默认每1分钟扫描一次，因此全为*即可）* * * * * command每小时的第3和第15分钟执行command3,15 * * * * command每天上午8-11点的第3和15分钟执行command：3,15 8-11 * * * command每隔2天的上午8-11点的第3和15分钟执行command：3,15 8-11 */2 * * command每个星期一的上午8点到11点的第3和第15分钟执行command3,15 8-11 * * 1 command每晚的21:30重启smb30 21 * * * /etc/init.d/smb restart每月1、10、22日的4 : 45重启smb45 4 1,10,22 * * /etc/init.d/smb restart每周六、周日的1 : 10重启smb10 1 * * 6,0 /etc/init.d/smb restart每天18 : 00至23 : 00之间每隔30分钟重启smb0,30 18-23 * * * /etc/init.d/smb restart每一小时重启smb* */1 * * * /etc/init.d/smb restart晚上11点到早上7点之间，每隔一小时重启smb* 23-7/1 * * * /etc/init.d/smb restart每月的4号与每周一到周三的11点重启smb0 11 4 * mon-wed /etc/init.d/smb restart每小时执行/etc/cron.hourly目录内的脚本0 1 * * * root run-parts /etc/cron.hourly crontab配置实例 举例12345678910111213141516171819202122232425262728293031323334353637383940414243# 每天早上6点 0 6 * * * echo &quot;Good morning.&quot; &gt;&gt; /tmp/test.txt //注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。# 每两个小时 0 */2 * * * echo &quot;Have a break now.&quot; &gt;&gt; /tmp/test.txt # 晚上11点到早上8点之间每两个小时和早上八点 0 23-7/2，8 * * * echo &quot;Have a good dream&quot; &gt;&gt; /tmp/test.txt# 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 11 4 * 1-3 command line# 1月1日早上4点 0 4 1 1 * command line SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root //如果出现错误，或者有数据输出，数据作为邮件发给这个帐号 HOME=/ # 每小时（第一分钟）执行/etc/cron.hourly内的脚本01 * * * * root run-parts /etc/cron.hourly# 每天（凌晨4：02）执行/etc/cron.daily内的脚本02 4 * * * root run-parts /etc/cron.daily # 每星期（周日凌晨4：22）执行/etc/cron.weekly内的脚本22 4 * * 0 root run-parts /etc/cron.weekly # 每月（1号凌晨4：42）去执行/etc/cron.monthly内的脚本 42 4 1 * * root run-parts /etc/cron.monthly # 注意: &quot;run-parts&quot;这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名。 # 每天的下午4点、5点、6点的5 min、15 min、25 min、35 min、45 min、55 min时执行命令。 5，15，25，35，45，55 16，17，18 * * * command# 每周一，三，五的下午3：00系统进入维护状态，重新启动系统。00 15 * *1，3，5 shutdown -r +5# 每小时的10分，40分执行用户目录下的innd/bbslin这个指令： 10，40 * * * * innd/bbslink # 每小时的1分执行用户目录下的bin/account这个指令： 1 * * * * bin/account# 每天早晨三点二十分执行用户目录下如下所示的两个指令（每个指令以;分隔）： 203 * * * （/bin/rm -f expire.ls logins.bad;bin/expire$#@62;expire.1st）","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"Linux日期获取","slug":"language/shell/Linux日期获取","date":"2021-10-18T03:19:29.345Z","updated":"2021-10-18T03:35:26.271Z","comments":true,"path":"2021/10/18/language/shell/Linux日期获取/","link":"","permalink":"https://wuhaocn.github.io/2021/10/18/language/shell/Linux%E6%97%A5%E6%9C%9F%E8%8E%B7%E5%8F%96/","excerpt":"","text":"1.linux获取日期 linux中通过date命令获取昨天或明天时间的方法. date命令可以获取当前的时间，通过man，可以看到date有很多参数可以用，很容易做到格式化 12345date +&quot;%F&quot;输出格式：2011-12-31 date +&quot;%F %H:%M:%S&quot;输出格式：2011-12-31 16:29:50 这都是打印出系统的当前时间，如果要获取相对当前时间的某个时间，需要怎么做，通过 -d 参数就能实现。例如：​ 12345date -d&quot;tomorrow&quot; +&quot;%F %H:%M:%S&quot;输出明天这个时候的时间date -d&quot;yesterday&quot; +&quot;%F %H:%M:%S&quot;输出昨天这个时候的时间 如果说我想获取13天前的时间怎么办，-d参数还有更加灵活的用法，例如： 123456789date -d&quot;-1 day ago&quot; +&quot;%F %H:%M:%S&quot;输出明天这个时候的时间date -d&quot;1 day ago&quot; +&quot;%F %H:%M:%S&quot;输出昨天这个时候的时间date -d&quot;1 week ago&quot; +&quot;%F %H:%M:%S&quot;输出7天前这个时候的时间，等价于date -d&quot;7 day ago&quot; +&quot;%F %H:%M:%S&quot; 可以看到ago的强大了吧，第一个数字可以是负数，负数表示将来时间，正数表示前面已经过去的时间，第二个参数minute、hour、day、month、week。 2.使用实例 定时删除三天前类似”2021_10_18_09”文件 编写shell脚本”clean_tcpdump.sh” 12345678910111213#!/bin/bashdumpfile3=`date -d&quot;3 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile3dumpfile3del=&quot;$dumpfile3*&quot; rm -rf $dumpfile3deldumpfile4=`date -d&quot;4 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile4dumpfile4del=&quot;$dumpfile4*&quot; rm -rf $dumpfile4deldumpfile5=`date -d&quot;5 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile5dumpfile5del=&quot;$dumpfile5*&quot; rm -rf $dumpfile5del 暴力一点部署特别优雅，其实可以用循环 3.参考：https://blog.csdn.net/qq_16885135/article/details/52063477","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"brew常用设置","slug":"tool/mac/brew常用设置","date":"2021-10-15T06:08:00.262Z","updated":"2021-10-15T06:30:00.475Z","comments":true,"path":"2021/10/15/tool/mac/brew常用设置/","link":"","permalink":"https://wuhaocn.github.io/2021/10/15/tool/mac/brew%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"1.brew更新or安装慢 更新ustc.edu源并设置强制更新 1234567891011cd $(brew --repo) git remote set-url origin https://mirrors.ustc.edu.cn/brew.git cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.gitexport HOMEBREW_FORCE_BREWED_GIT=&quot;1&quot; 更新github源并设置强制更新 1234567建议配置ssh快一些cd $(brew --repo)git clone git remote set-url origin git@github.com:Homebrew/brew.gitcd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git remote set-url origin git@github.com:Homebrew/homebrew-core.gitexport HOMEBREW_FORCE_BREWED_GIT=&quot;1&quot; 2.brew重启安装12345678910111213141516171819202122232425261、卸载ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot;2、安装【卸载与安装差别只有最后的install和undeinstall】ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;3、更新brew update 遇到问题：1、raw.githubusercontent.com 链接不到或者访问太慢解决：绑定host199.232.28.133 raw.githubusercontent.com有host修改软件，直接在软件修改即可没有的按照如下方式修改追加sudo vim /etc/hosts在hosts文件最后追加如下，保存退出即可：199.232.28.133 raw.githubusercontent.com 3.常见命令1234567891011121314151617181920安装软件：brew install 软件名，例：brew install wget搜索软件：brew search 软件名，例：brew search wget卸载软件：brew uninstall 软件名，例：brew uninstall wget更新所有软件：brew update更新具体软件：brew upgrade 软件名 ，例：brew upgrade git显示已安装软件：brew list查看软件信息：brew info／home 软件名 ，例：brew info git ／ brew home git显示包依赖：brew reps显示安装的服务：brew services list安装服务启动、停止、重启：brew services start/stop/restart serverName 全部替换国内源1/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot;","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"brew","slug":"brew","permalink":"https://wuhaocn.github.io/tags/brew/"}]},{"title":"docker常用命令","slug":"devops/docker/docker常用命令","date":"2021-10-14T02:20:08.920Z","updated":"2021-10-18T04:11:47.492Z","comments":true,"path":"2021/10/14/devops/docker/docker常用命令/","link":"","permalink":"https://wuhaocn.github.io/2021/10/14/devops/docker/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"组合命令 模糊删除镜像 1docker rmi --force `docker images | grep java | awk &#x27;&#123;print $3&#125;&#x27;` 删除停止容器 1docker rm `docker ps -a -q` 停止/启动容器 12docker start $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2)docker stop $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2) 提交容器 1234567docker commit 81a82e9b5ac2 wuhaocn/java-im:8docker tag wuhaocn/java-im:8 wuhaocn/java-im:8docker push wuhaocn/java-im:8 常用命令容器生命周期管理 run 12运行容器docker run -p 80:80 -v /data:/data -d nginx:latest start/stop/restart 1234启动/停止/重启容器docker start myrunoob kill 1234杀死容器docker kill -s KILL myrunoob rm 1234删除容器docker rm -f myrunoob1 myrunoob2 pause/unpause 12暂停数据库容器myrunoob提供服务docker pause myrunoob create 12使用docker镜像nginx:latest创建一个容器,并将容器命名为myrunoobdocker create --name myrunoob nginx:latest exec 12通过 exec 命令对指定的容器执行 bash:docker exec -it 9df70f9a0714 /bin/bash 容器操作 ps 12345列出容器runoob@runoob:~$ docker psCONTAINER ID IMAGE COMMAND ... PORTS NAMES09b93464c2f7 nginx:latest &quot;nginx -g &#x27;daemon off&quot; ... 80/tcp, 443/tcp myrunoob inspect 12获取镜像mysql:5.6的元信息。docker inspect mysql:5.6 top 1234查看容器mymysql的进程信息。docker top mymysql查看所有运行容器的进程信息。for i in `docker ps |grep Up|awk &#x27;&#123;print $1&#125;&#x27;`;do echo \\ &amp;&amp;docker top $i; done attach 12容器mynginx将访问日志指到标准输出，连接到容器查看访问信息。docker attach --sig-proxy=false mynginx events 1234显示docker 2016年7月1日后的所有事件。docker events --since=&quot;1467302400&quot;显示docker 镜像为mysql:5.6 2016年7月1日后的相关事件。docker events -f &quot;image&quot;=&quot;mysql:5.6&quot; --since=&quot;1467302400&quot; logs 12345跟踪查看容器mynginx的日志输出。docker logs -f mynginx查看容器mynginx从2016年7月1日后的最新10条日志。docker logs --since=&quot;2016-07-01&quot; --tail=10 mynginx wait 1234docker wait : 阻塞运行直到容器停止，然后打印出它的退出代码。docker wait CONTAINER export 12345将id为a404c6c174a2的容器按日期保存为tar文件。runoob@runoob:~$ docker export -o mysql-`date +%Y%m%d`.tar a404c6c174a2runoob@runoob:~$ ls mysql-`date +%Y%m%d`.tarmysql-20160711.tar port 12345查看容器mynginx的端口映射情况。docker port mymysql3306/tcp -&gt; 0.0.0.0:3306 容器rootfs命令 commit 1234将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。docker commit -a &quot;runoob.com&quot; -m &quot;my apache&quot; a404c6c174a2 mymysql:v1简化参考docker commit faa474c052c6 java-sctp:8 cp 123将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。docker cp /www/runoob 96f7f14e99ab:/www/ diff 1234567891011查看容器mymysql的文件结构更改。runoob@runoob:~$ docker diff mymysqlA /logsA /mysql_dataC /runC /run/mysqldA /run/mysqld/mysqld.pidA /run/mysqld/mysqld.sockC /tmp 镜像仓库 login 123登陆到Docker Hubdocker login -u 用户名 -p 密码 pull 123从Docker Hub下载java最新版镜像。docker pull java push 123上传本地镜像myapache:v1到镜像仓库中。docker push myapache:v1 search 1234从 Docker Hub 查找所有镜像名包含 java，并且收藏数大于 10 的镜像docker search -f stars=10 java 本地镜像管理 images 12345查看本地镜像列表。runoob@runoob:~$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmymysql v1 37af1236adef 5 minutes ago 329 MB rmi 1234强制删除本地镜像 runoob/ubuntu:v4。 docker rmi -f runoob/ubuntu:v4Untagged: runoob/ubuntu:v4 tag 123将镜像ubuntu:15.10标记为 runoob/ubuntu:v3 镜像。docker tag ubuntu:15.10 runoob/ubuntu:v3 build 123使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。docker build -t runoob/ubuntu:v1 . history 12345678查看本地镜像runoob/ubuntu:v3的创建历史。root@runoob:~# docker history runoob/ubuntu:v3IMAGE CREATED CREATED BY SIZE COMMENT4e3b13c8a266 3 months ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0 B &lt;missing&gt; 3 months ago /bin/sh -c sed -i &#x27;s/^#\\s*\\(deb.*universe\\)$/ 1.863 kB &lt;missing&gt; 3 months ago /bin/sh -c set -xe &amp;&amp; echo &#x27;#!/bin/sh&#x27; &gt; /u 701 B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) ADD file:43cb048516c6b80f22 136.3 MB save 123456将镜像 runoob/ubuntu:v3 生成 my_ubuntu_v3.tar 文档runoob@runoob:~$ docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3runoob@runoob:~$ ll my_ubuntu_v3.tar-rw------- 1 runoob runoob 142102016 Jul 11 01:37 my_ubuntu_v3.ta load 123导入镜像：$ docker load &lt; busybox.tar.gzLoaded image: busybox:latest import 1234A:export/import 是根据容器来导出镜像（因此没有镜像的历史记录）而 save/load 操作的对象是镜像B:export/import 镜像的历史记录再导后无法进行回滚操作，而save/load镜像有完整的历史记录可以回滚docker import : 从归档文件中创建镜像。docker import my_ubuntu_v3.tar runoob/ubuntu:v4 系统信息 info 12345678910111213141516$ docker infoContainers: 12Images: 41Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 66 Dirperm1 Supported: falseExecution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.13.0-32-genericOperating System: Ubuntu 14.04.1 LTSCPUs: 1Total Memory: 1.954 GiBName: iZ23mtq8bs1ZID: M5N4:K6WN:PUNC:73ZN:AONJ:AUHL:KSYH:2JPI:CH3K:O4MK:6OCX:5OYW version 1234567891011121314151617显示 Docker 版本信息。$ docker versionClient: Version: 1.8.2 API version: 1.20 Go version: go1.4.2 Git commit: 0a8c2e3 Built: Thu Sep 10 19:19:00 UTC 2015 OS/Arch: linux/amd64Server: Version: 1.8.2 API version: 1.20 Go version: go1.4.2 Git commit: 0a8c2e3 Built: Thu Sep 10 19:19:00 UTC 2015 OS/Arch: linux/amd64","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"hexo-配置","slug":"tool/hexo-config","date":"2021-10-01T13:12:11.461Z","updated":"2021-10-01T13:12:11.461Z","comments":true,"path":"2021/10/01/tool/hexo-config/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/tool/hexo-config/","excerpt":"","text":"hexo配置详解，包含分类，归档，标题等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# Sitetitle: #主页标题subtitle: #副标题description: #网站描述description主要用于SEOkeywords: #博客关键字author: #作者，左下角显示language: zh_Hans # 选择中文简体timezone: &#x27;Asia/Shanghai&#x27; #时区:国内选择上海# Urlurl: http://yoursite.com #填自己的github pages网址 root: / #网站根目录permalink: :year/:month/:day/:title/ #文章的 永久链接 格式permalink_defaults: #永久链接中各部分的默认值pretty_urls: #改写 permalink 的值来美化 URLtrailing_index: false # 比如，一个页面的永久链接是 https://wuhaocn.github.io/foo/bar/index.html 是否在 永久链接中保留尾部的 index.html，设置为 false 时去除trailing_html: true #是否在永久链接中保留尾部.html, 设置为 false 时去除# Directorysource_dir: source #资源文件夹，这个文件夹用来存放内容。public_dir: public #公共文件夹，这个文件夹用于存放生成的站点文件。tag_dir: tags #标签文件夹archive_dir: archives #归档文件夹category_dir: categories #分类文件夹code_dir: downloads/code #Include code 文件夹，source_dir 下的子目录i18n_dir: :lang #国际化（i18n）文件夹skip_render: #跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可 使用 glob 表达式来匹配路径。# Writingnew_post_name: :year-:month-:day-:title.md #生成yyyy-MM-dd-博文名称的名称有助于我们管理自己的博 文。 default_layout: post #预设布局titlecase: false #把标题转换为 title caseexternal_link: #在新标签中打开链接 enable: true #在新标签中打开链接 field: site #对整个网站（site）生效或仅对文章（post）生效 exclude: &#x27;&#x27; #需要排除的域名。主域名和子域名如 www 需分别配置filename_case: 0 #把文件名称转换为 (1) 小写或 (2) 大写render_drafts: false #显示草稿post_asset_folder: false #启动 Asset 文件夹 new 文件的同时，xxxx.md文件还有一个同名的文件夹relative_link: false #把链接改为与根目录的相对位址future: true #显示未来的文章highlight: enable: true #开启代码块高亮 line_number: true #显示行数 auto_detect: false #如果未指定语言，则启用自动检测 tab_replace: &#x27;&#x27; #用 n 个空格替换 tabs；如果值为空，则不会替换 tabs wrap: true # 将代码块包装到&lt;table&gt; hljs: false # CSS类使用hljs-*前缀# Home page setting# path: Root path for your blogs index page. (default = &#x27;&#x27;)# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: &#x27;&#x27; per_page: 10 order_by: -date# Category &amp; Tagdefault_category: uncategorized #默认分类category_map: #分类别名tag_map: #标签别名# Metadata elementsmeta_generator: true # Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签# Date / Time format## Hexo uses Moment.js to parse and display date Hexo 使用 Moment.js 来解析和显示时间## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DD #日期格式time_format: HH:mm:ss #时间格式use_date_for_updated: false #启用以后，如果Front Matter中没有指定 updated， post.updated 将会使用date的值而不是文件的创建时间。在Git工作流中这个选项会很有用# Pagination## Set per_page to 0 to disable paginationper_page: 10 #每页显示的文章量 (0 = 关闭分页功能)pagination_dir: page #分页目录# Include / Exclude file(s)## include:/exclude: options only apply to the &#x27;source/&#x27; folderinclude: #Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。exclude: #Hexo 会忽略这些文件和目录ignore: #Ignore files/folders# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus #当前主题名称。值为false时禁用主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: #部署部分的设置 type: git repo: https://github.com/CodePandaes/CodePandaes.github.io.git #github中仓库地址 branch: master","categories":[],"tags":[]},{"title":"AtomicInteger","slug":"language/java/juc/atomic/AtomicInteger","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/AtomicInteger/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/AtomicInteger/","excerpt":"","text":"源码导读AtomicInteger，应该是atomic框架中用得最多的原子类了。顾名思义， AtomicInteger是Integer类型的线程安全原子类，可以在应用程序中以原子的方式更新int值。 采用volatile int value类型原子变量保证内存可见性 采用Unsafe类 compareAndSwapInt方法实现变量值valueOffset的修改 知识参考点：Unsafe类/ volatile 关键字/ CAS 源码参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309/* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */package java.util.concurrent.atomic;import java.util.function.IntUnaryOperator;import java.util.function.IntBinaryOperator;import sun.misc.Unsafe;/** * An &#123;@code int&#125; value that may be updated atomically. See the * &#123;@link java.util.concurrent.atomic&#125; package specification for * description of the properties of atomic variables. An * &#123;@code AtomicInteger&#125; is used in applications such as atomically * incremented counters, and cannot be used as a replacement for an * &#123;@link java.lang.Integer&#125;. However, this class does extend * &#123;@code Number&#125; to allow uniform access by tools and utilities that * deal with numerically-based classes. * * @since 1.5 * @author Doug Lea*/public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new AtomicInteger with the given initial value. * * @param initialValue the initial value */ public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicInteger with initial value &#123;@code 0&#125;. */ public AtomicInteger() &#123; &#125; /** * Gets the current value. * * @return the current value */ public final int get() &#123; return value; &#125; /** * Sets to the given value. * * @param newValue the new value */ public final void set(int newValue) &#123; value = newValue; &#125; /** * Eventually sets to the given value. * * @param newValue the new value * @since 1.6 */ public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; /** * Atomically sets to the given value and returns the old value. * * @param newValue the new value * @return the previous value */ public final int getAndSet(int newValue) &#123; return unsafe.getAndSetInt(this, valueOffset, newValue); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * &lt;p&gt;&lt;a href=&quot;package-summary.html#weakCompareAndSet&quot;&gt;May fail * spuriously and does not provide ordering guarantees&lt;/a&gt;, so is * only rarely an appropriate alternative to &#123;@code compareAndSet&#125;. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful */ public final boolean weakCompareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; /** * Atomically increments by one the current value. * * @return the previous value */ public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125; /** * Atomically decrements by one the current value. * * @return the previous value */ public final int getAndDecrement() &#123; return unsafe.getAndAddInt(this, valueOffset, -1); &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */ public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta); &#125; /** * Atomically increments by one the current value. * * @return the updated value */ public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; /** * Atomically decrements by one the current value. * * @return the updated value */ public final int decrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, -1) - 1; &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the updated value */ public final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the previous value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the previous value * @since 1.8 */ public final int getAndUpdate(IntUnaryOperator updateFunction) &#123; int prev, next; do &#123; prev = get(); next = updateFunction.applyAsInt(prev); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the updated value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the updated value * @since 1.8 */ public final int updateAndGet(IntUnaryOperator updateFunction) &#123; int prev, next; do &#123; prev = get(); next = updateFunction.applyAsInt(prev); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the previous value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the previous value * @since 1.8 */ public final int getAndAccumulate(int x, IntBinaryOperator accumulatorFunction) &#123; int prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsInt(prev, x); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the updated value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the updated value * @since 1.8 */ public final int accumulateAndGet(int x, IntBinaryOperator accumulatorFunction) &#123; int prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsInt(prev, x); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Returns the String representation of the current value. * @return the String representation of the current value */ public String toString() &#123; return Integer.toString(get()); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as an &#123;@code int&#125;. */ public int intValue() &#123; return get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code long&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public long longValue() &#123; return (long)get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code float&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public float floatValue() &#123; return (float)get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code double&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public double doubleValue() &#123; return (double)get(); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"LogAdder","slug":"language/java/juc/atomic/LogAdder","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/LogAdder/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/LogAdder/","excerpt":"","text":"问题（1）java8 中为什么要新增 LongAdder？ （2）LongAdder 的实现方式？ （3）LongAdder 与 AtomicLong 的对比？ 简介LongAdder 是 java8 中新增的原子类，在多线程环境中，它比 AtomicLong 性能要高出不少，特别是写多的场景。 它是怎么实现的呢？让我们一起来学习吧。 原理LongAdder 的原理是，在最初无竞争时，只更新 base 的值，当有多线程竞争时通过分段的思想，让不同的线程更新不同的段，最后把这些段相加就得到了完整的 LongAdder 存储的值。 LongAdder 源码分析LongAdder 继承自 Striped64 抽象类，Striped64 中定义了 Cell 内部类和各重要属性。 主要内部类// Striped64 中的内部类，使用@sun.misc.Contended 注解，说明里面的值消除伪共享 123456789101112131415161718192021222324@sun.misc.Contended static final class Cell &#123; // 存储元素的值，使用volatile修饰保证可见性 volatile long value; Cell(long x) &#123; value = x; &#125; // CAS更新value的值 final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125; // Unsafe实例 private static final sun.misc.Unsafe UNSAFE; // value字段的偏移量 private static final long valueOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; Cell 类使用@sun.misc.Contended 注解，说明是要避免伪共享的。 使用 Unsafe 的 CAS 更新 value 的值，其中 value 的值使用 volatile 修饰，保证可见性。 关于 Unsafe 的介绍请查看【死磕 java 魔法类之 Unsafe 解析】。 关于伪共享的介绍请查看【杂谈 什么是伪共享（false sharing）？】。一篇对伪共享、缓存行填充和 CPU 缓存讲的很透彻的文章 主要属性 12345678// 这三个属性都在Striped64中// cells数组，存储各个段的值transient volatile Cell[] cells;// 最初无竞争时使用的，也算一个特殊的段transient volatile long base;// 标记当前是否有线程在创建或扩容cells，或者在创建Cell// 通过CAS更新该值，相当于是一个锁transient volatile int cellsBusy; 最初无竞争或有其它线程在创建 cells 数组时使用 base 更新值，有过竞争时使用 cells 更新值。最初无竞争是指一开始没有线程之间的竞争，但也有可能是多线程在操作，只是这些线程没有同时去更新 base 的值。有过竞争是指只要出现过竞争不管后面有没有竞争都使用 cells 更新值，规则是不同的线程 hash 到不同的 cell 上去更新，减少竞争。 add(x)方法add(x)方法是 LongAdder 的主要方法，使用它可以使 LongAdder 中存储的值增加 x，x 可为正可为负。 123456789101112131415161718192021222324252627public void add(long x) &#123; // as是Striped64中的cells属性 // b是Striped64中的base属性 // v是当前线程hash到的Cell中存储的值 // m是cells的长度减1，hash时作为掩码使用 // a是当前线程hash到的Cell Cell[] as; long b, v; int m; Cell a; // 条件1：cells不为空，说明出现过竞争，cells已经创建 // 条件2：cas操作base失败，说明其它线程先一步修改了base，正在出现竞争 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; // true表示当前竞争还不激烈 // false表示竞争激烈，多个线程hash到同一个Cell，可能要扩容 boolean uncontended = true; // 条件1：cells为空，说明正在出现竞争，上面是从条件2过来的 // 条件2：应该不会出现 // 条件3：当前线程所在的Cell为空，说明当前线程还没有更新过Cell，应初始化一个Cell // 条件4：更新当前线程所在的Cell失败，说明现在竞争很激烈，多个线程hash到了同一个Cell，应扩容 if (as == null || (m = as.length - 1) &lt; 0 || // getProbe()方法返回的是线程中的threadLocalRandomProbe字段 // 它是通过随机数生成的一个值，对于一个确定的线程这个值是固定的 // 除非刻意修改它 (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 调用Striped64中的方法处理 longAccumulate(x, null, uncontended); &#125;&#125; *（1）最初无竞争时只更新 base； *（2）直到更新 base 失败时，创建 cells 数组； *（3）当多个线程竞争同一个 Cell 比较激烈时，可能要扩容； longAccumulate()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; // 存储线程的probe值 int h; // 如果getProbe()方法返回0，说明随机数未初始化 if ((h = getProbe()) == 0) &#123; // 强制初始化 ThreadLocalRandom.current(); // force initialization // 重新获取probe值 h = getProbe(); // 都未初始化，肯定还不存在竞争激烈 wasUncontended = true; &#125; // 是否发生碰撞 boolean collide = false; // True if last slot nonempty for (;;) &#123; Cell[] as; Cell a; int n; long v; // cells已经初始化过 if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // 当前线程所在的Cell未初始化 if ((a = as[(n - 1) &amp; h]) == null) &#123; // 当前无其它线程在创建或扩容cells，也没有线程在创建Cell if (cellsBusy == 0) &#123; // Try to attach new Cell // 新建一个Cell，值为当前需要增加的值 Cell r = new Cell(x); // Optimistically create // 再次检测cellsBusy，并尝试更新它为1 // 相当于当前线程加锁 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 是否创建成功 boolean created = false; try &#123; // Recheck under lock Cell[] rs; int m, j; // 重新获取cells，并找到当前线程hash到cells数组中的位置 // 这里一定要重新获取cells，因为as并不在锁定范围内 // 有可能已经扩容了，这里要重新获取 if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; // 把上面新建的Cell放在cells的j位置处 rs[j] = r; // 创建成功 created = true; &#125; &#125; finally &#123; // 相当于释放锁 cellsBusy = 0; &#125; // 创建成功了就返回 // 值已经放在新建的Cell里面了 if (created) break; continue; // Slot is now non-empty &#125; &#125; // 标记当前未出现冲突 collide = false; &#125; // 当前线程所在的Cell不为空，且更新失败了 // 这里简单地设为true，相当于简单地自旋一次 // 通过下面的语句修改线程的probe再重新尝试 else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // 再次尝试CAS更新当前线程所在Cell的值，如果成功了就返回 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // 如果cells数组的长度达到了CPU核心数，或者cells扩容了 // 设置collide为false并通过下面的语句修改线程的probe再重新尝试 else if (n &gt;= NCPU || cells != as) collide = false; // At max size or stale // 上上个elseif都更新失败了，且上个条件不成立，说明出现冲突了 else if (!collide) collide = true; // 明确出现冲突了，尝试占有锁，并扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; try &#123; // 检查是否有其它线程已经扩容过了 if (cells == as) &#123; // Expand table unless stale // 新数组为原数组的两倍 Cell[] rs = new Cell[n &lt;&lt; 1]; // 把旧数组元素拷贝到新数组中 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; // 重新赋值cells为新数组 cells = rs; &#125; &#125; finally &#123; // 释放锁 cellsBusy = 0; &#125; // 已解决冲突 collide = false; // 使用扩容后的新数组重新尝试 continue; // Retry with expanded table &#125; // 更新失败或者达到了CPU核心数，重新生成probe，并重试 h = advanceProbe(h); &#125; // 未初始化过cells数组，尝试占有锁并初始化cells数组 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; // 是否初始化成功 boolean init = false; try &#123; // Initialize table // 检测是否有其它线程初始化过 if (cells == as) &#123; // 新建一个大小为2的Cell数组 Cell[] rs = new Cell[2]; // 找到当前线程hash到数组中的位置并创建其对应的Cell rs[h &amp; 1] = new Cell(x); // 赋值给cells数组 cells = rs; // 初始化成功 init = true; &#125; &#125; finally &#123; // 释放锁 cellsBusy = 0; &#125; // 初始化成功直接返回 // 因为增加的值已经同时创建到Cell中了 if (init) break; &#125; // 如果有其它线程在初始化cells数组中，就尝试更新base // 如果成功了就返回 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base &#125;&#125; *（1）如果 cells 数组未初始化，当前线程会尝试占有 cellsBusy 锁并创建 cells 数组； *（2）如果当前线程尝试创建 cells 数组时，发现有其它线程已经在创建了，就尝试更新 base，如果成功就返回； *（3）通过线程的 probe 值找到当前线程应该更新 cells 数组中的哪个 Cell； *（4）如果当前线程所在的 Cell 未初始化，就占有占有 cellsBusy 锁并在相应的位置创建一个 Cell； *（5）尝试 CAS 更新当前线程所在的 Cell，如果成功就返回，如果失败说明出现冲突； *（5）当前线程更新 Cell 失败后并不是立即扩容，而是尝试更新 probe 值后再重试一次； *（6）如果在重试的时候还是更新失败，就扩容； *（7）扩容时当前线程占有 cellsBusy 锁，并把数组容量扩大到两倍，再迁移原 cells 数组中元素到新数组中； *（8）cellsBusy 在创建 cells 数组、创建 Cell、扩容 cells 数组三个地方用到； sum()方法sum()方法是获取 LongAdder 中真正存储的值的大小，通过把 base 和所有段相加得到。 12345678910111213141516public long sum() &#123; Cell[] as = cells; Cell a; // sum初始等于base long sum = base; // 如果cells不为空 if (as != null) &#123; // 遍历所有的Cell for (int i = 0; i &lt; as.length; ++i) &#123; // 如果所在的Cell不为空，就把它的value累加到sum中 if ((a = as[i]) != null) sum += a.value; &#125; &#125; // 返回sum return sum;&#125; 可以看到 sum()方法是把 base 和所有段的值相加得到，那么，这里有一个问题，如果前面已经累加到 sum 上的 Cell 的 value 有修改，不是就没法计算到了么？ 答案确实如此，所以 LongAdder 可以说不是强一致性的，它是最终一致性的。 LongAdder VS AtomicLong直接上代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class LongAdderVSAtomicLongTest &#123; public static void main(String[] args)&#123; testAtomicLongVSLongAdder(1, 10000000); testAtomicLongVSLongAdder(10, 10000000); testAtomicLongVSLongAdder(20, 10000000); testAtomicLongVSLongAdder(40, 10000000); testAtomicLongVSLongAdder(80, 10000000); &#125; static void testAtomicLongVSLongAdder(final int threadCount, final int times)&#123; try &#123; System.out.println(&quot;threadCount：&quot; + threadCount + &quot;, times：&quot; + times); long start = System.currentTimeMillis(); testLongAdder(threadCount, times); System.out.println(&quot;LongAdder elapse：&quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); long start2 = System.currentTimeMillis(); testAtomicLong(threadCount, times); System.out.println(&quot;AtomicLong elapse：&quot; + (System.currentTimeMillis() - start2) + &quot;ms&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static void testAtomicLong(final int threadCount, final int times) throws InterruptedException &#123; AtomicLong atomicLong = new AtomicLong(); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i=0;i&lt;threadCount;i++)&#123; list.add(new Thread(() -&gt; &#123; for (int j = 0; j&lt;times; j++)&#123; atomicLong.incrementAndGet(); &#125; &#125;)); &#125; for (Thread thread : list)&#123; thread.start(); &#125; for (Thread thread : list)&#123; thread.join(); &#125; &#125; static void testLongAdder(final int threadCount, final int times) throws InterruptedException &#123; LongAdder longAdder = new LongAdder(); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i=0;i&lt;threadCount;i++)&#123; list.add(new Thread(() -&gt; &#123; for (int j = 0; j&lt;times; j++)&#123; longAdder.add(1); &#125; &#125;)); &#125; for (Thread thread : list)&#123; thread.start(); &#125; for (Thread thread : list)&#123; thread.join(); &#125; &#125;&#125; 运行结果如下： 123456789101112131415threadCount：1, times：10000000LongAdder elapse：158msAtomicLong elapse：64msthreadCount：10, times：10000000LongAdder elapse：206msAtomicLong elapse：2449msthreadCount：20, times：10000000LongAdder elapse：429msAtomicLong elapse：5142msthreadCount：40, times：10000000LongAdder elapse：840msAtomicLong elapse：10506msthreadCount：80, times：10000000LongAdder elapse：1369msAtomicLong elapse：20482ms 可以看到当只有一个线程的时候，AtomicLong 反而性能更高，随着线程越来越多，AtomicLong 的性能急剧下降，而 LongAdder 的性能影响很小。 总结*（1）LongAdder 通过 base 和 cells 数组来存储值； *（2）不同的线程会 hash 到不同的 cell 上去更新，减少了竞争； *（3）LongAdder 的性能非常高，最终会达到一种无竞争的状态； 在 longAccumulate()方法中有个条件是 n &gt;= NCPU 就不会走到扩容逻辑了，而 n 是 2 的倍数，那是不是代表 cells 数组最大只能达到大于等于 NCPU 的最小 2 次方？答案是明确的。因为同一个 CPU 核心同时只会运行一个线程，而更新失败了说明有两个不同的核心更新了同一个 Cell，这时会重新设置更新失败的那个线程的 probe 值，这样下一次它所在的 Cell 很大概率会发生改变，如果运行的时间足够长，最终会出现同一个核心的所有线程都会 hash 到同一个 Cell（大概率，但不一定全在一个 Cell 上）上去更新，所以，这里 cells 数组中长度并不需要太长，达到 CPU 核心数足够了。比如，笔者的电脑是 8 核的，所以这里 cells 的数组最大只会到 8，达到 8 就不会扩容了。","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"atomic","slug":"language/java/juc/atomic/readme","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.461Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/readme/","excerpt":"","text":"1.简介早期的JDK版本中，如果要并发的对Integer、Long、Double之类的Java原始类型或引用类型进行操作，一般都需要通过锁来控制并发， 以防止数据不一致。JUC-Atomic原子类位于java.util.concurrent.atomic包下。该包提供了许多Java原始/引用类型的映射类。 如AtomicInteger、AtomicLong、AtomicBoolean，这些类可以通过一种“无锁算法”，线程安全的操作Integer、Long、Boolean等原始类型。 包中类分为五种： 基本类型： AtomicBoolean：布尔型原子类 AtomicInteger：整型原子类 AtomicLong：长整型原子类 数组： AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型： AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子类 AtomicMarkableReference：原子更新带有标记位的引用类型 对象的属性： AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater：原子更新带有版本号的引用类型。 该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题 本文不会详细介绍这几种类型的api及使用，只是列出Atomic的实现原理，及比较重点的类 基本类型原子类： AtomicBoolean：布尔型原子类 AtomicInteger：整型原子类 AtomicLong：长整型原子类 这几个类的共同特点是都提供单个变量的原子方式访问和更新功能。以AtomicLong为代表，进行介绍。 2.实例解析 例子：我们使用 AtomicLong 来演示之前的线程不安全的 12345678910111213141516171819202122232425262728293031323334353637383940/** * 并发测试代码 */@ThreadSafepublic class AtomicExample2 &#123; //请求总数 public static int clientTotal = 5000; //同时并发执行的线程数 public static int threadTotal = 200; //变成了AtomicLong类型 public static AtomicLong count = new AtomicLong(0); public static void main(String[] args) throws InterruptedException &#123; //创建线程池 ExecutorService executorService = Executors.newCachedThreadPool(); //定义信号量 final Semaphore semaphore = new Semaphore(threadTotal); //定义计数器 闭锁 final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++) &#123; executorService.execute(() -&gt;&#123; try &#123; semaphore.acquire(); add(); //释放 semaphore.release(); &#125; catch (Exception e) &#123; System.out.println(&quot;exception:&quot;+e.getMessage()); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(&quot;count:&#123;&#125;&quot;+count.get()); &#125; private static void add()&#123; count.incrementAndGet();//先做增加再获取当前值 //count.getAndIncrement();先获取当前值再做增加 &#125;&#125; 解析 当使用AtomicLong去执行自增操作时，得出的最终结果count就是5000。数次运行情况下结果一致。不会带来线程不安全的情况。 那我们来看看AtomicLong是如何保证线程安全的呢。 我们看看incrementAndGet方法，看看AtomicLong如何实现单个变量的原子方式更新。Unsafe是CAS的核心类，AtomicLong是基于CAS实现的。 此处就介绍AtomicLong，AtomicBoolean、AtomicInteger、AtomicReference与之相似，就不一一介绍 12345private static final Unsafe unsafe = Unsafe.getUnsafe();public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;&#125; incrementAndGet 方法实际上是调用 Unsafe 类的方法来执行操作，我们进入 Unsafe 里看看具体的 getAndAddLong 是如何实现原子方式更新的。 1234567public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 我们来解析一下这个方法，var1为当前调用这个方法的对象，var2是当前值，假如执行的2+1=3的操作，那么var4就是1。 var6是调用底层方法获得底层当前值。假设没有其他线程来处理count，那么var6就是var2。此处使用了一个do while循环。 compareAndSwapLong方法是native的，代表是java底层的方法。也是遵循CAS算法的api。compareAndSwap，比较并交换。 在getAndAddLong的while判断中，该方法实现的是：对于var1这个对象，如果当前值var2和底层值var6相同的话，就更新为后面的操作结果值。 当我们执行更新结果时，可能被其他线程修改，因此此处判断当前值与期望值相同时才允许更新。否则重新取出当前的底层值，和当前count的值再做比较。 保证当前值与底层值完全一致时才进行结果更新，以此保证线程安全。这也是Atomic使用CAS原理实现的机制。底层值是主内存中的值，当前值是源自于工作内存。 由于该方法的逻辑是采用自旋的方式不断更新目标值，直到更新成功，在并发量较低的环境下，线程冲突较少，自旋次数不会很多。 但是在高并发情况下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时的AtomicLong的自旋会成为瓶颈， 因此为了解决高并发环境下的AtomicLong的自旋瓶颈问题，引入了LongAdder。 LongAdder： AtomicLong 中有个内部变量 value 保存着实际的 long 值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value 变量其实是一个热点，也就是 N 个线程竞争一个热点。LongAdder 的基本思路就是分散热点，将 value 值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行 CAS 操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的 long 值，只要将各个槽中的变量值累加返回。 低并发、一般的业务场景下 AtomicLong 是足够了。如果并发量很多，存在大量写多读少的情况，那 LongAdder 可能更合适。 AtomicBoolean： 针对该类我们主要研究 compareAndSet 函数 12345public final boolean compareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u);&#125; 该函数实现的功能是高并发情况下只有一个线程能访问这个属性值，常用于初始化一次的功能中。 12345678private static AtomicBoolean initialized = new AtomicBoolean(false); public void init() &#123; if( initialized.compareAndSet(false, true) )//如果为false，更新为true &#123; // 初始化操作代码.... &#125; &#125; 各原子类api及使用demo，可以参考：https://github.com/Snailclimb/JavaGuide/blob/master/Java%E7%9B%B8%E5%85%B3/Multithread/Atomic.md 主要是掌握CAS算法的设计思想，了解原子类如何保证原子操作。 参考https://www.cnblogs.com/zhangbLearn/p/9922790.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"深入理解单例模式:静态内部类单例","slug":"language/java/design/深入理解单例模式-静态内部类单例原理","date":"2021-10-01T13:12:11.459Z","updated":"2021-10-01T13:12:11.459Z","comments":true,"path":"2021/10/01/language/java/design/深入理解单例模式-静态内部类单例原理/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/design/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F-%E9%9D%99%E6%80%81%E5%86%85%E9%83%A8%E7%B1%BB%E5%8D%95%E4%BE%8B%E5%8E%9F%E7%90%86/","excerpt":"","text":"深入理解单例模式：静态内部类单例原理本文主要介绍 java 的单例模式，以及详细剖析静态内部类之所以能够实现单例的原理。OK，废话不多说，进入正文。 1.单例原则首先我们要先了解下单例的四大原则： 1.构造私有。 2.以静态方法或者枚举返回实例。 3.确保实例只有一个，尤其是多线程环境。 4.确保反序列换时不会重新构建对象。 2.常用的单例模式：饿汉模式、懒汉模式、双重锁懒汉模式、静态内部类模式、枚举模式，我们来逐一分析下这些模式的区别。 2.1.饿汉模式：饿汉模式在类被初始化时就已经在内存中创建了对象，以空间换时间，故不存在线程安全问题。参考如下： 1234567public class SingleTon&#123; private static SingleTon INSTANCE = new SingleTon(); private SingleTon()&#123;&#125; public static SingleTon getInstance()&#123; return INSTANCE; &#125;&#125; 2.2.懒汉模式：懒汉模式在方法被调用后才创建对象，以时间换空间，在多线程环境下存在风险。参考如下 12345678910public class SingleTon&#123; private static SingleTon INSTANCE = null; private SingleTon()&#123;&#125; public static SingleTon getInstance() &#123; if(INSTANCE == null)&#123; INSTANCE = new SingleTon(); &#125; return INSTANCE； &#125;&#125; 2.3.双重锁懒汉模式(Double Check Lock)DCL 模式的优点就是，只有在对象需要被使用时才创建，第一次判断 INSTANCE == null 为了避免非必要加锁，当第一次加载时才对实例进行加锁再实例化。这样既可以节约内存空间，又可以保证线程安全。但是，由于 jvm 存在乱序执行功能，DCL 也会出现线程不安全的情况。具体分析如下： 123456789101112public class SingleTon&#123; private static SingleTon INSTANCE = null; private SingleTon()&#123;&#125; public static SingleTon getInstance()&#123;if(INSTANCE == null)&#123; synchronized(SingleTon.class)&#123; if(INSTANCE == null)&#123; INSTANCE = new SingleTon(); &#125; &#125; return INSTANCE; &#125;&#125; INSTANCE = new SingleTon();这个步骤，其实在 jvm 里面的执行分为三步： 1.在堆内存开辟内存空间。 2.在堆内存中实例化 SingleTon 里面的各个参数。 3.把对象指向堆内存空间。 由于 jvm 存在乱序执行功能，所以可能在 2 还没执行时就先执行了 3，如果此时再被切换到线程 B 上，由于执行了 3，INSTANCE 已经非空了，会被直接拿出来用，这样的话，就会出现异常。这个就是著名的 DCL 失效问题。 不过在 JDK1.5 之后，官方也发现了这个问题，故而具体化了 volatile，即在 JDK1.6 及以后，只要定义为 1private volatile static SingleTon INSTANCE = null; 就可解决 DCL 失效问题。volatile 确保 INSTANCE 每次均在主内存中读取，这样虽然会牺牲一点效率，但也无伤大雅。 2.4.静态内部类模式：静态内部类的优点是：外部类加载时并不需要立即加载内部类，内部类不被加载则不去初始化 INSTANCE，故而不占内存。即当 SingleTon 第一次被加载时，并不需要去加载 SingleTonHoler，只有当 getInstance()方法第一次被调用时，才会去初始化 INSTANCE,第一次调用 getInstance()方法会导致虚拟机加载 SingleTonHoler 类，这种方法不仅能确保线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。 1234567891011public class SingleTon&#123; private SingleTon()&#123;&#125; private static class SingleTonHoler&#123; private static SingleTon INSTANCE = new SingleTon(); &#125; public static SingleTon getInstance()&#123; return SingleTonHoler.INSTANCE; &#125;&#125; 那么，静态内部类又是如何实现线程安全的呢？首先，我们先了解下类的加载时机。类加载时机：JAVA 虚拟机在有且仅有的 5 种场景下会对类进行初始化。 1.遇到 new、getstatic、setstatic 或者 invokestatic 这 4 个字节码指令时，对应的 java 代码场景为：new 一个关键字或者一个实例化对象时、读取或设置一个静态字段时(final 修饰、已在编译期把结果放入常量池的除外)、调用一个类的静态方法时。 2.使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没进行初始化，需要先调用其初始化方法进行初始化。 3.当初始化一个类时，如果其父类还未进行初始化，会先触发其父类的初始化。 4.当虚拟机启动时，用户需要指定一个要执行的主类(包含 main()方法的类)，虚拟机会先初始化这个类。 5.当使用 JDK 1.7 等动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 这 5 种情况被称为是类的主动引用，注意，这里《虚拟机规范》中使用的限定词是”有且仅有”，那么，除此之外的所有引用类都不会对类进行初始化，称为被动引用。静态内部类就属于被动引用的行列。 我们再回头看下 getInstance()方法，调用的是 SingleTonHoler.INSTANCE，取的是 SingleTonHoler 里的 INSTANCE 对象，跟上面那个 DCL 方法不同的是，getInstance()方法并没有多次去 new 对象，故不管多少个线程去调用 getInstance()方法，取的都是同一个 INSTANCE 对象，而不用去重新创建。当 getInstance()方法被调用时，SingleTonHoler 才在 SingleTon 的运行时常量池里，把符号引用替换为直接引用，这时静态对象 INSTANCE 也真正被创建，然后再被 getInstance()方法返回出去，这点同饿汉模式。那么 INSTANCE 在创建过程中又是如何保证线程安全的呢？在《深入理解 JAVA 虚拟机》中，有这么一句话: 虚拟机会保证一个类的()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作，就可能造成多个进程阻塞(需要注意的是，其他线程虽然会被阻塞，但如果执行()方法后，其他线程唤醒之后不会再次进入()方法。同一个加载器下，一个类型只会初始化一次。)，在实际应用中，这种阻塞往往是很隐蔽的。 故而，可以看出 INSTANCE 在创建过程中是线程安全的，所以说静态内部类形式的单例可保证线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。 那么，是不是可以说静态内部类单例就是最完美的单例模式了呢？其实不然，静态内部类也有着一个致命的缺点，就是传参的问题，由于是静态内部类的形式去创建单例的，故外部无法传递参数进去，例如 Context 这种参数，所以，我们创建单例时，可以在静态内部类与 DCL 模式里自己斟酌。 2.5.枚举类型单例模式1234567//枚举单例：public enum SingleTon&#123; INSTANCE; public void method()&#123; //TODO &#125;&#125; 枚举在 java 中与普通类一样，都能拥有字段与方法，而且枚举实例创建是线程安全的，在任何情况下，它都是一个单例。我们可直接以SingleTon.INSTANCE 的方式调用。 参考https://blog.csdn.net/mnb65482/article/details/80458571《深入理解 JAVA 虚拟机》《Android 源码设计模式解析与实战》《java 虚拟机规范》","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"design","slug":"design","permalink":"https://wuhaocn.github.io/tags/design/"}]},{"title":"AtomicBoolean","slug":"language/java/juc/atomic/AtomicBoolean","date":"2021-10-01T13:12:11.459Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/AtomicBoolean/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/AtomicBoolean/","excerpt":"","text":"源码导读java.util.concurrent.atomic.AtomicBoolean类提供了可以原子读取和写入的底层布尔值的操作，并且还包含高级原子操作。 AtomicBoolean支持基础布尔变量上的原子操作。 它具有获取和设置方法，如在volatile变量上的读取和写入。 也就是说，一个集合与同一变量上的任何后续get相关联。 原子compareAndSet方法也具有这些内存一致性功能。 一般情况下，我们使用 AtomicBoolean 高效并发处理 “只初始化一次” 的功能要求 采用volatile int value类型原子变量保证内存可见性 采用Unsafe类 compareAndSwapInt方法实现变量值valueOffset的修改 知识参考点：Unsafe类/ volatile 关键字/ CAS 源码参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package java.util.concurrent.atomic;import sun.misc.Unsafe;/** * A &#123;@code boolean&#125; value that may be updated atomically. See the * &#123;@link java.util.concurrent.atomic&#125; package specification for * description of the properties of atomic variables. An * &#123;@code AtomicBoolean&#125; is used in applications such as atomically * updated flags, and cannot be used as a replacement for a * &#123;@link java.lang.Boolean&#125;. * * @since 1.5 * @author Doug Lea */public class AtomicBoolean implements java.io.Serializable &#123; private static final long serialVersionUID = 4654671469794556979L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicBoolean.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new &#123;@code AtomicBoolean&#125; with the given initial value. * * @param initialValue the initial value */ public AtomicBoolean(boolean initialValue) &#123; value = initialValue ? 1 : 0; &#125; /** * Creates a new &#123;@code AtomicBoolean&#125; with initial value &#123;@code false&#125;. */ public AtomicBoolean() &#123; &#125; /** * Returns the current value. * * @return the current value */ public final boolean get() &#123; return value != 0; &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * &lt;p&gt;&lt;a href=&quot;package-summary.html#weakCompareAndSet&quot;&gt;May fail * spuriously and does not provide ordering guarantees&lt;/a&gt;, so is * only rarely an appropriate alternative to &#123;@code compareAndSet&#125;. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful */ public boolean weakCompareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u); &#125; /** * Unconditionally sets to the given value. * * @param newValue the new value */ public final void set(boolean newValue) &#123; value = newValue ? 1 : 0; &#125; /** * Eventually sets to the given value. * * @param newValue the new value * @since 1.6 */ public final void lazySet(boolean newValue) &#123; int v = newValue ? 1 : 0; unsafe.putOrderedInt(this, valueOffset, v); &#125; /** * Atomically sets to the given value and returns the previous value. * * @param newValue the new value * @return the previous value */ public final boolean getAndSet(boolean newValue) &#123; boolean prev; do &#123; prev = get(); &#125; while (!compareAndSet(prev, newValue)); return prev; &#125; /** * Returns the String representation of the current value. * @return the String representation of the current value */ public String toString() &#123; return Boolean.toString(get()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"分布式算法-raft","slug":"algorithm/分布式算法/分布式raft算法","date":"2021-10-01T13:12:11.458Z","updated":"2021-10-01T13:12:11.458Z","comments":true,"path":"2021/10/01/algorithm/分布式算法/分布式raft算法/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8Fraft%E7%AE%97%E6%B3%95/","excerpt":"","text":"raft算法介绍 Raft 算法一、更加直观的 Raft 算法Raft 适用于一个管理日志一致性的协议，相比于 Paxos 协议 Raft 更易于理解和去实现它。为了提高理解性，Raft 将一致性算法分为了几个部分，包括领导选取（leader selection）、日志复制（log replication）、安全（safety），并且使用了更强的一致性来减少了必须需要考虑的状态。 1.解决什么问题分布式存储系统通常通过维护多个副本来提高系统的 availability，带来的代价就是分布式存储系统的核心问题之一：维护多个副本的一致性。 Raft 协议基于复制状态机（replicated state machine），即一组 server 从相同的初始状态起，按相同的顺序执行相同的命令，最终会达到一直的状态，一组 server 记录相同的操作日志，并以相同的顺序应用到状态机。 Raft 有一个明确的场景，就是管理复制日志的一致性。 如图，每台机器保存一份日志，日志来自于客户端的请求，包含一系列的命令，状态机会按顺序执行这些命令。一致性算法管理来自客户端状态命令的复制日志，保证状态机处理的日志中的命令的顺序都是一致的，因此会得到相同的执行结果。 2.Raft 概览先看一段动画演示，Understandable Distributed Consensus 。 相比 Paxos，Raft 算法理解起来直观的很。 Raft 算法将 Server 划分为 3 种状态，或者也可以称作角色： Leader 负责 Client 交互和 log 复制，同一时刻系统中最多存在 1 个。 Follower 被动响应请求 RPC，从不主动发起请求 RPC。 Candidate 一种临时的角色，只存在于 leader 的选举阶段，某个节点想要变成 leader，那么就发起投票请求，同时自己变成 candidate。如果选举成功，则变为 candidate，否则退回为 follower 状态或者说角色的流转如下： 在 Raft 中，问题分解为：领导选取、日志复制、安全和成员变化。 复制状态机通过复制日志来实现： 日志：每台机器保存一份日志，日志来自于客户端的请求，包含一系列的命令 状态机：状态机会按顺序执行这些命令 一致性模型：分布式环境下，保证多机的日志是一致的，这样回放到状态机中的状态是一致的 二、Raft 算法流程Raft 中使用心跳机制来出发 leader 选举。当服务器启动的时候，服务器成为 follower。只要 follower 从 leader 或者 candidate 收到有效的 RPCs 就会保持 follower 状态。如果 follower 在一段时间内（该段时间被称为 election timeout）没有收到消息，则它会假设当前没有可用的 leader，然后开启选举新 leader 的流程。 1.TermTerm 的概念类比中国历史上的朝代更替，Raft 算法将时间划分成为任意不同长度的任期（term）。 任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最多只有一个领导人。 2.RPCRaft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs，为了在服务器之间传输快照增加了第三种 RPC。 RPC 有三种： RequestVote RPC：候选人在选举期间发起 AppendEntries RPC：领导人发起的一种心跳机制，复制日志也在该命令中完成 InstallSnapshot RPC: 领导者使用该 RPC 来发送快照给太落后的追随者 3.选举流程（1）follower 增加当前的 term，转变为 candidate。（2）candidate 投票给自己，并发送 RequestVote RPC 给集群中的其他服务器。（3）收到 RequestVote 的服务器，在同一 term 中只会按照先到先得投票给至多一个 candidate。且只会投票给 log 至少和自身一样新的 candidate。 candidate 节点保持（2）的状态，直到下面三种情况中的一种发生。 该节点赢得选举。即收到大多数的节点的投票。则其转变为 leader 状态。 另一个服务器成为了 leader。即收到了 leader 的合法心跳包（term 值等于或大于当前自身 term 值）。则其转变为 follower 状态。 一段时间后依然没有胜者。该种情况下会开启新一轮的选举。 Raft 中使用随机选举超时时间来解决当票数相同无法确定 leader 的问题。 4.日志复制日志复制（Log Replication）主要作用是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性。 当 Leader 选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过 Leader 处理，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作。 在 Raft 中当接收到客户端的日志（事务请求）后先把该日志追加到本地的 Log 中，然后通过 heartbeat 把该 Entry 同步给其他 Follower，Follower 接收到日志后记录日志然后向 Leader 发送 ACK，当 Leader 收到大多数（n/2+1）Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。 三、Raft 和 Paxos 的工程应用Raft 算法的论文相比 Paxos 直观很多，更容易在工程上实现。 可以看到 Raft 算法的实现已经非常多了，https://raft.github.io//#implementations 1.Raft 的应用这里用 ETCD 来关注 Raft 的应用，ETCD 目标是构建一个高可用的分布式键值（key-value）数据库，基于 Go 语言实现。Etcd 主要用途是共享配置和服务发现，实现一致性使用了 Raft 算法。更多 Etcd 的应用可以查看文档：https://coreos.com/etcd/docs/latest/ 2.Zookeeper 中的 PaxosZookeeper 使用了一种修改后的 Paxos 协议。 在 Zookeeper 中，始终分为两种场景: Leader activation 在这个场景里，系统中缺乏 Leader(primary)，通过一个类似 paxos 协议的过程完成 Leader 选举。 Active messaging在 这个场景里，Leader 接收客户端发送的更新操作，以一种类似两阶段提交的过程在各个 follower (secondary)节点上进行更新操作。 在 Leader activation 场景中完成 leader 选举及数据同步后，系统转入 Active messaging 场景，在 active messaging 中 leader 异常后，系统转入 Leader activation 场景。 无论在那种场景，Zookeeper 依赖于一个全局版本号:zxid。zxid 由(epoch, count)两部分组成， 高位的 epoch 部分是选举编号，每次提议进行新的 leader 选举时 epoch 都会增加，低位的 count 部分 是 leader 为每个更新操作决定的序号。可以认为，一个 leader 对应一个唯一的 epoch，每个 leader 任期内产生的更新操作对应一个唯一的有序的 count，从而从全局的视野，一个 zxid 代表了一个更新操作的全局序号(版本号)。 Zookeeper 通过 zxid 将两个场景阶段较好的结合起来，且能保证全局的强一致性。由于同一时刻只有一个 zookeeper 节点能获得超过半数的 follower，所以同一时刻最多只存在唯一的 leader;每个 leader 利用 FIFO 以 zxid 顺序更新各个 follower，只有成功完成前一个更新操作的才会进行下一个更新操作，在同一个 leader 任期内，数据在全局满足 quorum 约束的强一致，即读超过半数的节点 一定可以读到最新已提交的数据;每个成功的更新操作都至少被超过半数的节点确认，使得新选举 的 leader 一定可以包括最新的已成功提交的数据。 3.如何解决 split brain 问题分布式协议一个著名问题就是 split brain 问题。 简单说，就是比如当你的 cluster 里面有两个结点，它们都知道在这个 cluster 里需要选举出一个 master。那么当它们两之间的通信完全没有问题的时候，就会达成共识，选出其中一个作为 master。但是如果它们之间的通信出了问题，那么两个结点都会觉得现在没有 master，所以每个都把自己选举成 master。于是 cluster 里面就会有两个 master。 区块链的分叉其实类似分布式系统的 split brain。 一般来说，Zookeeper 会默认设置： zookeeper cluster 的节点数目必须是奇数。 zookeeper 集群中必须超过半数节点(Majority)可用，整个集群才能对外可用。 Majority 就是一种 Qunroms 的方式来支持 Leader 选举，可以防止 split brain 出现。奇数个节点可以在相同容错能力的情况下节省资源。 四、从 CAP 的角度理解几种不同的算法1.两阶段提交协议两阶段提交系统具有完全的 C，很糟糕的 A，很糟糕的 P。首先，两阶段提交协议保证了副本间是完全一致的，这也是协议的设计目的。再者，协议在一个节点出现异常时，就无法更新数据，其服务可用性较低。最后，一旦协调者与参与者之间网络分化，无法提供服务。 2.Paxos 和 Raft 算法Paxos 协议和 Raft 算法都是强一致性协议。Paxos 只有两种情况下服务不可用:一是超过半数的 Proposer 异常，二是出现活锁。前者可以通过增加 Proposer 的个数来 降低由于 Proposer 异常影响服务的概率，后者本身发生的概率就极低。最后，只要能与超过半数的 Proposer 通信就可以完成协议流程，协议本身具有较好的容忍网络分区的能力。 参考Raft 一致性算法Raft 一致性算法论文译文","categories":[],"tags":[]},{"title":"Java动态调试技术原理及实践","slug":"language/java/bytecode/Java动态调试技术原理及实践","date":"2021-10-01T13:12:11.458Z","updated":"2021-10-01T13:12:11.459Z","comments":true,"path":"2021/10/01/language/java/bytecode/Java动态调试技术原理及实践/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/bytecode/Java%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"Java动态调试技术原理及实践1. 动态调试要解决的问题断点调试是我们最常使用的调试手段，它可以获取到方法执行过程中的变量信息，并可以观察到方法的执行路径。但断点调试会在断点位置停顿，使得整个应用停止响应。在线上停顿应用是致命的，动态调试技术给了我们创造新的调试模式的想象空间。本文将研究 Java 语言中的动态调试技术，首先概括 Java 动态调试所涉及的技术基础，接着介绍我们在 Java 动态调试领域的思考及实践，通过结合实际业务场景，设计并实现了一种具备动态性的断点调试工具 Java-debug-tool，显著提高了故障排查效率。 2. Java Agent 技术JVMTI （JVM Tool Interface）是 Java 虚拟机对外提供的 Native 编程接口，通过 JVMTI，外部进程可以获取到运行时 JVM 的诸多信息，比如线程、GC 等。Agent 是一个运行在目标 JVM 的特定程序，它的职责是负责从目标 JVM 中获取数据，然后将数据传递给外部进程。加载 Agent 的时机可以是目标 JVM 启动之时，也可以是在目标 JVM 运行时进行加载，而在目标 JVM 运行时进行 Agent 加载具备动态性，对于时机未知的 Debug 场景来说非常实用。下面将详细分析 Java Agent 技术的实现细节。 2.1 Agent 的实现模式JVMTI 是一套 Native 接口，在 Java SE 5 之前，要实现一个 Agent 只能通过编写 Native 代码来实现。从 Java SE 5 开始，可以使用 Java 的 Instrumentation 接口（java.lang.instrument）来编写 Agent。无论是通过 Native 的方式还是通过 Java Instrumentation 接口的方式来编写 Agent，它们的工作都是借助 JVMTI 来进行完成，下面介绍通过 Java Instrumentation 接口编写 Agent 的方法。 2.1.1 通过 Java Instrumentation API实现 Agent 启动方法 Java Agent 支持目标 JVM 启动时加载，也支持在目标 JVM 运行时加载，这两种不同的加载模式会使用不同的入口函数，如果需要在目标 JVM 启动的同时加载 Agent，那么可以选择实现下面的方法： 12[1] public static void premain(String agentArgs, Instrumentation inst);[2] public static void premain(String agentArgs); JVM 将首先寻找[1]，如果没有发现[1]，再寻找[2]。如果希望在目标 JVM 运行时加载 Agent，则需要实现下面的方法： 12[1] public static void agentmain(String agentArgs, Instrumentation inst);[2] public static void agentmain(String agentArgs); 这两组方法的第一个参数 AgentArgs 是随同 “– javaagent”一起传入的程序参数，如果这个字符串代表了多个参数，就需要自己解析这些参数。inst 是 Instrumentation 类型的对象，是 JVM 自动传入的，我们可以拿这个参数进行类增强等操作。 指定 Main-ClassAgent 需要打包成一个 jar 包，在 ManiFest 属性中指定“Premain-Class”或者“Agent-Class”：Premain-Class: classAgent-Class: class挂载到目标 JVM将编写的 Agent 打成 jar 包后，就可以挂载到目标 JVM 上去了。如果选择在目标 JVM 启动时加载 Agent，则可以使用 “-javaagent:[=]”，具体的使用方法可以使用“Java -Help”来查看。如果想要在运行时挂载 Agent 到目标 JVM，就需要做一些额外的开发了。com.sun.tools.attach.VirtualMachine 这个类代表一个 JVM 抽象，可以通过这个类找到目标 JVM，并且将 Agent 挂载到目标 JVM 上。下面是使用 com.sun.tools.attach.VirtualMachine 进行动态挂载 Agent 的一般实现： 12345678910111213141516171819202122private void attachAgentToTargetJVM() throws Exception &#123; List&lt;VirtualMachineDescriptor&gt; virtualMachineDescriptors = VirtualMachine.list(); VirtualMachineDescriptor targetVM = null; for (VirtualMachineDescriptor descriptor : virtualMachineDescriptors) &#123; if (descriptor.id().equals(configure.getPid())) &#123; targetVM = descriptor; break; &#125; &#125; if (targetVM == null) &#123; throw new IllegalArgumentException(&quot;could not find the target jvm by process id:&quot; + configure.getPid()); &#125; VirtualMachine virtualMachine = null; try &#123; virtualMachine = VirtualMachine.attach(targetVM); virtualMachine.loadAgent(&quot;&#123;agent&#125;&quot;, &quot;&#123;params&#125;&quot;); &#125; catch (Exception e) &#123; if (virtualMachine != null) &#123; virtualMachine.detach(); &#125; &#125;&#125; 首先通过指定的进程 ID 找到目标 JVM，然后通过 Attach 挂载到目标 JVM 上，执行加载 Agent 操作。VirtualMachine 的 Attach 方法就是用来将 Agent 挂载到目标 JVM 上去的，而 Detach 则是将 Agent 从目标 JVM 卸载。关于 Agent 是如何挂载到目标 JVM 上的具体技术细节，将在下文中进行分析。 2.2 启动时加载 Agent2.2.1 参数解析创建 JVM 时，JVM 会进行参数解析，即解析那些用来配置 JVM 启动的参数，比如堆大小、GC 等；本文主要关注解析的参数为-agentlib、 -agentpath、 -javaagent，这几个参数用来指定 Agent，JVM 会根据这几个参数加载 Agent。下面来分析一下 JVM 是如何解析这几个参数的。 12345678910111213141516171819202122232425262728293031323334353637383940// -agentlib and -agentpathif (match_option(option, &quot;-agentlib:&quot;, &amp;tail) || (is_absolute_path = match_option(option, &quot;-agentpath:&quot;, &amp;tail))) &#123; if(tail != NULL) &#123; const char* pos = strchr(tail, &#x27;=&#x27;); size_t len = (pos == NULL) ? strlen(tail) : pos - tail; char* name = strncpy(NEW_C_HEAP_ARRAY(char, len + 1, mtArguments), tail, len); name[len] = &#x27;\\0&#x27;; char *options = NULL; if(pos != NULL) &#123; options = os::strdup_check_oom(pos + 1, mtArguments); &#125; #if !INCLUDE_JVMTI if (valid_jdwp_agent(name, is_absolute_path)) &#123; jio_fprintf(defaultStream::error_stream(), &quot;Debugging agents are not supported in this VM\\n&quot;); return JNI_ERR; &#125; #endif // !INCLUDE_JVMTI add_init_agent(name, options, is_absolute_path); &#125; // -javaagent &#125; else if (match_option(option, &quot;-javaagent:&quot;, &amp;tail)) &#123; #if !INCLUDE_JVMTI jio_fprintf(defaultStream::error_stream(), &quot;Instrumentation agents are not supported in this VM\\n&quot;); return JNI_ERR; #else if (tail != NULL) &#123; size_t length = strlen(tail) + 1; char *options = NEW_C_HEAP_ARRAY(char, length, mtArguments); jio_snprintf(options, length, &quot;%s&quot;, tail); add_init_agent(&quot;instrument&quot;, options, false); // java agents need module java.instrument if (!create_numbered_property(&quot;jdk.module.addmods&quot;, &quot;java.instrument&quot;, addmods_count++)) &#123; return JNI_ENOMEM; &#125; &#125; #endif // !INCLUDE_JVMTI &#125; 上面的代码片段截取自 hotspot/src/share/vm/runtime/arguments.cpp 中的 Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, Flag::Flags origin) 函数，该函数用来解析一个具体的 JVM 参数。这段代码的主要功能是解析出需要加载的 Agent 路径，然后调用 add_init_agent 函数进行解析结果的存储。下面先看一下 add_init_agent 函数的具体实现： 1234// -agentlib and -agentpath argumentsstatic AgentLibraryList _agentList;static void add_init_agent(const char* name, char* options, bool absolute_path) &#123; _agentList.add(new AgentLibrary(name, options, absolute_path, NULL)); &#125; AgentLibraryList 是一个简单的链表结构，add_init_agent 函数将解析好的、需要加载的 Agent 添加到这个链表中，等待后续的处理。 这里需要注意，解析-javaagent 参数有一些特别之处，这个参数用来指定一个我们通过 Java Instrumentation API 来编写的 Agent，Java Instrumentation API 底层依赖的是 JVMTI，对-JavaAgent 的处理也说明了这一点，在调用 add_init_agent 函数时第一个参数是“instrument”，关于加载 Agent 这个问题在下一小节进行展开。到此，我们知道在启动 JVM 时指定的 Agent 已经被 JVM 解析完存放在了一个链表结构中。下面来分析一下 JVM 是如何加载这些 Agent 的。 2.2.2 执行加载操作在创建 JVM 进程的函数中，解析完 JVM 参数之后，下面的这段代码和加载 Agent 相关： 1234567 // Launch -agentlib/-agentpath and converted -Xrun agentsif (Arguments::init_agents_at_startup()) &#123; create_vm_init_agents();&#125;static bool init_agents_at_startup() &#123; return !_agentList.is_empty();&#125; 当 JVM 判断出上一小节中解析出来的 Agent 不为空的时候，就要去调用函数 create_vm_init_agents 来加载 Agent，下面来分析一下 create_vm_init_agents 函数是如何加载 Agent 的。 12345678910void Threads::create_vm_init_agents() &#123; AgentLibrary* agent; for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) &#123; OnLoadEntry_t on_load_entry = lookup_agent_on_load(agent); if (on_load_entry != NULL) &#123; // Invoke the Agent_OnLoad function jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL); &#125; &#125;&#125; create_vm_init_agents 这个函数通过遍历 Agent 链表来逐个加载 Agent。通过这段代码可以看出，首先通过 lookup_agent_on_load 来加载 Agent 并且找到 Agent_OnLoad 函数，这个函数是 Agent 的入口函数。如果没找到这个函数，则认为是加载了一个不合法的 Agent，则什么也不做，否则调用这个函数，这样 Agent 的代码就开始执行起来了。对于使用 Java Instrumentation API 来编写 Agent 的方式来说，在解析阶段观察到在 add_init_agent 函数里面传递进去的是一个叫做”instrument”的字符串，其实这是一个动态链接库。在 Linux 里面，这个库叫做 libinstrument.so，在 BSD 系统中叫做 libinstrument.dylib，该动态链接库在{JAVA_HOME}/jre/lib/目录下。 2.2.3 Instrument 动态链接库libinstrument 用来支持使用 Java Instrumentation API 来编写 Agent，在 libinstrument 中有一个非常重要的类称为：JPLISAgent（Java Programming Language Instrumentation Services Agent），它的作用是初始化所有通过 Java Instrumentation API 编写的 Agent，并且也承担着通过 JVMTI 实现 Java Instrumentation 中暴露 API 的责任。我们已经知道，在 JVM 启动的时候，JVM 会通过-javaagent 参数加载 Agent。最开始加载的是 libinstrument 动态链接库，然后在动态链接库里面找到 JVMTI 的入口方法：Agent_OnLoad。下面就来分析一下在 libinstrument 动态链接库中，Agent_OnLoad 函数是怎么实现的。 1234567891011121314151617181920212223JNIEXPORT jint JNICALLDEF_Agent_OnLoad(JavaVM *vm, char *tail, void * reserved) &#123; initerror = createNewJPLISAgent(vm, &amp;agent); if ( initerror == JPLIS_INIT_ERROR_NONE ) &#123; if (parseArgumentTail(tail, &amp;jarfile, &amp;options) != 0) &#123; fprintf(stderr, &quot;-javaagent: memory allocation failure.\\n&quot;); return JNI_ERR; &#125; attributes = readAttributes(jarfile); premainClass = getAttribute(attributes, &quot;Premain-Class&quot;); /* Save the jarfile name */ agent-&gt;mJarfile = jarfile; /* * Convert JAR attributes into agent capabilities */ convertCapabilityAttributes(attributes, agent); /* * Track (record) the agent class name and options data */ initerror = recordCommandLineData(agent, premainClass, options); &#125; return result;&#125; 上述代码片段是经过精简的 libinstrument 中 Agent_OnLoad 实现的，大概的流程就是：先创建一个 JPLISAgent，然后将 ManiFest 中设定的一些参数解析出来， 比如（Premain-Class）等。创建了 JPLISAgent 之后，调用 initializeJPLISAgent 对这个 Agent 进行初始化操作。跟进 initializeJPLISAgent 看一下是如何初始化的： 1234567891011121314151617JPLISInitializationError initializeJPLISAgent(JPLISAgent *agent, JavaVM *vm, jvmtiEnv *jvmtienv) &#123; /* check what capabilities are available */ checkCapabilities(agent); /* check phase - if live phase then we don&#x27;t need the VMInit event */ jvmtierror = (*jvmtienv)-&gt;GetPhase(jvmtienv, &amp;phase); /* now turn on the VMInit event */ if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtiEventCallbacks callbacks; memset(&amp;callbacks, 0, sizeof(callbacks)); callbacks.VMInit = &amp;eventHandlerVMInit; jvmtierror = (*jvmtienv)-&gt;SetEventCallbacks(jvmtienv,&amp;callbacks,sizeof(callbacks)); &#125; if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtierror = (*jvmtienv)-&gt;SetEventNotificationMode(jvmtienv,JVMTI_ENABLE,JVMTI_EVENT_VM_INIT,NULL); &#125; return (jvmtierror == JVMTI_ERROR_NONE)? JPLIS_INIT_ERROR_NONE : JPLIS_INIT_ERROR_FAILURE;&#125; 这里，我们关注 callbacks.VMInit = &eventHandlerVMInit;这行代码，这里设置了一个 VMInit 事件的回调函数，表示在 JVM 初始化的时候会回调 eventHandlerVMInit 函数。下面来看一下这个函数的实现细节，猜测就是在这里调用了 Premain 方法： 1234567891011121314151617181920void JNICALL eventHandlerVMInit( jvmtiEnv *jvmtienv,JNIEnv *jnienv,jthread thread) &#123; // ... success = processJavaStart( environment-&gt;mAgent, jnienv); // ...&#125;jboolean processJavaStart(JPLISAgent *agent,JNIEnv *jnienv) &#123; result = createInstrumentationImpl(jnienv, agent); /* * Load the Java agent, and call the premain. */ if ( result ) &#123; result = startJavaAgent(agent, jnienv, agent-&gt;mAgentClassName, agent-&gt;mOptionsString, agent-&gt;mPremainCaller); &#125; return result;&#125;jboolean startJavaAgent( JPLISAgent *agent,JNIEnv *jnienv,const char *classname,const char *optionsString,jmethodID agentMainMethod) &#123; // ... invokeJavaAgentMainMethod(jnienv,agent-&gt;mInstrumentationImpl,agentMainMethod, classNameObject,optionsStringObject); // ...&#125; 看到这里，Instrument 已经实例化，invokeJavaAgentMainMethod 这个方法将我们的 Premain 方法执行起来了。接着，我们就可以根据 Instrument 实例来做我们想要做的事情了。 2.3 运行时加载 Agent比起 JVM 启动时加载 Agent，运行时加载 Agent 就比较有诱惑力了，因为运行时加载 Agent 的能力给我们提供了很强的动态性，我们可以在需要的时候加载 Agent 来进行一些工作。因为是动态的，我们可以按照需求来加载所需要的 Agent，下面来分析一下动态加载 Agent 的相关技术细节。 2.3.1 AttachListenerAttach 机制通过 Attach Listener 线程来进行相关事务的处理，下面来看一下 Attach Listener 线程是如何初始化的。 12345678910// Starts the Attach Listener threadvoid AttachListener::init() &#123; // 创建线程相关部分代码被去掉了 const char thread_name[] = &quot;Attach Listener&quot;; Handle string = java_lang_String::create_from_str(thread_name, THREAD); &#123; MutexLocker mu(Threads_lock); JavaThread* listener_thread = new JavaThread(&amp;attach_listener_thread_entry); // ... &#125;&#125; 我们知道，一个线程启动之后都需要指定一个入口来执行代码，Attach Listener 线程的入口是 attach_listener_thread_entry，下面看一下这个函数的具体实现： 12345678910111213141516static void attach_listener_thread_entry(JavaThread* thread, TRAPS) &#123; AttachListener::set_initialized(); for (;;) &#123; AttachOperation* op = AttachListener::dequeue(); // find the function to dispatch too AttachOperationFunctionInfo* info = NULL; for (int i=0; funcs[i].name != NULL; i++) &#123; const char* name = funcs[i].name; if (strcmp(op-&gt;name(), name) == 0) &#123; info = &amp;(funcs[i]); break; &#125;&#125; // dispatch to the function that implements this operation res = (info-&gt;func)(op, &amp;st); //... &#125;&#125; 整个函数执行逻辑，大概是这样的： 拉取一个需要执行的任务：AttachListener::dequeue。 查询匹配的命令处理函数。 执行匹配到的命令执行函数。 其中第二步里面存在一个命令函数表，整个表如下： 12345678910111213static AttachOperationFunctionInfo funcs[] = &#123; &#123; &quot;agentProperties&quot;, get_agent_properties &#125;, &#123; &quot;datadump&quot;, data_dump &#125;, &#123; &quot;dumpheap&quot;, dump_heap &#125;, &#123; &quot;load&quot;, load_agent &#125;, &#123; &quot;properties&quot;, get_system_properties &#125;, &#123; &quot;threaddump&quot;, thread_dump &#125;, &#123; &quot;inspectheap&quot;, heap_inspection &#125;, &#123; &quot;setflag&quot;, set_flag &#125;, &#123; &quot;printflag&quot;, print_flag &#125;, &#123; &quot;jcmd&quot;, jcmd &#125;, &#123; NULL, NULL &#125;&#125;; 对于加载 Agent 来说，命令就是“load”。现在，我们知道了 Attach Listener 大概的工作模式，但是还是不太清楚任务从哪来，这个秘密就藏在 AttachListener::dequeue 这行代码里面，接下来我们来分析一下 dequeue 这个函数： 12345678910111213141516171819LinuxAttachOperation* LinuxAttachListener::dequeue() &#123; for (;;) &#123; // wait for client to connect struct sockaddr addr; socklen_t len = sizeof(addr); RESTARTABLE(::accept(listener(), &amp;addr, &amp;len), s); // get the credentials of the peer and check the effective uid/guid // - check with jeff on this. struct ucred cred_info; socklen_t optlen = sizeof(cred_info); if (::getsockopt(s, SOL_SOCKET, SO_PEERCRED, (void*)&amp;cred_info, &amp;optlen) == -1) &#123; ::close(s); continue; &#125; // peer credential look okay so we read the request LinuxAttachOperation* op = read_request(s); return op; &#125;&#125; 这是 Linux 上的实现，不同的操作系统实现方式不太一样。上面的代码表面，Attach Listener 在某个端口监听着，通过 accept 来接收一个连接，然后从这个连接里面将请求读取出来，然后将请求包装成一个 AttachOperation 类型的对象，之后就会从表里查询对应的处理函数，然后进行处理。 1234567891011121314151617Attach Listener使用一种被称为“懒加载”的策略进行初始化，也就是说，JVM启动的时候Attach Listener并不一定会启动起来。下面我们来分析一下这种“懒加载”策略的具体实现方案。 // Start Attach Listener if +StartAttachListener or it can&#x27;t be started lazily if (!DisableAttachMechanism) &#123; AttachListener::vm_start(); if (StartAttachListener || AttachListener::init_at_startup()) &#123; AttachListener::init(); &#125; &#125;// Attach Listener is started lazily except in the case when// +ReduseSignalUsage is usedbool AttachListener::init_at_startup() &#123; if (ReduceSignalUsage) &#123; return true; &#125; else &#123; return false; &#125;&#125; 上面的代码截取自 create_vm 函数，DisableAttachMechanism、StartAttachListener 和 ReduceSignalUsage 这三个变量默认都是 false，所以 AttachListener::init();这行代码不会在 create_vm 的时候执行，而 vm_start 会执行。下面来看一下这个函数的实现细节： 123456789101112131415void AttachListener::vm_start() &#123; char fn[UNIX_PATH_MAX]; struct stat64 st; int ret; int n = snprintf(fn, UNIX_PATH_MAX, &quot;%s/.java_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); assert(n &lt; (int)UNIX_PATH_MAX, &quot;java_pid file name buffer overflow&quot;); RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == 0) &#123; ret = ::unlink(fn); if (ret == -1) &#123; log_debug(attach)(&quot;Failed to remove stale attach pid file at %s&quot;, fn); &#125; &#125;&#125; 这是在 Linux 上的实现，是将/tmp/目录下的.java_pid{pid}文件删除，后面在创建 Attach Listener 线程的时候会创建出来这个文件。上面说到，AttachListener::init()这行代码不会在 create_vm 的时候执行，这行代码的实现已经在上文中分析了，就是创建 Attach Listener 线程，并监听其他 JVM 的命令请求。现在来分析一下这行代码是什么时候被调用的，也就是“懒加载”到底是怎么加载起来的。 // Signal Dispatcher needs to be started before VMInit event is postedos::signal_init();这是 create_vm 中的一段代码，看起来跟信号相关，其实 Attach 机制就是使用信号来实现“懒加载“的。下面我们来仔细地分析一下这个过程。 12345678910111213141516171819202122232425void os::signal_init() &#123; if (!ReduceSignalUsage) &#123; // Setup JavaThread for processing signals EXCEPTION_MARK; Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK); instanceKlassHandle klass (THREAD, k); instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK); const char thread_name[] = &quot;Signal Dispatcher&quot;; Handle string = java_lang_String::create_from_str(thread_name, CHECK); // Initialize thread_oop to put it into the system threadGroup Handle thread_group (THREAD, Universe::system_thread_group()); JavaValue result(T_VOID); JavaCalls::call_special(&amp;result, thread_oop,klass,vmSymbols::object_initializer_name(),vmSymbols::threadgroup_string_void_signature(), thread_group,string,CHECK); KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass()); JavaCalls::call_special(&amp;result,thread_group,group,vmSymbols::add_method_name(),vmSymbols::thread_void_signature(),thread_oop,CHECK); os::signal_init_pd(); &#123; MutexLocker mu(Threads_lock); JavaThread* signal_thread = new JavaThread(&amp;signal_thread_entry); // ... &#125; // Handle ^BREAK os::signal(SIGBREAK, os::user_handler()); &#125;&#125; JVM 创建了一个新的进程来实现信号处理，这个线程叫“Signal Dispatcher”，一个线程创建之后需要有一个入口，“Signal Dispatcher”的入口是 signal_thread_entry： 这段代码截取自 signal_thread_entry 函数，截取中的内容是和 Attach 机制信号处理相关的代码。这段代码的意思是，当接收到“SIGBREAK”信号，就执行接下来的代码，这个信号是需要 Attach 到 JVM 上的信号发出来，这个后面会再分析。我们先来看一句关键的代码：AttachListener::is_init_trigger()： 123456789101112131415161718192021222324bool AttachListener::is_init_trigger() &#123; if (init_at_startup() || is_initialized()) &#123; return false; // initialized at startup or already initialized &#125; char fn[PATH_MAX+1]; sprintf(fn, &quot;.attach_pid%d&quot;, os::current_process_id()); int ret; struct stat64 st; RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == -1) &#123; log_trace(attach)(&quot;Failed to find attach file: %s, trying alternate&quot;, fn); snprintf(fn, sizeof(fn), &quot;%s/.attach_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); RESTARTABLE(::stat64(fn, &amp;st), ret); &#125; if (ret == 0) &#123; // simple check to avoid starting the attach mechanism when // a bogus user creates the file if (st.st_uid == geteuid()) &#123; init(); return true; &#125; &#125; return false;&#125; 首先检查了一下是否在 JVM 启动时启动了 Attach Listener，或者是否已经启动过。如果没有，才继续执行，在/tmp 目录下创建一个叫做.attach_pid%d 的文件，然后执行 AttachListener 的 init 函数，这个函数就是用来创建 Attach Listener 线程的函数，上面已经提到多次并进行了分析。到此，我们知道 Attach 机制的奥秘所在，也就是 Attach Listener 线程的创建依靠 Signal Dispatcher 线程，Signal Dispatcher 是用来处理信号的线程，当 Signal Dispatcher 线程接收到“SIGBREAK”信号之后，就会执行初始化 Attach Listener 的工作。 2.3.2 运行时加载 Agent 的实现我们继续分析，到底是如何将一个 Agent 挂载到运行着的目标 JVM 上，在上文中提到了一段代码，用来进行运行时挂载 Agent，可以参考上文中展示的关于“attachAgentToTargetJvm”方法的代码。这个方法里面的关键是调用 VirtualMachine 的 attach 方法进行 Agent 挂载的功能。下面我们就来分析一下 VirtualMachine 的 attach 方法具体是怎么实现的。 12345678910111213141516171819202122public static VirtualMachine attach(String var0) throws AttachNotSupportedException, IOException &#123; if (var0 == null) &#123; throw new NullPointerException(&quot;id cannot be null&quot;); &#125; else &#123; List var1 = AttachProvider.providers(); if (var1.size() == 0) &#123; throw new AttachNotSupportedException(&quot;no providers installed&quot;); &#125; else &#123; AttachNotSupportedException var2 = null; Iterator var3 = var1.iterator(); while(var3.hasNext()) &#123; AttachProvider var4 = (AttachProvider)var3.next(); try &#123; return var4.attachVirtualMachine(var0); &#125; catch (AttachNotSupportedException var6) &#123; var2 = var6; &#125; &#125; throw var2; &#125; &#125;&#125; 这个方法通过 attachVirtualMachine 方法进行 attach 操作，在 MacOS 系统中，AttachProvider 的实现类是 BsdAttachProvider。我们来看一下 BsdAttachProvider 的 attachVirtualMachine 方法是如何实现的： 12345678910111213141516171819202122232425262728293031323334353637public VirtualMachine attachVirtualMachine(String var1) throws AttachNotSupportedException, IOException &#123; this.checkAttachPermission(); this.testAttachable(var1); return new BsdVirtualMachine(this, var1); &#125;BsdVirtualMachine(AttachProvider var1, String var2) throws AttachNotSupportedException, IOException &#123; int var3 = Integer.parseInt(var2); this.path = this.findSocketFile(var3); if (this.path == null) &#123; File var4 = new File(tmpdir, &quot;.attach_pid&quot; + var3); createAttachFile(var4.getPath()); try &#123; sendQuitTo(var3); int var5 = 0; long var6 = 200L; int var8 = (int)(this.attachTimeout() / var6); do &#123; try &#123; Thread.sleep(var6); &#125; catch (InterruptedException var21) &#123; ; &#125; this.path = this.findSocketFile(var3); ++var5; &#125; while(var5 &lt;= var8 &amp;&amp; this.path == null); &#125; finally &#123; var4.delete(); &#125; &#125; int var24 = socket(); connect(var24, this.path); &#125; private String findSocketFile(int var1) &#123; String var2 = &quot;.java_pid&quot; + var1; File var3 = new File(tmpdir, var2); return var3.exists() ? var3.getPath() : null; &#125; findSocketFile 方法用来查询目标 JVM 上是否已经启动了 Attach Listener，它通过检查”tmp/“目录下是否存在 java_pid{pid}来进行实现。如果已经存在了，则说明 Attach 机制已经准备就绪，可以接受客户端的命令了，这个时候客户端就可以通过 connect 连接到目标 JVM 进行命令的发送，比如可以发送“load”命令来加载 Agent。如果 java_pid{pid}文件还不存在，则需要通过 sendQuitTo 方法向目标 JVM 发送一个“SIGBREAK”信号，让它初始化 Attach Listener 线程并准备接受客户端连接。可以看到，发送了信号之后客户端会循环等待 java_pid{pid}这个文件，之后再通过 connect 连接到目标 JVM 上。 2.3.3 load 命令的实现下面来分析一下，“load”命令在 JVM 层面的实现： 1234567891011121314151617static jint load_agent(AttachOperation* op, outputStream* out) &#123; // get agent name and options const char* agent = op-&gt;arg(0); const char* absParam = op-&gt;arg(1); const char* options = op-&gt;arg(2); // If loading a java agent then need to ensure that the java.instrument module is loaded if (strcmp(agent, &quot;instrument&quot;) == 0) &#123; Thread* THREAD = Thread::current(); ResourceMark rm(THREAD); HandleMark hm(THREAD); JavaValue result(T_OBJECT); Handle h_module_name = java_lang_String::create_from_str(&quot;java.instrument&quot;, THREAD); JavaCalls::call_static(&amp;result,SystemDictionary::module_Modules_klass(),vmSymbols::loadModule_name(), vmSymbols::loadModule_signature(),h_module_name,THREAD); &#125; return JvmtiExport::load_agent_library(agent, absParam, options, out);&#125; 这个函数先确保加载了 java.instrument 模块，之后真正执行 Agent 加载的函数是 load_agent_library ,这个函数的套路就是加载 Agent 动态链接库，如果是通过 Java instrument API 实现的 Agent，则加载的是 libinstrument 动态链接库，然后通过 libinstrument 里面的代码实现运行 agentmain 方法的逻辑，这一部分内容和 libinstrument 实现 premain 方法运行的逻辑其实差不多，这里不再做分析。至此，我们对 Java Agent 技术已经有了一个全面而细致的了解。 3. 动态替换类字节码技术3.1 动态字节码修改的限制上文中已经详细分析了 Agent 技术的实现，我们使用 Java Instrumentation API 来完成动态类修改的功能，在 Instrumentation 接口中，通过 addTransformer 方法来增加一个类转换器，类转换器由类 ClassFileTransformer 接口实现。ClassFileTransformer 接口中唯一的方法 transform 用于实现类转换，当类被加载的时候，就会调用 transform 方法，进行类转换。在运行时，我们可以通过 Instrumentation 的 redefineClasses 方法进行类重定义，在方法上有一段注释需要特别注意： The redefinition may change method bodies, the constant pool and attributes. The redefinition must not add, remove or rename fields or methods, change the signatures of methods, or change inheritance. These restrictions maybe be lifted in future versions. The class file bytes are not checked, verified and installed until after the transformations have been applied, if the resultant bytes are in error this method will throw an exception.这里面提到，我们不可以增加、删除或者重命名字段和方法，改变方法的签名或者类的继承关系。认识到这一点很重要，当我们通过 ASM 获取到增强的字节码之后，如果增强后的字节码没有遵守这些规则，那么调用 redefineClasses 方法来进行类的重定义就会失败。那 redefineClasses 方法具体是怎么实现类的重定义的呢？它对运行时的 JVM 会造成什么样的影响呢？下面来分析 redefineClasses 的实现细节。 3.2 重定义类字节码的实现细节上文中我们提到，libinstrument 动态链接库中，JPLISAgent 不仅实现了 Agent 入口代码执行的路由，而且还是 Java 代码与 JVMTI 之间的一道桥梁。我们在 Java 代码中调用 Java Instrumentation API 的 redefineClasses，其实会调用 libinstrument 中的相关代码，我们来分析一下这条路径。 1234567891011121314151617public void redefineClasses(ClassDefinition... var1) throws ClassNotFoundException &#123; if (!this.isRedefineClassesSupported()) &#123; throw new UnsupportedOperationException(&quot;redefineClasses is not supported in this environment&quot;); &#125; else if (var1 == null) &#123; throw new NullPointerException(&quot;null passed as &#x27;definitions&#x27; in redefineClasses&quot;); &#125; else &#123; for(int var2 = 0; var2 &lt; var1.length; ++var2) &#123; if (var1[var2] == null) &#123; throw new NullPointerException(&quot;element of &#x27;definitions&#x27; is null in redefineClasses&quot;); &#125; &#125; if (var1.length != 0) &#123; this.redefineClasses0(this.mNativeAgent, var1); &#125; &#125;&#125;private native void redefineClasses0(long var1, ClassDefinition[] var3) throws ClassNotFoundException; 这是 InstrumentationImpl 中的 redefineClasses 实现，该方法的具体实现依赖一个 Native 方法 redefineClasses()，我们可以在 libinstrument 中找到这个 Native 方法的实现： 1234JNIEXPORT void JNICALL Java_sun_instrument_InstrumentationImpl_redefineClasses0 (JNIEnv * jnienv, jobject implThis, jlong agent, jobjectArray classDefinitions) &#123; redefineClasses(jnienv, (JPLISAgent*)(intptr_t)agent, classDefinitions);&#125; redefineClasses 这个函数的实现比较复杂，代码很长。下面是一段关键的代码片段： 可以看到，其实是调用了 JVMTI 的 RetransformClasses 函数来完成类的重定义细节。 12345678// class_count - pre-checked to be greater than or equal to 0// class_definitions - pre-checked for NULLjvmtiError JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) &#123;//TODO: add locking VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine); VMThread::execute(&amp;op); return (op.check_error());&#125; /* end RedefineClasses */ 重定义类的请求会被 JVM 包装成一个 VM_RedefineClasses 类型的 VM_Operation，VM_Operation 是 JVM 内部的一些操作的基类，包括 GC 操作等。VM_Operation 由 VMThread 来执行，新的 VM_Operation 操作会被添加到 VMThread 的运行队列中去，VMThread 会不断从队列里面拉取 VM_Operation 并调用其 doit 等函数执行具体的操作。VM_RedefineClasses 函数的流程较为复杂，下面是 VM_RedefineClasses 的大致流程： 加载新的字节码，合并常量池，并且对新的字节码进行校验工作// Load the caller’s new class definition(s) into _scratch_classes.// Constant pool merging work is done here as needed. Also calls// compare_and_normalize_class_versions() to verify the class// definition(s).jvmtiError load_new_class_versions(TRAPS);清除方法上的断点 1234567 // Remove all breakpoints in methods of this class JvmtiBreakpoints&amp; jvmti_breakpoints = JvmtiCurrentBreakpoints::get_jvmti_breakpoints(); jvmti_breakpoints.clearall_in_class_at_safepoint(the_class());JIT逆优化 // Deoptimize all compiled code that depends on this class flush_dependent_code(the_class, THREAD); 进行字节码替换工作，需要进行更新类 itable/vtable 等操作进行类重定义通知 1SystemDictionary::notice_modification(); VM_RedefineClasses 实现比较复杂的，详细实现可以参考 RedefineClasses 的实现。 4. Java-debug-tool 设计与实现Java-debug-tool 是一个使用 Java Instrument API 来实现的动态调试工具，它通过在目标 JVM 上启动一个 TcpServer 来和调试客户端通信。调试客户端通过命令行来发送调试命令给 TcpServer，TcpServer 中有专门用来处理命令的 handler，handler 处理完命令之后会将结果发送回客户端，客户端通过处理将调试结果展示出来。下面将详细介绍 Java-debug-tool 的整体设计和实现。 4.1 Java-debug-tool 整体架构Java-debug-tool 包括一个 Java Agent 和一个用于处理调试命令的核心 API，核心 API 通过一个自定义的类加载器加载进来，以保证目标 JVM 的类不会被污染。整体上 Java-debug-tool 的设计是一个 Client-Server 的架构，命令客户端需要完整的完成一个命令之后才能继续执行下一个调试命令。Java-debug-tool 支持多人同时进行调试，下面是整体架构图： 下面对每一层做简单介绍： 交互层：负责将程序员的输入转换成调试交互协议，并且将调试信息呈现出来。 连接管理层：负责管理客户端连接，从连接中读调试协议数据并解码，对调试结果编码并将其写到连接中去；同时将那些超时未活动的连接关闭。 业务逻辑层：实现调试命令处理，包括命令分发、数据收集、数据处理等过程。 基础实现层：Java-debug-tool 实现的底层依赖，通过 Java Instrumentation 提供的 API 进行类查找、类重定义等能力，Java Instrumentation 底层依赖 JVMTI 来完成具体的功能。 在 Agent 被挂载到目标 JVM 上之后，Java-debug-tool 会安排一个 Spy 在目标 JVM 内活动，这个 Spy 负责将目标 JVM 内部的相关调试数据转移到命令处理模块，命令处理模块会处理这些数据，然后给客户端返回调试结果。命令处理模块会增强目标类的字节码来达到数据获取的目的，多个客户端可以共享一份增强过的字节码，无需重复增强。下面从 Java-debug-tool 的字节码增强方案、命令设计与实现等角度详细说明。 4.2 Java-debug-tool 的字节码增强方案Java-debug-tool 使用字节码增强来获取到方法运行时的信息，比如方法入参、出参等，可以在不同的字节码位置进行增强，这种行为可以称为“插桩”，每个“桩”用于获取数据并将他转储出去。Java-debug-tool 具备强大的插桩能力，不同的桩负责获取不同类别的数据，下面是 Java-debug-tool 目前所支持的“桩”： 方法进入点：用于获取方法入参信息。 Fields 获取点 1：在方法执行前获取到对象的字段信息。 变量存储点：获取局部变量信息。 Fields 获取点 2：在方法退出前获取到对象的字段信息。 方法退出点：用于获取方法返回值。 抛出异常点：用于获取方法抛出的异常信息。 通过上面这些代码桩，Java-debug-tool 可以收集到丰富的方法执行信息，经过处理可以返回更加可视化的调试结果。 4.2.1 字节码增强Java-debug-tool 在实现上使用了 ASM 工具来进行字节码增强，并且每个插桩点都可以进行配置，如果不想要什么信息，则没必要进行对应的插桩操作。这种可配置的设计是非常有必要的，因为有时候我们仅仅是想要知道方法的入参和出参，但 Java-debug-tool 却给我们返回了所有的调试信息，这样我们就得在众多的输出中找到我们所关注的内容。如果可以进行配置，则除了入参点和出参点外其他的桩都不插，那么就可以快速看到我们想要的调试数据，这种设计的本质是为了让调试者更加专注。下面是 Java-debug-tool 的字节码增强工作方式： 图 4-2-1 如图 4-2-1 所示，当调试者发出调试命令之后，Java-debug-tool 会识别命令并判断是否需要进行字节码增强，如果命令需要增强字节码，则判断当前类+当前方法是否已经被增强过。上文已经提到，字节码替换是有一定损耗的，这种具有损耗的操作发生的次数越少越好，所以字节码替换操作会被记录起来，后续命令直接使用即可，不需要重复进行字节码增强，字节码增强还涉及多个调试客户端的协同工作问题，当一个客户端增强了一个类的字节码之后，这个客户端就锁定了该字节码，其他客户端变成只读，无法对该类进行字节码增强，只有当持有锁的客户端主动释放锁或者断开连接之后，其他客户端才能继续增强该类的字节码。字节码增强模块收到字节码增强请求之后，会判断每个增强点是否需要插桩，这个判断的根据就是上文提到的插桩配置，之后字节码增强模块会生成新的字节码，Java-debug-tool 将执行字节码替换操作，之后就可以进行调试数据收集了。经过字节码增强之后，原来的方法中会插入收集运行时数据的代码，这些代码在方法被调用的时候执行，获取到诸如方法入参、局部变量等信息，这些信息将传递给数据收集装置进行处理。数据收集的工作通过 Advice 完成，每个客户端同一时间只能注册一个 Advice 到 Java-debug-tool 调试模块上，多个客户端可以同时注册自己的 Advice 到调试模块上。Advice 负责收集数据并进行判断，如果当前数据符合调试命令的要求，Java-debug-tool 就会卸载这个 Advice，Advice 的数据就会被转移到 Java-debug-tool 的命令结果处理模块进行处理，并将结果发送到客户端。 4.2.2 Advice 的工作方式Advice 是调试数据收集器，不同的调试策略会对应不同的 Advice。Advice 是工作在目标 JVM 的线程内部的，它需要轻量级和高效，意味着 Advice 不能做太过于复杂的事情，它的核心接口“match”用来判断本次收集到的调试数据是否满足调试需求。如果满足，那么 Java-debug-tool 就会将其卸载，否则会继续让他收集调试数据，这种“加载 Advice” -&gt; “卸载 Advice”的工作模式具备很好的灵活性。关于 Advice，需要说明的另外一点就是线程安全，因为它加载之后会运行在目标 JVM 的线程中，目标 JVM 的方法极有可能是多线程访问的，这也就是说，Advice 需要有能力处理多个线程同时访问方法的能力，如果 Advice 处理不当，则可能会收集到杂乱无章的调试数据。下面的图片展示了 Advice 和 Java-debug-tool 调试分析模块、目标方法执行以及调试客户端等模块的关系。 图 4-2-2Advice 的首次挂载由 Java-debug-tool 的命令处理器完成，当一次调试数据收集完成之后，调试数据处理模块会自动卸载 Advice，然后进行判断，如果调试数据符合 Advice 的策略，则直接将数据交由数据处理模块进行处理，否则会清空调试数据，并再次将 Advice 挂载到目标方法上去，等待下一次调试数据。非首次挂载由调试数据处理模块进行，它借助 Advice 按需取数据，如果不符合需求，则继续挂载 Advice 来获取数据，否则对调试数据进行处理并返回给客户端。 4.3 Java-debug-tool 的命令设计与实现4.3.1 命令执行上文已经完整的描述了 Java-debug-tool 的设计以及核心技术方案，本小节将详细介绍 Java-debug-tool 的命令设计与实现。首先需要将一个调试命令的执行流程描述清楚，下面是一张用来表示命令请求处理流程的图片： 图 4-3-1图 4-3-1 简单的描述了 Java-debug-tool 的命令处理方式，客户端连接到服务端之后，会进行一些协议解析、协议认证、协议填充等工作，之后将进行命令分发。服务端如果发现客户端的命令不合法，则会立即返回错误信息，否则再进行命令处理。命令处理属于典型的三段式处理，前置命令处理、命令处理以及后置命令处理，同时会对命令处理过程中的异常信息进行捕获处理，三段式处理的好处是命令处理被拆成了多个阶段，多个阶段负责不同的职责。前置命令处理用来做一些命令权限控制的工作，并填充一些类似命令处理开始时间戳等信息，命令处理就是通过字节码增强，挂载 Advice 进行数据收集，再经过数据处理来产生命令结果的过程，后置处理则用来处理一些连接关闭、字节码解锁等事项。Java-debug-tool 允许客户端设置一个命令执行超时时间，超过这个时间则认为命令没有结果，如果客户端没有设置自己的超时时间，就使用默认的超时时间进行超时控制。Java-debug-tool 通过设计了两阶段的超时检测机制来实现命令执行超时功能：首先，第一阶段超时触发，则 Java-debug-tool 会友好的警告命令处理模块处理时间已经超时，需要立即停止命令执行，这允许命令自己做一些现场清理工作，当然需要命令执行线程自己感知到这种超时警告；当第二阶段超时触发，则 Java-debug-tool 认为命令必须结束执行，会强行打断命令执行线程。超时机制的目的是为了不让命令执行太长时间，命令如果长时间没有收集到调试数据，则应该停止执行，并思考是否调试了一个错误的方法。当然，超时机制还可以定期清理那些因为未知原因断开连接的客户端持有的调试资源，比如字节码锁。 4.3.4 获取方法执行视图Java-debug-tool 通过下面的信息来向调试者呈现出一次方法执行的视图：正在调试的方法信息。 方法调用堆栈。 调试耗时，包括对目标 JVM 造成的 STW 时间。 方法入参，包括入参的类型及参数值。 方法的执行路径。 代码执行耗时。 局部变量信息。 方法返回结果。 方法抛出的异常。 对象字段值快照。 图 4-3-2 展示了 Java-debug-tool 获取到正在运行的方法的执行视图的信息。 图 4-3-2 4.4 Java-debug-tool 与同类产品对比分析Java-debug-tool 的同类产品主要是 greys，其他类似的工具大部分都是基于 greys 进行的二次开发，所以直接选择 greys 来和 Java-debug-tool 进行对比。 5. 总结本文详细剖析了 Java 动态调试关键技术的实现细节，并介绍了我们基于 Java 动态调试技术结合实际故障排查场景进行的一点探索实践；动态调试技术为研发人员进行线上问题排查提供了一种新的思路，我们基于动态调试技术解决了传统断点调试存在的问题，使得可以将断点调试这种技术应用在线上，以线下调试的思维来进行线上调试，提高问题排查效率。 6. 参考文献ASM 4 guide Java Virtual Machine Specification JVM Tool Interface alibaba arthas openjdk 摘自https://mp.weixin.qq.com/s/ZlNcvwJ_swspifWTLHA92Q","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"动态调试技术","slug":"动态调试技术","permalink":"https://wuhaocn.github.io/tags/%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/"}]},{"title":"计数排序","slug":"algorithm/sort/7.计数排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/7.计数排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/7.%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F/","excerpt":"","text":"计数排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package org.coral.algorithm.sort;/** * 1.找出待排序的数组中最大和最小的元素； 2.统计数组中每个值为i的元素出现的次数,存入数组C的第i项； 3.对所有的计数累加(从C中的第一个元素开始,每一项和前一项相加）； 4.反向填充目标数组:将每个元素i放在新数组的第C(i)项,每放一个元素就将C(i)减去1. */public class CountSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; CountSort countSort = new CountSort(); countSort.print(numbers); countSort.sort(numbers); &#125; @Override public void sort(int[] numbers) &#123; int max = Integer.MIN_VALUE; int min = Integer.MAX_VALUE; //找出数组中的最大最小值 for(int i = 0; i &lt; numbers.length; i++)&#123; max = Math.max(max, numbers[i]); min = Math.min(min, numbers[i]); &#125; int[] help = new int[max - min + 1]; //找出每个数字出现的次数 for(int i = 0; i &lt; numbers.length; i++)&#123; int mapPos = numbers[i] - min; help[mapPos]++; &#125; //计算每个数字应该在排序后数组中应该处于的位置 for(int i = 1; i &lt; help.length; i++)&#123; help[i] = help[i-1] + help[i]; &#125; //根据help数组进行排序 int res[] = new int[numbers.length]; for(int i = 0; i &lt; numbers.length; i++)&#123; int post = --help[numbers[i] - min]; res[post] = numbers[i]; &#125; print(res); &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"桶排序","slug":"algorithm/sort/8-桶排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/8-桶排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/8-%E6%A1%B6%E6%8E%92%E5%BA%8F/","excerpt":"","text":"桶排序详细参考 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 桶排序 * &lt;p&gt; 桶排序的基本思想是： 把数组 arr 划分为 n 个大小相同子区间（桶），每个子区间各自排序，最 后合并 。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里只有一个元素的情况。 1.找出待排序数组中的最大值 max、最小值 min 2.我们使用 动态数组 ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为(max min)/arr.length+1 3.遍历数组 arr，计算每个元素 arr[i] 放的桶 4.每个桶各自排序 */public class BucketSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; BucketSort bucketSort = new BucketSort(); System.out.println(&quot;BucketSort&quot;); bucketSort.sort(numbers); bucketSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; int max = Integer.MIN_VALUE; int min = Integer.MAX_VALUE; for (int i = 0; i &lt; arr.length; i++) &#123; max = Math.max(max, arr[i]); min = Math.min(min, arr[i]); &#125; //创建桶 int bucketNum = (max - min) / arr.length + 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum); for (int i = 0; i &lt; bucketNum; i++) &#123; bucketArr.add(new ArrayList&lt;Integer&gt;()); &#125; //将每个元素放入桶 for (int i = 0; i &lt; arr.length; i++) &#123; int num = (arr[i] - min) / (arr.length); bucketArr.get(num).add(arr[i]); &#125; //对每个桶进行排序 for (int i = 0; i &lt; bucketArr.size(); i++) &#123; Collections.sort(bucketArr.get(i)); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"基数排序","slug":"algorithm/sort/9-基数排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/9-基数排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/9-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/","excerpt":"","text":"基数排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 基数排序 * 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位 * 开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序 * 列。 */public class RadixSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; RadixSort radixSort = new RadixSort(); System.out.println(&quot;RadixSort&quot;); radixSort.sort(numbers); radixSort.print(numbers); &#125; @Override public void sort(int[] array) &#123; //首先确定排序的趟数; int max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; if (array[i] &gt; max) &#123; max = array[i]; &#125; &#125; int time = 0; //判断位数; while (max &gt; 0) &#123; max /= 10; time++; &#125; //建立 10 个队列; List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for (int i = 0; i &lt; 10; i++) &#123; ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); &#125; //进行 time 次分配和收集; for (int i = 0; i &lt; time; i++) &#123; //分配数组元素; for (int j = 0; j &lt; array.length; j++) &#123; //得到数字的第 time+1 位数; int x = array[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(array[j]); queue.set(x, queue2); &#125; int count = 0;//元素计数器; //收集队列元素; for (int k = 0; k &lt; 10; k++) &#123; while (queue.get(k).size() &gt; 0) &#123; ArrayList&lt;Integer&gt; queue3 = queue.get(k); array[count] = queue3.get(0); queue3.remove(0); count++; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"归并（Merge）排序","slug":"algorithm/sort/4-归并排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/4-归并排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/4-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/","excerpt":"","text":"归并（Merge）排序详细参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 归并（Merge）排序 * &lt;p&gt; 归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序 分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 */public class MergeSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; MergeSort mergeSort = new MergeSort(); System.out.println(&quot;MergeSort&quot;); mergeSort.sort(numbers); mergeSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1); &#125; public void sort(int[] data, int left, int right) &#123; if (left &gt;= right) return; // 找出中间索引 int center = (left + right) / 2; // 对左边数组进行递归 sort(data, left, center); // 对右边数组进行递归 sort(data, center + 1, right); // 合并 merge(data, left, center, right); print(data); &#125; /** * 将两个数组进行归并，归并前面 2 个数组已有序，归并后依然有序13/04/2018 Page 239 of 283 * * @param data 数组对象 * @param left 左数组的第一个元素的索引 * @param center 左数组的最后一个元素的索引， center+1 是右数组第一个元素的索引 * @param right 右数组最后一个元素的索引 */ public static void merge(int[] data, int left, int center, int right) &#123; // 临时数组 int[] tmpArr = new int[data.length]; // 右数组第一个元素索引 int mid = center + 1; // third 记录临时数组的索引 int third = left; // 缓存左数组第一个元素的索引 int tmp = left; while (left &lt;= center &amp;&amp; mid &lt;= right) &#123; // 从两个数组中取出最小的放入临时数组 if (data[left] &lt;= data[mid]) &#123; tmpArr[third++] = data[left++]; &#125; else &#123; tmpArr[third++] = data[mid++]; &#125; &#125; // 剩余部分依次放入临时数组（实际上两个 while 只会执行其中一个） while (mid &lt;= right) &#123; tmpArr[third++] = data[mid++]; &#125; while (left &lt;= center) &#123; tmpArr[third++] = data[left++]; &#125; // 将临时数组中的内容拷贝回原数组中 // （原 left-right 范围的内容被复制回原数组） while (tmp &lt;= right) &#123; data[tmp] = tmpArr[tmp++]; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"希尔排序","slug":"algorithm/sort/5-希尔排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/5-希尔排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/5-%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/","excerpt":"","text":"希尔排序详细参考 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 希尔排序 * &lt;p&gt; * 基本思想：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列 * 中的记录“基本有序” 时，再对全体记录进行依次直接插入排序。 * 1. 操作方法： * 选择一个增量序列 t1， t2， …， tk，其中 ti&gt;tj， tk=1； * 2. 按增量序列个数 k，对序列进行 k 趟排序； * 3. 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进 * 行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长 * 度。 */public class ShellSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; ShellSort shellSort = new ShellSort(); System.out.println(&quot;ShellSort&quot;); shellSort.sort(numbers); shellSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; int dk = arr.length / 2; while (dk &gt;= 1) &#123; ShellInsertSort(arr, dk); dk = dk / 2; &#125; &#125; private void ShellInsertSort(int[] a, int dk) &#123; //类似插入排序，只是插入排序增量是 1，这里增量是 dk,把 1 换成 dk 就可以了 for (int i = dk; i &lt; a.length; i++) &#123; if (a[i] &lt; a[i - dk]) &#123; int j; int x = a[i];//x 为待插入元素 a[i] = a[i - dk]; for (j = i - dk; j &gt;= 0 &amp;&amp; x &lt; a[j]; j = j - dk) &#123; //通过循环，逐个后移一位找到要插入的位置。 a[j + dk] = a[j]; &#125; a[j + dk] = x;//插入 &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"堆排序","slug":"algorithm/sort/6-堆排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/6-堆排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/6-%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"堆排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149/** * 堆排序 * 堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。 * 可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。 * 大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]] &gt;= A[i]。 * 在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶 * 定义 * n个关键字序列Kl，K2，…，Kn称为（Heap），当且仅当该序列满足如下性质（简称为堆性质）： * (1)ki&lt;=k(2i）且ki&lt;=k(2i+1)(1≤i≤ n/2），当然，这是小根堆，大根堆则换成&gt;=号(2)ki&gt;=k(2i）且ki&gt;=k(2i+1)(1≤i≤ n/2）。//k(i）相当于二叉树的非叶子结点，K(2i）则是左子节点，k(2i+1）是右子节点 * 若将此序列所存储的向量R[1..n]看做是一棵完全二叉树的存储结构，则堆实质上是满足如下性质的完全二叉树： * 树中任一非叶子结点的关键字均不大于（或不小于）其左右孩子（若存在）结点的关键字。 * 【例】关键字序列（10，15，56，25，30，70）和（70，56，30，25，15，10）分别满足堆性质（1）和（2），故它们均是堆，其对应的完全二叉树分别如小根堆示例和大根堆示例所示。 * 大根堆和小根堆：根结点（亦称为堆顶）的关键字是堆里所有结点关键字中最小者的堆称为小根堆，又称最小堆。 * 根结点（亦称为堆顶）的关键字是堆里所有结点关键字中最大者，称为大根堆，又称最大堆。注意：①堆中任一子树亦是堆。②以上讨论的堆实际上是二叉堆（Binary Heap），类似地可定义k叉堆。 * 堆排序的时间，主要由建立初始堆和反复重建堆这两部分的时间开销构成，它们均是通过调用Heapify实现的。 * 平均性能 * O(N*logN)。 * * （2）大根堆排序算法的基本操作： ①建堆，建堆是不断调整堆的过程，从len/2处开始调整，一直到第一个节点，此处len是堆中元素的个数。 建堆的过程是线性的过程，从len/2到0处一直调用调整堆的过程，相当于o(h1)+o(h2)…+o(hlen/2) 其中h表示节点的深度，len/2表示节点的个数，这是一个求和的过程，结果是线性的O(n)。 ②调整堆：调整堆在构建堆的过程中会用到，而且在堆排序过程中也会用到。利用的思想是比较节点i和它的孩子节点left(i),right(i)， 选出三者最大(或者最小)者，如果最大（小）值不是节点i而是它的一个孩子节点，那边交互节点i和该节点，然后再调用调整堆过程，这是一个递归的过程。 调整堆的过程时间复杂度与堆的深度有关系，是lgn的操作，因为是沿着深度方向进行调整的。 ③堆排序：堆排序是利用上面的两个过程来进行的。首先是根据元素构建堆。 然后将堆的根节点取出(一般是与最后一个节点进行交换)，将前面len-1个节点继续进行堆调整的过程，然后再将根节点取出，这样一直到所有节点都取出。堆排序过程的时间复杂度是O(nlgn)。 因为建堆的时间复杂度是O(n)（调用一次）；调整堆的时间复杂度是lgn，调用了n-1次，所以堆排序的时间复杂度是O(nlgn) [2] * 其他性能 * 由于建初始堆所需的比较次数较多，所以堆排序不适宜于记录数较少的文件。 * 堆排序是就地排序，辅助空间为O(1). * 它是不稳定的排序方法。（排序的稳定性是指如果在排序的序列中，存在前后相同的两个元素的话，排序前 和排序后他们的相对位置不发生变化） * * 总结： * 1.建立最大堆 * 2.把最大堆元素移动至最后为有序 */public class HeapSort implements Sort &#123; public static void main(String[] args) &#123; HeapSort bubbleSort = new HeapSort(); System.out.println(&quot;HeapSort&quot;); bubbleSort.test(); &#125; @Override public void sort(int[] data) &#123; //step1.buildMaxHeapify //没有子节点的才需要创建最大堆，从最后一个的父节点开始 int startIndex = getParentIndex(data.length - 1); //从尾端开始创建最大堆，每次都是正确的堆 for (int i = startIndex; i &gt;= 0; i--) &#123; maxHeapify(data, data.length, i); &#125; //---此时最大堆创建完成 System.out.println(&quot;printTree MaxTree Ok&quot;); //step2.heapSort //末尾与头交换，交换后调整最大堆 for (int i = data.length - 1; i &gt; 0; i--) &#123; System.out.print(&quot;i=&quot; + i); printTree(data); swap(data, 0, i); printTree(data); maxHeapify(data, i, 0); &#125; printTree(data); &#125; /** * 创建最大堆 * * @paramdata * @paramheapSize需要创建最大堆的大小，一般在sort的时候用到，因为最多值放在末尾，末尾就不再归入最大堆了 * @paramindex当前需要创建最大堆的位置 */ private void maxHeapify(int[] data, int heapSize, int index) &#123; //当前点与左右子节点比较 int left = getChildLeftIndex(index); int right = getChildRightIndex(index); System.out.print(&quot;index=&quot; + index + &quot; left=&quot; + left+&quot; right=&quot; + right); printTree(data); int largest = index; if (left &lt; heapSize &amp;&amp; data[index] &lt; data[left]) &#123; largest = left; &#125; if (right &lt; heapSize &amp;&amp; data[largest] &lt; data[right]) &#123; largest = right; &#125; //得到最大值后可能需要交换，如果交换了，其子节点可能就不是最大堆了，需要重新调整 if (largest != index) &#123; swap(data, largest, index); maxHeapify(data, heapSize, largest); &#125; &#125; /** * 父节点位置 * * @return * @paramcurrent */ private int getParentIndex(int current) &#123; return (current - 1) &gt;&gt; 1; &#125; /** * 左子节点position注意括号，加法优先级更高 * * @return * @paramcurrent */ private int getChildLeftIndex(int current) &#123; return (current &lt;&lt; 1) + 1; &#125; /** * 右子节点position * * @return * @paramcurrent */ private int getChildRightIndex(int current) &#123; return (current &lt;&lt; 1) + 2; &#125; public void printTree(int[] data) &#123; int pre = -2; for (int i = 0; i &lt; data.length; i++) &#123; if (pre &lt; (int) getLog(i + 1)) &#123; pre = (int) getLog(i + 1); System.out.println(); &#125; System.out.print(data[i] + &quot;|&quot;); &#125; System.out.println(); System.out.println(); &#125; /** * 以2为底的对数 * * @return * @paramparam */ private static double getLog(double param) &#123; return Math.log(param) / Math.log(2); &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"人工智能算法","slug":"algorithm/ai/ai","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/ai/ai/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/ai/ai/","excerpt":"","text":"1.人工智能的三大基石算法、数据、计算能力 2.算法2.1.学习算法按照模型训练方式可以分为四类： 监督学习（Supervised Learning） 无监督学习（Unsupervised Learning） 半监督学习（Semi-supervised Learning） 强化学习（Reinforcement Learning） 深度学习(Deep Learning) 2.2.监督学习常见的监督学习算法包含以下几类： 2.2.1.人工神经网络（Artificial NeuralNetwork： 反向传播（Backpropagation） 波尔兹曼机（Boltzmann Machine） 卷积神经网络（Convolutional Neural Network） Hopfield 网络（hopfield Network） 多层感知器（Multilyer Perceptron） 径向基函数网络（Radial Basis Function Network，RBFN） 受限波尔兹曼机（Restricted Boltzmann Machine） 回归神经网络（Recurrent NeuralNetwork，RNN） 自组织映射（Self-organizing Map，SOM） 尖峰神经网络（Spiking Neural Network） 2.2.2.贝叶斯类（Bayesin） 朴素贝叶斯（Naive Bayes） 高斯贝叶斯（Gaussian Naive Bayes） 多项朴素贝叶斯（Multinomial Naive Bayes） 平均-依赖性评估（Averaged One-Dependence Estimators，AODE） 贝叶斯信念网络（Bayesian Belief Network，BBN） 贝叶斯网络（Bayesian Network，BN） 2.2.3.决策树（Decision Tree） 分类和回归树（Classification and Regression Tree，CART） 迭代 Dichotomiser3（Iterative Dichotomiser 3， ID3） C4.5 算法（C4.5 Algorithm）、C5.0 算法（C5.0 Algorithm） 卡方自动交互检测（Chi-squared Automatic Interaction Detection，CHAID） 决策残端（Decision Stump） ID3 算法（ID3 Algorithm） 随机森林（Random Forest） SLIQ（Supervised Learning in Quest） 2.2.4.线性分类器（Linear Classifier）类： Fisher 的线性判别（Fisher’s Linear Discriminant） 线性回归（Linear Regression） 逻辑回归（Logistic Regression） 多项逻辑回归（Multionmial Logistic Regression） 朴素贝叶斯分类器（Naive Bayes Classifier） 感知（Perception） 支持向量机（Support Vector Machine） 2.3.无监督学习：2.3.1.人工神经网络（Artificial Neural Network） 生成对抗网络（Generative Adversarial Networks，GAN） 前馈神经网络（Feedforward Neural Network） 逻辑学习机（Logic Learning Machine） 自组织映射（Self-organizing Map） 2.3.2.关联规则学习（Association Rule Learning） 先验算法（Apriori Algorithm） Eclat 算法（Eclat Algorithm） FP-Growth 2.3.3.分层聚类算法（Hierarchical Clustering） 单连锁聚类（Single-linkage Clustering） 概念聚类（Conceptual Clustering） 2.3.4.聚类分析（Cluster analysis） BIRCH 算法 DBSCAN 算法 期望最大化（Expectation-maximization，EM） 模糊聚类（Fuzzy Clustering） K-means 算法 K 均值聚类（K-means Clustering） K-medians 聚类 均值漂移算法（Mean-shift） OPTICS 算法 2.3.5.异常检测（Anomaly detection） K 最邻近（K-nearest Neighbor，KNN）算法 局部异常因子算法（Local Outlier Factor，LOF） 2.4.半监督学习： 生成模型（Generative Models） 低密度分离（Low-density Separation） 基于图形的方法（Graph-based Methods） 联合训练（Co-training） 2.5.强化学习类算法 Q 学习（Q-learning） 状态-行动-奖励-状态-行动（State-Action-Reward-State-Action，SARSA） DQN（Deep Q Network） 策略梯度算法（Policy Gradients） 基于模型强化学习（Model Based RL） 时序差分学习（Temporal Different Learning） 2.6.深度学习类算法： 深度信念网络（Deep Belief Machines） 深度卷积神经网络（Deep Convolutional Neural Networks） 深度递归神经网络（Deep Recurrent Neural Network） 分层时间记忆（Hierarchical Temporal Memory，HTM） 深度波尔兹曼机（Deep Boltzmann Machine，DBM） 栈式自动编码器（Stacked Autoencoder） 生成对抗网络（Generative Adversarial Networks） 3.解决任务算法按照解决任务的不同来分类，粗略可以分为五种： 二分类算法（Two-class Classification） 多分类算法（Multi-class Classification） 回归算法（Regression） 聚类算法（Clustering） 异常检测（Anomaly Detection） 3.1.二分类（Two-class Classification） （1）二分类支持向量机（Two-class SVM）：适用于数据特征较多、线性模型的场景。 （2）二分类平均感知器（Two-class Average Perceptron）：适用于训练时间短、线性模型的场景。 （3）二分类逻辑回归（Two-class Logistic Regression）：适用于训练时间短、线性模型的场景。 （4）二分类贝叶斯点机（Two-class Bayes Point Machine）：适用于训练时间短、线性模型的场景。（5）二分类决策森林（Two-class Decision Forest）：适用于训练时间短、精准的场景。 （6）二分类提升决策树（Two-class Boosted Decision Tree）：适用于训练时间短、精准度高、内存占用量大的场景 （7）二分类决策丛林（Two-class Decision Jungle）：适用于训练时间短、精确度高、内存占用量小的场景。 （8）二分类局部深度支持向量机（Two-class Locally Deep SVM）：适用于数据特征较多的场景。 （9）二分类神经网络（Two-class Neural Network）：适用于精准度高、训练时间较长的场景。 3.2.多分类（Multi-class Classification）多分类问题通常适用三种解决方案：第一种，从数据集和适用方法入手，利用二分类器解决多分类问题；第二种，直接使用具备多分类能力的多分类器；第三种，将二分类器改进成为多分类器今儿解决多分类问题。常用的算法：（1）多分类逻辑回归（Multiclass Logistic Regression）：适用训练时间短、线性模型的场景。（2）多分类神经网络（Multiclass Neural Network）：适用于精准度高、训练时间较长的场景。（3）多分类决策森林（Multiclass Decision Forest）：适用于精准度高，训练时间短的场景。（4）多分类决策丛林（Multiclass Decision Jungle）：适用于精准度高，内存占用较小的场景。（5）“一对多”多分类（One-vs-all Multiclass）：取决于二分类器效果。 3.3.回归回归问题通常被用来预测具体的数值而非分类。除了返回的结果不同，其他方法与分类问题类似。我们将定量输出，或者连续变量预测称为回归；将定性输出，或者离散变量预测称为分类。常见的算法有： （1）排序回归（Ordinal Regression）：适用于对数据进行分类排序的场景。 （2）泊松回归（Poission Regression）：适用于预测事件次数的场景。 （3）快速森林分位数回归（Fast Forest Quantile Regression）：适用于预测分布的场景。 （4）线性回归（Linear Regression）：适用于训练时间短、线性模型的场景。 （5）贝叶斯线性回归（Bayesian Linear Regression）：适用于线性模型，训练数据量较少的场景。 （6）神经网络回归（Neural Network Regression）：适用于精准度高、训练时间较长的场景。 （7）决策森林回归（Decision Forest Regression）：适用于精准度高、训练时间短的场景。 （8）提升决策树回归（Boosted Decision Tree Regression）：适用于精确度高、训练时间短、内存占用较大的场景。 3.4.聚类聚类的目标是发现数据的潜在规律和结构。聚类通常被用做描述和衡量不同数据源间的相似性，并把数据源分类到不同的簇中。（1）层次聚类（Hierarchical Clustering）：适用于训练时间短、大数据量的场景。（2）K-means 算法：适用于精准度高、训练时间短的场景。（3）模糊聚类 FCM 算法（Fuzzy C-means，FCM）：适用于精确度高、训练时间短的场景。（4）SOM 神经网络（Self-organizing Feature Map，SOM）：适用于运行时间较长的场景。 3.5.异常检测异常检测是指对数据中存在的不正常或非典型的分体进行检测和标志，有时也称为偏差检测。异常检测看起来和监督学习问题非常相似，都是分类问题。都是对样本的标签进行预测和判断，但是实际上两者的区别非常大，因为异常检测中的正样本（异常点）非常小。常用的算法有：（1）一分类支持向量机（One-class SVM）：适用于数据特征较多的场景。（2）基于 PCA 的异常检测（PCA-based Anomaly Detection）：适用于训练时间短的场景。 4.迁移学习类算法 归纳式迁移学习（Inductive Transfer Learning） 直推式迁移学习（Transductive Transfer Learning） 无监督式迁移学习（Unsupervised Transfer Learning） 传递式迁移学习（Transitive Transfer Learning） 算法的适用场景，需要考虑的因素有： （1）数据量的大小、数据质量和数据本身的特点 （2）机器学习要解决的具体业务场景中问题的本质是什么？ （3）可以接受的计算时间是什么？ （4）算法精度要求有多高？ 5.应用场景有了算法，有了被训练的数据（经过预处理过的数据），那么多次训练（考验计算能力的时候到了）后，经过模型评估和算法人员调参后，会获得训练模型。当新的数据输入后，那么我们的训练模型就会给出结果。业务要求的最基础的功能就算实现了。 互联网产品自动化运维是趋势，因为互联网需要快速响应的特性，决定了我们对问题要快速响应、快速修复。人工智能产品也不例外。AI + 自动化运维是如何工作的呢？","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://wuhaocn.github.io/tags/ai/"}]},{"title":"选择排序","slug":"algorithm/sort/0.选择排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/0.选择排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/0.%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/","excerpt":"","text":"选择排序123456789101112131415161718192021222324252627282930313233343536373839/** * 算法步骤: 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 */public class SelectionSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; SelectionSort selectionSort = new SelectionSort(); selectionSort.sort(numbers); selectionSort.print(numbers); &#125; @Override public void sort(int[] numbers) &#123; // 总共要经过 N-1 轮比较 for (int i = 0; i &lt; numbers.length - 1; i++) &#123; int min = i; // 每轮需要比较的次数 N-i for (int j = i + 1; j &lt; numbers.length; j++) &#123; if (numbers[j] &lt; numbers[min]) &#123; // 记录目前能找到的最小值元素的下标 min = j; &#125; &#125; // 将找到的最小值和i位置所在的值进行交换 if (i != min) &#123; int tmp = numbers[i]; numbers[i] = numbers[min]; numbers[min] = tmp; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"冒泡排序","slug":"algorithm/sort/1.冒泡排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/1.冒泡排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/1.%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"冒泡排序详细参考 123456789101112131415161718192021222324252627282930313233package com.coral.learning.alg.udemo.algorithms.sort;/** * 冒泡排序 * * 它重复地走访过要排序的元素列，一次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。 * 走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。 * 这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。 */public class BubbleSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; BubbleSort bubbleSort = new BubbleSort(); System.out.println(&quot;BubbleSort&quot;); bubbleSort.sort(numbers); &#125; @Override public void sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = 0; j &lt; arr.length - i - 1; j++) &#123;//-1为了防止溢出 print(arr); if (arr[j] &gt; arr[j + 1]) &#123; swap(arr, j, j + 1); &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"插入排序","slug":"algorithm/sort/2.插入排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/2.插入排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/2.%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","excerpt":"","text":"插入排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839/** * 插入排序 * 通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。 * 插入排序非常类似于整扑克牌。在开始摸牌时，左手是空的，牌面朝下放在桌上。接着， 一次从 * 桌上摸起一张牌，并将它插入到左手一把牌中的正确位置上。 为了找到这张牌的正确位置，要将 * 它与手中已有的牌从右到左地进行比较。无论什么时候，左手中的牌都是排好序的。 * 如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函 * 数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是(n2)。 */public class InsertSort implements Sort &#123; public static void main(String[] args) &#123; InsertSort bubbleSort = new InsertSort(); System.out.println(&quot;InsertSort&quot;); bubbleSort.test(); &#125; @Override public void sort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++) &#123; print(arr); //插入的数 int insertVal = arr[i]; //被插入的位置(准备和前一个数比较) int index = i - 1; //如果插入的数比被插入的数小 while (index &gt;= 0 &amp;&amp; insertVal &lt; arr[index]) &#123; //将把 arr[index] 向后移动 arr[index + 1] = arr[index]; //让 index 向前移动 index--; &#125; //把插入的数放入合适位置 arr[index + 1] = insertVal; print(arr); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"快速排序","slug":"algorithm/sort/3-快速排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/3-快速排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/3-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","excerpt":"","text":"快速排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/** * 快速排序： * * 快速排序（Quicksort）是对冒泡排序的一种改进。 * 由C. A. R. Hoare在1962年提出。 * 它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小， * 然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 * &lt;p&gt; * 选择一个关键值作为基准值。比基准值小的都在左边序列（一般是无序的）， * 比基准值大的都在右边（一般是无序的）。 * 一般选择序列的第一个元素。 * 一次循环： 从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有 * 继续比较下一个，直到找到第一个比基准值小的值才交换。 找到这个值之后，又从前往后开始比 * 较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的 * 值才交换。直到从前往后的比较索引&gt;从后往前比较的索引，结束第一次循环，此时，对于基准值 * 来说，左右两边就是有序的了。 * 算法分析： * 1.当分区选取的基准元素为待排序元素中的最大或最小值时，为最坏的情况，时间复杂度和直接插入排序的一样，移动次数达到最大值 * Cmax = 1+2+...+(n-1) = n*(n-1)/2 = O(n2) 此时最好时间复杂为O(n2) * 2.当分区选取的基准元素为待排序元素中的&quot;中值&quot;，为最好的情况，时间复杂度为O(nlog2n)。 * 3.快速排序的空间复杂度为O(log2n). * 4.当待排序元素类似[6,1,3,7,3]且基准元素为6时，经过分区，形成[1,3,3,6,7],两个3的相对位置发生了改变，所是快速排序是一种不稳定排序。 */public class QuickSort implements Sort&#123; public static void main(String[] args) &#123; int[] numbers1 = new int[]&#123;1, 10, 6, 3, 4, 4, 5&#125;; int[] numbers2 = new int[]&#123;1, 10, 6, 3, 4, 4, 5, 10&#125;; int[] numbers3 = new int[]&#123;1, 10, 6, 3, 4, 4, 5&#125;; QuickSort quickSort = new QuickSort(); System.out.println(&quot;quick sortOne&quot;); quickSort.sortOne(numbers1, 0, numbers1.length - 1); System.out.println(&quot;quick sortTwo&quot;); quickSort.sortTwo(numbers2, 0, numbers2.length - 1); System.out.println(&quot;quick sortTree&quot;); quickSort.sortThree(numbers3, 0, numbers3.length - 1); &#125; @Override public void sort(int[] numbers) &#123; sortOne(numbers, 0, numbers.length - 1); &#125; /** * 快速排序 * * @param numbers * @param sign * @param length */ public void sortOne(int[] numbers, int sign, int length) &#123; int start = sign; //start为最小值 int end = length; //end为最大值 int key = numbers[sign]; while (start &lt; end) &#123; print(numbers); //比较右侧 while (key &lt;= numbers[end] &amp;&amp; start &lt; end) &#123; end--; &#125; if (key &gt;= numbers[end]) &#123; swap(numbers, start, end); &#125; //比较左侧 while (key &gt;= numbers[start] &amp;&amp; start &lt; end) &#123; start++; &#125; if (key &lt;= numbers[start]) &#123; swap(numbers, start, end); &#125; //进行左侧串比较 if (start &gt; sign) &#123; sortOne(numbers, sign, start - 1); &#125; //进行右侧串比较 if (end &lt; length) &#123; sortOne(numbers, start + 1, length); &#125; &#125; &#125; /** * 更高效点的代码 * * @param targetArr * @return */ void sortTwo(int[] targetArr, int start, int end) &#123; int i = start + 1, j = end; int key = targetArr[start]; if (start &gt;= end) &#123; return; &#125; /*从i++和j--两个方向搜索不满足条件的值并交换 * *条件为：i++方向小于key，j--方向大于key */ while (true) &#123; print(targetArr); while (targetArr[j] &gt; key) &#123; j--; &#125; while (targetArr[i] &lt; key &amp;&amp; i &lt; j) &#123; i++; &#125; if (i &gt; j) &#123; break; &#125; swap(targetArr, i, j); if (targetArr[i] == key) &#123; j--; &#125; else &#123; i++; &#125; &#125; /*关键数据放到‘中间’*/ swap(targetArr, start, j); if (start &lt; i - 1) &#123; sortTwo(targetArr, start, i - 1); &#125; if (j + 1 &lt; end) &#123; sortTwo(targetArr, j + 1, end); &#125; &#125; /** * 方式三：减少交换次数，提高效率 * * @param targetArr */ void sortThree(int[] targetArr, int start, int end) &#123; int i = start, j = end; int key = targetArr[start]; while (i &lt; j) &#123; print(targetArr); /*按j--方向遍历目标数组，直到比key小的值为止*/ while (j &gt; i &amp;&amp; targetArr[j] &gt;= key) &#123; j--; &#125; if (i &lt; j) &#123; /*targetArr[i]已经保存在key中，可将后面的数填入*/ targetArr[i] = targetArr[j]; i++; &#125; /*按i++方向遍历目标数组，直到比key大的值为止*/ while (i &lt; j &amp;&amp; targetArr[i] &lt;= key) /*此处一定要小于等于零，假设数组之内有一亿个1，0交替出现的话，而key的值又恰巧是1的话，那么这个小于等于的作用就会使下面的if语句少执行一亿次。*/ &#123; i++; &#125; if (i &lt; j) &#123; /*targetArr[j]已保存在targetArr[i]中，可将前面的值填入*/ targetArr[j] = targetArr[i]; j--; &#125; &#125; /*此时i==j*/ targetArr[i] = key; /*递归调用，把key前面的完成排序*/ if (i &gt; start) &#123; sortThree(targetArr, start, i - 1); &#125; /*递归调用，把key后面的完成排序*/ if (j &lt; end) &#123; sortThree(targetArr, j + 1, end); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"ftp服务器搭建","slug":"devops/docker/jenkins搭建","date":"2021-08-31T12:59:00.145Z","updated":"2021-09-01T11:31:14.371Z","comments":true,"path":"2021/08/31/devops/docker/jenkins搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/08/31/devops/docker/jenkins%E6%90%AD%E5%BB%BA/","excerpt":"","text":"jenkins搭建在 macOS 和 Linux 上打开一个终端窗口。 下载 jenkinsci/blueocean 镜像并使用以下 docker run 命令将其作为 Docker 中的容器运行 ： 1mkdir /data/jenkins_home docker 安装 123456789101112131415161718192021222324docker stop jenkinsdocker rm jenkinsdocker run \\-u root \\--name jenkins \\-d \\-p 8080:8080 \\-p 50000:50000 \\jenkinsci/blueoceandocker update jenkins --restart=alwaysdocker stop jenkinsdocker rm jenkinsdocker run \\-u root \\--name jenkins \\-d \\-p 8080:8080 \\-p 50000:50000 \\jenkinsci/blueoceandocker update jenkins --restart=always 查询密码12访问 jenkins 地址/var/jenkins_home/secrets/initialAdminPassword","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://wuhaocn.github.io/tags/jenkins/"}]},{"title":"CMPP短信客户端","slug":"network/sms/CMPP短信","date":"2021-08-27T08:57:01.984Z","updated":"2021-08-27T09:45:44.843Z","comments":true,"path":"2021/08/27/network/sms/CMPP短信/","link":"","permalink":"https://wuhaocn.github.io/2021/08/27/network/sms/CMPP%E7%9F%AD%E4%BF%A1/","excerpt":"","text":"最近公司有需求采用cmpp发送短信调研了一下相关工具，发现如下测试工具挺好用分享一下。​ 工具类 [https://www.cnblogs.com/tuyile006/p/12051168.html](https://www.cnblogs.com/tuyile006/p/12051168.html) 开源源码 https://github.com/Lihuanghe/SMSGate 1.介绍CMPP2.0/CMPP3.0服务端，带数据库，可以接收第三方CMPP客户端的短信，并存入数据库，结合我的cmpp客户端服务程序，将可以实现接收第三方SP的短信并转发到网关实现发送，并将状态报告、上行短信转发给第三方SP，实现了透明网关的作用。程序界面如下：源码截图如下：如界面所示，可以直接给下游SP发MO短信。本程序已经在多个项目中使用，支持长短信，可以实现多个客户端并发连接。提供试用版DEMO下载 注意360会提示木马，请不用理会。目前程序已经升级到V5.0版本，性能更加强大稳定。V5.0版演示如下： 2.下载 下载 ： 客户端V5.0版Demo 服务端V5.0版Demo相关源码是作者的劳动成果，如有需要，请联系作者购买。 ​3.参考https://www.cnblogs.com/tuyile006/p/12051168.html​","categories":[{"name":"短信","slug":"短信","permalink":"https://wuhaocn.github.io/categories/%E7%9F%AD%E4%BF%A1/"}],"tags":[{"name":"cmpp","slug":"cmpp","permalink":"https://wuhaocn.github.io/tags/cmpp/"}]},{"title":"ftp服务器搭建","slug":"devops/docker/ftp服务搭建","date":"2021-08-24T07:05:26.767Z","updated":"2021-08-31T08:18:33.466Z","comments":true,"path":"2021/08/24/devops/docker/ftp服务搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/08/24/devops/docker/ftp%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1.拉取 镜像12docker pull fauria/vsftpd 2.启动容器123456789101112docker pull fauria/vsftpdmkdir /data/ftpdocker stop vsftpddocker rm vsftpddocker run -d -v /data/ftp:/home/vsftpd -p 2120:20 -p 2121:21 -p 21100-21110:21100-21110 -e FTP_USER=urcs -e FTP_PASS=urcs@2018 -e PASV_ADDRESS=10.10.208.194 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpddocker ps 3. 进入容器123456789docker exec -i -t vsftpd bash 进去dockervi /etc/vsftpd/virtual_users.txt 编辑配置文件写入用户跟密码mkdir /home/vsftpd/user 建立新用户文件夹/usr/bin/db_load -T -t hash -f /etc/vsftpd/virtual_users.txt /etc/vsftpd/virtual_users.db 写入数据库docker restart +(虚拟机运行的 imageId) 重启服务","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"ftp","slug":"ftp","permalink":"https://wuhaocn.github.io/tags/ftp/"}]},{"title":"nexus服务搭建","slug":"devops/docker/nexus服务搭建","date":"2021-08-24T07:05:26.756Z","updated":"2021-08-24T07:10:16.393Z","comments":true,"path":"2021/08/24/devops/docker/nexus服务搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/08/24/devops/docker/nexus%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/","excerpt":"","text":"nexus安装123456rm -rf /home/wuhao/nexusmkdir /home/wuhao/nexusdocker stop nexusdocker rm nexusdocker run -d --name nexus -p 5260:8081 -p 5261:8082 -p 5262:8083 -p 5263:8084 -p 5264:5000 -v /home/wuhao/nexus:/var/nexus-data sonatype/nexus3docker logs -f nexus 配置1234567891011121314http://10.10.208.193:5260/bash-4.0$ cd /nexus-data/bash-4.0$ lsadmin.password blobs cache db elasticsearch etc generated-bundles instances javaprefs kar keystores lock log orient port restore-from-backup tmpbash-4.0$ cat admin.password51a030af-f7ab-43d5-875e-3c2775dbae2c登录进去修改密码~~注意修改密码之后，提示是否开启anonymous模式，这个要勾选，否则public需要密码访问","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"nexus","slug":"nexus","permalink":"https://wuhaocn.github.io/tags/nexus/"}]},{"title":"数据环境","slug":"devops/docker/数据环境","date":"2021-08-24T07:00:25.063Z","updated":"2021-08-31T11:45:24.029Z","comments":true,"path":"2021/08/24/devops/docker/数据环境/","link":"","permalink":"https://wuhaocn.github.io/2021/08/24/devops/docker/%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/","excerpt":"","text":"docker部署数据中间件 docker部署开发环境数据中间件 常见工具命令123docker rm `docker ps -a -q`docker start $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2)docker stop $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2) mysql1234567891011121314151617181920212223# mysql5.6.40docker stop mysql.5.6.40docker rm mysql.5.6.40docker run --privileged=true --name mysql.5.6.40 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql.5.6.40 --restart=always# mysql3336docker stop mysql3336docker rm mysql3336docker run --privileged=true --name mysql3336 -p 3336:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql3336 --restart=always# mysql3337docker stop mysql3337docker rm mysql3337docker run --privileged=true --name mysql3337 -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql3337 --restart=always# mysql5.7.19docker stop mysql5.7.19docker rm mysql5.7.19docker run --name mysql5.7.19 --privileged=true -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.7.19 redis12345678910111213141516171819202122232425262728293031# redis 单机docker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:3.2 redis-server --port 6379 --requirepass &quot;urcs@2021&quot;docker update redis-6379 --restart=alwaysdocker stop redis-6380docker rm redis-6380docker run -d -p 6380:6380 --name redis-6380 --privileged=true redis:3.2 redis-server --port 6380docker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:3.2 redis-server --port 6379docker update redis-6379 --restart=alwaysdocker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:6.2 redis-server --port 6379docker update redis-6379 --restart=always# sentinel在当前目录配置文件vim sentinel.confsentinel monitor mymaster 10.10.220.120 6379 1启动sentineldocker stop redis-sentinel-26379docker rm redis-sentinel-26379docker run -d -p 26379:26379 -v /Users/wuhao/data/soft/redis/sentinel.conf:/usr/local/bin/redis-conf/sentinel.conf --name redis-sentinel-26379 redis:3.2 redis-sentinel /usr/local/bin/redis-conf/sentinel.conf --port 26379docker logs -f redis-sentinel-26379 hbase12345678910拉取镜像docker pull harisekhon/hbase:1.2运行镜像docker stop hbase1.2docker rm hbase1.2docker run -d -h hbase --privileged=true -p 2181:2181 -p 18080:8080 -p 18085:8085 -p 19090:9090 -p 19095:9095 -p 16000:16000 -p 16020:16020 -p 16010:16010 -p 16201:16201 -p 16301:16301 --name hbase1.2 harisekhon/hbase:1.2docker update hbase1.2 --restart=alwaysdocker exec -it hbase bashdocker run -d -h hbase --privileged=true -p 2181:2181 -p 18080:8080 -p 18085:8085 -p 19090:9090 -p 19095:9095 -p 16000:16000 -p 16010:16010 -p 16201:16201 -p 16301:16301 --name hbase1.2 harisekhon/hbase:1.2 zk1234567docker pull zookeeper:3.5docker run --name zookeeper3.5 -p 7998:2181 -d zookeeper:3.5docker stop zookeeperdocker rm zookeeperdocker run --privileged=true -d --name zookeeper --publish 2181:2181 -d zookeeper:3.5docker update zookeeper --restart=always kafka1234567891011docker pull wurstmeister/kafka:2.11-1.1.1docker stop kafka2.11docker rm kafka2.11docker run \\--env KAFKA_BROKER_ID=0 \\--env KAFKA_ZOOKEEPER_CONNECT=172.16.106.78:7998 \\--env KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://172.16.106.78:9092 \\--env KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ --privileged=true -d --name kafka2.11 -p 9092:9092 \\wurstmeister/kafka:2.11-1.1.1 fastdfs123456789sudo docker stop trakcersudo docker rm trakcersudo docker run -d --privileged=true -p 22122:22122 --name trakcer --net=host 10.10.208.193:5000/urcs/fastdfs_tracker:4.08 trackersudo docker update trakcer --restart=alwayssudo docker stop storagesudo docker rm storagesudo docker run -d --privileged=true -p 23000:23000 -p 8888:8888 --name storage --net=host --env TRACKER_SERVER=172.16.106.78:22122 10.10.208.193:5000/urcs/fastdfs_storage:4.08 storagesudo docker update storage --restart=always es123456docker pull docker.elastic.co/elasticsearch/elasticsearch:6.0.0docker stop elasticsearchdocker rm elasticsearchdocker run -d --name elasticsearch \\-p 9200:9200 -p 9300:9300 \\-e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:6.0.0 1234567docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.2docker stop elasticsearchdocker rm elasticsearchdocker run -d --name elasticsearch \\-p 9200:9200 -p 9300:9300 \\-e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:6.3.2docker update elasticsearch --restart=always kibana123456docker pull elastic/kibana:6.0.0//做了定制化设置docker stop kibana6.0.0docker rm kibana6.0.0docker run -d --name kibana6.0.0 -e ELASTICSEARCH_URL=http://172.29.203.16:9200 -p 5601:5601 elastic/kibana:6.0.0 1234567docker pull elastic/kibana:6.3.2docker stop kibana6.3.2docker rm kibana6.3.2docker run -d --name kibana6.3.2 -e ELASTICSEARCH_URL=http://10.40.1.180:9200 -p 5601:5601 elastic/kibana:6.3.2docker update kibana6.3.2 --restart=always spark12docker pull sequenceiq/spark:1.6.0 docker run -it -p 8088:8088 -p 8042:8042 -h sandbox sequenceiq/spark:1.6.0 bash git123456789101112131415161718192021获取镜像docker pull beginor/gitlab-ce:11.3.0-ce.0运行通常会将 GitLab 的配置 (etc) 、 日志 (log) 、数据 (data) 放到容器之外， 便于日后升级， 因此请先准备这三个目录。sudo mkdir -p /mnt/sda1/gitlab/etcsudo mkdir -p /mnt/sda1/gitlab/logsudo mkdir -p /mnt/sda1/gitlab/data准备好这三个目录之后， 就可以开始运行 Docker 镜像了。 我的建议是使用unless-stopped 作为重启策略， 因为这样可以手工停止容器， 方便维护。完整的运行命令如下：docker run \\ --detach \\ --publish 8443:443 \\ --publish 8080:80 \\ --name gitlab \\ --restart unless-stopped \\ --volume /mnt/sda1/gitlab/etc:/etc/gitlab \\ --volume /mnt/sda1/gitlab/log:/var/log/gitlab \\ --volume /mnt/sda1/gitlab/data:/var/opt/gitlab \\ beginor/gitlab-ce:11.3.0-ce.0 ftp123456docker pull fauria/vsftpdmkdir /home/ultra/ftpdocker stop vsftpddocker rm vsftpddocker run -d -v /home/ultra/ftp:/home/vsftpd -p 2120:20 -p 2121:21 -p 21100-21110:21100-21110 -e FTP_USER=urcs -e FTP_PASS=urcs@2018 -e PASV_ADDRESS=10.10.208.194 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpddocker ps speed123docker stop speedtestdocker rm speedtestdocker run -d --name speedtest -p 8888:80 adolfintel/speedtest:latest","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"SCTP概要","slug":"network/protocol/SCTP概要","date":"2021-08-04T06:25:13.672Z","updated":"2021-08-04T06:25:13.672Z","comments":true,"path":"2021/08/04/network/protocol/SCTP概要/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/protocol/SCTP%E6%A6%82%E8%A6%81/","excerpt":"","text":"1.简介SCTP(Stream Control Transmission Protocol),流控制传输协议,和UDP，TCP类似TCP是一种面向连接的协议，提供可靠传输，确保数据有序发送；UDP是一种面向消息的协议，不能确保数据有序发送SCTP是后来引入的一种新的协议，提供了和TCP一样的可靠、有序的数据传输功能，同时却能和UDP一样面对消息的方式来进行操作，保护消息边界，有下面一些特性 2.SCTP特性 多宿主（Multi-Homing） 多流（Multi-streaming） 初始化保护（Initiation protection） 消息分帧（Message framing） 可配置的无序发送（Configurable unordered delivery） 平滑关闭（Graceful shutdown） ​ 2.1 多宿主SCTP里面引入了联合（Association）的概念TCP连接是在两个主机的单个接口之间建立的SCTP可以把多条路径合并到一个联合中，数据可以在任意一个连接路径上进行传输 2.2 多流 SCTP可以在一个联合中支持多流机制，每个流（stream）都是独立的。每个流都有各自的编号，编码在SCTP报文中阻塞的流不会影响同一联合中的其他流，可以并行进行传输 2.3 初始化保护 TCP中的三次握手机制会被利用来进行DoS（Denial of Service）攻击，通过发送大量的SYN报文最终耗尽服务器的资源SCTP通过引入4次握手机制来避免这种场景：服务器的INIT-ACK中会包含cookie（标识这个连接的唯一上下文）； 客户端使用这个cookie来进行响应。服务器收到这个响应后，才为这个连接分配资源；为了解决4次握手机制带来的时延，SCTP协议还允许在COOKIE-ECHO和COOKIE-ACK报文中传输数据包消息分帧TCP协议是按照字节流的方式进行数据传输的，并不存在消息边界，比如说音频视频都可以通过流的方式进行传递；UDP使用的是消息分帧，发端多大的数据包，收端收到的数据包也是这么大；可配置的无序发送TCP能确保数据按照次序发送；UDP无法保证消息有序；SCTP中也可以配置成接受无序的消息；这样的通信方式对于面向消息的传输非常有用，因为每个消息都是各自独立的，次序并不重要。平滑关闭TCP和SCTP都是基于连接的协议，完成传输后都需要有一个拆除连接的过程。TCP中连接的删除是半关闭的，服务的某一端可以关闭自己这端的socket，但是可以继续接受数据。SCTP协议设计的时候考虑这种半关闭的状态实际上很少使用，所以简化了关闭的过程，一旦某一端发起了连接拆除，对等的两端都关闭。 版权声明：本文为博主原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接和本声明。本文链接：https://blog.csdn.net/qq_34709713/article/details/106511096","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"NGAP","slug":"NGAP","permalink":"https://wuhaocn.github.io/tags/NGAP/"}]},{"title":"DPDK-架构解析","slug":"network/dpdk/DPDK-架构解析","date":"2021-08-04T06:25:13.670Z","updated":"2021-08-04T06:25:13.670Z","comments":true,"path":"2021/08/04/network/dpdk/DPDK-架构解析/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/dpdk/DPDK-%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/","excerpt":"","text":"目录DPDK-架构解析 目录 前文列表 DPDK 架构 内核态模块 IGB_UIO KNI PMD DPDK Lib（核心部件库） 组件代码 平台相关模块 Classify 库 QoS 库前文列表《DPDK — 安装部署》《DPDK — 数据平面开发技术》DPDK 架构 内核态模块： IGB_UIO： KNI 用户态函数库以及网卡驱动程序： 用户态轮询模式的网卡驱动程序（PMD Driver） 核心部件库（Core Libraries） 操作系统平台相关模块（Platform） QoS 库 报文转发分类算法库（Classify） 用户应用程序可以应用以上函数库以及驱动支持，来实现完全内核旁路的数据面转发应用程序，例如：OVS-DPDK。 EAL（Environment Abstraction Layer，环境抽象层）：为应用提供了一个通用接口，隐藏了与底层库与设备打交道的相关细节。EAL 实现了 DPDK 运行的初始化工作，基于大页表的内存分配，多核亲缘性设置，原子和锁操作，并将 PCI 设备地址映射到用户空间，方便应用程序访问。 Buffer Manager API：通过预先从 EAL 上分配固定大小的多个内存对象，避免了在运行过程中动态进行内存分配和回收，以此来提高效率，用于数据包 Buffer 的管理。 Queue/Ring Manager API：以高效的方式实现了无锁的 FIFO 环形队列，适用于一个生产者多个消费者、一个消费者多个生产者模型。支持批量无锁操作，可避免锁冲突导致的等待。 Packet Flow Classification API：通过 Intel SSE 基于多元组的方式实现了高效的 HASH 算法，以便快速对数据包进行分类处理。该 API 一般用于路由查找过程中的最长前缀匹配。此外，安全产品场景中，可以根据 DataFlow 五元组来标记不同的用户。 PMD（Poll Mode Library）：则实现了 Intel 1GbE、10GbE 和 40GbE 网卡下基于轮询收发包的工作模式，大大加速网卡收发包性能。 内核态模块IGB_UIO《DPDK — IGB_UIO，与 UIO Framework 进行交互的内核模块》 KNIKNI（Kernel NIC Interface，内核网卡接口），是 DPDK 允许用户态和内核态交换报文的解决方案，模拟了一个虚拟的网口，提供 DPDK 应用程序和 Linux 内核之间通讯没接。即 KNI 接口允许报文从用户态接收后转发到 Linux 内核协议栈中去。虽然 DPDK 的高速转发性能很出色，但是也有自己的一些缺点，比如没有标准协议栈就是其中之一，当然也可能当时设计时就将没有将协议栈考虑进去，毕竟协议栈需要将报文转发处理，可能会使处理报文的能力大大降低。上图是 KNI 的 mbuf 的使用流程，也可以看出报文的流向，因为报文在代码中其实就是一个个内存指针。其中 rx_q 右边是用户态，左边是内核态。最后通过调用 netif_rx 将报文送入 Linux 内核协议栈，这其中需要将 DPDK 的 mbuf 转换成标准的 skb_buf 结构体。当 Linux 内核向 KNI 端口发送报文时，调用回调函数 kni_net_tx，然后报文经过转换之后发送到端口上。 PMD《DPDK — PMD，DPDK 的核心优化》 DPDK Lib（核心部件库）核心部件库（Core Libraries）是 DPDK 面向用户态协议栈应用程序员开发的模块。 EAL（Environment Abstraction Layer，环境抽象层）：对 DPDK 的运行环境（e.g. Linux 操作系统）进行初始化，包括：HugePage 内存分配、内存/缓冲区/队列分配、原子性无锁操作、NUMA 亲和性、CPU 绑定等，并通过 UIO 或 VFIO 技术将 PCI/PCIe 设备地址映射到用户态，方便了用户态的 DPDK 应用程序调用。同时为应用程序提供了一个通用接口，隐藏了其与底层库以及设备打交道的相关细节。 MALLOC（堆内存管理组件）：为 DPDK 应用程序提供从 HugePage 内分配堆内存的接口。当需要为 SKB（Socket Buffer，本质是若干个数据包的缓存区）分配大量的小块内存时（如：分配用于存储 Buffer descriptor table 中每个表项指针的内存）可以调用该接口。由于堆内存是从 HugePage 内存分配的，所以可以减少 TLB 缺页。 注：堆，是由开发人员主动分配和释放的存储空间， 若开发人员不释放，则程序结束时由 OS 回收，分配方式类似于链表；与堆不同，栈，是由操作系统自动分配和释放的存储空间 ，用于存放函数的参数值、局部变量等，其操作方式类似于数据结构中的栈。 MBUF（网络报文缓存块管理组件）：为 DPDK 应用程序提供创建和释放用于存储数据报文信息的缓存块的接口。提供了两种类型的 MBUF，一种用于存储一般信息，一种用于存储实际的报文数据。这些 MBUF 存储在一个内存池中。 MEMPOOL（内存池管理组件）：为 DPDK 应用程序和其它组件提供分配内存池的接口，内存池是一个由固定大小的多个内存块组成的内存容器，可用于存储不同的对像实体，如：数据报文缓存块等。内存池由内存池的名称（一个字符串）进行唯一标识，它由一个 Ring 缓冲区和一组本地缓存队列组成，每个 CPU Core 优先从自身的缓存队列中分配内存块，当本地缓存队列减少到一定程度时，开始从内存环缓冲区中申请内存块来进行补充。 RING（环缓冲区管理组件）：为 DPDK 应用程序和其它组件提供一个无锁的多生产者多消费者 FIFO 队列。 NOTE：DPDK 基于 Linux 内核的无锁环形缓冲 kfifo 实现了一套自己的无锁机制。支持单生产者入列/单消费者出列和多生产者入列/多消费者出列操作，在数据传输的时候，降低性能的同时还能保证数据的同步。 TIMER（定时器组件）：提供一些异步周期执行的接口（也可以只执行一次），可以指定某个函数在规定时间内的异步执行，就像 LIBC 中的 timer 定时器。但是这里的定时器需要 DPDK 应用程序在主循环中周期内调用 rte_timer_manage 来使能定时器，使用起来不那么方便。TIMER 的时间参考来自 EAL 层提供的时间接口。 注：除了以上六个核心组件外，DPDK 还提供以下功能： 以太网轮询模式驱动（PMD）架构：把以太网驱动从内核移到应用层，采用同步轮询机制而不是内核态的异步中断机制来提高报文的接收和发送效率。 报文转发算法支持：Hash 库和 LPM 库为报文转发算法提供支持。 网络协议定义和相关宏定义：基于 FreeBSD IP 协议栈的相关定义，如：TCP、UDP、SCTP 等协议头定义。 报文 QoS 调度库：支持随机早检测、流量整形、严格优先级和加权随机循环优先级调度等相关 QoS 功能。 内核网络接口库（KNI）：提供一种 DPDK 应用程序与内核协议栈的通信的方法，类似 Linux 的 TUN/TAP 接口，但比 TUN/TAP 接口效率高。每个物理网口可以虚拟出多个 KNI 接口。组件代码 注： RTE：Run-Time Environment EAL：Environment Abstraction Layer PMD：Poll-Mode Driver 核心部件库对应的 DPDK 核心组件实现： Memory Manager（librte_malloc，堆内存管理器）：提供一组 API，用于从 HugePages 内存创建的 memzones 中分配内存，而不是在堆中分配。这有助于改善 Linux 用户空间环境下典型的从堆中大量分配 4KB 页面而容易引起 TLB 不命中。 Memory Pool Manager（librte_mempool，内存池管理器）：内存池管理器负责分配的内存中的 Pool 对象。Pool 由名称唯一标识，并使用一个 Ring 来存储空闲对象。它提供了其他一些可选的服务，例如：每个 CPU Core 的对象缓存和对齐方式帮助，以确保将填充的对象在所有内存通道上得到均匀分布。 Ring Manager（librte_ring，环形队列管理器）：在一个大小有限的页表中，Ring 数据结构提供了一个无锁的多生产者-多消费者 FIFO API。相较于无锁队列，它有一些的优势，如：更容易实现，适应于大容量操作，而且速度更快。 一个 Ring 可以在 Memory Pool Manager 中被使用，也可以用于不同 CPU Core 或 Processor 之间作为通用的通信机制。 Network Packet Buffer Management（librte_mbuf，网络报文缓冲区管理）：提供一组 API，用于分配、释放和操作 MBUFs（数据报文缓冲区），DPDK 应用程序中可以使用这些缓存区来存储消息以及报文数据。 Timer Manager（librte_timer，定时器管理）：为 DPDK 应用程序的执行单元提供了定时服务，支持以异步的方式执行函数。定时器可以设置周期调用，也可以设置为只调用一次。DPDK 应用程序可以使用 EAL 提供的 HPET 接口来获取高精度时钟的引用，并且能在每个 Core 上根据需要进行初始化。 代码目录： 平台相关模块平台相关模块（Platform）包括 KNI、POWER（能耗管理）以及 IVSHMEM 接口。 KNI：主要通过 Linux 内核中的 kni.ko 模块将数据报文从用户态传递给内核态协议栈处理，以便常规的用户进程（e.g. Container）可以使用 Linux 内核协议栈传统的 Socket 接口对相关报文进行处理。 POWER：提供了一些 API，让 DPDK 应用程序可以根据收包速率动态调整 CPU 频率或让 CPU 进入不同的休眠状态。 IVSHMEM：模块提供了虚拟机与虚拟机之间，或者虚拟机与主机之间的零拷贝共享内存机制。当 DPDK 应用程序运行时，IVSHMEM 模块会调用 Core Libraries 的 API，把几个 HugePage 内存映射为一个 IVSHMEM 设备池，并通过参数传递给 QEMU，这样，就实现了虚拟机之间的零拷贝内存共享。Classify 库支持精确匹配（Exact Match）、最长匹配（LPM）和通配符匹配（ACL）数据报文，并提供常用的包处理的查表操作。QoS 库提供网络服务质量相关的组件，如：限速（Meter）和调度（Scheduler）。","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"}]},{"title":"一文看懂DPDK","slug":"network/dpdk/一文看懂DPDK","date":"2021-08-04T06:25:13.670Z","updated":"2021-08-04T06:25:13.671Z","comments":true,"path":"2021/08/04/network/dpdk/一文看懂DPDK/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/dpdk/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82DPDK/","excerpt":"","text":"大纲： 一、 网络IO的处境和趋势 二、 Linux + x86网络IO瓶颈 三、 DPDK的基本原理 四、 DPDK的基石UIO 五、 DPDK核心优化：PMD 六、 DPDK的高性能代码实现 七、 DPDK生态 一、网络IO的处境和趋势从我们用户的使用就可以感受到网速一直在提升，而网络技术的发展也从1GE/10GE/25GE/40GE/100GE的演变，从中可以得出单机的网络IO能力必须跟上时代的发展。1.传统的电信领域IP层及以下，例如路由器、交换机、防火墙、基站等设备都是采用硬件解决方案。基于专用网络处理器（NP），有基于FPGA，更有基于ASIC的。但是基于硬件的劣势非常明显，发生Bug不易修复，不易调试维护，并且网络技术一直在发展，例如2G/3G/4G/5G等移动技术的革新，这些属于业务的逻辑基于硬件实现太痛苦，不能快速迭代。传统领域面临的挑战是急需一套软件架构的高性能网络IO开发框架。2.云的发展私有云的出现通过网络功能虚拟化（NFV）共享硬件成为趋势，NFV的定义是通过标准的服务器、标准交换机实现各种传统的或新的网络功能。急需一套基于常用系统和标准服务器的高性能网络IO开发框架。3.单机性能的飙升网卡从1G到100G的发展，CPU从单核到多核到多CPU的发展，服务器的单机能力通过横行扩展达到新的高点。但是软件开发却无法跟上节奏，单机处理能力没能和硬件门当户对，如何开发出与时并进高吞吐量的服务，单机百万千万并发能力。即使有业务对QPS要求不高，主要是CPU密集型，但是现在大数据分析、人工智能等应用都需要在分布式服务器之间传输大量数据完成作业。这点应该是我们互联网后台开发最应关注，也最关联的。 二、Linux + x86网络IO瓶颈在数年前曾经写过《网卡工作原理及高并发下的调优》一文，描述了Linux的收发报文流程。根据经验，在C1（8核）上跑应用每1W包处理需要消耗1%软中断CPU，这意味着单机的上限是100万PPS（Packet Per Second）。从TGW（Netfilter版）的性能100万PPS，AliLVS优化了也只到150万PPS，并且他们使用的服务器的配置还是比较好的。假设，我们要跑满10GE网卡，每个包64字节，这就需要2000万PPS（注：以太网万兆网卡速度上限是1488万PPS，因为最小帧大小为84B《Bandwidth, Packets Per Second, and Other Network Performance Metrics》），100G是2亿PPS，即每个包的处理耗时不能超过50纳秒。而一次Cache Miss，不管是TLB、数据Cache、指令Cache发生Miss，回内存读取大约65纳秒，NUMA体系下跨Node通讯大约40纳秒。所以，即使不加上业务逻辑，即使纯收发包都如此艰难。我们要控制Cache的命中率，我们要了解计算机体系结构，不能发生跨Node通讯。从这些数据，我希望可以直接感受一下这里的挑战有多大，理想和现实，我们需要从中平衡。问题都有这些1.传统的收发报文方式都必须采用硬中断来做通讯，每次硬中断大约消耗100微秒，这还不算因为终止上下文所带来的Cache Miss。2.数据必须从内核态用户态之间切换拷贝带来大量CPU消耗，全局锁竞争。3.收发包都有系统调用的开销。4.内核工作在多核上，为可全局一致，即使采用Lock Free，也避免不了锁总线、内存屏障带来的性能损耗。5.从网卡到业务进程，经过的路径太长，有些其实未必要的，例如netfilter框架，这些都带来一定的消耗，而且容易Cache Miss。 三、DPDK的基本原理从前面的分析可以得知IO实现的方式、内核的瓶颈，以及数据流过内核存在不可控因素，这些都是在内核中实现，内核是导致瓶颈的原因所在，要解决问题需要绕过内核。所以主流解决方案都是旁路网卡IO，绕过内核直接在用户态收发包来解决内核的瓶颈。Linux社区也提供了旁路机制Netmap，官方数据10G网卡1400万PPS，但是Netmap没广泛使用。其原因有几个：1.Netmap需要驱动的支持，即需要网卡厂商认可这个方案。2.Netmap仍然依赖中断通知机制，没完全解决瓶颈。3.Netmap更像是几个系统调用，实现用户态直接收发包，功能太过原始，没形成依赖的网络开发框架，社区不完善。那么，我们来看看发展了十几年的DPDK，从Intel主导开发，到华为、思科、AWS等大厂商的加入，核心玩家都在该圈子里，拥有完善的社区，生态形成闭环。早期，主要是传统电信领域3层以下的应用，如华为、中国电信、中国移动都是其早期使用者，交换机、路由器、网关是主要应用场景。但是，随着上层业务的需求以及DPDK的完善，在更高的应用也在逐步出现。DPDK旁路原理：图片引自Jingjing Wu的文档《Flow Bifurcation on Intel® Ethernet Controller X710/XL710》左边是原来的方式数据从 网卡 -&gt; 驱动 -&gt; 协议栈 -&gt; Socket接口 -&gt; 业务右边是DPDK的方式，基于UIO（Userspace I/O）旁路数据。数据从 网卡 -&gt; DPDK轮询模式-&gt; DPDK基础库 -&gt; 业务用户态的好处是易用开发和维护，灵活性好。并且Crash也不影响内核运行，鲁棒性强。DPDK支持的CPU体系架构：x86、ARM、PowerPC（PPC）DPDK支持的网卡列表：https://core.dpdk.org/supported/，我们主流使用Intel 82599（光口）、Intel x540（电口） 四、DPDK的基石UIO为了让驱动运行在用户态，Linux提供UIO机制。使用UIO可以通过read感知中断，通过mmap实现和网卡的通讯。UIO原理：要开发用户态驱动有几个步骤：1.开发运行在内核的UIO模块，因为硬中断只能在内核处理2.通过/dev/uioX读取中断3.通过mmap和外设共享内存 五、DPDK核心优化：PMDDPDK的UIO驱动屏蔽了硬件发出中断，然后在用户态采用主动轮询的方式，这种模式被称为PMD（Poll Mode Driver）。UIO旁路了内核，主动轮询去掉硬中断，DPDK从而可以在用户态做收发包处理。带来Zero Copy、无系统调用的好处，同步处理减少上下文切换带来的Cache Miss。运行在PMD的Core会处于用户态CPU100%的状态网络空闲时CPU长期空转，会带来能耗问题。所以，DPDK推出Interrupt DPDK模式。Interrupt DPDK：图片引自David Su/Yunhong Jiang/Wei Wang的文档《Towards Low Latency Interrupt Mode DPDK》它的原理和NAPI很像，就是没包可处理时进入睡眠，改为中断通知。并且可以和其他进程共享同个CPU Core，但是DPDK进程会有更高调度优先级。 六、DPDK的高性能代码实现1.采用HugePage减少TLB Miss默认下Linux采用4KB为一页，页越小内存越大，页表的开销越大，页表的内存占用也越大。CPU有TLB（Translation Lookaside Buffer）成本高所以一般就只能存放几百到上千个页表项。如果进程要使用64G内存，则64G/4KB=16000000（一千六百万）页，每页在页表项中占用16000000 * 4B=62MB。如果用HugePage采用2MB作为一页，只需64G/2MB=2000，数量不在同个级别。而DPDK采用HugePage，在x86-64下支持2MB、1GB的页大小，几何级的降低了页表项的大小，从而减少TLB-Miss。并提供了内存池（Mempool）、MBuf、无锁环（Ring）、Bitmap等基础库。根据我们的实践，在数据平面（Data Plane）频繁的内存分配释放，必须使用内存池，不能直接使用rte_malloc，DPDK的内存分配实现非常简陋，不如ptmalloc。2.SNA（Shared-nothing Architecture）软件架构去中心化，尽量避免全局共享，带来全局竞争，失去横向扩展的能力。NUMA体系下不跨Node远程使用内存。3.SIMD（Single Instruction Multiple Data）从最早的mmx/sse到最新的avx2，SIMD的能力一直在增强。DPDK采用批量同时处理多个包，再用向量编程，一个周期内对所有包进行处理。比如，memcpy就使用SIMD来提高速度。SIMD在游戏后台比较常见，但是其他业务如果有类似批量处理的场景，要提高性能，也可看看能否满足。4.不使用慢速API这里需要重新定义一下慢速API，比如说gettimeofday，虽然在64位下通过vDSO已经不需要陷入内核态，只是一个纯内存访问，每秒也能达到几千万的级别。但是，不要忘记了我们在10GE下，每秒的处理能力就要达到几千万。所以即使是gettimeofday也属于慢速API。DPDK提供Cycles接口，例如rte_get_tsc_cycles接口，基于HPET或TSC实现。在x86-64下使用RDTSC指令，直接从寄存器读取，需要输入2个参数，比较常见的实现： 1234567891011static inline uint64_trte_rdtsc(void)&#123; uint32_t lo, hi; __asm__ __volatile__ ( &quot;rdtsc&quot; : &quot;=a&quot;(lo), &quot;=d&quot;(hi) ); return ((unsigned long long)lo) | (((unsigned long long)hi) &lt;&lt; 32);&#125; 这么写逻辑没错，但是还不够极致，还涉及到2次位运算才能得到结果，我们看看DPDK是怎么实现： 12345678910111213141516static inline uint64_trte_rdtsc(void)&#123; union &#123; uint64_t tsc_64; struct &#123; uint32_t lo_32; uint32_t hi_32; &#125;; &#125; tsc; asm volatile(&quot;rdtsc&quot; : &quot;=a&quot; (tsc.lo_32), &quot;=d&quot; (tsc.hi_32)); return tsc.tsc_64;&#125; 巧妙的利用C的union共享内存，直接赋值，减少了不必要的运算。但是使用tsc有些问题需要面对和解决 CPU亲和性，解决多核跳动不精确的问题 内存屏障，解决乱序执行不精确的问题 禁止降频和禁止Intel Turbo Boost，固定CPU频率，解决频率变化带来的失准问题 5.编译执行优化 分支预测现代CPU通过pipeline、superscalar提高并行处理能力，为了进一步发挥并行能力会做分支预测，提升CPU的并行能力。遇到分支时判断可能进入哪个分支，提前处理该分支的代码，预先做指令读取编码读取寄存器等，预测失败则预处理全部丢弃。我们开发业务有时候会非常清楚这个分支是true还是false，那就可以通过人工干预生成更紧凑的代码提示CPU分支预测成功率。123456789101112131415#pragma once#if !__GLIBC_PREREQ(2, 3)# if !define __builtin_expect# define __builtin_expect(x, expected_value) (x)# endif#endif#if !defined(likely)#define likely(x) (__builtin_expect(!!(x), 1))#endif#if !defined(unlikely)#define unlikely(x) (__builtin_expect(!!(x), 0))#endif CPU Cache预取Cache Miss的代价非常高，回内存读需要65纳秒，可以将即将访问的数据主动推送的CPU Cache进行优化。比较典型的场景是链表的遍历，链表的下一节点都是随机内存地址，所以CPU肯定是无法自动预加载的。但是我们在处理本节点时，可以通过CPU指令将下一个节点推送到Cache里。API文档：https://doc.dpdk.org/api/rte__prefetch_8h.html 12345678static inline void rte_prefetch0(const volatile void *p)&#123; asm volatile (&quot;prefetcht0 %[p]&quot; : : [p] &quot;m&quot; (*(const volatile char *)p));&#125;#if !defined(prefetch)#define prefetch(x) __builtin_prefetch(x)#endif …等等3) 内存对齐内存对齐有2个好处：l 避免结构体成员跨Cache Line，需2次读取才能合并到寄存器中，降低性能。结构体成员需从大到小排序和以及强制对齐。参考《Data alignment: Straighten up and fly right》 1#define __rte_packed __attribute__((__packed__)) l 多线程场景下写产生False sharing，造成Cache Miss，结构体按Cache Line对齐 1234567#ifndef CACHE_LINE_SIZE#define CACHE_LINE_SIZE 64#endif#ifndef aligined#define aligined(a) __attribute__((__aligned__(a)))#endif 常量优化常量相关的运算的编译阶段完成。比如C++11引入了constexp，比如可以使用GCC的__builtin_constant_p来判断值是否常量，然后对常量进行编译时得出结果。举例网络序主机序转换123#define rte_bswap32(x) ((uint32_t)(__builtin_constant_p(x) ? \\ rte_constant_bswap32(x) : \\ rte_arch_bswap32(x))) 其中rte_constant_bswap32的实现12345#define RTE_STATIC_BSWAP32(v) \\ ((((uint32_t)(v) &amp; UINT32_C(0x000000ff)) &lt;&lt; 24) | \\ (((uint32_t)(v) &amp; UINT32_C(0x0000ff00)) &lt;&lt; 8) | \\ (((uint32_t)(v) &amp; UINT32_C(0x00ff0000)) &gt;&gt; 8) | \\ (((uint32_t)(v) &amp; UINT32_C(0xff000000)) &gt;&gt; 24)) 5）使用CPU指令现代CPU提供很多指令可直接完成常见功能，比如大小端转换，x86有bswap指令直接支持了。12345678static inline uint64_t rte_arch_bswap64(uint64_t _x)&#123; register uint64_t x = _x; asm volatile (&quot;bswap %[x]&quot; : [x] &quot;+r&quot; (x) ); return x;&#125; 这个实现，也是GLIBC的实现，先常量优化、CPU指令优化、最后才用裸代码实现。毕竟都是顶端程序员，对语言、编译器，对实现的追求不一样，所以造轮子前一定要先了解好轮子。Google开源的cpu_features可以获取当前CPU支持什么特性，从而对特定CPU进行执行优化。高性能编程永无止境，对硬件、内核、编译器、开发语言的理解要深入且与时俱进。七、DPDK生态对我们互联网后台开发来说DPDK框架本身提供的能力还是比较裸的，比如要使用DPDK就必须实现ARP、IP层这些基础功能，有一定上手难度。如果要更高层的业务使用，还需要用户态的传输协议支持。不建议直接使用DPDK。目前生态完善，社区强大（一线大厂支持）的应用层开发项目是FD.io（The Fast Data Project），有思科开源支持的VPP，比较完善的协议支持，ARP、VLAN、Multipath、IPv4/v6、MPLS等。用户态传输协议UDP/TCP有TLDK。从项目定位到社区支持力度算比较靠谱的框架。腾讯云开源的F-Stack也值得关注一下，开发更简单，直接提供了POSIX接口。Seastar也很强大和灵活，内核态和DPDK都随意切换，也有自己的传输协议Seastar Native TCP/IP Stack支持，但是目前还未看到有大型项目在使用Seastar，可能需要填的坑比较多。我们GBN Gateway项目需要支持L3/IP层接入做Wan网关，单机20GE，基于DPDK开发。","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"}]},{"title":"5G网络","slug":"network/5G移动网络","date":"2021-08-04T06:25:13.668Z","updated":"2021-08-24T07:20:36.540Z","comments":true,"path":"2021/08/04/network/5G移动网络/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/5G%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/","excerpt":"","text":"5G网络概述1.网络架构 5G网络的主要涵盖基站(gNB)、承载网、5G核心网(5GC)、IMS核心网(IMS)、5G消息(RCS)、边缘计算(MEC)等网络功能模块,借助上述网路功能模块，提供无线射频信号的收发、网路流量的转发、短信、音视频电话、富媒体消息、MAAP消息业务(类似微信公众号+小程序)等。下图为5G网络架构图。下文分别针对设备接入层、接入网、5G核心网、IMS网络、5G消息等模块进行介绍。 设备接入（5G手机）： 设备网络通信模块主要是基于芯片，市面上分为高通、海思、天玑等几大类。主流手机小米10、华为P40、华为Mate、荣耀30等之后型号基本都支持。 接入网（gNB）： gNB主要分为宏基站与微基站（室内站），国内宏基站以华为、中兴、大唐为主，以华为基站为例包含AAU 、BBU，AAU负责无线信号收发，BBU与核心网联通，微基站以京信、共进、佰才邦，以共进为例，主要是以一体化基站为主。其中宏基站用于增加网路覆盖，微基站用于增强信号质量。 5G核心网(5GC)： 核心网络建设主要用于提供 5G 终端设备（如手机，车载终端，摄像头等设备）的身份鉴权、流量分发、边缘计算、网络切片等业务能力，核心网网元较多，这针对重点网元进行介绍，AMF用于提供用户接入控制，对外主要网络协议为NAS、NGAP，UDM用于提供用户信息存储，即用户开卡信息，网络认证秘钥等， SMF用于提供网络流量控制，UPF用于提供网络流量转发。 IMS核心网(IMS)： 主要提供短信、音视频通话、电话会议等能力，主要通信协议为SIP、RTP，音频编解码为AMR，视频编解码4G为H264,5G为H265。其中SBC/P-CSCF提供终端接入功能, CSCF提供信令路由功能，IP Centex提供会议接入等功能。 5G消息(RCS)： 5G消息主要提供富媒体通信能力，借助手机原生能力能力实现富媒体通信，主要提供单聊、群聊、MAAP等业务，对手机侧通信协议主要包含SIP、MSRP等协议，对企业接入主要提供HTTP协议。 通过上述业务分析，相比原有通信能力，5G网络整体趋势为网络精细化、网络开放化、通信多样化、网络智能化演进。 下文对主要业务流程进行接入. 5G核心网文档可参考(TS 23.501, TS 23.502) 2.5G主要网络协议栈2.1 4/5G协议栈对比相比4G核心网来说主要是架构及内部协议层面： 5G核心网架构发生比较大的变化，引入NRF设备用于网络设备的注册与发现 网元间协议由原来的diamter换为http2 用户面与控制面解耦，为UPF下沉提供支持 控制面协议有s1-ap改为ngap 用户面协议增加扩展头 2.2 5G数据面传输协议 5G网络中UPF设备主要用于用户面数据的转发，主要功能是流量控制以及GTP包的拆解包。 https://github.com/5GOpenUPF/openupf 3.5G网络重要特性 3.1 网络切片5G网络基于三大业务场景的网络切片，使切片场景更加多样化。 eMBB，提供大带宽流量通道，主要是借助无线侧提升带宽上限。 uRLLC，提供低时延网络，主要借助边缘网络进行边缘计算降低端到端网络距离。 mMTC，提供大规模机器通信，及4G中NB-IOT规范在制定中预计R16版本制定。现在采用4G核心网eLTE增强实现。 切片实现基于核心网信令侧提供切片标识传输，用户面实现切片能力提供。切片承载标识以NSSAI，SST，SD等作为切片标识。详细可参考：https://www.yuque.com/wuhao-bo7rr/rb9zmq/epd319 3.2 边缘计算 概述 边缘计算在靠近数据源或用户的地方提供计算、存储等基础设施，并为边缘应用提供云服务和 IT 环境服务。相比于集中部署的云计算服务，边缘计算解决了时延过长、汇聚流量过大等问题，为实时性和带宽密集型业务提供更好的支持。随着 5G 和工业互联网的快速发展，新兴业务对边缘计算的需求十分迫切。在众多垂直行业新兴业务中，对边缘计算的需求主要体现在时延、带宽和安全三个方面。 实现 UPF 地址下发可采用 NRF(5G 网络注册设备)获取或 OAM(系统配置)配置 通过 5G 核心网配置及 SMF 下发 UPF 地址实现 UPF 地址的下沉 示例 以移动边缘计算平台为例主要涵盖 边缘设备管理 支持纳管不同算力、不同平台的边缘节点，实现对边缘节点和终端设备进行管理，如：状态监控、资源调度、日志查询等 边缘协议适配 边缘计算通过驱动方式灵活支持多种工业协议设备接入，原生支持MQTT、OPC-UA、Modbus协议设备接入 边缘应用管理 边缘应用市场提供预置边缘容器应用，也可进行自定义应用开发，并支持下发至边缘节点运行，云端可对应用进行全生命周期管理 边缘数据路由 支持将边缘节点数据通过灵活的方式路由到OneNET云端。并可以通过云端再分发到其他PaaS服务或客户自有应用 边缘规则计算 支持在边缘节点进行规则引擎计算，按照既定规则进行匹配，若匹配成功后则按照相关预定动作执行 边缘数据存储 支持在边缘节点进行多并发的海量时序列数据库存储，并在断网的情况自动实现离线存储 边缘数据分析 基于flink计算引擎，实现在云端通过可视化的方式配置计算任务，再下发到边缘节点执行 边缘智能推理 通过预置应用方式，将针对特定行业和场景的AI模型下发至边缘节点进行推理 参考 移动边缘计算平台：https://open.iot.10086.cn/productservice/edge/ 5G开源边缘计算平台https://gitee.com/edgegallery4.关键技术点解析 4.1 无线侧增强各网络速率对比 网络制式 2G 3G 4G 5G 下行速率 150K 2.8Mbps 100Mbps 1.54Gbps 上行速率 40K 384Kbps 50Mbps 308Mbps \u0000 5G网速计算公式 △ 5G载波的峰值计算公式 MIMO层数：下行4层，上行2层。 调制阶数：下行8阶（256QAM），上行6阶（64QAM）。 编码码率：948/1024≈0.926。 PRB个数：273，公式里面的12代表每个PRB包含12个子载波。 资源开销占比意为无线资源中用作控制，不能用来发送数据的比例，协议给出了典型的数据：下行14%，上行8%。 符号数意为每秒可实际传送数据的符号个数，因不同的TDD帧结构而异，具体可参考前面第二部分的表格。现取2.5毫秒双周期帧结构的值：下行18400，上行9200。 △ 5G载波的峰值计算因素图示把上述数据代入前面的公式，可得： 下行峰值速率为：1.54Gbps 上行峰值速率为：308Mbps 现在电信和联通正在共享3.5GHz频段上的100MHz的带宽，单个手机能达到的理论速率就是上述的两个值。如果这两家后续开通200MHz的话，因为带宽翻倍，速率也将翻倍，下行速率可以高达3.08Gbps！详细可参考：https://zhuanlan.zhihu.com/p/108553808​ 4G理论网速 ** LTE-Advanced（长期演进技术升级版）：** LTE的升级演进，由3GPP所主导制定，完全向后兼容LTE，通常通过在LTE上通过软件升级即可，升级过程类似于从W-CDMA升级到HSPA。峰值速率：下行1Gbps，上行500Mbps。是第一批被国际电信联盟承认的4G标准，也是事实上的唯一主流4G标准。另有TD-LTE的升级演进TD-LTE-Advanced（TD-LTE-A）。** LTE FDD（频分双工长期演进技术）：** 最早提出的LTE制式，目前该技术最成熟，全球应用最广泛，终端种类最多[5]。峰值速率：下行150Mbps，上行40Mbps。** LTE TDD（时分双工长期演进技术）：** 又称TD-LTE，是LTE的另一个分支。峰值速率：下行100Mbps，上行50Mbps。由上海贝尔、诺基亚西门子通信、大唐电信、华为技术、中兴通信、中国移动、高通、ST-Ericsson等业者共同开发。** WirelessMAN-Advanced（无线城域网升级版）：** 又称WiMAX-Advanced、WiMAX 2，即IEEE 802.16m是WiMAX的升级演进，由IEEE所主导制定，接收下行与上行最高速率可达到100Mbps，在静止定点接收可高达1Gbps。也是国际电信联盟承认的4G标准，不过随着Intel于2010年退出，WiMAX技术也已经被运营商放弃，并开始将设备升级为TD-LTE。 运营商 上行(MHz) 下行(MHz) 上行速率(bps) 下行速率(bps) 中国电信 2370～2390 2635～2655 50M 100M 中国移动 2300～2320 2555～2575 50M 100M 中国联通 1880～1900、2320～2370 2575～2635 50M 100M 详细可参考：https://zh.wikipedia.org/wiki/4G 3G理论网速 3G理论网速为1-6Mbps，折合下载速度120K/s-600K/s；是指支持高速数据传输的蜂窝移动通讯技 术。3G服务能够同时传送声音及数据信息，速率一般在几百kbps以上； 运营商 上行(MHz) 下行(MHz) 上行速率(bps) 下行速率(bps) 调制方式 CDMA2000 (中国电信) 825～835 870～880 1.8M 3.1M FDD TD-SCDMA (中国移动) 1880～1920 2010～2025 384K 2.8M TDD WCDMA (中国联通) 1920-1980 2110～2170 5.76M 7.2M FDD 详细可参考：https://zh.wikipedia.org/wiki/3G 2G理论网速 2G理论网速是150Kbps，折合下载速度15-20K/s；2G是第二代手机通信技术规格，以数字语音传输技术为核心。一般定义为无法直接传送如电子邮件、软件等信息；只具有通话和一些如时间日期等传送的手机通信技术规格； 运营商 制式 上行速率(bps) 下载速率(bps) 理论峰值(bps) 带宽 移动 GPRS 21.4K 85.6K 171.2K 150K EDGE 45K 90K 384K 200K 联通 GPRS 21.4K 85.6K 171.2K 150K EDGE 45K 90K 384K 200K 详细可参考：[https://jingyan.baidu.com/article/9158e0009e4708e2541228b4.html](https://jingyan.baidu.com/article/9158e0009e4708e2541228b4.html) 其他参考：[https://blog.csdn.net/mao834099514/article/details/79456881](https://blog.csdn.net/mao834099514/article/details/79456881) 4.2 控制面SCTP协议 UDP 用户数据报协议（_UDP_，User Datagram Protocol） 123456789101112User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Source Port: 5060 Destination Port: 5060 Length: 356 Checksum: 0xf8a5 [unverified] [Checksum Status: Unverified] [Stream index: 0] [Timestamps] [Time since first frame: 0.007303000 seconds] [Time since previous frame: 0.007303000 seconds] UDP payload (348 bytes) TCP 传输控制协议（_TCP_，Transmission Control Protocol） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Transmission Control Protocol, Src Port: 54872, Dst Port: 6070, Seq: 1, Ack: 1, Len: 3294 Source Port: 54872 Destination Port: 6070 [Stream index: 84] [TCP Segment Len: 3294] Sequence Number: 1 (relative sequence number) Sequence Number (raw): 1324026701 [Next Sequence Number: 3295 (relative sequence number)] Acknowledgment Number: 1 (relative ack number) Acknowledgment number (raw): 3153941596 1000 .... = Header Length: 32 bytes (8) Flags: 0x018 (PSH, ACK) 000. .... .... = Reserved: Not set ...0 .... .... = Nonce: Not set .... 0... .... = Congestion Window Reduced (CWR): Not set .... .0.. .... = ECN-Echo: Not set .... ..0. .... = Urgent: Not set .... ...1 .... = Acknowledgment: Set .... .... 1... = Push: Set .... .... .0.. = Reset: Not set .... .... ..0. = Syn: Not set .... .... ...0 = Fin: Not set [TCP Flags: ·······AP···] Window: 32748 [Calculated window size: 32748] [Window size scaling factor: -1 (unknown)] Checksum: 0x3972 [unverified] [Checksum Status: Unverified] Urgent Pointer: 0 Options: (12 bytes), No-Operation (NOP), No-Operation (NOP), Timestamps TCP Option - No-Operation (NOP) Kind: No-Operation (1) TCP Option - No-Operation (NOP) Kind: No-Operation (1) TCP Option - Timestamps: TSval 919902009, TSecr 919895231 Kind: Time Stamp Option (8) Length: 10 Timestamp value: 919902009 Timestamp echo reply: 919895231 [SEQ/ACK analysis] [Bytes in flight: 3294] [Bytes sent since last PSH flag: 3294] [Timestamps] [Time since first frame in this TCP stream: 0.000000000 seconds] [Time since previous frame in this TCP stream: 0.000000000 seconds] TCP payload (3294 bytes) 详细参考：https://segmentfault.com/a/1190000022410446​ SCTP 流控制传输协议SCTP(Stream Control Transmission Protocol) 123456789101112131415161718192021Stream Control Transmission Protocol, Src Port: 38412 (38412), Dst Port: 38412 (38412) Source port: 38412 Destination port: 38412 Verification tag: 0x0491fd24 [Association index: 65535] Checksum: 0xc759d633 [unverified] [Checksum Status: Unverified] DATA chunk(ordered, complete segment, TSN: 39, SID: 1, SSN: 33, PPID: 60, payload length: 67 bytes) Chunk type: DATA (0) Chunk flags: 0x03 .... 0... = I-Bit: Possibly delay SACK .... .0.. = U-Bit: Ordered delivery .... ..1. = B-Bit: First segment .... ...1 = E-Bit: Last segment Chunk length: 83 Transmission sequence number: 39 Stream identifier: 0x0001 Stream sequence number: 33 Payload protocol identifier: NGAP (60) Chunk padding: 00 详细参考：https://zhuanlan.zhihu.com/p/67819220 协议 安全可靠 小包传输 大包传输 生态健全 成熟度 UDP * *** *** *** *** TCP ** ** * *** *** SCTP *** * ** * ** 4.3 网络转发常见的网路转发技术分为用户态转发技术、内核态转发技术、UIO旁路转发技术，之外还有交换芯片之类的这里不做过多介绍，下面主要介绍用户态、内核态、UIO旁路转发。在转发速率，难度及趋势上做了相关对比 类型 用户态 内核态 DPDK 速度 * ** *** 开发难度 * ***(不小心把内核态搞崩) ** 周边工具 *** *** (借助VPP可以达到**) 社区趋势 * * *** 综上所述DPDK基本是网络转发技术主流。https://www.yuque.com/wuhao-bo7rr/rb9zmq/ak1moi 5.主要业务流程 商用手机终端入网，基站握手、核心网注册、IMS注册为必须项，只完成核心网注册，未完成IMS注册手机会自动掉线。 5.1 基站建联​ 手机与基站建联主要流程可以归结为： 小区搜索与选择 UE开机选网，小区搜索并完成下行同步。 系统消息广播 UE读取广播信息，选择合适小区进行驻留。 随机接入 UE与gNB建立上行同步。 RRC连接建立 UE与gNB建立RRC连接。 注册过程 UE注册到5G网络，网络侧开始维护该UE的上下文。​ 5.2 核心网注册 整体可归纳为： 注册请求 终端携带SIM信息进行注册，核心网通过用户信息在UDM查询数据，以此判断是否需要identity request 鉴权处理 核心网查询到用户信息后，发起Authentication request，终端收到请求后进行校验，回复Authentication response 此时双方共同进行双向鉴权。 加密协商 终端与网络双方为选择加密算法，可选类型为4种，其中第一种为不加密，其余三种为加密算法，加密算法包含完整性保护算法和报文加密算法，分别是为了保护报文的安全性与正确性 注册完成 网络侧返回注册完成，网络侧会携带网络能力告知终端。比如4G回落，IP短信能力。 无线能力上报 终端上报无线能力，终端上报无线能力至服务端，此信令为非必须应答信令 会话创建 终端创建流量传输通道，核心网在网络侧分配网络资源，此处一般会创建两个会话通道一个是IMS用来发短信打电话，一个是internet用来上网。由于IMS网络与Internet网络隔离这就是为什么在人多的地方有的时候网速慢打电话确没有影响。 IMS注册 终端完成会话通道创建后，会发起sip注册，商用终端必须完成sip注册后才可进行上网，这个原因大概是上网功能与ims功能为运营商基础能力，都需要完成后才算入网完成，手机层面表现为，出现HD为IMS网络注册完成。 详细可参考：https://www.yuque.com/wuhao-bo7rr/rb9zmq/gv4tpd 5.3 IMS注册 5.4 短信发送 5.5 语音呼叫 ​","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"MEC","slug":"MEC","permalink":"https://wuhaocn.github.io/tags/MEC/"},{"name":"网络切片","slug":"网络切片","permalink":"https://wuhaocn.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%87%E7%89%87/"}]},{"title":"java字节码增强","slug":"language/java/bytecode/java字节码增强","date":"2021-08-04T06:25:13.668Z","updated":"2021-08-04T06:25:13.668Z","comments":true,"path":"2021/08/04/language/java/bytecode/java字节码增强/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/java%E5%AD%97%E8%8A%82%E7%A0%81%E5%A2%9E%E5%BC%BA/","excerpt":"","text":"Java 字节码增强探秘1.字节码1.1 什么是字节码？Java 之所以可以“一次编译，到处运行”，一是因为 JVM 针对各种操作系统、平台都进行了定制，二是因为无论在什么平台，都可以编译生成固定格式的字节码（.class 文件）供 JVM 使用。因此，也可以看出字节码对于 Java 生态的重要性。之所以被称之为字节码，是因为字节码文件由十六进制值组成，而 JVM 以两个十六进制值为一组，即以字节为单位进行读取。在 Java 中一般是用 javac 命令编译源代码为字节码文件，一个.java 文件从编译到运行的示例如图 1 所示。 对于开发人员，了解字节码可以更准确、直观地理解 Java 语言中更深层次的东西，比如通过字节码，可以很直观地看到 Volatile 关键字如何在字节码上生效。另外，字节码增强技术在 Spring AOP、各种 ORM 框架、热部署中的应用屡见不鲜，深入理解其原理对于我们来说大有裨益。除此之外，由于 JVM 规范的存在，只要最终可以生成符合规范的字节码就可以在 JVM 上运行，因此这就给了各种运行在 JVM 上的语言（如 Scala、Groovy、Kotlin）一种契机，可以扩展 Java 所没有的特性或者实现各种语法糖。理解字节码后再学习这些语言，可以“逆流而上”，从字节码视角看它的设计思路，学习起来也“易如反掌”。本文重点着眼于字节码增强技术，从字节码开始逐层向上，由 JVM 字节码操作集合到 Java 中操作字节码的框架，再到我们熟悉的各类框架原理及应用，也都会一一进行介绍。 参考","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy介绍","slug":"language/java/bytecode/bytebuddy-code","date":"2021-08-04T06:25:13.667Z","updated":"2021-08-04T06:25:13.667Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-code/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-code/","excerpt":"","text":"字节码增强技术-Byte Buddy1.为什么需要在运行时生成代码？Java 是一个强类型语言系统，要求变量和对象都有一个确定的类型，不兼容类型赋值都会造成转换异常，通常情况下这种错误都会被编译器检查出来，如此严格的类型在大多数情况下是比较令人满意的，这对构建具有非常强可读性和稳定性的应用有很大的帮助，这也是 Java 能在企业编程中的普及的一个原因之一。然而，因为起强类型的检查，限制了其他领域语言应用范围。比如在编写一个框架是，通常我们并不知道应用程序定义的类型，因为当这个库被编译时， 我们还不知道这些类型，为了能在这种情况下能调用或者访问应用程序的方法或者变量，Java类库提供了一套反射 API。使用这套反射 API， 我们就可以反省为知类型，进而调用方法或者访问属性。但是，Java 反射有如下缺点： 需要执行一个相当昂贵的方法查找来获取描述特定方法的对象，因此，相比硬编码的方法调用，使用 反射 API 非常慢。 反射 API 能绕过类型安全检查，可能会因为使用不当照成意想不到的问题，这样就错失了 Java 编程语言的一大特性。 2.简介正如官网说的：Byte Buddy 是一个代码生成和操作库，用于在Java应用程序运行时创建和修改Java类，而无需编译器的帮助。 除了Java类库附带的代码生成实用程序外，ByteBuddy还允许创建任意类，并且不限于实现用于创建运行时代理的接口。 此外，Byte Buddy提供了一种方便的API，可以使用Java代理或在构建过程中手动更改类。Byte Buddy 相比其他字节码操作库有如下优势： 无需理解字节码格式，即可操作，简单易行的 API 能很容易操作字节码。 支持 Java 任何版本，库轻量，仅取决于Java字节代码解析器库ASM的访问者API，它本身不需要任何其他依赖项。 比起JDK动态代理、cglib、Javassist，Byte Buddy在性能上具有优势。 3.性能在选择字节码操作库时，往往需要考虑库本身的性能。对于许多应用程序，生成代码的运行时特性更有可能确定最佳选择。而 在生成的代码本身的运行时间之外，用于创建动态类的运行时也是一个问题。官网对库进行了性能测试，给出以下结果图： 图中的每一行分别为，类的创建、接口实现、方法调用、类型扩展、父类方法调用的性能结果。 从性能报告中可以看出，Byte Buddy 的主要侧重点在于以最少的运行时生成代码，需要注意的是，我们这些衡量 Java 代码性能的测试， 都由 Java虚拟机即时编译器优化过，如果你的代码只是偶尔运行，没有得到虚拟机的优化，可能性能会有所偏差。 所以我们在使用 Byte Buddy 开发时，我们希望监控这些指标，以避免在添加新功能时造成性能损失。 4.Hello world代码123456789101112Class&lt;?&gt; dynamicType = new ByteBuddy() .subclass(Object.class) .method(ElementMatchers.named(&quot;toString&quot;)) .intercept(FixedValue.value(&quot;Hello World&quot;)) .make() .load(HelloWorldBuddy.class.getClassLoader()) .getLoaded(); Object instance = dynamicType.newInstance(); String toString = instance.toString(); System.out.println(toString); System.out.println(instance.getClass().getCanonicalName()); 从例子中看到，操作创建一个类如此的简单。正如 ByteBuddy 说明的，ByteBuddy 提供了一个领域特定语言，这样就可以尽可能地提高人类可读性简单易行的 API， 可能能让你在初次使用的过程中就能不需要查阅 API的前提下完成编码。这也真是 ByteBuddy 能完爆其他同类型库的一个原因。 上面的示例中使用的默认ByteBuddy配置会以最新版本的类文件格式创建Java类，该类文件格式可以被正在处理的Java虚拟机理解。 subclass指定了新创建的类的父类，同时 method 指定了 Object 的 toString 方法，intercept 拦截了 toString 方法并返回固定的 value ， 最后 make 方法生产字节码，有类加载器加载到虚拟机中。此外，Byte Buddy不仅限于创建子类和操作类，还可以转换现有代码。Byte Buddy 还提供了一个方便的 API，用于定义所谓的 Java 代理， 该代理允许在任何 Java应用程序的运行期间进行代码转换，代理会在下篇单独写一篇文章讲解。 5.创建一个类任何一个由 ByteBuddy 创建的类型都是通过 ByteBuddy 类的实例来完成的。通过简单地调用 new ByteBuddy() 就可以创建一个新实例。 123DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy() .subclass(Object.class) .make(); 上面的示例代码会创建一个继承至 Object 类型的类。这个动态创建的类型与直接扩展 Object 并且没有实现任何方法、属性和构造函数的类型是等价的 。该列子没有命名动态生成的类型，但是在定义 Java类时却是必须的，所以很容易的你会想到，ByteBuddy 会有默认的策略给我们生成。 当然，你也可以很容易地明确地命名这个类型。 1234DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy().subclass(Object.class).name(&quot;example.Type&quot;).make(); 那么默认的策略是如何做的呢？这个将与 ByteBuddy 与 约定大于配置息息相关，它提供了我们认为比较全面的默认配置。 至于类型命名，ByteBuddy 的默认配置提供了NamingStrategy，它基于动态类型的超类名称来随机生成类名。 此外，名称定义在与父类相同的包下，这样父类的包级访问权限的方法对动态类型也可见。如果你将示例子类命名为 example.Foo， 那么生成的名称将会类似于example.FooByteBuddy1376491271，这里的数字序列是随机的。 此外，在一些需要指定类型的场景中，可以通过重写 NamingStrategy 的方法来实现，或者使用 ByteBuddy 内置的NamingStrategy.SuffixingRandom 来实现。 同时需要注意的是，我们编码时需要遵守所谓的领域特定语言和不变性原则，这是说明意思呢？就是说在 ByteBuddy 中， 几乎所有的类都被构建成不可变的；极少数情况，我们不可能把对象构建成不可变的。请看下面一个例子： 123ByteBuddy byteBuddy = new ByteBuddy();byteBuddy.with(new NamingStrategy.SuffixingRandom(&quot;suffix&quot;));DynamicType.Unloaded&lt;?&gt; dynamicType1 = byteBuddy.subclass(Object.class).make(); 上述例子你会发现类的命名策略还是默认的，其根本原因就是没有遵守上述原则导致的。所以在编码过程中要基于此原则进行。 6.加载类上节创建的 DynamicType.Unloaded，代表一个尚未加载的类，顾名思义，这些类型不会加载到 Java 虚拟机中，它仅仅表示创建好了类的字节码， 通过 DynamicType.Unloaded 中的 getBytes方法你可以获取到该字节码，在你的应用程序中， 你可能需要将该字节码保存到文件，或者注入的现在的 jar 文件中，因此该类型还提供了一个 saveIn(File) 方法， 可以将类存储在给定的文件夹中； inject(File)方法将类注入到现有的 Jar 文件中， 另外你只需要将该字节码直接加载到虚拟机使用，你可以通过 ClassLoadingStrategy 来加载。 如果不指定ClassLoadingStrategy，Byte Buffer根据你提供的ClassLoader来推导出一个策略，内置的策略定义在枚举ClassLoadingStrategy.Default中 WRAPPER：创建一个新的Wrapping类加载器 CHILD_FIRST：类似上面，但是子加载器优先负责加载目标类 INJECTION：利用反射机制注入动态类型 示例 12345Class&lt;?&gt; type = new ByteBuddy().subclass(Object.class).make().load(getClass().getClassLoader(), ClassLoadingStrategy.Default.WRAPPER).getLoaded() 这样我们创建并加载了一个类。我们使用 WRAPPER 策略来加载适合大多数情况的类。getLoaded 方法返回一个 Java Class 的实例，它就表示现在加载的动态类。 重新加载类 得益于JVM的HostSwap特性，已加载的类可以被重新定义： // 安装Byte Buddy的Agent，除了通过-javaagent静态安装，还可以： 12345678ByteBuddyAgent.install();Foo foo = new Foo(); new ByteBuddy() .redefine(Bar.class) .name(Foo.class.getName()) .make() .load(Foo.class.getClassLoader(), ClassReloadingStrategy.fromInstalledAgent()); assertThat(foo.m(), is(&quot;bar&quot;)); 可以看到，即使时已经存在的对象，也会受到类Reloading的影响。但是需要注意的是HostSwap具有限制： 类再重新载入前后，必须具有相同的Schema，也就是方法、字段不能减少（可以增加） 不支持具有静态初始化块的类 修改类 redefine 重定义一个类时，Byte Buddy可以对一个已有的类添加属性和方法，或者删除已经存在的方法实现。新添加的方法，如果签名和原有方法一致，则原有方法会消失。 rebase 类似于redefine，但是原有的方法不会消失，而是被重命名，添加后缀 $original，这样，就没有实现会被丢失。重定义的方法可以继续通过它们重命名过的名称调用原来的方法，例如类： 123class Foo &#123; String bar() &#123; return &quot;bar&quot;; &#125;&#125; rebase 之后： 1234class Foo &#123; String bar() &#123; return &quot;foo&quot; + bar$original(); &#125; private String bar$original() &#123; return &quot;bar&quot;; &#125;&#125; 7.方法拦截通过匹配模式拦截 ByteBuddy 提供了很多用于匹配方法的 DSL，如下例子： 123456789101112Foo dynamicFoo = new ByteBuddy() .subclass(Foo.class) // 匹配由Foo.class声明的方法 .method(isDeclaredBy(Foo.class)).intercept(FixedValue.value(&quot;One!&quot;)) // 匹配名为foo的方法 .method(named(&quot;foo&quot;)).intercept(FixedValue.value(&quot;Two!&quot;)) // 匹配名为foo，入参数量为1的方法 .method(named(&quot;foo&quot;).and(takesArguments(1))).intercept(FixedValue.value(&quot;Three!&quot;)) .make() .load(getClass().getClassLoader()) .getLoaded() .newInstance(); ByteBuddy 通过 net.bytebuddy.matcher.ElementMatcher 来定义配置策略，可以通过此接口实现自己定义的匹配策略。库本身提供的 Matcher 非常多。Uploading file… 8.方法委托使用MethodDelegation可以将方法调用委托给任意POJO。Byte Buddy不要求Source（被委托类）、Target类的方法名一致 123456789101112131415161718class Source &#123; public String hello(String name) &#123; return null; &#125;&#125;class Target &#123; public static String hello(String name) &#123; return &quot;Hello &quot; + name + &quot;!&quot;; &#125;&#125;String helloWorld = new ByteBuddy() .subclass(Source.class) .method(named(&quot;hello&quot;)).intercept(MethodDelegation.to(Target.class)) .make() .load(getClass().getClassLoader()) .getLoaded() .newInstance() .hello(&quot;World&quot;); 其中 Target 还可以如下实现： 12345class Target &#123; public static String intercept(String name) &#123; return &quot;Hello &quot; + name + &quot;!&quot;; &#125; public static String intercept(int i) &#123; return Integer.toString(i); &#125; public static String intercept(Object o) &#123; return o.toString(); &#125;&#125; 前一个实现因为只有一个方法，而且类型也匹配，很好理解，那么后一个呢，Byte Buddy到底会委托给哪个方法？Byte Buddy遵循一个最接近原则： intercept(int)因为参数类型不匹配，直接Pass 另外两个方法参数都匹配，但是 intercept(String)类型更加接近，因此会委托给它 同时需要注意的是被拦截的方法需要声明为public，否则没法进行拦截增强。除此之外，还可以使用 @RuntimeType 注解来标注方法 12345@RuntimeTypepublic static Object intercept(@RuntimeType Object value) &#123; System.out.println(&quot;Invoked method with: &quot; + value); return value;&#125; 9.参数绑定可以在拦截器（Target）的拦截方法 intercept 中使用注解注入参数，ByteBuddy 会根据注解给我们注入对于的参数值。比如： 1234void intercept(Object o1, Object o2)// 等同于void intercept(@Argument(0) Object o1, @Argument(1) Object o2)复制代码常用的注解如下表： 注解 描述 @Argument 绑定单个参数 @AllArguments 绑定所有参数的数组 @This 当前被拦截的、动态生成的那个对象 @DefaultCall 调用默认方法而非super的方法 @SuperCall 用于调用父类版本的方法 @RuntimeType 可以用在返回值、参数上，提示ByteBuddy禁用严格的类型检查 @Super 当前被拦截的、动态生成的那个对象的父类对象 @FieldValue 注入被拦截对象的一个字段的值 10.字段属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class UserType &#123; public String doSomething() &#123; return null; &#125;&#125;public interface Interceptor &#123; String doSomethingElse();&#125;public interface InterceptionAccessor &#123; Interceptor getInterceptor(); void setInterceptor(Interceptor interceptor);&#125;public interface InstanceCreator &#123; Object makeInstance();&#125;public class HelloWorldInterceptor implements Interceptor &#123; @Override public String doSomethingElse() &#123; return &quot;Hello World!&quot;; &#125;&#125;Class&lt;? extends UserType&gt; dynamicUserType = new ByteBuddy() .subclass(UserType.class) .method(not(isDeclaredBy(Object.class))) // 非父类 Object 声明的方法 .intercept(MethodDelegation.toField(&quot;interceptor&quot;)) // 拦截委托给属性字段 interceptor .defineField(&quot;interceptor&quot;, Interceptor.class, Visibility.PRIVATE) // 定义一个属性字段 .implement(InterceptionAccessor.class).intercept(FieldAccessor.ofBeanProperty()) // 实现 InterceptionAccessor 接口 .make() .load(getClass().getClassLoader()) .getLoaded(); InstanceCreator factory = new ByteBuddy() .subclass(InstanceCreator.class) .method(not(isDeclaredBy(Object.class))) // 非父类 Object 声明的方法 .intercept(MethodDelegation.toConstructor(dynamicUserType)) // 委托拦截的方法来调用提供的类型的构造函数 .make() .load(dynamicUserType.getClassLoader()) .getLoaded().newInstance();UserType userType = (UserType) factory.makeInstance();((InterceptionAccessor) userType).setInterceptor(new HelloWorldInterceptor());String s = userType.doSomething();System.out.println(s); // Hello World! 上述例子将 UserType 类实现了 InterceptionAccessor 接口，同时使用 MethodDelegation.toField 可以使拦截的方法可以委托给新增的字段。 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 11.参考https://juejin.cn/post/6844903965553852423https://www.cnblogs.com/yungyu16/p/13167240.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy替换类实现","slug":"language/java/bytecode/bytebuddy-替换类实现","date":"2021-08-04T06:25:13.667Z","updated":"2021-08-04T06:25:13.668Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-替换类实现/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-%E6%9B%BF%E6%8D%A2%E7%B1%BB%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"bytebuddy-替换类实现1.依赖1234dependencies &#123; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy&#x27;, version: &#x27;1.11.8&#x27; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy-agent&#x27;, version: &#x27;1.11.8&#x27;&#125; 2.测试类被替换类12345678910package org.coral.jcode.simple.bytebuddy.reload;public class Log &#123; public static void log(String a) &#123; System.out.println(&quot;Log: &quot; + a); &#125;&#125; 3.测试类替换目的类12345678910111213package org.coral.jcode.simple.bytebuddy.reload;public class Log4j &#123; /** * 注意代理类要和原实现类的方法声明保持一致 * @param a */ public static void log(String a) &#123; System.err.println(&quot;Log4j: &quot; + a); &#125;&#125; 4.测试验证类123456789101112131415161718192021222324package org.coral.jcode.simple.bytebuddy.reload;import net.bytebuddy.ByteBuddy;import net.bytebuddy.agent.ByteBuddyAgent;import net.bytebuddy.dynamic.loading.ClassReloadingStrategy;import net.bytebuddy.implementation.MethodDelegation;import net.bytebuddy.matcher.ElementMatchers;public class LogMain &#123; public static void main(String[] args) &#123; // 替换 ByteBuddyAgent.install(); new ByteBuddy().redefine(Log.class) .method(ElementMatchers.named(&quot;log&quot;)) .intercept(MethodDelegation.to(Log4j.class)) .make() .load(Thread.currentThread().getContextClassLoader(), ClassReloadingStrategy.fromInstalledAgent()); // 调用 Log.log(&quot;hello&quot;); &#125;&#125; 1Log4j: hello 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 5.参考https://houbb.github.io/2019/10/30/bytecode-byte-buddy-02-replace","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"AspectJ使用介绍","slug":"language/java/bytecode/aspectj使用介绍","date":"2021-08-04T06:25:13.666Z","updated":"2021-08-04T06:25:13.666Z","comments":true,"path":"2021/08/04/language/java/bytecode/aspectj使用介绍/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/aspectj%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1.AspectJ 使用介绍AspectJ 作为 AOP 编程的完全解决方案，提供了三种织入时机，分别为 compile-time：编译期织入，在编译的时候一步到位，直接编译出包含织入代码的 .class 文件 post-compile：编译后织入，增强已经编译出来的类，如我们要增强依赖的 jar 包中的某个类的某个方法 load-time：在 JVM 进行类加载的时候进行织入 1.1 编译插桩分类编译插桩技术具体可以分为两类，如下所示： 1）、APT（Annotation Process Tools） ：用于生成 Java 代码。 2）、AOP（Aspect Oriented Programming）：用于操作字节码。 我们分别来详细介绍下它们的作用。 1、APT（Annotation Process Tools）总所周知，ButterKnife、Dagger、GreenDao、Protocol Buffers 这些常用的注解生成框架都会在编译过程中生成代码。而 使用 AndroidAnnotation 结合 APT 技术 来生成代码的时机，是在编译最开始的时候介入的。但是 AOP 是在编译完成后生成 dex 文件之前的时候，直接通过修改 .class 文件的方式，来直接添加或者修改代码逻辑的。使用 APT 技术生成 Java 代码的方式具有如下 两方面 的优势： 1）、隔离了框架复杂的内部实现，使得开发更加地简单高效。2）、大大减少了手工重复的工作量，降低了开发时出错的机率。 2、AOP（Aspect Oriented Programming） 而对于操作字节码的方式来说，一般都在 代码监控、代码修改、代码分析 这三个场景有着很广泛的应用。 相对于 Java 代码生成的方式，操作字节码的方式有如下 特点： 1）、应用场景更广。 2）、功能更加强大。 3）、使用复杂度较高。 2.依赖引入以gradle依赖为例 123456789101112131415161718192021buildscript &#123; repositories &#123; mavenLocal() maven &#123; url &#x27;https://plugins.gradle.org/m2/&#x27; &#125; &#125; dependencies &#123; classpath group: &#x27;io.freefair.gradle&#x27;, name: &#x27;aspectj-plugin&#x27;, version: &#x27;5.3.3.3&#x27; &#125;&#125;apply plugin: &quot;io.freefair.aspectj&quot;dependencies &#123; compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjweaver&#x27;, version: &#x27;1.9.5&#x27; compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjrt&#x27;, version: &#x27;1.9.5&#x27; &#125; aspectj底层依赖库 net.bytebuddy:byte-buddy 3.代码编写 代码地址请参考：https://github.com/wuhaocn/jcode-simple.git 注意下面操作类应放在”src/main/aspectj”包下面 3.1.定义业务类 Account.java123456789101112public class Account &#123; public int balance = 20; public boolean pay(int amount) &#123; if (balance &lt; amount) &#123; return false; &#125; balance -= amount; return true; &#125;&#125; 3.2.定义注解类 AccountAspect.aj1234567891011121314151617181920212223public aspect AccountAspect &#123; pointcut callPay(int amount, Account account): call(boolean com.rcloud.Account.pay(int)) &amp;&amp; args(amount) &amp;&amp; target(account); before(int amount, Account account): callPay(amount, account) &#123; System.out.println(&quot;[AccountAspect]付款前总金额: &quot; + account.balance); System.out.println(&quot;[AccountAspect]需要付款: &quot; + amount); &#125; boolean around(int amount, Account account): callPay(amount, account) &#123; if (account.balance &lt; amount) &#123; System.out.println(&quot;[AccountAspect]拒绝付款!&quot;); return false; &#125; return proceed(amount, account); &#125; after(int amount, Account balance): callPay(amount, balance) &#123; System.out.println(&quot;[AccountAspect]付款后，剩余：&quot; + balance.balance); &#125;&#125; 3.3.使用类 AccountDoWork.java1234567public class AccountDoWork &#123; public static void pay() &#123; Account account = new Account(); account.pay(1); &#125;&#125; 4.AspectJ 的优势与局限性最常用的字节码处理框架有 AspectJ、ASM 等等，它们的相同之处在于输入输出都是 Class 文件。并且，它们都是 在 Java 文件编译成 .class 文件之后，生成 Dalvik 字节码之前执行。而 AspectJ 作为 Java 中流行的 AOP（aspect-oriented programming） 编程扩展框架，其内部使用的是 BCEL框架 来完成其功能。下面，我们就来了解下 AspectJ 具备哪些优势。4.1.AspectJ 的优势 它的优势有两点：成熟稳定、使用非常简单。 1、成熟稳定字节码的处理并不简单，特别是 针对于字节码的格式和各种指令规则，如果处理出错，就会导致程序编译或者运行过程中出现问题。而 AspectJ 作为从 2001 年发展至今的框架，它已经发展地非常成熟，通常不用考虑插入的字节码发生正确性相关的问题。 2、使用非常简单AspectJ 的使用非常简单，并且它的功能非常强大，我们完全不需要理解任何 Java 字节码相关的知识，就可以在很多情况下对字节码进行操控。例如，它可以在如下五个位置插入自定义的代码：1）、在方法（包括构造方法）被调用的位置。2）、在方法体（包括构造方法）的内部。3）、在读写变量的位置。4）、在静态代码块内部。5）、在异常处理的位置的前后。此外，它也可以 直接将原位置的代码替换为自定义的代码。 4.2.AspectJ 的缺陷而 AspectJ 的缺点可以归结为如下 三点： 1、切入点固定AspectJ 只能在一些固定的切入点来进行操作，如果想要进行更细致的操作则很难实现，它无法针对一些特定规则的字节码序列做操作。 2、正则表达式的局限性AspectJ 的匹配规则采用了类似正则表达式的规则，比如 匹配 Activity 生命周期的 onXXX 方法，如果有自定义的其他以 on 开头的方法也会匹配到，这样匹配的正确性就无法满足。 3、性能较低AspectJ 在实现时会包装自己一些特定的类，它并不会直接把 Trace 函数直接插入到代码中，而是经过一系列自己的封装。这样不仅生成的字节码比较大，而且对原函数的性能会有不小的影响。如果想对 App 中所有的函数都进行插桩，性能影响肯定会比较大。如果你只插桩一小部分函数，那么 AspectJ 带来的性能损耗几乎可以忽略不计。5.AspectJ 核心语法简介AspectJ 其实就是一种 AOP 框架，AOP 是实现程序功能统一维护的一种技术。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合性降低，提高程序的可重用性，同时大大提高了开发效率。因此 AOP 的优势可总结为如下 两点： 1）、无侵入性。2）、修改方便。 此外，AOP 不同于 OOP 将问题划分到单个模块之中，它把 涉及到众多模块的同一类问题进行了统一处理。比如我们可以设计两个切面，一个是用于处理 App 中所有模块的日志输出功能，另外一个则是用于处理 App 中一些特殊函数调用的权限检查。下面👇，我们就来看看要掌握 AspectJ 的使用，我们需要了解的一些 核心概念。 1、横切关注点对哪些方法进行拦截，拦截后怎么处理。 2、切面（Aspect）类是对物体特征的抽象，切面就是对横切关注点的抽象。 3、连接点（JoinPoint）JPoint 是一个程序的关键执行点，也是我们关注的重点。它就是指被拦截到的点（如方法、字段、构造器等等）。 4、切入点（PointCut）对 JoinPoint 进行拦截的定义。PointCut 的目的就是提供一种方法使得开发者能够选择自己感兴趣的 JoinPoint。 5、通知（Advice）切入点仅用于捕捉连接点集合，但是，除了捕捉连接点集合以外什么事情都没有做。事实上实现横切行为我们要使用通知。它 一般指拦截到 JoinPoint 后要执行的代码，分为 前置、后置、环绕 三种类型。这里，我们需要 注意 Advice Precedence（优先权） 的情况，比如我们对同一个切面方法同时使用了 @Before 和 @Around 时就会报错，此时会提示需要设置 Advice 的优先级。AspectJ 作为一种基于 Java 语言实现的一套面向切面程序设计规范。它向 Java 中加入了 连接点(Join Point) 这个新概念 ，其实它也只是现存的一个 Java 概 念的名称而已。它向 Java 语言中加入了少许新结构，譬如 切入点(pointcut)、通知(Advice)、类型间声明(Inter-type declaration) 和 切面(Aspect)。切入点和通知动态地影响程序流程，类型间声明则是静态的影响程序的类等级结构，而切面则是对所有这些新结构的封装。对于 AsepctJ 中的各个核心概念来说，其 连接点就恰如程序流中适当的一点。而切入点收集特定的连接点集合和在这些点中的值。一个通知则是当一个连接点到达时执行的代码，这些都是 AspectJ 的动态部分。其实连接点就好比是 程序中那一条一条的语句，而切入点就是特定一条语句处设置的一个断点，它收集了断点处程序栈的信息，而通知就是在这个断点前后想要加入的程序代码。此外，AspectJ 中也有许多不同种类的类型间声明，这就允许程序员修改程序的静态结构、名称、类的成员以及类之间的关系。AspectJ 中的切面是横切关注点的模块单元。它们的行为与 Java 语言中的类很象，但是切面 还封装了切入点、通知以及类型间声明。 6.小结AspectJ 的三种织入方式中，个人觉得前面的两种会比较实用一些，因为第三种需要修改启动脚本，对于大型公司来说会比较不友好，需要专门找运维人员配置。 在实际生产中，我们用得最多的还是纯 Spring AOP，通过本文的介绍，相信大家对于 AspectJ 的使用应该也没什么压力了。大家如果对于本文介绍的内容有什么不清楚的，请直接在评论区留言，如果对于 Spring + AspectJ 感兴趣的读者，碰到问题也可以在评论区和大家互动讨论。 7.参考https://javadoop.com/post/aspectjhttps://juejin.cn/post/6844904112396615688","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://wuhaocn.github.io/tags/AOP/"},{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy实现aop","slug":"language/java/bytecode/bytebuddy-aop","date":"2021-08-04T06:25:13.666Z","updated":"2021-08-04T06:25:13.667Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-aop/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-aop/","excerpt":"","text":"1.背景最近业务服务需要做一些组件第三方组件监控的事，需要用到字节码修改相关的技术，bytebuddy就是其中一种，网上找了一下bytebuddy相关资料，不少大佬写的不错的帖子就直接拿过来了，下方备注参考连接 本文主要介绍 bytebuddy-aop相关操作 2.ByteBuddy简介Byte Buddy 是一个代码生成和操作库，用于在 Java 应用程序运行时创建和修改 Java 类，无需编译器的帮助。除了Java 类库附带的代码生成实用程序，Byte Buddy 允许创建任意类，并且不限于实现用于创建运行时代理的接口。此外，Byte Buddy 提供了一个方便的 API，用于手动、使用 Java 代理或在构建期间更改类。 简单来说，ByteBuddy是一个可以在运行时动态生成java class的类库。在这篇文章中，我们将会使用ByteBuddy这个框架操作已经存在的类，创建指定的新类，甚至拦截方法调用。 官网：https://bytebuddy.net/#/ 代码地址参考：https://github.com/wuhaocn/jcode-simple.git 3.AOP注解实现3.1 依赖引入 依赖byte-buddy、byte-buddy-agent相关类 1234dependencies &#123; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy&#x27;, version: &#x27;1.11.8&#x27;&#125; 3.2 定义相关类定义 注解类、业务类、监听类; 注解类 123@Retention(RetentionPolicy.RUNTIME)public @interface Monitor &#123;&#125; 业务类此处定义监控方法并加上Monitor注解123456789101112public class BizAnnotationService &#123; @Monitor public int foo(int value) &#123; System.out.println(&quot;foo: &quot; + value); return value; &#125; public int bar(int value) &#123; System.out.println(&quot;bar: &quot; + value); return value; &#125;&#125; 监听类实现 @Advice.OnMethodEnter @Advice.OnMethodExit 监听业务123456789101112131415class MonitorAnnotationAdvisor &#123; @Advice.OnMethodEnter public static void onMethodEnter(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments) &#123; if (method.getAnnotation(Monitor.class) != null) &#123; System.out.println(&quot;onMethodEnter &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; &#125; @Advice.OnMethodExit public static void onMethodExit(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments, @Advice.Return Object ret) &#123; if (method.getAnnotation(Monitor.class) != null) &#123; System.out.println(&quot;onMethodExit &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; &#125;&#125; 测试类 测试注解生效 123456789101112131415public class BizAnnotationTest &#123; public static void main(String[] args) throws Exception &#123; BizAnnotationService service = new ByteBuddy() .subclass(BizAnnotationService.class) .method(ElementMatchers.any()) .intercept(Advice.to(MonitorAnnotationAdvisor.class)) .make() .load(BizAnnotationService.class.getClassLoader()) .getLoaded() .newInstance(); service.bar(11111); service.foo(99999); &#125;&#125; 结果输出 123456&gt; Task :code-gen:bytebuddy:BizAnnotationTest.main()bar: 11111onMethodEnter foo with arguments: [99999]foo: 99999onMethodExit foo with arguments: [99999] 4.AOP监听第三方组件4.1 定义相关类定义 业务类、监听类、测试类; 主要原因是调用代码无法增加注解 业务类此处定义监控方法并加上未添加注解 1234567891011public class BizService &#123; public int foo(int value) &#123; System.out.println(&quot;foo: &quot; + value); return value; &#125; public int bar(int value) &#123; System.out.println(&quot;bar: &quot; + value); return value; &#125;&#125; 监听类实现 @Advice.OnMethodEnter @Advice.OnMethodExit 监听业务 1234567891011class MonitorAdvisor &#123; @Advice.OnMethodEnter public static void onMethodEnter(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments) &#123; System.out.println(&quot;onMethodEnter &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; @Advice.OnMethodExit public static void onMethodExit(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments, @Advice.Return Object ret) &#123; System.out.println(&quot;onMethodExit &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments) + &quot; return: &quot; + ret); &#125;&#125; 测试类 测试不添加注解验证 123456789101112131415public class BizServiceTest &#123; public static void main(String[] args) throws Exception &#123; BizService service = new ByteBuddy() .subclass(BizService.class) .method(ElementMatchers.any()) .intercept(Advice.to(MonitorAdvisor.class)) .make() .load(BizService.class.getClassLoader()) .getLoaded() .newInstance(); service.bar(00000); service.foo(99999); &#125;&#125; 结果输出 1234567&gt; Task :code-gen:bytebuddy:BizServiceTest.main()onMethodEnter bar with arguments: [11111]bar: 11111onMethodExit bar with arguments: [11111] return: 11111onMethodEnter foo with arguments: [99999]foo: 99999onMethodExit foo with arguments: [99999] return: 99999 5.监控耗时5.1 定义相关类 业务类耗时处理 12345678public class CostService &#123; public int play(int value) throws Exception &#123; System.out.println(&quot;foo: &quot; + value); Thread.sleep(1000); return value; &#125;&#125; 监控类实现 @RuntimeType通过 Object intercept(@SuperCall Callable&lt;?&gt; callable)返回处理结果 1234567891011public class CostMonitorAdvisor &#123; @RuntimeType public static Object intercept(@SuperCall Callable&lt;?&gt; callable) throws Exception &#123; long start = System.currentTimeMillis(); try &#123; return callable.call(); &#125; finally &#123; System.out.println(&quot;方法耗时：&quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); &#125; &#125;&#125; 测试类 通过方法委托实现 ByteBuddy#intercept(MethodDelegation.to(CostMonitorAdvisor.class)) 1234567891011121314public class CostServiceTest &#123; public static void main(String[] args) throws Exception &#123; CostService service = new ByteBuddy() .subclass(CostService.class) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(CostMonitorAdvisor.class)) .make() .load(CostService.class.getClassLoader()) .getLoaded() .newInstance(); service.play(11111); &#125;&#125; 结果输出 1234&gt; Task :code-gen:bytebuddy:CostServiceTest.main()play: 11111方法耗时：35ms 带参传递部分构造函数携带参数，这里以redis为例简单写了下带参数传递的类1234567891011ByteBuddy byteBuddy = new ByteBuddy();Class aClass = byteBuddy.subclass(Jedis.class) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(RedisMonitorAdvisor.class)) .make() .load(Jedis.class.getClassLoader()) .getLoaded();Class[] p = &#123;String.class, int.class&#125;;Constructor&lt;Jedis&gt; classDeclaredConstructor = aClass.getDeclaredConstructor(p);Jedis jedis = classDeclaredConstructor.newInstance(&quot;10.3.4.111&quot;, 6379); 6.总结 通过ByteBuddy创建实例，并注入切面可实现横切 可执行onMethodEnter onMethodExit相关操作 RuntimeType监听方法耗时 对象创建需要通过ByteBuddy创建，自己创建类无法实现 无法监控静态对象 7.注解含义 注解 说明 @Argument 绑定单个参数 @AllArguments 绑定所有参数的数组 @This 当前被拦截的、动态生成的那个对象 @Super 当前被拦截的、动态生成的那个对象的父类对象 @Origin 可以绑定到以下类型的参数：Method 被调用的原始方法 Constructor 被调用的原始构造器 Class 当前动态创建的类 MethodHandle MethodType String 动态类的toString()的返回值 int 动态方法的修饰符 @DefaultCall 调用默认方法而非super的方法 @SuperCall 用于调用父类版本的方法 @Super 注入父类型对象，可以是接口，从而调用它的任何方法 @RuntimeType 可以用在返回值、参数上，提示ByteBuddy禁用严格的类型检查 @Empty 注入参数的类型的默认值 @StubValue 注入一个存根值。对于返回引用、void的方法，注入null；对于返回原始类型的方法，注入0 @FieldValue 注入被拦截对象的一个字段的值 @Morph 类似于@SuperCall，但是允许指定调用参数 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 8.参考https://zhuanlan.zhihu.com/p/151843984https://bytebuddy.net/#/https://www.jianshu.com/p/be2efc2b0e4chttps://blog.csdn.net/generalfu/article/details/106086475","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[]},{"title":"JVM软引用和弱引用","slug":"language/jvm/JVM软引用和弱引用","date":"2021-08-04T06:25:13.665Z","updated":"2021-08-04T06:25:13.666Z","comments":true,"path":"2021/08/04/language/jvm/JVM软引用和弱引用/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E5%BC%95%E7%94%A8/","excerpt":"","text":"一个场景12345如果有一个值，对应的键已经不再使用了, 将会出现什么情况呢？假定对某个键的最后一次引用已经消亡, 不再有任何途径引用这个值的对象了, 但是, 由于在程序中的任何部分没有再出现这个键, 所以, 这个 键/值 对无法从映射中删除.垃圾收集器怎么处理这样的场景呢? 引用出现了! JAVA 中的引用强引用 StrongReference: 普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，当然具体回收时机还是要看垃圾收集策略 软引用 SoftReference: 一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存, 维护一种非强制性的映射关系 弱引用 WeakReference: 并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系,如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。这个类对象的引用，一般主要是在 major collection 的时候回收，所以它可能在 minor collection 后仍然存在。 **虚引用 PhantomReference: **The object is the referent of a PhantomReference, and it has already been selected for collection and its finalizer (if any) has run. The term “reachable” is really a misnomer in this case, as there’s no way for you to access the actual object. 不可达, 不影响对象的生命周期, 通过虚引用的 get() 方法永远返回 null. 正如您可能猜到的，向对象生命周期图添加三个新的可选状态会造成混乱。尽管文档指出了从强可达到软、弱和虚到回收的逻辑过程，但实际过程取决于程序创建的引用对象。如果创建 WeakReference 但不创建SoftReference，则对象将直接从强可达到弱可达，再从最终确定到收集。 References and ReferentsA reference object is a layer of indirection between your program code and some other object, called a referent. Each reference object is constructed around its referent, and the referent cannot be changed. 引用意义垃圾回收时的垃圾判定方式: 垃圾回收JVM 在进行垃圾回收的时候，会判定对象是否还存在引用，它会针对不同的引用类型分别对待。弱引用可以用来访问对象，但进行垃圾回收时，如果对象仅有弱引用指向，则仍然会被 GC 回收。 小例子1234567891011121314151617181920// 软引用和弱引用的一个例子// 强引用String str = new String(&quot;str-value&quot;);SoftReference&lt;String&gt; softRef = new SoftReference&lt;String&gt;(str); // 软引用str = null; // 去掉强引用System.gc(); // 垃圾回收器进行回收System.out.println(softRef.get());// 强引用String abc = new String(&quot;abc-value&quot;);WeakReference&lt;String&gt; weakRef = new WeakReference&lt;String&gt;(abc); // 弱引用abc = null; // 去掉强引用System.gc(); // 垃圾回收器进行回收System.out.println(weakRef.get());输出:str-valuenull 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.WeakHashMap;public class ReferenceDemo &#123; public static void main(String[] args) &#123; String a = new String(&quot;key-a&quot;); String b = new String(&quot;key-b&quot;); Map map = new HashMap(); map.put(a, &quot;aaa&quot;); map.put(b, &quot;bbb&quot;); Map weakmap = new WeakHashMap(); weakmap.put(a, &quot;aaaa&quot;); weakmap.put(b, &quot;bbbb&quot;); map.remove(a); a = null; // 移除 a 的强引用, key-a 也没人引用了; map.size(); b = null; // 移除 b 的强引用, key-b 还被 map 引用着 map.get(b); map.get(&quot;key-b&quot;); System.gc(); Iterator i = map.entrySet().iterator(); while (i.hasNext()) &#123; Map.Entry en = (Map.Entry) i.next(); System.out.println(&quot;map:&quot; + en.getKey() + &quot;:&quot; + en.getValue()); &#125; Iterator j = weakmap.entrySet().iterator(); while (j.hasNext()) &#123; Map.Entry en = (Map.Entry) j.next(); System.out.println(&quot;weakmap:&quot; + en.getKey() + &quot;:&quot; + en.getValue()); &#125; &#125;&#125;输出map:key-b:bbbweakmap:key-b:bbbb 想说的话1234567891011121314151617181920212223242526272829303132// 平时使用的缓存存在的问题1. 对象都是强引用的2. 不确定单个对象占用的 byte size 大小3. 无法准确的估算创建缓存的时候为其指定一个准确的大小4. JVM 即使报 OOM 也不会清理这些缓存, 失去缓存的意义 =&gt; LRU // 弱引用缓存 WeakHashMap1. key 是经过弱引用化处理的, value 不是2. 即使不被主动调用 remove, clear 方法，元素也是会有机会清除的3. key-value 的清理时机, key 伴随 gc 清理, value 根据 ReferenceQueue 进行清理4. ReferenceQueue5. 为什么会存在 ReferenceQueue ? 我们可以通过 reference.get() 的返回值确定 referent 是否被回收了, 但是现实是我们有大量的引用对象，这么操作是不实际的，一个好的解决方案就出来了 - 引用队列， 在构造时将引用与队列相关联，并且在清除引用后将其放在队列上。要发现哪些引用已被清除, 可以轮询队列。这可以通过后台线程完成，但是在创建新引用时轮询队列通常更简单(WeakHashMap就是这么做的) 引用队列更像是监听器. // 弱引用的特点更适合高速缓存// 引用的状态1. Active: 新创建的实例处于活动状态, 由垃圾收集者进行特殊处理, 收集器检测到引用对象的可访问性已更改为适当的状态后的一段时间，它会将实例的状态更改为挂起或不活动， 这取决于创建实例时是否向队列注册了实例, 在前一种情况下，它还将实例添加到挂起引用列表中.2. Pending: 挂起引用列表的元素，等待引用处理程序线程排队,未注册的实例从不处于此状态.3. Enqueued 在创建实例时向其注册的队列元素. 当实例从其引用队列中移除时,它将变为非活动状态. 未注册的实例从不处于此状态4. Inactive 一旦实例变为非活动状态,其状态将永远不会再改变. 弱引用的应用WeakHashMap (源码分析) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261. 根据 API 文档，当 Map 中的键不再使用，键对应的键值也将自动在 WeakHashMap 中删除。WeakHashMap 中的键为弱键，和其他 Map 接口的实现有些不同；2. 和 HashMap 类似; 但是支持 key 和 value 为 null, 不存在红黑树结构，因为没必要3. 同样不是线程安全的，可以使用 Collections.synchronizedMap(Map map) 来使之线程安全4. 没有实现 Cloneable, Serializable接口, 没有必要public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 基本组成属性 private static final int DEFAULT_INITIAL_CAPACITY = 16; private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private static final Object NULL_KEY = new Object(); Entry&lt;K,V&gt;[] table; // 这个 Entry 继承了 WeakReference private int size; private int threshold; private final float loadFactor; /** * Reference queue for cleared WeakEntries * * 队列放的是什么 ? */ private final ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;(); int modCount;&#125;// 1. put 方法分析public V put(K key, V value) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int i = indexFor(h, tab.length); // 遍历 table[i] 链表, 如果找到相同的 key 则将老的 value 用新的 value 替换 for (Entry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; V oldValue = e.value; if (value != oldValue) e.value = value; return oldValue; &#125; &#125; modCount++;// 修改次数++ Entry&lt;K,V&gt; e = tab[i];// 取得链表的第一个元素 // 构建新的链表（将新元素放在链表最前面）,同时将 key 注册到引用队列 tab[i] = new Entry&lt;&gt;(k, value, queue, h, e); if (++size &gt;= threshold) resize(tab.length * 2); return null;&#125;private static Object maskNull(Object key) &#123; return (key == null) ? NULL_KEY : key;&#125;final int hash(Object k) &#123; int h = k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;private Entry&lt;K,V&gt;[] getTable() &#123; expungeStaleEntries(); return table;&#125;// 将引用队列里的元素拿出来，修正 table 中的无效数据private void expungeStaleEntries() &#123; for (Object x; (x = queue.poll()) != null; ) &#123; synchronized (queue) &#123; @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x;// queue 放的是元素, 将要被清理的元素 int i = indexFor(e.hash, table.length);// 定位在 table 数组的位置 Entry&lt;K,V&gt; prev = table[i];// 取得 table [i] 处链表的第一个元素 Entry&lt;K,V&gt; p = prev; while (p != null) &#123;// 链表是否为空或者是否是链表的最后一个元素 Entry&lt;K,V&gt; next = p.next; if (p == e) &#123; // 找到了要被清理的元素 if (prev == e)// prev 不一定和 p 相同 table[i] = next; // 用下一个元素对 e 元素替换 else prev.next = next; // 修复链接 // Must not null out e.next; // stale entries may be in use by a HashIterator e.value = null; // Help GC size--; break; &#125; prev = p; // 没找到要被清理的元素,交换指针,移动位置,继续比对 p = next; &#125; &#125; &#125;&#125;Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; super(key, queue); this.value = value; this.hash = hash; this.next = next;&#125;/** * Creates a new weak reference that refers to the given object and is * registered with the given queue. * * @param referent object the new weak reference will refer to * @param q the queue with which the reference is to be registered, * or &lt;tt&gt;null&lt;/tt&gt; if registration is not required * * 监听器效果, 如果引用的对象被回收(reference.get() == null)，则将其加入该队列 */public WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q);&#125;Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243// 2. get 方法分析public V get(Object key) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int index = indexFor(h, tab.length); Entry&lt;K,V&gt; e = tab[index]; while (e != null) &#123; if (e.hash == h &amp;&amp; eq(k, e.get())) return e.value; e = e.next; &#125; return null;&#125;// 3. remove 方法, 分析过 expungeStaleEntries 方法，该方法就没必要看了public V remove(Object key) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int i = indexFor(h, tab.length); Entry&lt;K,V&gt; prev = tab[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; modCount++; size--; if (prev == e) tab[i] = next; else prev.next = next; return e.value; &#125; prev = e; e = next; &#125; return null;&#125;// 通过分析可以看到 getTable() 经常被调用到，它和 ReferenceQueue 一起完成的对 k-v 的清理工作","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM性能调优的6大步骤-关键调优参数详解","slug":"language/jvm/JVM性能调优的6大步骤-关键调优参数详解","date":"2021-08-04T06:25:13.664Z","updated":"2021-08-04T06:25:13.664Z","comments":true,"path":"2021/08/04/language/jvm/JVM性能调优的6大步骤-关键调优参数详解/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%846%E5%A4%A7%E6%AD%A5%E9%AA%A4-%E5%85%B3%E9%94%AE%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"一、JVM 内存调优对 JVM 内存的系统级的调优主要的目的是减少 GC 的频率和 Full GC 的次数。 1.Full GC会对整个堆进行整理，包括 Young、Tenured 和 Perm。Full GC 因为需要对整个堆进行回收，所以比较慢，因此应该尽可能减少 Full GC 的次数。 2.导致 Full GC 的原因1)年老代（Tenured）被写满 调优时尽量让对象在新生代 GC 时被回收、让对象在新生代多存活一段时间和不要创建过大的对象及数组避免直接在旧生代创建对象 。 2)持久代 Pemanet Generation 空间不足 增大 Perm Gen 空间，避免太多静态对象 ， 控制好新生代和旧生代的比例 3)System.gc()被显示调用 垃圾回收不要手动触发，尽量依靠 JVM 自身的机制 在对 JVM 调优的过程中，很大一部分工作就是对于 FullGC 的调节，下面详细介绍对应 JVM 调优的方法和步骤。 二、JVM 性能调优方法和步骤 1.监控 GC 的状态使用各种 JVM 工具，查看当前日志，分析当前 JVM 参数设置，并且分析当前堆内存快照和 gc 日志，根据实际的各区域内存划分和 GC 执行时间，觉得是否进行优化。 举一个例子： 系统崩溃前的一些现象： 每次垃圾回收的时间越来越长，由之前的 10ms 延长到 50ms 左右，FullGC 的时间也有之前的 0.5s 延长到 4、5s FullGC 的次数越来越多，最频繁时隔不到 1 分钟就进行一次 FullGC年老代的内存越来越大并且每次 FullGC 后年老代没有内存被释放 之后系统会无法响应新的请求，逐渐到达 OutOfMemoryError 的临界值，这个时候就需要分析 JVM 内存快照 dump。 2.生成堆的 dump 文件通过 JMX 的 MBean 生成当前的 Heap 信息，大小为一个 3G（整个堆的大小）的 hprof 文件，如果没有启动 JMX 可以通过 Java 的 jmap 命令来生成该文件。 3.分析 dump 文件打开这个 3G 的堆信息文件，显然一般的 Window 系统没有这么大的内存，必须借助高配置的 Linux，几种工具打开该文件： Visual VM IBM HeapAnalyzer JDK 自带的 Hprof 工具 Mat(Eclipse 专门的静态内存分析工具)推荐使用 备注：文件太大，建议使用 Eclipse 专门的静态内存分析工具 Mat 打开分析。 4.分析结果，判断是否需要优化如果各项参数设置合理，系统没有超时日志出现，GC 频率不高，GC 耗时不高，那么没有必要进行 GC 优化，如果 GC 时间超过 1-3 秒，或者频繁 GC，则必须优化。 注：如果满足下面的指标，则一般不需要进行 GC： Minor GC 执行时间不到 50ms； Minor GC 执行不频繁，约 10 秒一次； Full GC 执行时间不到 1s； Full GC 执行频率不算频繁，不低于 10 分钟 1 次； 5.调整 GC 类型和内存分配如果内存分配过大或过小，或者采用的 GC 收集器比较慢，则应该优先调整这些参数，并且先找 1 台或几台机器进行 beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择。 6.不断的分析和调整通过不断的试验和试错，分析并找到最合适的参数，如果找到了最合适的参数，则将这些参数应用到所有服务器。 cms 参数优化步流程下面我再继续介绍下 JVM 的关键参数配置(仅用于参考)。 JVM 调优参数参考1.针对 JVM 堆的设置，一般可以通过-Xms -Xmx 限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值;2.年轻代和年老代将根据默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率 NewRadio 来调整二者之间的大小，也可以针对回收代。比如年轻代，通过 -XX:newSize -XX:MaxNewSize 来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize 设置为同样大小。 3.年轻代和年老代设置多大才算合理1）更大的年轻代必然导致更小的年老代，大的年轻代会延长普通 GC 的周期，但会增加每次 GC 的时间；小的年老代会导致更频繁的 Full GC2）更小的年轻代必然导致更大年老代，小的年轻代会导致普通 GC 很频繁，但每次的 GC 时间会更短；大的年老代会减少 Full GC 的频率 如何选择应该依赖应用程序对象生命周期的分布情况：如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。 但很多应用都没有这样明显的特性。 在抉择时应该根 据以下两点： （1）本着 Full GC 尽量少的原则，让年老代尽量缓存常用对象，JVM 的默认比例 1：2 也是这个道理 。 （2）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响 Full GC 的前提下，根据实际情况加大年轻代，比如可以把比例控制在 1：1。 但应该给年老代至少预留 1/3 的增长空间。 4.在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。5.线程堆栈的设置：每个线程默认会开启 1M 的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般 256K 就足用。理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。 觉得不错请点赞支持下。 —-end—- JVM 相关技术干货推荐： 深入详解 JVM 内存模型与 JVM 参数详细配置 7 种 JVM 垃圾收集器特点，优劣势、及使用场景 JVM 的 4 种垃圾回收算法、垃圾回收机制与总结 深入剖析 JVM：G1 收集器+回收流程+推荐用例 参考：https://zhuanlan.zhihu.com/p/58897189","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM类加载机制","slug":"language/jvm/JVM类加载机制","date":"2021-08-04T06:25:13.664Z","updated":"2021-08-04T06:25:13.665Z","comments":true,"path":"2021/08/04/language/jvm/JVM类加载机制/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"类加载机制1. 类的加载过程类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7 个阶段。其中准备、验证、解析 3 个部分统称为连接（Linking）。如图所示: 1234567graph LR加载--&gt;验证验证--&gt;准备准备--&gt;解析解析--&gt;初始化初始化--&gt;使用使用--&gt;卸载 加载、验证、准备、初始化和卸载这 5 个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 语言的运行时绑定（也称为动态绑定或晚期绑定）。以下陈述的内容都已 HotSpot 为基准。 1.1 加载虚拟机在加载阶段需要完成三件事: 通过一个类的全限定名来获取定义此类的二进制字节流，如 Class 文件,网络,动态生成,数据库等 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口加载阶段和连接阶段（Linking）的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 1.2 验证验证是连接阶段的第一步，这一阶段的目的是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全，验证阶段大致会完成 4 个阶段的检验动作： 文件格式验证：验证字节流是否符合 Class 文件格式的规范；例如：是否以魔术 0xCAFEBABE 开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比 javac 编译阶段的语义分析），以保证其描述的信息符合 Java 语言规范的要求；例如：这个类是否有父类，除了 java.lang.Object 之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。验证阶段可能抛出一个 java.lang.IncompatibleClassChangeError 异常的子类，如 java.lang.IllegalAccessError、 java. lang. NoSuchFieldError、验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 1.3 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量（被 static 修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值. 如下定义:public static int value=123; 那变量 value 在准备阶段过后的初始值为 0 而不是 123.因为这时候尚未开始执行任何 java 方法，而把 value 赋值为 123 的 putstatic 指令是程序被编译后，存放于类构造器()方法之中，所以把 value 赋值为 123 的动作将在初始化阶段才会执行。 如下定义：public static final int value=123; 即当类字段的字段属性是 ConstantValue 时，会在准备阶段初始化为指定的值，所以标注为 final 之后，value 的值在准备阶段初始化为 123 而非 0. 1.4 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析针对如下 7 类符号引用进行： 类或接口字段类方法接口方法方法类型方法句柄调用点限定符 1.5 初始化类初始化阶段是类加载过程的最后一步，才真正开始执行类中定义的 Java 程序代码（或者说是字节码）。前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。 在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器()方法的过程。我们放到后面再讲()方法是怎么生成的，在这里，我们先看一下()方法执行过程中可能会影响程序运行行为的一些特点和细节，这部分相对更贴近于普通的程序开发人员[7]：·()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块中可以赋值，但是不能访问。·()方法与类的构造函数（或者说实例构造器()方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的()方法执行之前，父类的()方法已经执行完毕。因此在虚拟机中第一个被执行的()方法的类肯定是 java.lang.Object。·由于父类的()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作，如下代码执行字段 B 的值将会是 2 而不是 1。()方法执行顺序： 12345678910111213141516171819202122232425262728293031323334353637383940414243package sf.jvm.load; class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; public int getA()&#123; return A; &#125;&#125;class Sub extends Parent &#123; public static int B = A; public int getB()&#123; return B; &#125; public static void main(String[] args) &#123; new Parent(); System.out.println(Sub.B); System.out.println(new Sub().getB()); &#125;&#125;/** Compiled from &quot;Parent.java&quot; class sf.jvm.load.Parent &#123; public static int A; sf.jvm.load.Parent(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public int getA(); Code: 0: getstatic #2 // Field A:I 3: ireturn static &#123;&#125;; Code: 0: iconst_1 1: putstatic #2 // Field A:I 4: iconst_2 5: putstatic #2 // Field A:I 8: return &#125; */ ·()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成()方法。·接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成()方法。但接口与类不同的是，执行接口的()方法不需要先执行父接口的()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的()方法。·虚拟机会保证一个类的()方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作，那就可能造成多个进程阻塞，在实际应用中这种阻塞往往是很隐蔽的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package sf.jvm.load;class DeadLoopClass &#123; static &#123; //如果不加上这个if语句，编译器将提示&quot;Initializerdoesnotcompletenormally&quot;并拒绝编译 if (true) &#123; System.out.println(Thread.currentThread() + &quot;initDeadLoopClass&quot;); while (true) &#123; &#125; &#125; &#125; public static void main(String[] args) &#123; Runnable script = new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread() + &quot;start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot;runover&quot;); &#125; &#125;; Thread thread1 = new Thread(script); Thread thread2 = new Thread(script); thread1.start(); thread2.start(); &#125;&#125;/** * &quot;C:\\Program Files\\Java\\jdk1.8.0_91\\bin\\javap.exe&quot; -c sf.jvm.load.DeadLoopClass Compiled from &quot;DeadLoopClass.java&quot; class sf.jvm.load.DeadLoopClass &#123; sf.jvm.load.DeadLoopClass(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class sf/jvm/load/DeadLoopClass$1 3: dup 4: invokespecial #3 // Method sf/jvm/load/DeadLoopClass$1.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: new #4 // class java/lang/Thread 11: dup 12: aload_1 13: invokespecial #5 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 16: astore_2 17: new #4 // class java/lang/Thread 20: dup 21: aload_1 22: invokespecial #5 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 25: astore_3 26: aload_2 27: invokevirtual #6 // Method java/lang/Thread.start:()V 30: aload_3 31: invokevirtual #6 // Method java/lang/Thread.start:()V 34: return static &#123;&#125;; Code: 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: new #8 // class java/lang/StringBuilder 6: dup 7: invokespecial #9 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 10: invokestatic #10 // Method java/lang/Thread.currentThread:()Ljava/lang/Thread; 13: invokevirtual #11 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder; 16: ldc #12 // String initDeadLoopClass 18: invokevirtual #13 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 21: invokevirtual #14 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 24: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 27: goto 27 &#125; * */ 运行结果如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546Thread[main,5,main]initDeadLoopClass通过分析：一条线程正在死循环以模拟长时间操作，另外一条线程在阻塞等待.线程堆栈如下:2017-07-29 20:05:00Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode):&quot;Monitor Ctrl-Break&quot; #10 daemon prio=5 os_prio=0 tid=0x0000000018554800 nid=0x4920 runnable [0x00000000190de000] java.lang.Thread.State: RUNNABLE at java.net.DualStackPlainSocketImpl.accept0(Native Method) at java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199) - locked &lt;0x00000000d79d67c0&gt; (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:545) at java.net.ServerSocket.accept(ServerSocket.java:513) at com.intellij.rt.execution.application.AppMain$1.run(AppMain.java:79) at java.lang.Thread.run(Thread.java:745)&quot;Finalizer&quot; #3 daemon prio=8 os_prio=1 tid=0x00000000027d8800 nid=0x2d14 in Object.wait() [0x000000001837e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000d7808ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000d7808ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=2 tid=0x00000000027d3000 nid=0x4914 in Object.wait() [0x000000001827f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000d7806b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000000d7806b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)&quot;main&quot; #1 prio=5 os_prio=0 tid=0x000000000220e000 nid=0x450c runnable [0x00000000026de000] java.lang.Thread.State: RUNNABLE at sf.jvm.load.DeadLoopClass.&lt;clinit&gt;(DeadLoopClass.java:8) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:264) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:123)&quot;VM Thread&quot; os_prio=2 tid=0x0000000016ff7000 nid=0x6d4 runnable&quot;GC task thread#0 (ParallelGC)&quot; os_prio=0 tid=0x00000000026f7800 nid=0x4890 runnable&quot;GC task thread#1 (ParallelGC)&quot; os_prio=0 tid=0x00000000026f9000 nid=0x4514 runnable&quot;VM Periodic Task Thread&quot; os_prio=2 tid=0x00000000184e1800 nid=0x4934 waiting on conditionJNI global references: 15 2 类加载器2.1 类加载器概述虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到 Java 虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。类加载器可以说是 Java 语言的一项创新，也是 Java 语言流行的重要原因之一，它最初是为了满足 JavaApplet 的需求而被开发出来的。如今 JavaApplet 技术基本上已经死掉[1]，但类加载器却在类层次划分、OSGi、热部署、代码加密等领域大放异彩，成为了 Java 技术体系中一块重要的基石。类加载器（class loader）用来加载 Java 类到 Java 虚拟机中。一般来说，Java 虚拟机使用 Java 类的方式如下：Java 源程序（.java 文件）在经过 Java 编译器编译之后就被转换成 Java 字节代码（.class 文件）。类加载器负责读取 Java 字节代码，并转换成 java.lang.Class 类的一个实例。每个这样的实例用来表示一个 Java 类。通过此实例的 newInstance()方法就可以创建出该类的一个对象。实际的情况可能更加复杂，比如 Java 字节代码可能是通过工具动态生成的，也可能是通过网络下载的。 2.2 类加载器的结构12345graph BT启动类加载器--&gt;扩展类加载器扩展类加载器--&gt;应用类加载器应用类加载器--&gt;自定义加载器1应用类加载器--&gt;自定义加载器2 Java 虚拟机的角度讲，只存在两种不同的类加载器：一种是启动类加载器（BootstrapClassLoader），这个类加载器使用 C++语言实现[2]，是虚拟机自身的一部分；另外一种就是所有其他的类加载器，这些类加载器都由 Java 语言实现，独立于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。从 Java 开发人员的角度来看，类加载器就还可以划分得更细致一些，绝大部分 Java 程序都会使用到以下三种系统提供的类加载器：：引导类加载器（bootstrap class loader）：它用来加载 Java 的核心库，是用原生代码来实现的，并不继承自 java.lang.ClassLoader。扩展类加载器（extensions class loader）：它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。应用程序类加载器（application class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。除了系统提供的类加载器以外，开发人员可以通过继承 java.lang.ClassLoader 类的方式实现自己的类加载器，以满足一些特殊的需求。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 破坏双亲委派模型双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即 JDK1.2 发布之前。由于双亲委派模型在 JDK1.2 之后才被引入的，而类加载器和抽象类 java.lang.ClassLoader 则在 JDK1.0 时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java 设计者们引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2 之后的 java.lang.ClassLoader 添加了一个新的 protected 方法 findClass()，双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以被称为“基础”，是因为它们总是作为被用户代码调用的 API，但世事往往没有绝对的完美，如果基础类又要调用回用户的代码，那该怎么办了？这并非是不可能的事情，一个典型的例子便是 JNDI 服务，JNDI 现在已经是 Java 的标准服务，它的代码由启动类加载器去加载（在 JDK1.3 时代放进去的 rt.jar），但 JNDI 的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的 ClassPath 下的 JNDI 接口提供者（SPI，ServiceProviderInterface）的代码，但启动类加载器不可能“认识”这些代码啊！那该怎么办？为了解决这个困境，Java 设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（ThreadContextClassLoader）。这个类加载器可以通过 java.lang.Thread 类的 setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个；如果在应用程序的全局范围内都没有设置过，那么这个类加载器默认就是应用程序类加载器。有了线程上下文类加载器，就可以做一些“舞弊”的事情了，JNDI 服务使用这个线程上下文类加载器去加载所需要的 SPI 代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java 中所有涉及 SPI 的加载动作基本上都采用这种方式，例如 JNDI、JDBC、JCE、JAXB 和 JBI 等。双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的，这里所说的“动态性”指的是当前一些非常“热”门的名词：代码热替换（HotSwap）、模块热部署（HotDeployment）等，说白了就是希望应用程序能像我们的电脑外设那样，插上鼠标或 U 盘，不用重启机器就能立即使用，鼠标有问题或要升级就换个鼠标，不用停机也不用重启。对于个人电脑来说，重启一次其实没有什么大不了的，但对于一些生产系统来说，关机重启一次可能就要被列为生产事故，这种情况下热部署就对软件开发者，尤其是企业级软件开发者具有很大的吸引力。在 JSR-297[4]、JSR-277[5]规范从纸上标准变成真正可运行的程序之前，OSGi 是当前业界“事实上”的 Java 模块化标准，而 OSGi 实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块（OSGi 中称为 Bundle）都有一个自己的类加载器，当需要更换一个 Bundle 时，就把 Bundle 连同类加载器一起换掉以实现代码的热替换。在 OSGi 环境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为网状结构，当收到类加载请求时，OSGi 将按照下面的顺序进行类搜索： （1）将以 java.*开头的类，委派给父类加载器加载。（2）否则，将委派列表名单内的类，委派给父类加载器加载。（3）否则，将 Import 列表中的类，委派给 Export 这个类的 Bundle 的类加载器加载。（4）否则，查找当前 Bundle 的 ClassPath，使用自己的类加载器加载。（5）否则，查找类是否在自己的 FragmentBundle 中，如果在，则委派给 FragmentBundle 的类加载器加载。（6）否则，查找 DynamicImport 列表的 Bundle，委派给对应 Bundle 的类加载器加载。（7）否则，类查找失败。上面的查找顺序中只有开头两点仍然符合双亲委派规则，其余的类查找都是在平级的类加载器中进行的。 虽然使用了“被破坏”这个词来形容上述不符合双亲委派模型原则的行为，但这里“被破坏”并不带有贬义的感情色彩。只要有足够意义和理由，突破已有的原则就可算作一种创新。正如 OSGi 中的类加载器并不符合传统的双亲委派的类加载器，并且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议，但在 Java 程序员中基本有一个共识：OSGi 中对类加载器的使用是很值得学习的，弄懂了 OSGi 的实现，自然就明白了类加载器的精粹。//TODOOSGI 2.3 自定义类加载器实例:2.3.1 文件加载:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package sf.jvm.load.classloader;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.lang.reflect.Method;public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;; &#125; public static void main(String[] args) &#123; String classDataRootPath = &quot;D:\\\\Code\\\\Jcode\\\\notes\\\\java-jlp\\\\java-jvm\\\\target\\\\classes&quot;; FileSystemClassLoader fileSystemClassLoader1 = new FileSystemClassLoader(classDataRootPath); FileSystemClassLoader fileSystemClassLoader2 = new FileSystemClassLoader(classDataRootPath); String className = &quot;sf.jvm.load.simple.Sample&quot;; try &#123; Class&lt;?&gt; class1 = fileSystemClassLoader1.loadClass(className); Object obj1 = class1.newInstance(); Class&lt;?&gt; class2 = fileSystemClassLoader1.loadClass(className); Object obj2 = class2.newInstance(); Method setSampleMethod = class1.getMethod(&quot;setSample&quot;, Object.class); setSampleMethod.invoke(obj1, obj2); Method setSampleMethod2 = class1.getMethod(&quot;compare&quot;, Object.class); setSampleMethod2.invoke(obj1, obj2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.2 网络加载:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package sf.jvm.load.classloader;import sf.jvm.load.api.ICalculator;import java.io.ByteArrayOutputStream;import java.io.InputStream;import java.net.URL;public class NetworkClassLoader extends ClassLoader &#123; private String rootUrl; public NetworkClassLoader(String rootUrl) &#123; this.rootUrl = rootUrl; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; URL url = new URL(path); InputStream ins = url.openStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootUrl + &quot;/&quot; + className.replace(&#x27;.&#x27;, &#x27;/&#x27;) + &quot;.class&quot;; &#125; public static void main(String[] args) &#123; String url = &quot;http://localhost:8080/ClassloaderTest/classes&quot;; NetworkClassLoader ncl = new NetworkClassLoader(url); String basicClassName = &quot;sf.jvm.load.simple.CalculatorBasic&quot;; String advancedClassName = &quot;sf.jvm.load.simple.CalculatorAdvanced&quot;; try &#123; Class&lt;?&gt; clazz = ncl.loadClass(basicClassName); ICalculator calculator = (ICalculator) clazz.newInstance(); System.out.println(calculator.getVersion()); clazz = ncl.loadClass(advancedClassName); calculator = (ICalculator) clazz.newInstance(); System.out.println(calculator.getVersion()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM常见参数设置","slug":"language/jvm/JVM常见参数设置","date":"2021-08-04T06:25:13.663Z","updated":"2021-08-04T06:25:13.663Z","comments":true,"path":"2021/08/04/language/jvm/JVM常见参数设置/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%B8%B8%E8%A7%81%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"1. 查看-XX:+PrintFlagsFinal 查看堆的默认值，使用下面的代码。其中 InitialHeapSize 为最开始的堆的大小，MaxHeapSize 为堆的最大值。 12345678910$ java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 134217728 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 2147483648 &#123;product&#125;java version &quot;1.8.0_25&quot;Java(TM) SE Runtime Environment (build 1.8.0_25-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode) 查看栈的默认值, 其中 ThreadStackSize 为栈内存的大小。 12345678$ java -XX:+PrintFlagsFinal -version | grep ThreadStackSize intx CompilerThreadStackSize = 0 &#123;pd product&#125; intx ThreadStackSize = 1024 &#123;pd product&#125; intx VMThreadStackSize = 1024 &#123;pd product&#125;java version &quot;1.8.0_25&quot;Java(TM) SE Runtime Environment (build 1.8.0_25-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode) 2. 堆 -Xmx：初始堆的大小 -Xms：最大堆大小，建议这两个参数大小保持一致，为物理内存的 1/4 -Xmn：指定新生代的大小（Eden + Survior from + Survior to）的大小，增大新生代的大小，老年代的大小将被减小，sun 官方推荐 新生代的大小：堆 = 3 : 8 -XX:NewSize：设置新生代大小 -XX:MaxNewSize：设置新生代的最大值-Xmn 相当于设同时设置 NewSize=MaxNewSize -XX:NewRation：老年代：新生代 = 4，即 old：(Eden + Survivor from + Survivor to) ，则说明新生代为整个堆区的 1/5 -XX:SurvivorRation：设置 Eden 区和 Survivor。默认值为8；即：Eden：Survivor=8:1 ==&gt; Eden：Survivor from：Survivor to = 8:1:1若值为3，即：Eden：Survivor=8:1 ==&gt; Eden：Survivor from：Survivor to = 3:1:1 3. 方法区（非堆） -XX:PermSize：设置方法区大小 -XX:MaxPermSize： 设置方法区的最大值 1.8 之前可以理解为 永久区（PerSize，MaxPerSize）。 1.8 之后使用 元数据区 取代。（MaxMetaspaceSize）。 4. 栈 -Xss：栈内存的大小 5. 详细参数5.1.基础参数 参数名称 含义 默认值 -Xms 初始堆大小 物理内存的1/64(&lt;1GB) 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. -Xmx 最大堆大小 物理内存的1/4(&lt;1GB) 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 -Xmn 年轻代大小(1.4or lator) 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。 整个堆大小=年轻代大小 + 年老代大小 + 持久代大小. 增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -Xss 每个线程的堆栈大小 JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K. 根据应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右 一般小的应用， 如果栈不是很深， 应该128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。 和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:”-Xss is translated in a VM flag named ThreadStackSize”. 一般设置128k或者256k这个值就可以了。 -XX:ThreadStackSize Thread Stack Size (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.] -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5 Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 -XX:SurvivorRatio Eden区与Survivor区的大小比值 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 -XX:LargePageSizeInBytes 内存页的大小不可设置过大， 会影响Perm的大小 =128m -XX:+UseFastAccessorMethods 原始类型的快速优化 -XX:+DisableExplicitGC 关闭System.gc() 这个参数需要严格的测试 -XX:MaxTenuringThreshold 垃圾最大年龄 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率 该参数只有在串行GC时才有效. -XX:+AggressiveOpts 加快编译 -XX:+UseBiasedLocking 锁机制的性能改善 -Xnoclassgc 禁用垃圾回收 -XX:SoftRefLRUPolicyMSPerMB 每兆堆空闲空间中SoftReference的存活时间 1s softly reachable objects will remain alive for some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte in the heap -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 0 单位字节 新生代采用Parallel Scavenge GC时无效 另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. -XX:TLABWasteTargetPercent TLAB占eden区的百分比 1% -XX:+CollectGen0First FullGC时是否先YGC false 5.2 并行收集器相关参数| -XX:+UseParallelGC | Full GC采用parallel MSC(此项待验证) | | 选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证) || — | — | — | — || -XX:+UseParNewGC | 设置年轻代为并行收集 | | 可与CMS收集同时使用JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值 || -XX:ParallelGCThreads | 并行收集器的线程数 | | 此值最好配置与处理器数目相等 同样适用于CMS || -XX:+UseParallelOldGC | 年老代垃圾收集方式为并行收集(Parallel Compacting) | | 这个是JAVA 6出现的参数选项 || -XX:MaxGCPauseMillis | 每次年轻代垃圾回收的最长时间(最大暂停时间) | | 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值. || -XX:+UseAdaptiveSizePolicy | 自动选择年轻代区大小和相应的Survivor区比例 | | 设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开. || -XX:GCTimeRatio | 设置垃圾回收时间占程序运行时间的百分比 | | 公式为1/(1+n) || -XX:+ScavengeBeforeFullGC | Full GC前调用YGC | true | Do young generation GC prior to a full GC. (Introduced in 1.4.1.) | 5.3 CMS相关参数 -XX:+UseConcMarkSweepGC 使用CMS内存收集 测试中配置这个以后,-XX:NewRatio=4的配置失效了,原因不明.所以,此时年轻代大小最好用-Xmn设置.??? -XX:+AggressiveHeap 试图是使用大量的物理内存 长时间大内存使用的优化，能检查计算资源（内存， 处理器数量） 至少需要256MB内存 大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升） -XX:CMSFullGCsBeforeCompaction 多少次后进行内存压缩 由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生”碎片”,使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理. -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX+UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的压缩 CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。 增加这个参数是个好习惯。 可能会影响性能,但是可以消除碎片 -XX:+UseCMSInitiatingOccupancyOnly 使用手动定义初始化定义开始CMS收集 禁止hostspot自行触发CMS GC -XX:CMSInitiatingOccupancyFraction=70 使用cms作为垃圾回收 使用70％后开始CMS收集 92 为了保证不出现promotion failed(见下面介绍)错误,该值的设置需要满足以下公式CMSInitiatingOccupancyFraction计算公式 -XX:CMSInitiatingPermOccupancyFraction 设置Perm Gen使用到达多少比率时触发 92 -XX:+CMSIncrementalMode 设置为增量模式 用于单CPU情况 -XX:+CMSClassUnloadingEnabled 5.4 辅助信息| -XX:+PrintGC | | | 输出形式:[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] || — | — | — | — || -XX:+PrintGCDetails | | | 输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] || -XX:+PrintGCTimeStamps | | | || -XX:+PrintGC:PrintGCTimeStamps | | | 可与-XX:+PrintGC -XX:+PrintGCDetails混合使用输出形式:11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] || -XX:+PrintGCApplicationStoppedTime | 打印垃圾回收期间程序暂停的时间.可与上面混合使用 | | 输出形式:Total time for which application threads were stopped: 0.0468229 seconds || -XX:+PrintGCApplicationConcurrentTime | 打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用 | | 输出形式:Application time: 0.5291524 seconds || -XX:+PrintHeapAtGC | 打印GC前后的详细堆栈信息 | | || -Xloggc:filename | 把相关日志信息记录到文件以便分析.与上面几个配合使用 | | || -XX:+PrintClassHistogram | garbage collects before printing the histogram. | | || -XX:+PrintTLAB | 查看TLAB空间的使用情况 | | || XX:+PrintTenuringDistribution | 查看每次minor GC后新的存活周期的阈值 | | Desired survivor size 1048576 bytes, new threshold 7 (max 15)new threshold 7即标识新的存活周期的阈值为7。 | 6.参考https://juejin.cn/post/6844903740848242695http://ssword.cn/f/view-3-be0e37a28e984c9c832a864b70d615cf.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM性能监控及故障分析工具","slug":"language/jvm/JVM性能监控及故障分析工具","date":"2021-08-04T06:25:13.663Z","updated":"2021-08-04T06:25:13.664Z","comments":true,"path":"2021/08/04/language/jvm/JVM性能监控及故障分析工具/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%8F%8A%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"JVM 性能监控及故障分析工具1.概要JDK官方提供了不少好用的JAVA故障处理工具,JDK的命令行工具在JDK的bin目录下供用户使用。 ２.jps２.1.简介jps是jdk提供的查看当前java进程的工具，简单看作为JavaVirtual Machine Process Status Tool。命令格式： 1jps [options] [hostid] options 参数详解:参数 | 解释—-| —- -q | 仅输出VM标识符，不包括classname,jar name,arguments in main method -m | 输出main method的参数 -l | 输出完全的包名，应用主类名，jar的完全路径名 -v | 输出jvm参数 -V | 输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 -J | 传递参数到vm,例如:-J-Xms512mhostid 参数解释:[protocol:][[//]hostname][:port][/servername] ２.２.实例123[java@RCS-AS-01 root]$ jps3201 Jps20819 AuthBootstrap 12[java@RCS-AS-01 root]$ jps -lv20819 com.feinno.urcs.auth.main.AuthBootstrap -Duser.dir=/home/urcs/urcs-as-authentication -Xmx1024m -Xms1024m 1234[java@RCS-AS-01 root]$ jps -lvm 10.10.220.101RMI Registry not available at 10.10.220.101:1099Connection refused to host: 10.10.220.101; nested exception is:java.net.ConnectException: Connection refused。需要在远程机器上开启：jstatd 3.jstat3.1.简介Jstat是JDK自带的一个轻量级小工具。全称“Java Virtual Machine statistics monitoring tool”，它位于Java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控。可见，Jstat是轻量级的、专门针对JVM的工具。命令格式： 1jstat [options] 3.2.options 参数详解: 3.2.1. jstat -class : 显示加载 class 的数量,及所占空间等信息, 显示列名 具体描述 Loaded 装载的类的数量 Bytes 装载类所占用的字节数 Unloaded 卸载类的数量 Bytes 卸载类的字节数 Time 装载和卸载类所花费的时间 3.2.2.jstat -compiler :显示 VM 实时编译的数量等信息, 显示列名 具体描述 Compiled 编译任务执行数量 Failed 编译任务执行失败数量 Invalid 编译任务执行失效数量 Time 编译任务消耗时间 FailedType 最后一个编译失败任务的类型 FailedMethod 最后一个编译失败任务所在的类及方法 3.2.3.jstat -gc : 可以显示 gc 的信息,查看 gc 的次数,及时间, 显示列名 具体描述 S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) S0U 年轻代中第一个 survivor(幸存区)目前已使用空间(字节) S1U 年轻代中第二个 survivor(幸存区)目前已使用空间(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) EU 年轻代中 Eden(伊甸园)目前已使用空间(字节) OC Old 代的容量(字节) OU Old 代目前已使用空间(字节) PC Perm(持久代)的容量(字节) PU Perm(持久代)目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.4. jstat -gccapacity :可以显示,VM 内存中三代(young,old,perm)对象的使用和占用大小 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量(字节) NGC 年轻代(young)中当前的容量(字节) S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) OGCMN old 代中初始化(最小)的大小(字节) OGCMX old 代的最大容量(字节) OGC old 代当前新生成的容量(字节) OC Old 代的容量(字节) PGCMN perm 代中初始化(最小)的大小(字节) PGCMX perm 代的最大容量(字节) PGC perm 代当前新生成的容量(字节) PC Perm(持久代)的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 3.2.5.jstat -gcutil :统计 gc 信息 显示列名 具体描述 S0 年轻代中第一个 survivor(幸存区)已使用的占当前容量百分比 S1 年轻代中第二个 survivor(幸存区)已使用的占当前容量百分比 E 年轻代中 Eden(伊甸园)已使用的占当前容量百分比 O old 代已使用的占当前容量百分比 P perm 代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.6. jstat -gcnew :年轻代对象的信息, 显示列名 具体描述 S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) S0U 年轻代中第一个 survivor(幸存区)目前已使用空间(字节) S1U 年轻代中第二个 survivor(幸存区)目前已使用空间(字节) TT 持有次数限制 MTT 最大持有次数限制 EC 年轻代中 Eden(伊甸园)的容量(字节) EU 年轻代中 Eden(伊甸园)目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) 3.2.7. jstat -gcnewcapacity : 年轻代对象的信息及其占用量, 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量(字节) NGC 年轻代(young)中当前的容量(字节) S0CMX 年轻代中第一个 survivor(幸存区)的最大容量(字节) S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1CMX 年轻代中第二个 survivor(幸存区)的最大容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) ECMX 年轻代中 Eden(伊甸园)的最大容量(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) 3.2.8. jstat -gcold :old 代对象的信息, 显示列名 具体描述 PC Perm(持久代)的容量(字节) PU Perm(持久代)目前已使用空间(字节) OC Old 代的容量(字节) OU Old 代目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.9.stat -gcoldcapacity : old 代对象的信息及其占用量 显示列名 具体描述 OGCMN old 代中初始化(最小)的大小(字节) OGCMX old 代的最大容量(字节) OGC old 代当前新生成的容量(字节) OC Old 代的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.10. jstat -gcpermcapacity: perm 对象的信息及其占用量, 显示列名 具体描述 PGCMN perm 代中初始化(最小)的大小(字节) PGCMX perm 代的最大容量(字节) PGC perm 代当前新生成的容量(字节) PC Perm(持久代)的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.11. jstat -printcompilation :当前 VM 执行的信息, 显示列名 具体描述 Compiled 编译任务的数目 Size 方法生成的字节码的大小 Type 编译类型 Method 类名和方法名用来标识编译的方法,类名使用/做为一个命名空间分隔符,方法名是给定类中的方法,上述格式是由-XX:+PrintComplation 选项进行设置的 3.3.实例:1234[java@RCS-AS-01 root]$ jstat -gcutil 16885 1000 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 93.51 54.24 10.36 98.25 96.86 205 16.720 3 1.041 17.760 0.00 93.51 54.24 10.36 98.25 96.86 205 16.720 3 1.041 17.760 1234[java@RCS-AS-01 root]$ jstat -class 16885 1000Loaded Bytes Unloaded Bytes Time 10051 19327.1 32 44.2 27.15 10051 19327.1 32 44.2 27.15 4.jinfo4.1.简介jinfo(Java Configuration Information)，主要用于查看指定Java进程(或核心文件、远程调试服务器)的Java配置信息。命令格式： 123jinfo [options] pidjinfo [options] executable corejinfo [options] [server-id@]remote-hostname-or-IP 参数详解:参数 | 解释—-| —- pid | 进程号 executable | 产生core dump的java executable core | core file remote-hostname-or-IP | 主机名或ip server-id | 远程主机上的debug server的唯一id options 参数详解: 参数 解释 no option 打印命令行参数和系统属性 -flags 打印命令行参数 -sysprops 打印系统属性 -h 帮助 4.2.实例123456789101112131415161718[java@RCS-AS-01 root]$ jinfo 16885Attaching to process ID 16885, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.65-b01Java System Properties:java.runtime.name = Java(TM) SE Runtime Environmentjava.vm.version = 25.65-b01sun.boot.library.path = /usr/local/jdk8u65/jre/lib/amd64java.vendor.url = http://java.oracle.com/java.vm.vendor = Oracle Corporationpath.separator = :file.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VM.....VM Flags:Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357564416 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=357564416 -XX:OldSize=716177408 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGCCommand line: -Duser.dir=/home/urcs/urcs-as-im -Xmx1024m -Xms1024m 1234567[java@RCS-AS-01 root]$ jinfo -flags 16885Attaching to process ID 16885, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.65-b01Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357564416 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=357564416 -XX:OldSize=716177408 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGCCommand line: -Duser.dir=/home/urcs/urcs-as-im -Xmx1024m -Xms1024m 5.jmap5.1.简介jps是jdk提供的查看当前java进程的工具，简单看作为JavaVirtual Machine Process Status Tool。命令格式： 123jmap [options] pidjmap [options] executable corejmap [options] [server-id@]remote-hostname-or-IP 参数详解:参数 | 解释—-| —- pid | 进程号 executable | 产生core dump的java executable core | core file remote-hostname-or-IP | 主机名或ip server-id | 远程主机上的debug server的唯一id options 参数详解:参数 | 解释—-| —--dump:[live,]format=b,file= | 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件.-finalizerinfo | 打印正等候回收的对象的信息.-heap | 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况.-histo[:live] | 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量.-permstat | 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来.-F | 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效.-h | -help 打印辅助信息-J | 传递参数给jmap启动的jvm. 5.2.实例123[java@RCS-AS-01 root]$ jmap -dump:live,format=b,file=/tmp/heap.dump 16885Dumping heap to /tmp/heap.dump ...Heap dump file created 6.jstack6.1.简介jstack（ Stack Trace for Java） 命令 用于 生成 虚拟 机 当前 时刻 的 线程 快照（ 一般 称为 threaddump 或 javacore 文件）。 线程 快照 就是 当前 虚拟 机内 每一 条 线程 正在 执行 的 方法 堆栈 的 集合， 生成 线程 快照 的 主要 目的 是 定位 线程 出现 长时间 停顿 的 原因， 如 线程间死锁,死 循环,请求 外部 资源 导致 的 长时间 等待 等 都是 导致 线程 长时间 停顿 的 常见 原因。 命令格式： 123jstack [options] pidjstack [options] executable corejstack [options] [server-id@]remote-hostname-or-IP 参数详解: 参数 解释 pid 进程号 executable 产生 core dump 的 java executable core core file remote-hostname-or-IP 主机名或 ip server-id 远程主机上的 debug server 的唯一 id options 参数详解: 参数 解释 -F 当 jstack [-l] pid 没有相应的时候强制打印栈信息 -l 长列表. 打印关于锁的附加信息,例如属于 java.util.concurrent 的 ownable synchronizers 列表. -m 打印 java 和 native c/c++框架的所有栈信息. -h -help 打印帮助信息 6.2.实例123456789101112131415161718[java@RCS-AS-01 root]$ jstack 16885 &gt; /tmp/stack16885.1查看文件显示：2017-07-29 16:20:51Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode):&quot;HikariCP connection filler (pool HikariPool-11)&quot; #26011 daemon prio=5 os_prio=0 tid=0x0000000000f46000 nid=0x2bde waiting on condition [0x00007f334e8b4000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000c25016e8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1066) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)............ 7.jhat7.1.简介提供 jhat（ JVM Heap Analysis Tool） 命令 与 jmap 搭配 使用， 来 分析 jmap 生成 的 堆 转储 快照。命令格式： 1 jhat -J-Xmx512m &lt;heap dump file&gt; 备注:jhat 内置 了 一个 微型 的 HTTP/ HTML 服务器， 生成 dump 文件 的 分析 结果 后， 可以 在 浏览器 中 查看。 不过 实事求是 地说， 在 实际 工作中， 除非 笔者 手上 真的 没有 别的 工具 可用， 否则 一般 都 不会 去 直接 使用 jhat 命令 来 分析 dump 文件， 主要原因 有 二： 一是 一般 不会 在 部署 应用 程序 的 服务器 上 直接 分析 dump 文件， 即使 可以 这样做， 也会 尽量 将dump 文件 拷贝 到 其他 机器[ 4] 上进 行 分析， 因为 分析 工作 是一 个 耗时 而且 消耗 硬件 资源 的 过程， 既然 都要 在 其他 机器 上 进行， 就 没 必要 受到 命令行 工具 的 限制 了。 另外 一个 原因 是 jhat 的 分析 功能 相对来说 比较 简陋， 后文 将会 介绍 到 的 VisualVM 7.2.实例:1、产生dump文件 c:&gt;jmap -dump:file=f:\\yown\\dump.bin 16912Dumping heap to F:\\apps\\dump.txt …Heap dump file created 2、生成站点分析报告，便于网络访问 c:&gt;jhat -J-Xmx512m -port 88f:\\yown\\dump.bin 12345678910111213141516171819Reading from f:\\apps\\dump.bin...Dump file created Thu Jul 26 16:31:36 CST 2012Snapshot read, resolving...Resolving 2194971 objects...Chasing references, expect 438 dots......................................................................................................................................................................................................................................................................................................................................................................................................................................................Eliminating duplicate references......................................................................................................................................................................................................................................................................................................................................................................................................................................................Snapshot resolved.Started HTTP server on port 88Server is ready. 3.访问 http://localhost:88/ 这里记录了进程中所有类及实例个数 8.jvisualvm8.1.简介:VisualVM（ All- in- One Java Troubleshooting Tool） 是 到 目前 为止， 随 JDK 发布 的 功能 最强 大的 运行 监视 和 故障 处理 程序， 并且 可以 预见 在 未来 一段时间 内 都是 官方 主力 发展 的 虚拟 机 故障 处理 工具。 官方 在 VisualVM 的 软件 说明 中写 上了“ All- in- One” 的 描述 字样， 预示 着 它 除了 运行 监视、 故障 处理 外， 还 提供 了 很多 其他 方面 的 功能。VisualVM 基于 NetBeans 平台 开发， 因此 它 一 开始 就 具备 了 插件 扩展 功能 的 特性， 通过 插件 扩展 支持， VisualVM 可以 做到：·显示 虚拟 机 进程 及 进程 的 配置 和 环境 信息（ jps、 jinfo）·监视 应用 程序 的 CPU、 GC、 堆、 方法 区 及 线程 的 信息（ jstat、 jstack）。·dump 及 分析 堆 转储 快照（ jmap、 jhat）·方法 级 的 程序 运行 性能 分析， 找出 被 调用 最多、 运行 时间 最长 的 方法·离 线程 序 快照： 收集 程序 的 运行时 配置、 线程 dump、 内存 dump 等 信息 建立 一个 快照， 可以 将 快照 发送 开发者 处 进行 Bug 反馈。·其他 plugins 的 无限 的 可能性 8.2.界面展示如下图 9.开启Java服务远程监控9.1.启动脚本中添加如下参数1JAVA_ARGS[2]=&quot;-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=10.10.220.101&quot; 9.2.通过jvisualvm可以监控远程java服务，如下：","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM内存模型","slug":"language/jvm/JVM内存模型","date":"2021-08-04T06:25:13.662Z","updated":"2021-08-04T06:25:13.662Z","comments":true,"path":"2021/08/04/language/jvm/JVM内存模型/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"##JVM 内存模型 1.内存模型结构图 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有， 生命周期与线程相同 大致为字节码行号指示器 无 无 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss OutOfMemoryError，StackOverflowError java 堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx -Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 -XX:PermSize:16M-XX:MaxPermSize64M OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 无 无 1.1 程序计数器 程序 计数器（ Program Counter Register） 是一 块 较小 的 内存 空间， 它的 作用 可以 看做 是 当前 线程 所 执行 的 字节 码 的 行号 指示器。 在 虚拟 机 的 概念 模型 里（ 仅是 概念 模型， 各种 虚拟 机 可能 会 通过 一些 更 高效 的 方式 去 实现）， 字节 码 解释器 工作 时 就是 通过 改变 这个 计数器 的 值 来 选取 下一 条 需要 执行 的 字节 码 指令， 分支、 循环、 跳 转、 异常 处理、 线程 恢复 等 基础 功能 都 需要 依赖 这个 计数器 来 完成。 由于 Java 虚拟 机 的 多 线程 是 通过 线程 轮流 切换 并 分配 处理器 执行 时间 的 方式 来 实现 的， 在任 何 一个 确定 的 时刻， 一个 处理器（ 对于 多 核 处理器 来说 是一 个 内核） 只会 执行 一条 线程 中的 指令。 因此， 为了 线程 切换 后能 恢复 到 正确 的 执行 位置， 每条 线程 都 需要 有一个 独立 的 程序 计数器， 各条 线程 之间 的 计数器 互不 影响， 独立 存储， 我们 称 这类 内存 区域 为“ 线程 私有” 的 内存。 如果 线程 正在 执行 的 是 一个 Java 方法， 这个 计数器 记录 的 是 正在 执行 的 虚拟 机 字节 码 指令 的 地址； 如果 正在 执 行的 是 Natvie 方法， 这个 计数器 值 则为 空（ Undefined）。 此 内存 区域 是 唯一 一个 在 Java 虚拟 机 规范 中 没有 规定 任何 OutOfMemoryError 情况 的 区域。 1.2 Java 虚拟 机 栈 与 程序 计数器 一样， Java 虚拟 机 栈（ Java Virtual Machine Stacks） 也是 线程 私有 的， 它的 生命 周期 与 线程 相同。 虚拟 机 栈 描述 的 是 Java 方法 执行 的 内存 模型： 每个 方法 被 执行 的 时候 都会 同时 创建 一个 栈 帧（ Stack Frame[ 1]） 用于 存储 局部 变 量表、 操作 栈、 动态 链接、 方法 出口 等 信息。 每一个 方法 被 调用 直至 执行 完成 的 过程， 就 对应 着 一个 栈 帧 在 虚拟 机 栈 中 从 入栈 到 出 栈 的 过程,对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 经常 有人 把 Java 内存 区 分为 堆 内存（ Heap） 和 栈 内存（ Stack）， 这种 分法 比较 粗糙， Java 内存 区域 的 划分 实际上 远比 这 复杂。 这种 划分 方式 的 流行 只能 说明 大多数 程序员 最 关注 的、 与 对象 内存 分配 关系 最 密切 的 内存 区域 是 这 两块。 其中 所指 的“ 堆” 在后面 会 专门 讲述， 而 所指 的“ 栈” 就是 现在 讲的 虚拟 机 栈， 或者 说是 虚拟 机 栈 中的 局部 变量 表 部分。 局部 变量 表 存放 了 编译 期 可知 的 各种 基本 数据 类型（ boolean、 byte、 char、 short、 int、 float、 long、 double）、 对象 引用（ reference 类型， 它不 等同 于 对象 本身， 根据 不同 的 虚拟 机 实现， 它可 能 是一 个 指向 对象 起始 地址 的 引用 指针， 也可能 指向 一个 代表 对象 的 句柄 或者 其他 与此 对象 相关 的 位置） 和 returnAddress 类型（ 指向 了 一条 字节 码 指令 的 地址）。 其中 64 位 长度 的 long 和 double 类型 的 数据 会 占用 2 个 局部 变量 空间（Slot）， 其余 的 数据 类型 只占 用 1 个。 局部 变量 表 所需 的 内存 空间 在编 译 期间 完成 分配， 当 进入 一个 方法 时， 这个 方法 需 要在 帧 中 分配 多大 的 局部 变量 空间 是 完全 确定 的， 在 方法 运行 期间 不会 改变 局部 变 量表 的 大小。 在 Java 虚拟 机 规范 中， 对这 个 区域 规定了 两种 异常 状况： 如果 线程 请求 的 栈 深度 大于 虚拟 机 所 允许 的 深度， 将 抛出 StackOverflowError 异常； 如果 虚拟 机 栈 可以 动态 扩展（ 当前 大部分 的 Java 虚拟 机 都可 动态 扩展， 只不过 Java 虚拟 机 规范 中 也 允许 固定 长度 的 虚拟 机 栈）， 当 扩展 时 无法 申请 到 足够 的 内存 时会 抛出 OutOfMemoryError 异常。 1.2.1 局部变量表 局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在Java程序被编译成Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需要分配的最大局部变量表的容量。 局部变量表的容量以变量槽（Slot）为最小单位，32位虚拟机中一个Slot可以存放一个32位以内的数据类型（boolean、byte、char、short、int、float、reference和returnAddress八种）。 reference类型虚拟机规范没有明确说明它的长度，但一般来说，虚拟机实现至少都应当能从此引用中直接或者间接地查找到对象在Java堆中的起始地址索引和方法区中的对象类型数据。 returnAddress类型是为字节码指令jsr、jsr_w和ret服务的，它指向了一条字节码指令的地址。 虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 Slot是可以重用的，当Slot中的变量超出了作用域，那么下一次分配Slot的时候，将会覆盖原来的数据。Slot对对象的引用会影响GC（要是被引用，将不会被回收）。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 1.2.2 操作数栈 和局部变量区一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作——压栈和出栈—来访问的。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机在操作数栈中存储数据的方式和在局部变量区中是一样的：如int、long、float、double、reference和returnType的存储。对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int。 虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。比如，iadd指令就要从操作数栈中弹出两个整数，执行加法运算，其结果又压回到操作数栈中。如下演示了虚拟机是如何把两个int类型的局部变量相加，再把结果保存到第三个局部变量的： 123456begin iload_0 // push the int in local variable 0 ontothe stack iload_1 //push the int in local variable 1 onto the stack iadd // pop two ints, add them, push result istore_2 // pop int, store into local variable 2 end 1. 指令iload_0和iload_1将存储在局部变量中索引为0和1的整数压入操作数栈中 2. iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈 3. istore_2则从操作数栈中弹出结果，并把它存储到局部变量区索引为2的位置。 4. 局部变量和操作数栈的状态变化，图中没有使用的局部变量区和操作数栈区域以空白表示。 1.2.3 动态连接 虚拟机运行的时候,运行时常量池会保存大量的符号引用，这些符号引用可以看成是每个方法的间接引用。如果代表栈帧A的方法想调用代表栈帧B的方法，那么这个虚拟机的方法调用指令就会以B方法的符号引用作为参数，但是因为符号引用并不是直接指向代表B方法的内存位置，所以在调用之前还必须要将符号引用转换为直接引用，然后通过直接引用才可以访问到真正的方法。 如果符号引用是在类加载阶段或者第一次使用的时候转化为直接应用，那么这种转换成为静态解析，如果是在运行期间转换为直接引用，那么这种转换就成为动态连接。 1.2.4 返回地址 方法的返回分为两种情况，一种是正常退出，退出后会根据方法的定义来决定是否要传返回值给上层的调用者，一种是异常导致的方法结束，这种情况是不会传返回值给上层的调用方法。 不过无论是那种方式的方法结束，在退出当前方法时都会跳转到当前方法被调用的位置，如果方法是正常退出的，则调用者的PC计数器的值就可以作为返回地址,，果是因为异常退出的，则是需要通过异常处理表来确定。 方法的的一次调用就对应着栈帧在虚拟机栈中的一次入栈出栈操作，因此方法退出时可能做的事情包括：恢复上层方法的局部变量表以及操作数栈，如果有返回值的话，就把返回值压入到调用者栈帧的操作数栈中，还会把PC计数器的值调整为方法调用入口的下一条指令。 1.2.5 异常 在Java 虚拟机规范中，对虚拟机栈规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。如下代码为请求大于虚拟机堆栈深度所出现的异常 123456789101112131415161718192021 javapackage com.sf.jvm;/*** VM Args：- Xss128k*/public class JavaVMStackSOF &#123; private intstackLength=1; public void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args)throwsThrowable &#123; JavaVMStackSOF oom =newJavaVMStackSOF(); try&#123; oom.stackLeak(); &#125;catch(Throwable e) &#123; System.out.println(&quot; stack length:&quot; + oom.stackLength); throw e; &#125; &#125;&#125; 运行出现如下情况： 12345678stack length:22337Exception in thread &quot;main&quot; java.lang.StackOverflowErrorat com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) 1.3 本地 方法 栈 本地 方法 栈（ Native Method Stacks） 与 虚拟 机 栈 所 发挥 的 作用 是非 常 相似 的， 其 区别 不过 是 虚拟 机 栈 为 虚拟 机 执行 Java 方法（ 也就是 字节 码） 服务， 而 本地 方法 栈 则是 为 虚拟 机 使 用到 的 Native 方法 服务。 虚拟 机 规范 中 对本 地 方法 栈 中的 方法 使用 的 语言、 使用 方式 与 数据 结构 并没有 强制 规定， 因此 具体 的 虚拟 机 可以 自由 实现 它。 甚至 有的 虚拟 机（ 譬如 Sun HotSpot 虚拟 机） 直接 就把 本地 方法 栈 和 虚拟 机 栈 合二为一。 与 虚拟 机 栈 一样， 本地 方法 栈 区域 也会 抛出 StackOverflowError 和 OutOfMemoryError 异常。 对于一个运行中的 Java 程序而言，它还可能会用到一些跟本地方法相关的数据区。当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。本地方法可以通过本地方法接口来访问虚拟机的运行时数据区，但不止如此，它还可以做任何它想做的事情。 本地方法本质上时依赖于实现的，虚拟机实现的设计者们可以自由地决定使用怎样的机制来让 Java 程序调用本地方法。 任何本地方法接口都会使用某种本地方法栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法。 如果某个虚拟机实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当 C 程序调用一个 C 函数时，其栈操作都是确定的。传递给该函数的参数以某个确定的顺序压入栈，它的返回值也以确定的方式传回调用者。同样，这就是虚拟机实现中本地方法栈的行为。 很可能本地方法接口需要回调 Java 虚拟机中的 Java 方法，在这种情况下，该线程会保存本地方法栈的状态并进入到另一个 Java 栈。 这幅图展示了 JAVA 虚拟机内部线程运行的全景图。当一个线程调用一个本地方法时，本地方法又回调虚拟机中的另一个 Java 方法，一个线程可能在整个生命周期中都执行 Java 方法，操作它的 Java 栈；或者它可能毫无障碍地在 Java 栈和本地方法栈之间跳转。 该线程首先调用了两个 Java 方法，而第二个 Java 方法又调用了一个本地方法，这样导致虚拟机使用了一个本地方法栈。假设这是一个 C 语言栈，其间有两个 C 函数，第一个 C 函数被第二个 Java 方法当做本地方法调用，而这个 C 函数又调用了第二个 C 函数。之后第二个 C 函数又通过本地方法接口回调了一个 Java 方法（第三个 Java 方法），最终这个 Java 方法又调用了一个 Java 方法（它成为图中的当前方法）。内存溢出实例： 1234567891011121314151617181920212223242526272829303132333435packagecom.sf.jvm;/*** VM Args：* -Xss2M*/public classJavaVMStackOOM &#123; private void dontStop() &#123; while(true) &#123; try&#123; Thread.sleep(100000); &#125;catch(InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void stackLeakByThread() &#123; int threadNum =0; while(true) &#123; Thread thread =newThread(newRunnable() &#123; public void run() &#123; dontStop(); &#125; &#125;); thread.start(); threadNum++; &#125; &#125; public static void main(String[] args)throwsThrowable &#123; JavaVMStackOOM oom =newJavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125;运行程序抛出如下异常：Exception in thread &quot;main&quot; java. lang. OutOfMemoryError: unable to create new native thread 1.4 Java 堆 Java 堆（ Java Heap） 是 Java 虚拟 机 所 管理 的 内存 中最 大的 一块。 Java 堆 是 被 所有 线程 共享 的 一块 内存 区域， 在 虚拟 机 启动 时 创建。 此 内存 区域 的 唯一 目的 就是 存放 对象 实例， 几乎 所有 的 对象 实例 都在 这里 分配 内存。 这一 点在 Java 虚拟 机 规范 中的 描述 是： 所有 的 对象 实例 以及 数组 都 要在 堆 上 分配[ 2]， 但是 随着 JIT 编译器 的 发展 与 逃逸 分析 技术 的 逐渐 成熟， 栈 上 分配、 标量 替换[ 3] 优化 技术 将会 导致 一些 微妙 的 变化 发生， 所有 的 对象 都 分配 在 堆 上 也 渐渐 变得 不是 那么“ 绝对” 了。 Java 堆 是 垃圾 收集 器 管理 的 主要 区域， 因此 很多 时候 也 被 称做“ GC 堆”（ Garbage Collected Heap）。 如果 从内 存 回收 的 角度 看， 由于 现在 收集 器 基本 都是 采 用的 分 代收 集 算法， 所以 Java 堆 中 还可以 细分 为： 新生代 和 老 年代； 再 细致 一点 的 有 Eden 空间、 From Survivor 空间、 To Survivor 空间 等。 如果 从内 存 分配 的 角度 看， 线程 共享 的 Java 堆 中 可能 划分 出 多个 线程 私有 的 分配 缓冲区（ Thread Local Allocation Buffer， TLAB）。 不过， 无论如何 划分， 都与 存放 内容 无关， 无论 哪个 区域， 存储 的 都 仍然是 对象 实例， 进一步 划分 的 目的 是 为了 更好 地 回收 内存， 或者 更快 地 分配 内存。 在 本章 中， 我们 仅仅 针对 内存 区域 的 作用 进行 讨论， Java 堆 中的 上述 各个 区域 的 分配 和 回收 等 细节 将会 是 下 一章 的 主题。 根据 Java 虚拟 机 规范 的 规定， Java 堆 可以 处于 物理上 不连续 的 内存 空间 中， 只要 逻辑上 是 连续 的 即可， 就 像 我们 的 磁盘 空间 一样。 在 实现 时， 既可以 实现 成 固定 大小 的， 也可以 是 可扩展 的， 不过 当前 主流 的 虚拟 机 都是 按照 可扩展 来 实现 的（ 通过- Xmx 和- Xms 控制）。Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。在 Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收。如下图所示： 从图中可以看出： 堆大小 = 新生代 + 老年代。其中，堆的大小可以通过参数 –Xms、-Xmx 来指定。默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。因此，新生代实际可用的内存空间为 9/10 ( 即 90% )的新生代空间。 GC 堆Java 中的堆也是 GC 收集垃圾的主要区域。GC 分为两种：Minor GC、Full GC ( 或称为 Major GC )。Minor GC 是发生在新生代中的垃圾收集动作，所采用的是复制算法。新生代几乎是所有 Java 对象出生的地方，即 Java 对象申请的内存以及存放都是在这个地方。Java 中的大部分对象通常不需长久存活，具有朝生夕灭的性质。当一个对象被判定为 “死亡” 的时候，GC 就有责任来回收掉这部分对象的内存空间。新生代是 GC 收集垃圾的频繁区域。当对象在 Eden ( 包括一个 Survivor 区域，这里假设是 from 区域 ) 出生后，在经过一次 Minor GC 后，如果对象还存活，并且能够被另外一块 Survivor 区域所容纳( 上面已经假设为 from 区域，这里应为 to 区域，即 to 区域有足够的内存空间来存储 Eden 和 from 区域中存活的对象 )，则使用复制算法将这些仍然还存活的对象复制到另外一块 Survivor 区域 ( 即 to 区域 ) 中，然后清理所使用过的 Eden 以及 Survivor 区域 ( 即 from 区域 )，并且将这些对象的年龄设置为 1，以后对象在 Survivor 区每熬过一次 Minor GC，就将对象的年龄 + 1，当对象的年龄达到某个值时 ( 默认是 15 岁，可以通过参数 -XX:MaxTenuringThreshold 来设定 )，这些对象就会成为老年代。但这也不是一定的，对于一些较大的对象 ( 即需要分配一块较大的连续内存空间 ) 则是直接进入到老年代。Full GC 是发生在老年代的垃圾收集动作，所采用的是标记-清除算法。现实的生活中，老年代的人通常会比新生代的人 “早死”。堆内存中的老年代(Old)不同于这个，老年代里面的对象几乎个个都是在 Survivor 区域中熬过来的，它们是不会那么容易就 “死掉” 了的。因此，Full GC 发生的次数不会有 Minor GC 那么频繁，并且做一次 Full GC 要比进行一次 Minor GC 的时间更长。另外，标记-清除算法收集垃圾的时候会产生许多的内存碎片 ( 即不连续的内存空间 )，此后需要为较大的对象分配内存空间时，若无法找到足够的连续的内存空间，就会提前触发一次 GC 的收集动作。 设置 JVM 参数为 -XX:+PrintGCDetails，使得控制台能够显示 GC 相关的日志信息，执行上面代码，下面是其中一次执行的结果。 jvm 参数 解释 -Xms 初始堆大小。如：-Xms256m -Xmx 最大堆大小。如：-Xmx512m -Xmn 新生代大小。通常为 Xmx 的 1/3 或 1/4。新生代 = Eden + 2 个 Survivor 空间。实际可用空间为 = Eden + 1 个 Survivor，即 90% -Xss JDK1.5+ 每个线程堆栈大小为 1M，一般来说如果栈不是很深的话， 1M 是绝对够用了的。 -XX:NewRatio 新生代与老年代的比例，如 –XX:NewRatio=2，则新生代占整个堆空间的 1/3，老年代占 2/3 -XX:SurvivorRatio 新生代中 Eden 与 Survivor 的比值。默认值为 8。即 Eden 占新生代空间的 8/10，另外两个 Survivor 各占 1/10 -XX:PermSize 永久代(方法区)的初始大小 -XX:MaxPermSize 永久代(方法区)的最大值 -XX:+PrintGCDetails 打印 GC 信息 -XX:+HeapDumpOnOutOfMemoryError 让虚拟机在发生内存溢出时 Dump 出当前的内存堆转储快照，以便分析用 Java 堆 用于 储存 对象 实例， 我们 只要 不断 地 创建 对象， 并且 保证 GC Roots 到 对象 之间 有可 达 路径 来 避免 垃圾 回收 机制 清除 这些 对象， 就会 在 对象 数量 到达 最 大堆 的 容量 限制 后 产生 内存 溢出 异常。实例如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152packagecom.sf.jvm;importjava.util.ArrayList;importjava.util.List;/*** VM Args：* -Xms20m -Xmx20m* -XX:+HeapDumpOnOutOfMemoryError* -XX:+PrintGCDetails*/public classHeapOutOfMemory &#123; public static void main(String[] args) &#123; outOfMemory(); &#125; static void noOutOfMemory()&#123; while(true) &#123; newOOMObject(); &#125; &#125; static void outOfMemory()&#123; List&lt;OOMObject&gt; list =newArrayList&lt;OOMObject&gt;(); while(true) &#123; list.add(newOOMObject()); &#125; &#125;&#125;classOOMObject &#123; bytemem[] =new byte[2014];&#125;异常信息如下：[GC (Allocation Failure) [PSYoungGen: 5632K-&gt;512K(6144K)] 5632K-&gt;5024K(19968K), 0.0027725 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][GC (Allocation Failure) [PSYoungGen: 6144K-&gt;504K(6144K)] 10656K-&gt;11432K(19968K), 0.0022202 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (Ergonomics) [PSYoungGen: 504K-&gt;0K(6144K)] [ParOldGen: 10928K-&gt;10092K(13824K)] 11432K-&gt;10092K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0149535 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]........[Full GC (Allocation Failure) [PSYoungGen: 5632K-&gt;5632K(6144K)] [ParOldGen: 13823K-&gt;13823K(13824K)] 19455K-&gt;19455K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0086009 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid2780.hprof ...Heap dump file created [20898436 bytes in 0.027 secs][Full GC (Ergonomics) Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap spaceat com.sf.jvm.OOMObject.&lt;init&gt;(HeapOutOfMemory.java:29)at com.sf.jvm.HeapOutOfMemory.outOfMemory(HeapOutOfMemory.java:23)at com.sf.jvm.HeapOutOfMemory.main(HeapOutOfMemory.java:12)[PSYoungGen: 5632K-&gt;0K(6144K)] [ParOldGen: 13823K-&gt;579K(13824K)] 19455K-&gt;579K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0096016 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]HeapPSYoungGen total 6144K, used 177K [0x00000000ff980000, 0x0000000100000000, 0x0000000100000000)eden space 5632K, 3% used [0x00000000ff980000,0x00000000ff9ac4a0,0x00000000fff00000)from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)ParOldGen total 13824K, used 579K [0x00000000fec00000, 0x00000000ff980000, 0x00000000ff980000)object space 13824K, 4% used [0x00000000fec00000,0x00000000fec90c20,0x00000000ff980000)Metaspace used 3005K, capacity 4496K, committed 4864K, reserved 1056768Kclass space used 326K, capacity 388K, committed 512K, reserved 1048576K 用 jvisualvm.exe 打开查看 dump，发现主要是 OOMobject 不被释放。 1.5 方法 区 1.5.1 方法区 方法 区（ Method Area） 与 Java 堆 一样， 是 各个 线程 共享 的 内存 区域， 它 用于 存储 已被 虚拟 机 加载 的 类 信息、 常量、 静态 变量、 即时 编译器 编译 后的 代码 等 数据。 虽然 Java 虚拟 机 规范 把 方法 区 描述为 堆 的 一个 逻辑 部分， 但是 它 却有 一个 别名 叫做 Non- Heap（ 非 堆）， 目的 应该 是与 Java 堆 区分 开来。 对于 习惯 在 HotSpot 虚拟 机上 开发 和 部署 程序 的 开发者 来说， 很多人 愿意 把 方法 区 称为“ 永久 代”（ Permanent Generation）， 本质上 两者 并不 等价， 仅仅 是因为 HotSpot 虚拟 机 的 设计 团队 选择 把 GC 分 代收 集 扩展 至 方法 区， 或者说 使用 永久 代 来 实现 方法 区 而已。 对于 其他 虚拟 机（ 如 BEA JRockit、 IBM J9 等） 来说 是 不存在 永久 代 的 概念 的。 即使是 HotSpot 虚拟 机 本身， 根据 官方 发布 的 路线 图 信息， 现在 也有 放弃 永久 代 并“ 搬家” 至 Native Memory 来 实现 方法 区 的 规划 了。 Java 虚拟 机 规范 对这 个 区域 的 限制 非常 宽松， 除了 和 Java 堆 一样 不需要 连续 的 内存 和 可以 选择 固定 大小 或者 可扩展 外， 还可以 选择 不实 现 垃圾 收集。 相对而言， 垃圾 收集 行为 在这 个 区域 是 比较 少 出现 的， 但 并非 数据 进入 了 方法 区 就 如 永久 代 的 名字 一样“ 永久” 存在 了。 这个 区域 的 内存 回收 目标 主要 是 针对 常量 池 的 回收 和 对 类型 的 卸载， 一般来说 这个 区域 的 回收“ 成绩” 比较 难以 令人满意， 尤其是 类型 的 卸载， 条件 相当 苛刻， 但是 这部 分 区域 的 回收 确实 是有 必要 的。 在 Sun 公司 的 BUG 列表 中， 曾 出现 过 的 若干个 严重 的 BUG 就是 由于 低 版本 的 HotSpot 虚拟 机 对此 区域 未完 全 回收 而 导致 内存 泄漏。 根据 Java 虚拟 机 规范 的 规定， 当 方法 区 无法 满足 内存 分配 需求 时， 将 抛出 OutOfMemoryError 异常。方法 区 用于 存放 Class 的 相关 信息， 如 类 名、 访问 修饰 符、 常量 池、 字段 描述、 方法 描述 等。 对于 这个 区域 的 测试， 基本 的 思路 是 运行时 产生 大量 的 类 去 填满 方法 区， 直到 溢出。 虽然 直接 使用 Java SE API 也可以 动态 产生 类（ 如 反射 时 的 GeneratedConstructorAccessor 和 动态 代理 等）， 但在 本次 实验 中 操作 起来 比较 麻烦。 在 代码 清单 2- 5 中， 笔者 借助 CGLib[ 3] 直接 操作 字节 码 运行时， 生成 了 大量 的 动态 类。 值得 特别 注意 的 是， 我们 在这 个 例子 中 模拟 的 场景 并非 纯粹 是一 个 实验， 这样 的 应用 经常 会 出现 在 实际 应用 中： 当前 的 很多 主流 框架， 如 Spring 和 Hibernate 对 类 进行 增强 时， 都会 使用 到 CGLib 这类 字节 码 技术， 增 强的 类 越多， 就 需要 越大 的 方法 区 来 保证 动态 生成 的 Class 可以 加载 入 内存。 方法 区 溢出 也是 一种 常见 的 内存 溢出 异常， 一个 类 如果 要被 垃圾 收集 器 回收 掉， 判定 条件 是非 常 苛刻 的。 在 经常 动态 生成 大量 Class 的 应用 中， 需要 特别 注意 类 的 回收 状况。 这类 场景 除了 上面 提到 的 程序 使用 了 GCLib 字节 码 增强 外， 常见 的 还有： 大量 JSP 或 动态 产生 JSP 文件 的 应用（ JSP 第一次 运行时 需要 编译 为 Java 类）、 基于 OSGi 的 应用（ 即使是 同一个 类 文件， 被 不同 的 加载 器 加载 也会 视为 不同 的 类） 等。 代码 清单 2- 5 借助 CGLib 使得 方法 区 出现 内存 溢出 异常 12345678910111213141516171819202122232425262728packagecom.sf.jvm;/*** VM Args： -XX: PermSize= 10M -XX: MaxPermSize= 10M*/public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while(true) &#123; Enhancer enhancer =newEnhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(newMethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy)throwsThrowable &#123; returnproxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; static classOOMObject &#123; &#125;&#125;运行 结果：Caused by: java. lang. OutOfMemoryError: PermGen space at java. lang. ClassLoader. defineClass1( Native Method)at java. lang. ClassLoader. defineClassCond( ClassLoader. java: 632) at java. lang. ClassLoader. defineClass( ClassLoader. java: 616） 1.5.2 运行时常量池 运行时 常量 池（ Runtime Constant Pool） 是 方法 区 的 一部分。 Class 文件 中 除了 有 类 的 版本、 字段、 方法、接口 等 描述 等 信息 外， 还有 一项 信息 是 常量 池（ Constant Pool Table）， 用于 存放 编译 期 生成 的 各种 字面 量 和 符号 引用， 这部 分 内容 将 在 类 加载 后 存放 到 方法 区 的 运行时 常量 池 中。 Java 虚拟 机 对 Class 文件 的 每一 部分（ 自然 也 包括 常量 池） 的 格式 都有 严格 的 规定， 每一个 字节 用于 存储 哪种 数据 都 必须 符合 规范 上 的 要求， 这样 才会 被 虚拟 机 认可、 装载 和 执行。 但 对于 运行时 常量 池， Java 虚拟 机 规范 没有 做 任何 细节 的 要求， 不同 的 提供 商 实现 的 虚拟 机 可以 按照 自己的 需要 来 实现 这个 内存 区域。 不过， 一般来说， 除了 保存 Class 文件 中 描述 的 符号 引用 外， 还会 把 翻译 出来 的 直接 引用 也 存储 在 运行时 常量 池 中[ 4]。 运行时 常量 池 相对于 Class 文件 常量 池 的 另外 一个 重要 特征 是 具备 动态 性， Java 语言 并不 要求 常量 一定 只能 在 编译 期 产生， 也就是 并非 预置 入 Class 文件 中 常量 池 的 内容 才能 进入 方法 区 运行时 常量 池， 运行 期间 也可 能将 新的 常量 放入 池 中， 这种 特性 被 开发 人员 利用 得比 较多 的 便是 String 类 的 intern() 方法。 既然 运行时 常量 池 是 方法 区 的 一部分， 自然 会受 到 方法 区 内存 的 限制， 当 常量 池 无法 再 申请 到 内存 时会 抛出 OutOfMemoryError 异常。 123456789101112131415161718192021package com.sf.jvm;importjava.util.ArrayList;importjava.util.List;/*** VM Args：- XX:PermSize=10M -XX:MaxPermSize=10M*/public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; // 使用 List 保持 着 常量 池 引用， 避免 Full GC 回收 常量 池 行为 List&lt;String&gt; list =new ArrayList&lt;String&gt;(); // 10MB 的 PermSize 在 integer 范围内 足够 产生 OOM 了 int i = 0; while(true) &#123; list.add(String.valueOf(i++ +&quot;xxxxxxxxxxxxxxxxxxxxx&quot;).intern()); &#125; &#125;&#125;运行异常：Exception in thread &quot;main&quot; java. lang. OutOfMemoryError: PermGen space at java. lang. String. intern( Native Method) at org. fenixsoft. oom. RuntimeConstantPoolOOM. main( RuntimeConstantPoolOOM. java:... 1.7 直接 内存 直接内存（DirectMemory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，所以我们放到这里一起讲解。在JDK1.4中新加入了NIO（NewInput/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。服务器管理员配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但经常会忽略掉直接内存，使得各个内存区域的总和大于物理内存限制（包括物理上的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。DirectMemory容量可通过-XX：MaxDirectMemorySize指定，如果不指定，则默认与Java堆的最大值（-Xmx指定）一样。越过了DirectByteBuffer类，直接通过反射获取Unsafe实例并进行内存分配（Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例，也就是设计者希望只有rt.jar中的类才能使用Unsafe的功能）。因为，虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常，真正申请分配内存的方法是unsafe.allocateMemory()。如下实例为直接内存溢出。 12345678910111213141516171819202122package com.sf.jvm;import sun.misc.Unsafe;import java.lang.reflect.Field;import staticcom.sun.deploy.util.BufferUtil.MB;/*** VM Args：- Xmx20M -XX: MaxDirectMemorySize= 10M*/public classDirectMemoryOOM &#123; private static final int_1MB=1024*1024; public static void main(String[] args)throwsException &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while(true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125;运行异常：Exception in thread &quot;main&quot; java.lang.OutOfMemoryErrorat sun.misc.Unsafe.allocateMemory(Native Method)at com.sf.jvm.DirectMemoryOOM.main(DirectMemoryOOM.java:20) 1.8 对象的访问 介绍完Java虚拟机的运行时数据区之后，我们就可以来探讨一个问题：在Java语言中，对象访问是如何进行的？对象访问在Java语言中无处不在，是最普通的程序行为，但即使是最简单的访问，也会却涉及Java栈、Java堆、方法区这三个最重要内存区域之间的关联关系，如下面的这句代码：Objectobj=newObject();假设这句代码出现在方法体中，那“Objectobj”这部分的语义将会反映到Java栈的本地变量表中，作为一个reference类型数据出现。而“newObject()”这部分的语义将会反映到Java堆中，形成一块存储了Object类型所有实例数据值（InstanceData，对象中各个实例字段的数据）的结构化内存，根据具体类型以及虚拟机实现的对象内存布局（ObjectMemoryLayout）的不同，这块内存的长度是不固定的。另外，在Java堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据则存储在方法区中。由于reference类型在Java虚拟机规范里面只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问到Java堆中的对象的具体位置，因此不同虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄和直接指针。 如果使用句柄访问方式，Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息，如图: ![这里写图片描述](http://img.blog.csdn.net/20170728094239784?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY253dWhhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 如果使用直接指针访问方式，Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，reference中直接存储的就是对象地址，如图:``![这里写图片描述](http://img.blog.csdn.net/20170728094300056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY253dWhhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 这两种对象的访问方式各有优势，使用句柄访问方式的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。就本书讨论的主要虚拟机SunHotSpot而言，它是使用第二种方式进行对象访问的，但从整个软件开发的范围来看，各种语言和框架使用句柄来访问的情况也十分常见。 参照： 深入理解Java虚拟机 http://blog.csdn.net/u012152619/article/details/46968883 http://www.importnew.com/14630.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM垃圾回收","slug":"language/jvm/JVM垃圾回收","date":"2021-08-04T06:25:13.662Z","updated":"2021-08-04T06:25:13.663Z","comments":true,"path":"2021/08/04/language/jvm/JVM垃圾回收/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"JVM垃圾回收1.简介 jvm要进行垃圾回收粗略分为两个步骤：找出需要清理的内存(无效的内存区域) ， 清理无效的内存区域 程序计数器、虚拟机栈、本地方法栈三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器进行一些优化，但在本章基于概念模型的讨论中，大体上可以认为是编译期可知的），因此这几个区域的内存分配和回收都具备确定性，在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾回收所关注的是这部分内存。 2. 无效内存区域的查找2.1 概要Java堆中几乎存放着Java世界中所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象有哪些还“存活”着，哪些已经“死去”。判断方法有引用计数器法和根搜索算法等。 2.1.1 引用计数算法简单解释为给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当该引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不可能再被使用的。客观地说，引用计数算法（ReferenceCounting）的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法，也有一些比较著名的应用案例，例如微软的COM（ComponentObjectModel）技术、使用ActionScript3的FlashPlayer、Python语言以及在游戏脚本领域中被广泛应用的Squirrel中都使用了引用计数算法进行内存管理。但Java语言中没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间的相互循环引用的问题。如下： 1234567891011121314151617181920212223/** *testGC()方法执行后，objA和objB会不会被GC呢？ *@authorzzm */public class ReferenceCountingGC&#123; public Object instance=null; private static final int _1MB=1024*1024; /** *这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否被回收过 */ private byte[] bigSize=new byte[2*_1MB]; public static void testGC()&#123; ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = newReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //假设在这行发生GC，那么objA和objB是否能被回收？ System.gc(); &#125;&#125;运行结果： 1234567891011121314[FullGC(System)[Tenured:0K-&gt;210K(10240K),0.0149142secs]4603K-&gt;210K(19456K),[Perm:2999K-&gt;2999K(21248K)],0.0150007secs][Times:user=0.01sys=0.00,real=0.02secs]Heapdefnewgenerationtotal9216K,used82K[0x00000000055e0000,0x0000000005fe0000,0x0000000005fe0000)Edenspace8192K,1%used[0x00000000055e0000,0x00000000055f4850,0x0000000005de0000)fromspace1024K,0%used[0x0000000005de0000,0x0000000005de0000,0x0000000005ee0000)tospace1024K,0%used[0x0000000005ee0000,0x0000000005ee0000,0x0000000005fe0000)tenuredgenerationtotal10240K,used210K[0x0000000005fe0000,0x00000000069e0000,0x00000000069e0000)thespace10240K,2%used[0x0000000005fe0000,0x0000000006014a18,0x0000000006014c00,0x00000000069e0000)compactingpermgentotal21248K,used3016K[0x00000000069e0000,0x0000000007ea0000,0x000000000bde0000)thespace21248K,14%used[0x00000000069e0000,0x0000000006cd2398,0x0000000006cd2400,0x0000000007ea0000)Nosharedspacesconfigured. 代码中testGC()方法：对象objA和objB都有字段instance，赋值令objA.instance=objB及objB.instance=objA，除此之外，这两个对象再无任何引用，实际上这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们，为引用计数器的缺陷。但从运行结果中可以清楚地看到GC日志中包含“4603K-&gt;210K”，意味着虚拟机并没有因为这两个对象互相引用就不回收它们，这也从侧面说明虚拟机并不是通过引用计数算法来判断对象是否存活的。 2.1.2 根搜索算法在主流的商用程序语言中（Java和C#，甚至包括前面提到的古老的Lisp），都是使用根搜索算法（GCRootsTracing）判定对象是否存活的。这个算法的基本思路就是通过一系列的名为“GCRoots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（ReferenceChain），当一个对象到GCRoots没有任何引用链相连（用图论的话来说就是从GCRoots到这个对象不可达）时，则证明此对象是不可用的。如下： 对象object5、object6、object7虽然互相有关联，但是它们到GCRoots是不可达的，所以它们将会被判定为是可回收的对象。在Java语言里，可作为GCRoots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中的引用的对象。 方法区中的类静态属性引用的对象。 方法区中的常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）的引用的对象。 2.2 java的引用类型无论是通过引用计数算法判断对象的引用数量，还是通过根搜索算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。在JDK1.2之前，Java中的引用的定义很传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些“食之无味，弃之可惜”的对象就显得无能为力。我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。JDK1.2之后，Java对引用的概念进行了扩充，并且引用强度不同。如下 引用类型 概述 强引用（StrongReference） 强引用就是指在程序代码之中普遍存在的，类似“Objectobj=newObject()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象 软引用（SoftReference） 软引用用来描述一些还有用，但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。在JDK1.2之后，提供了SoftReference类来实现软引用 弱引用（WeakReference） 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用 虚引用（PhantomReference） 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是希望能在这个对象被收集器回收时收到一个系统通知。在JDK1.2之后，提供了PhantomReference类来实现虚引用 2.3 对象自救在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经经历两次标记过程：如果对象在进行根搜索后发现没有与GCRoots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那它就真的离死不远了。 123456789101112131415161718192021222324252627282930313233343536/***此代码演示了两点： *1.对象可以在被GC时自我拯救。 *2.这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次 *@authorzzm * */public class FinalizeEscapeGC &#123; public static FinalizeEscapeGC SAVE_HOOK = null; public static void main(String[] args) throws Throwable &#123; SAVE_HOOK = new FinalizeEscapeGC(); //对象 第一次 成功 拯救 自己 SAVE_HOOK = null; System.gc(); // 因为 Finalizer 方法 优先级 很低， 暂停 0. 5 秒， 以 等待 它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(&quot; no, i am dead :(&quot;); &#125; // 下面 这段 代码 与 上面 的 完全 相同， 但是 这次 自救 却 失败 了 SAVE_HOOK = null; System.gc(); // 因为 Finalizer 方法 优先级 很低， 暂停 0. 5 秒， 以 等待 它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(&quot; no, i am dead :(&quot;); &#125; &#125; public void isAlive() &#123; System.out.println(&quot; yes, i am still alive :)&quot;); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(&quot; finalize mehtod executed!&quot;); FinalizeEscapeGC.SAVE_HOOK = this; &#125;&#125; 1234运行结果：finalize mehtod executed! yes, i am still alive :) no, i am dead :( 从代码中我们可以看到一个对象的finalize()被执行，但是它仍然可以存活。代码中一次对象自我拯救的演示，在运行结果可以看到，SAVE_HOOK对象的finalize()方法确实被GC收集器触发过，并且在被收集前成功逃脱了。另外一个值得注意的地方就是，代码中有两段完全一样的代码片段，执行结果却是一次逃脱成功，一次失败，这是因为任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行，因此第二段代码的自救行动失败了。需要特别说明的是，上面关于对象死亡时finalize()方法的描述可能带有悲情的艺术色彩，笔者并不鼓励大家使用这种方法来拯救对象。相反，笔者建议大家尽量避免使用它，因为它不是C/C++中的析构函数，而是Java刚诞生时为了使C/C++程序员更容易接受它所做出的一个妥协。它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。有些教材中提到它适合做“关闭外部资源”之类的工作，这完全是对这种方法的用途的一种自我安慰。finalize()能做的所有工作，使用try-finally或其他方式都可以做得更好、更及时，大家完全可以忘掉Java语言中还有这个方法的存在。 2.4 回收方法区很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%~95%的空间，而永久代的垃圾收集效率远低于此。永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。回收废弃常量与回收Java堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果在这时候发生内存回收，而且必要的话，这个“abc”常量就会被系统“请”出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。java中同时满足下面3个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制。可以使用-verbose：class及-XX：+TraceClassLoading、-XX：+TraceClassUnLoading查看类的加载和卸载信息，其中-verbose：class和-XX：+TraceClassLoading可以在Product版的虚拟机中使用，但-XX：+TraceClassLoading参数需要fastdebug版的虚拟机支持。在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 3. 清理无效内存3.1 垃圾收集算法由于垃圾收集算法的实现涉及大量的程序细节，而且各个平台的虚拟机操作内存的方法又各不相同，因此本节不打算过多地讨论算法的实现，只是介绍几种算法的思想及其发展过程。 3.1.1 标记-清除算法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经基本介绍过了。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。它的主要缺点有两个： 一个是效率问题，标记和清除过程的效率都不高； 一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。如下图为执行标记清除算法后的内存区域： 3.1.2 标记-整理算法标记操作和“标记-清除”算法一致，后续操作不只是直接清理对象，而是在清理无用对象完成后让所有存活的对象都向一端移动，并更新引用其对象的指针。主要缺点：在标记-清除的基础上还需进行对象的移动，成本相对较高，好处则是不会产生内存碎片。如下图为执行标记清除算法后的内存区域： ####3.1.3 复制算法 为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，未免太高了一点。复制算法执行后的内存区域： 3.1.4 分代收集算法分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（GenerationalCollection）算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 3.2 垃圾收集器垃圾收集器对比 垃圾收集器 解释 对比 Serial收集器 新生代复制算法，老年代采用标记整理算法，Serial收集器到JDK1.7为止，它依然是JAVA虚拟机运行在Client模式下的默认新生代收集器。 它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率 ParNew收集器 新生代复制算法，老年代采用标记整理算法，ParNew收集器其实就是Serial收集器的多线程版本 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器。当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源的利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 ParallelScavenge收集器 新生代收集器采用复制算法 Parallel Scavenge 收集 器 的 特点 是它 的 关注 点 与其 他 收集 器 不同， CMS 等 收集 器 的 关注 点 尽可能 地 缩短 垃圾 收集 时 用户 线程 的 停顿 时间， 而 Parallel Scavenge 收集 器 的 目标 则是 达到 一个 可 控制 的 吞吐量（ Throughput）。 Serial Old 收集 器 Serial Old 是 Serial 收集 器 的 老年 代 版本 标记-整理算法 这个 收集 器 的 主要 意义 也是 被 Client 模式 下 的 虚拟 机 使用 Parallel Old 收集 器 Parallel Scavenge 收集 器 的 老年 代 版本 标记-整理算法 注重 吞吐量 及 CPU 资源 敏感 的 场合， 都可以 优先 考虑 Parallel Scavenge 加 Parallel Old 收集 器。 CMS收集器 CMS（ConcurrentMarkSweep）针对老年代进行回收的GC，标记-清除算法 收集器是一种以获取最短回收停顿时间为目标的收集器 G1收集器 内存结构变更，相对于CMS的“标记——清理”算法，G1会使用压缩算法，保证不产生多余的碎片。收集阶段，G1会将某个区域存活的对象拷贝的其他区域，然后将整个区域整个回收。 服务类型的收集器，目标是多处理器机器、大内存机器。它高度符合垃圾收集暂停时间的目标，同时实现高吞吐量。Oracle JDK 7 update 4 以及更新发布版完全支持G1垃圾收集器。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序继续运行，而垃圾收集程序运行于另一个CPU上。如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大的差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。这里讨论的收集器基于SunHotSpot虚拟机1.6版Update22，这个虚拟机包含的所有收集器如图所示。 HotSpotJVM1.6的垃圾收集器展示了7种作用于不同分代的收集器（包括JDK1.6_Update14后引入的EarlyAccess版G1收集器），如果两个收集器之间存在连线，就说明它们可以搭配使用。在介绍这些收集器各自的特性之前，我们先来明确一个观点：虽然我们是在对各个收集器进行比较，但并非为了挑选一个最好的收集器出来。因为直到现在为止还没有最好的收集器出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。这点不需要多加解释就能证明：如果有一种放之四海皆准、任何场景下都适用的完美收集器存在，那HotSpot虚拟机就没必要实现那么多不同的收集器了。####3.2.1 Serial收集器 Serial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。大家看名字就会知道，这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。“Stop The World”这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。读者不妨试想一下，要是你的计算机每运行一个小时就会暂停响应5分钟，你会有什么样的心情？Serial / Serial Old收集器的运行过程如下： 从 JDK 1.3 开始，一直到现在最新的 JDK 1.7，HotSpot 虚拟机开发团队为消除或者减少工作线程因内存回收而导致停顿的努力一直在进行着，从 Serial 收集器到 Parallel 收集器，再到 Concurrent Mark Sweep（CMS）乃至 GC 收集器的最前沿成果 Garbage First（G1）收集器，我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现，用户线程的停顿时间在不断缩短，但是仍然没有办法完全消除（这里暂不包括 RTSJ 中的收集器）。寻找更优秀的垃圾收集器的工作仍在继续！ 写到这里，笔者似乎已经把 Serial 收集器描述成一个“老而无用、食之无味弃之可惜”的鸡肋了，但实际上到现在为止，它依然是虚拟机运行在 Client 模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial 收集器对于运行在 Client 模式下的虚拟机来说是一个很好的选择。 3.2.2 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数（例如：-XX:SurvivorRatio、 -XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，实现上这两种收集器也共用了相当多的代码。ParNew收集器的工作过程如下 ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器（Concurrent Mark Sweep，本节稍后将详细介绍这款收集器），这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作，用前面那个例子的话来说，就是做到了在你妈妈打扫房间的时候你还能同时往地上扔纸屑。 不幸的是，它作为老年代的收集器，却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，所以在 JDK 1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或 Serial 收集器中的一个。ParNew 收集器也是使用 -XX: +UseConcMarkSweepGC 选项后的默认新生代收集器，也可以使用 -XX:+UseParNewGC 选项来强制指定它。 ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证能超越 Serial 收集器。当然，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（譬如 32 个，现在 CPU 动辄就 4 核加超线程，服务器超过 32 个逻辑 CPU 的情况越来越多了）的环境下，可以使用-XX:ParallelGCThreads 参数来限制垃圾收集的线程数。 注意 从 ParNew 收集器开始，后面还将会接触到几款并发和并行的收集器。在大家可能产生疑惑之前，有必要先解释两个名词：并发和并行。这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，他们可以解释为： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序继续运行，而垃圾收集程序运行于另一个 CPU 上。 3.2.3 ParallelScavenge收集器Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和ParNew都一样，那它有什么特别之处呢？ Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99%。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge 收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis 参数以及直接设置吞吐量大小的-XX:GCTimeRatio 参数。 MaxGCPauseMillis 参数允许的值是一个大于 0 的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC 停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集 300MB 新生代肯定比收集 500MB 快吧，这也直接导致垃圾收集发生得更频繁一些，原来 10 秒收集一次、每次停顿 100 毫秒，现在变成 5 秒收集一次、每次停顿 70 毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个大于 0 且小于 100 的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为 19，那允许的最大 GC 时间就占总时间的 5%（即 1 /（1+19）），默认值为 99，就是允许最大 1%（即 1 /（1+99））的垃圾收集时间。 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge 收集器还有一个参数-XX:+UseAdaptiveSizePolicy 值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。如果读者对于收集器运作原来不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx 设置最大堆），然后使用 MaxGCPauseMillis 参数（更关注最大停顿时间）或 GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。自适应调节策略也是 Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别。 ####3.2.4 Serial Old 收集 器 Serial Old 是 Serial 收集 器 的 老年 代 版本， 它 同样是 一个 单线 程 收集 器， 使用“ 标记- 整理” 算法。 这个 收集 器 的 主要 意义 也是 被 Client 模式 下 的 虚拟 机 使用。 如果 在 Server 模式 下， 它 主要 还有 两大 用途： 一个 是在 JDK 1. 5 及 之前 的 版本 中 与 Parallel Scavenge 收集 器 搭配 使用[ 4]， 另外 一个 就是 作为 CMS 收集 器 的 后备 预 案， 在 并发 收集 发生 Concurrent Mode Failure 的 时候 使用。 这 两点 都将 在后 面的 内容 中 详细 讲解。 Serial Old 收集 器 的 工作 过程 如图 所示。 ####3.2.5 Parallel Old 收集 器 Parallel Old 是 Parallel Scavenge 收集 器 的 老年 代 版本， 使用 多 线程 和“ 标记－整理” 算法。 这个 收集 器 是在 JDK 1. 6 中 才 开始 提供 的， 在此之前， 新生代 的 Parallel Scavenge 收集 器 一直 处于 比较 尴尬 的 状态。 原因 是， 如果 新生代 选择 了 Parallel Scavenge 收集 器， 老年 代 除了 Serial Old（ PS MarkSweep） 收集 器 外 别无选择（ 还 记得 上面 说过 Parallel Scavenge 收集 器 无法 与 CMS 收集 器 配合 工作 吗？）。 由于 单 线程 的 老 年代 Serial Old 收集 器 在 服务 端 应用 性 能上 的“ 拖累”， 即便 使用 了 Parallel Scavenge 收集 器 也 未必 能在 整体 应用 上 获得 吞吐量 最大化 的 效果， 又因 为 老年 代收 集中 无法 充分 利用 服务器 多 CPU 的 处理 能力， 在 老年 代 很大 而且 硬件 比较 高级的 环境 中， 这种 组合 的 吞吐量 甚至 还不 一 定有 ParNew 加 CMS 的 组合“ 给 力”。 直到 Parallel Old 收集 器 出现 后，“ 吞吐量 优先” 收集 器 终于 有了 比较 名副其实 的 应用 组合， 在 注重 吞吐量 及 CPU 资源 敏感 的 场合， 都可以 优先 考虑 Parallel Scavenge 加 Parallel Old 收集 器。 Parallel Old 收集 器 的 工作 过程 如图所示。 3.2.6 CMS收集器CMS（ConcurrentMarkSweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。从名字（包含“MarkSweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分如下步骤，包括： 阶段 说明 (1) 初始标记 (Initial Mark) (Stop the World Event,所有应用线程暂停) 在老年代(old generation)中的对象, 如果从年轻代(young generation)中能访问到, 则被 “标记,marked” 为可达的(reachable).对象在旧一代“标志”可以包括这些对象可能可以从年轻一代。暂停时间一般持续时间较短,相对小的收集暂停时间. (2) 并发标记 (Concurrent Marking) 在Java应用程序线程运行的同时遍历老年代(tenured generation)的可达对象图。扫描从被标记的对象开始,直到遍历完从root可达的所有对象. 调整器(mutators)在并发阶段的2、3、5阶段执行,在这些阶段中新分配的所有对象(包括被提升的对象)都立刻标记为存活状态. (3) 再次标记(Remark) (Stop the World Event, 所有应用线程暂停) 查找在并发标记阶段漏过的对象，这些对象是在并发收集器完成对象跟踪之后由应用线程更新的. (4) 并发清理(Concurrent Sweep) 回收在标记阶段(marking phases)确定为不可及的对象. 死对象的回收将此对象占用的空间增加到一个空闲列表(free list),供以后的分配使用。死对象的合并可能在此时发生. 请注意,存活的对象并没有被移动. (5) 重置(Resetting) 清理数据结构,为下一个并发收集做准备. 其中初始标记、重新标记这两个步骤仍然需要“StopTheWorld”。初始标记仅仅只是标记一下GCRoots能直接关联到的对象，速度很快，并发标记阶段就是进行GCRootsTracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行的。ConcurrentMarkSweep收集器运行示意图： CMS是一款优秀的收集器，它的最主要优点在名字上已经体现出来了：并发收集、低停顿，Sun的一些官方文档里面也称之为并发低停顿收集器（ConcurrentLowPauseCollector）。但是CMS还远达不到完美的程度，它有以下三个显著的缺点： CMS收集器对CPU资源非常敏感。其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程最多占用不超过25%的CPU资源。但是当CPU不足4个时（譬如2个），那么CMS对用户程序的影响就可能变得很大，如果CPU负载本来就比较大的时候，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，这也很让人受不了。为了解决这种情况，虚拟机提供了一种称为“增量式并发收集器”（IncrementalConcurrentMarkSweep/i-CMS）的CMS收集器变种，所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样，就是在并发标记和并发清理的时候让GC线程、用户线程交替运行，尽量减少GC线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些，速度下降也就没有那么明显，但是目前版本中，i-CMS已经被声明为“deprecated”，即不再提倡用户使用。 CMS收集器无法处理浮动垃圾（FloatingGarbage），可能出现“ConcurrentModeFailure”失败而导致另一次FullGC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序的运行自然还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理掉它们，只好留待下一次GC时再将其清理掉。这一部分垃圾就称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，即还需要预留足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在默认设置下，CMS收集器在老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数以获取更好的性能。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“ConcurrentModeFailure”失败，这时候虚拟机将启动后备预案：临时启用SerialOld收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量“ConcurrentModeFailure”失败，性能反而降低。 还有最后一个缺点，在本节在开头说过，CMS是一款基于“标记-清除”算法实现的收集器，如果读者对前面这种算法介绍还有印象的话，就可能想到这意味着收集结束时会产生大量空间碎片。空间碎片过多时，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC。为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开关参数，用于在“享受”完FullGC服务之后额外免费附送一个碎片整理过程，内存整理的过程是无法并发的。空间碎片问题没有了，但停顿时间不得不变长了。虚拟机设计者们还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数用于设置在执行多少次不压缩的FullGC后，跟着来一次带压缩的。后续分开介绍： 3.2.7.G1收集器G1（GarbageFirst）收集器G1 GC 是 Jdk7 的新特性之一、Jdk7+版本都可以自主配置 G1 作为 JVM GC 选项；作为 JVM GC 算法的一次重大升级、DK7u 后 G1 已相对稳定、且未来计划替代 CMS、所以有必要深入了解下： 不同于其他的分代回收算法、G1 将堆空间划分成了互相独立的区块。每块区域既有可能属于 O 区、也有可能是 Y 区，且每类区域空间可以是不连续的（对比 CMS 的 O 区和 Y 区都必须是连续的）。这种将 O 区划分成多块的理念源于：当并发后台线程寻找可回收的对象时、有些区块包含可回收的对象要比其他区块多很多。虽然在清理这些区块时 G1 仍然需要暂停应用线程、但可以用相对较少的时间优先回收包含垃圾最多区块。如下： 这也是为什么G1命名为Garbage First的原因：第一时间处理垃圾最多的区块。平时工作中大多数系统都使用CMS、即使静默升级到JDK7默认仍然采用CMS、那么G1相对于CMS的区别在： G1 在压缩空间方面有优势G1 通过将内存空间分成区域（Region）的方式避免内存碎片问题Eden, Survivor, Old 区不再固定、在内存使用效率上来说更灵活G1 可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象G1 在回收内存后会马上同时做合并空闲内存的工作、而 CMS 默认是在 STW（stop the world）的时候做G1 会在 Young GC 中使用、而 CMS 只能在 O 区使用就目前而言、CMS 还是默认首选的 GC 策略、可能在以下场景下 G1 更适合： 服务端多核 CPU、JVM 内存占用较大的应用（至少大于 4G）应用在运行过程中会产生大量内存碎片、需要经常压缩空间想要更可控、可预期的 GC 停顿周期；防止高并发下应用雪崩现象一次完整 G1GC 的详细过程： G1 在运行过程中主要包含如下 4 种操作方式： YGC（不同于 CMS）并发阶段混合模式full GC （一般是 G1 出现问题时发生）YGC： 下面是一次 YGC 前后内存区域是示意图： 图中每个小区块都代表 G1 的一个区域（Region），区块里面的字母代表不同的分代内存空间类型（如[E]Eden,[O]Old,[S]Survivor）空白的区块不属于任何一个分区；G1 可以在需要的时候任意指定这个区域属于 Eden 或是 O 区之类的。G1 YoungGC 在 Eden 充满时触发，在回收之后所有之前属于 Eden 的区块全变成空白。然后至少有一个区块是属于 S 区的（如图半满的那个区域），同时可能有一些数据移到了 O 区。 目前淘系的应用大都使用 PrintGCDetails 参数打出 GC 日志、这个参数对 G1 同样有效、但日志内容颇为不同；下面是一个 Young GC 的例子： 123423.430: [GC pause (young), 0.23094400 secs]...[Eden: 1286M(1286M)-&gt;0B(1212M)Survivors: 78M-&gt;152M Heap: 1454M(4096M)-&gt;242M(4096M)][times: user=0.85 sys=0.05, real=0.23 secs] 上面日志的内容解析：Young GC 实际占用 230 毫秒、其中 GC 线程占用 850 毫秒的 CPU 时间E：内存占用从 1286MB 变成 0、都被移出S：从 78M 增长到了 152M、说明从 Eden 移过来 74MHeap:占用从 1454 变成 242M、说明这次 Young GC 一共释放了 1212M 内存空间很多情况下，S 区的对象会有部分晋升到 Old 区，另外如果 S 区已满、Eden 存活的对象会直接晋升到 Old 区，这种情况下 Old 的空间就会涨 并发阶段： 一个并发 G1 回收周期前后内存占用情况如下图所示： 从上面的图表可以看出以下几点：1、Young区发生了变化、这意味着在G1并发阶段内至少发生了一次YGC（这点和CMS就有区别），Eden在标记之前已经被完全清空，因为在并发阶段应用线程同时在工作、所以可以看到Eden又有新的占用2、一些区域被X标记，这些区域属于O区，此时仍然有数据存放、不同之处在G1已标记出这些区域包含的垃圾最多、也就是回收收益最高的区域3、在并发阶段完成之后实际上O区的容量变得更大了（O+X的方块）。这时因为这个过程中发生了YGC有新的对象进入所致。此外，这个阶段在O区没有回收任何对象：它的作用主要是标记出垃圾最多的区块出来。对象实际上是在后面的阶段真正开始被回收 G1 并发标记周期可以分成几个阶段、其中有些需要暂停应用线程。第一个阶段是初始标记阶段。这个阶段会暂停所有应用线程-部分原因是这个过程会执行一次 YGC、下面是一个日志示例： 50.541: [GC pause (young) (initial-mark), 0.27767100 secs][eden: 1220m(1220m)-&gt;0b(1220m) survivors: 144m-&gt;144m heap: 3242m(4096m)-&gt;2093m(4096m)] [Times: user=1.02 sys=0.04, real=0.28 secs] 上面的日志表明发生了 YGC、应用线程为此暂停了 280 毫秒，Eden 区被清空（71MB 从 Young 区移到了 O 区）。日志里面 initial-mark 的字样表明后台的并发 GC 阶段开始了。因为初始标记阶段本身也是要暂停应用线程的，G1 正好在 YGC 的过程中把这个事情也一起干了。为此带来的额外开销不是很大、增加了 20%的 CPU，暂停时间相应的略微变长了些。 接下来，G1 开始扫描根区域、日志示例： 1250.819: [GC concurrent-root-region-scan-start]51.408: [GC concurrent-root-region-scan-end, 0.5890230] 一共花了 580 毫秒，这个过程没有暂停应用线程；是后台线程并行处理的。这个阶段不能被 YGC 所打断、因此后台线程有足够的 CPU 时间很关键。如果 Young 区空间恰好在 Root 扫描的时候满了、YGC 必须等待 root 扫描之后才能进行。带来的影响是 YGC 暂停时间会相应的增加。这时的 GC 日志是这样的： 123&gt; 350.994: [GC pause (young)&gt; 351.093: [GC concurrent-root-region-scan-end, 0.6100090]&gt; 351.093: [GC concurrent-mark-start],0.37559600 secs] GC 暂停这里可以看出在 root 扫描结束之前就发生了，表明 YGC 发生了等待，等待时间大概是 100 毫秒。在 root 扫描完成后，G1 进入了一个并发标记阶段。这个阶段也是完全后台进行的；GC 日志里面下面的信息代表这个阶段的开始和结束： 12111.382: [GC concurrent-mark-start] ....120.905: [GC concurrent-mark-end, 9.5225160 sec] 并发标记阶段是可以被打断的，比如这个过程中发生了 YGC 就会。这个阶段之后会有一个二次标记阶段和清理阶段： 12&gt; 120.910: [GC remark 120.959: [GC ref-PRC, 0.0000890 secs], 0.0718990 secs][times: user=0.23 sys=0.01, real=0.08 secs]&gt; 120.985: [GC cleanup 3510M-&gt;3434M(4096M), 0.0111040 secs][times: user=0.04 sys=0.00, real=0.01 secs] 这两个阶段同样会暂停应用线程，但时间很短。接下来还有额外的一次并发清理阶段： 12120.996: [GC concurrent-cleanup-start]120.996: [GC concurrent-cleanup-end, 0.0004520] 到此为止，正常的一个 G1 周期已完成–这个周期主要做的是发现哪些区域包含可回收的垃圾最多（标记为 X），实际空间释放较少。 混合 GC： 接下来 G1 执行一系列的混合 GC。这个时期因为会同时进行 YGC 和清理上面已标记为 X 的区域，所以称之为混合阶段，下面是一个混合 GC 执行的前后示意图： 像普通的YGC那样、G1完全清空掉Eden同时调整survivor区。另外，两个标记也被回收了，他们有个共同的特点是包含最多可回收的对象，因此这两个区域绝对部分空间都被释放了。这两个区域任何存活的对象都被移到了其他区域（和YGC存活对象晋升到O区类似）。这就是为什么G1的堆比CMS内存碎片要少很多的原因–移动这些对象的同时也就是在压缩对内存。下面是一个混合GC的日志： 79.826: [GC pause (mixed), 0.26161600 secs] …. [Eden: 1222M(1222M)-&gt;0B(1220M) Survivors: 142M-&gt;144M Heap:3200M(4096M)-&gt;1964M(4096M)][times: user=1.01 sys=0.00, real=0.26 secs]上面的日志可以注意到 Eden 释放了 1222MB、但整个堆的空间释放内存要大于这个数目。数量相差看起来比较少、只有 16MB，但是要考虑同时有 survivor 区的对象晋升到 O 区；另外，每次混合 GC 只是清理一部分的 O 区内存，整个 GC 会一直持续到几乎所有的标记区域垃圾对象都被回收，这个阶段完了之后 G1 会重新回到正常的 YGC 阶段。周期性的，当 O 区内存占用达到一定数量之后 G1 又会开启一次新的并行 GC 阶段.后续分开介绍：。。 参考深入理解 java 虚拟机http://ifeve.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3g1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM内存与线程","slug":"language/jvm/JVM内存与线程","date":"2021-08-04T06:25:13.661Z","updated":"2021-08-04T06:25:13.661Z","comments":true,"path":"2021/08/04/language/jvm/JVM内存与线程/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%86%85%E5%AD%98%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"1 内存1.1 内存一致性由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也引入了新的问题：缓存一致性（CacheCoherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory），如图所示： 当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly 及 DragonProtocol，等等。 1.2 主内存与工作内存Java 内存模型的主要目标是定义程序各个变量的访问规则，即在虚拟机机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variable）与 Java 编程中所说的变量略有区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为后者是线程私有的[3]，不会被共享，自然就不存在竞争问题。为了获得较好的执行效能，Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器调整代码执行顺序这类权利，线程对变量的操作都必须在工作内存中进行，而不能直接读写主内存，线程间无法直接访问对方工作内存的中变量，线程间变量值得传递均需要通过主内存来完成。如图所示： 1.3 内存间的交互操作关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java 内存模型定义了以下八种操作来完成： lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。 unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的 load 动作使用 load（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的 write 的操作。 write（写入）：作用于主内存的变量，它把 store 操作从工作内存中一个变量的值传送到主内存的变量中。 如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行 read 和 load 操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行 store 和 write 操作。Java 内存 模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是 read 和 load 之间， store 和 write 之间是可以插入其他指令的，如对主内存中的变量 a、b 进行访问时，可能的顺 序是 read a，read b，load b， load a。 Java 内存模型还规定了在执行上述八种基本操作时，必须满足如下规则： 不允许 read 和 load、store 和 write 操作之一单独出现 不允许一个线程丢弃它的最近 assign 的操作，即变量在工作内存中改变了之后必须同步到主内存中。 不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load 或 assign）的变量。即就是对一个变量实施 use 和 store 操作之前，必须先执行过了 assign 和 load 操作。 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。lock 和 unlock 必须成对出现 如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行 load 或 assign 操作初始化变量的值 如果一个变量事先没有被 lock 操作锁定，则不允许对它执行 unlock 操作；也不允许去 unlock 一个被其他线程锁定的变量。 对一个变量执行 unlock 操作之前，必须先把此变量同步到主内存中（执行 store 和 write 操作）。 1.4 重排序在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型： 1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。 2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 Java 源代码到最终实际执行的指令序列，会经过下面三种重排序： 为了保证内存的可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java 内存模型把内存屏障分为 LoadLoad、LoadStore、StoreLoad 和 StoreStore 四种： 1.5 volatile 型变量当一个变量定义为 volatile 之后，它将具备两种特性： 第一：保证此变量对所有线程的可见性，这里的可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。普通变量的值在线程间传递需要通过主内存来完成 由于 valatile 只能保证可见性，在不符合一下两条规则的运算场景中，我们仍要通过加锁来保证原子性 1.运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 2.变量不需要与其他的状态变量共同参与不变约束 第二：禁止指令重排序，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中执行顺序一致，这个就是所谓的线程内表现为串行的语义 Java 内存模型中对 volatile 变量定义的特殊规则。假定 T 表示一个线程，V 和 W 分别表示两个 volatile 变量，那么在进行 read、load、use、assign、store、write 操作时需要满足如下的规则： 1.只有当线程 T 对变量 V 执行的前一个动作是 load 的时候，线程 T 才能对变量 V 执行 use 动作；并且，只有当线程 T 对变量 V 执行的后一个动作是 use 的时候，线程 T 才能对变量 V 执行 load 操作。线程 T 对变量 V 的 use 操作可以认为是与线程 T 对变量 V 的 load 和 read 操作相关联的，必须一起连续出现。这条规则要求在工作内存中，每次使用变量 V 之前都必须先从主内存刷新最新值，用于保证能看到其它线程对变量 V 所作的修改后的值。 2.只有当线程 T 对变量 V 执行的前一个动是 assign 的时候，线程 T 才能对变量 V 执行 store 操作；并且，只有当线程 T 对变量 V 执行的后一个动作是 store 操作的时候，线程 T 才能对变量 V 执行 assign 操作。线程 T 对变量 V 的 assign 操作可以认为是与线程 T 对变量 V 的 store 和 write 操作相关联的，必须一起连续出现。这一条规则要求在工作内存中，每次修改 V 后都必须立即同步回主内存中，用于保证其它线程可以看到自己对变量 V 的修改。 3.假定操作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，假定操作 F 是操作 A 相关联的 load 或 store 操作，假定操作 P 是与操作 F 相应的对变量 V 的 read 或 write 操作；类型地，假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作，假定操作 G 是操作 B 相关联的 load 或 store 操作，假定操作 Q 是与操作 G 相应的对变量 V 的 read 或 write 操作。如果 A 先于 B，那么 P 先于 Q。这条规则要求 valitile 修改的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同。 1.6 对于 long 和 double 型变量的特殊规则Java 模型要求 lock、unlock、read、load、assign、use、store、write 这 8 个操作都具有原子性，但是对于 64 为的数据类型（long 和 double），在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作分为两次 32 为的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这 4 个操作的原子性 1.7 原子性、可见性和有序性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。Java 内存模型是通过在变量修改后将新值同步会主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性，valatile 特殊规则保障新值可以立即同步到祝内存中。Synchronized 是在对一个变量执行 unlock 之前，必须把变量同步回主内存中（执行 store、write 操作）。被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有吧 this 的引用传递出去，那在其他线程中就能看见 final 字段的值 可见性：可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。 1.8 先行发生原则这些先行发生关系无须任何同步就已经存在，如果不再此列就不能保障顺序性，虚拟机就可以对它们任意地进行重排序 1.程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确的说，应该是控制顺序而不是程序代码顺序，因为要考虑分支。循环等结构 2.管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是同一个锁，而后面的是指时间上的先后顺序 3.Volatile 变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的后面同样是指时间上的先后顺序 4.线程启动规则：Thread 对象的 start()方法先行发生于此线程的每一个动作 5.线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread.joke()方法结束、ThradisAlive()的返回值等手段检测到线程已经终止执行 6.线程中断规则：对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断时间的发生，可以通过 Thread.interrupted()方法检测到是否有中断发生 7.对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize()方法的开始 8.传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论 2 Java 线程协同式调度：线程的执行时间由线程本身控制 抢占式调度：线程的执行时间由系统来分配 2.1 状态转换1.新建 2.运行：可能正在执行。可能正在等待 CPU 为它分配执行时间 3.无限期等待：不会被分配 CUP 执行时间，它们要等待被其他线程显式唤醒 4.限期等待：不会被分配 CUP 执行时间，它们无须等待被其他线程显式唤醒，一定时间会由系统自动唤醒 5.阻塞：阻塞状态在等待这获取到一个排他锁，这个时间将在另一个线程放弃这个锁的时候发生；等待状态就是在等待一段时间，或者唤醒动作的发生 6.结束：已终止线程的线程状态，线程已经结束执行 2.2 线程安全1、不可变：不可变的对象一定是线程安全的、无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障。例如：把对象中带有状态的变量都声明为 final，这样在构造函数结束之后，它就是不可变的。 2、绝对线程安全 3、相对线程安全：相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性 4、线程兼容：对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全使用 5、线程对立：是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码 2.3 线程安全的实现方法1.互斥同步： 同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。互斥是因，同步是果：互斥是方法，同步是目的 在 Java 中，最基本的互斥同步手段就是 synchronized 关键字，它经过编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这两个字节码指令，这两个字节码都需要一个 reference 类型的参数来指明要锁定和解锁的对象。如果 Java 程序中的 synchronized 明确指定了对象参数，那就是这个对象的 reference；如果没有指明，那就根据 synchronized 修饰的是实例方法还是类方法，去取对应的对象实例或 Class 对象来作为锁对象。在执行 monitorenter 指令时，首先要尝试获取对象的锁。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加 1，对应的在执行 monitorexit 指令时会将锁计数器减 1，当计数器为 0 时，锁就被释放。如果获取对象锁失败，哪当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止 Synchronized，ReentrantLock 增加了一些高级功能 1.等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助 2.公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；非公平锁则不能保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。Synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁 3.锁绑定多个条件是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait()和 notify()或 notifyAll()方法可以实现一个隐含的条件，如果要和多余一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition 方法即可 2.非阻塞同步 3.无同步方案 可重入代码：也叫纯代码，可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身）而在控制权返回后，原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。 判断一个代码是否具备可重入性：如果一个方法，它的返回结果是可预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的 线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保障，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题 2.4 锁优化适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁 2.4.1 自旋锁与自适应自旋自旋锁：如果物理机器上有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程稍等一下，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁 自适应自旋转：是由前一次在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自过程，以避免浪费处理器资源。 2.4.2 锁消除锁消除是指虚拟机即时编辑器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。如果在一段代码中。推上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行 2.4.3 锁粗化如果虚拟机检测到有一串零碎的操作都是对同一对象的加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部 2.4.4 轻量级锁2.4.5 偏向锁它的目的是消除无竞争情况下的同步原语，进一步提高程序的运行性能。如果轻量级锁是在无竞争的情况下使用 CAS 操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把这个同步都消除掉，CAS 操作都不做了 如果在接下俩的执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要在进行同步 3 逃逸分析逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他方法中，成为方法逃逸。甚至还可能被外部线程访问到，比如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸 如果一个对象不会逃逸到方法或线程之外，也就是别的方法或线程无法通过任何途径访问到这个对象，则可能为这个变量进行一些高效的优化 栈上分配：如果确定一个对象不会逃逸出方法外，那让这个对象在栈上分配内存将会是一个不错的注意，对象所占用的内存空间就可以随栈帧出栈而销毁。如果能使用栈上分配，那大量的对象就随着方法的结束而销毁了，垃圾收集系统的压力将会小很多 同步消除：如果确定一个变量不会逃逸出线程，无法被其他线程访问，那这个变量的读写肯定就不会有竞争，对这个变量实施的同步措施也就可以消除掉 标量替换：标量就是指一个数据无法在分解成更小的数据表示了，int、long 等及 refrence 类型等都不能在进一步分解，它们称为标量。 如果一个数据可以继续分解，就称为聚合量，Java 中的对象就是最典型的聚合量 如果一个对象不会被外部访问，并且这个对象可以被拆散的化，那程序正整执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM优秀文章","slug":"language/jvm/JVM优秀文章","date":"2021-08-04T06:25:13.659Z","updated":"2021-08-04T06:25:13.661Z","comments":true,"path":"2021/08/04/language/jvm/JVM优秀文章/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E4%BC%98%E7%A7%80%E6%96%87%E7%AB%A0/","excerpt":"","text":"JVM G1 算法系列 G1 垃圾收集器介绍 G1 垃圾收集器之 RSet G1 垃圾收集器之 SATB G1 垃圾收集器之对象分配过程 ZGC 系列 ZGC，一个超乎想象的垃圾收集器 ZGC 什么时候进行垃圾回收 JVM 源码分析系列 深入分析 Object.finalize 方法的实现原理 JVM 源码分析之 Object.wait/notify 实现 JVM 源码分析之 java 对象头实现 JVM 源码分析之 synchronized 实现 JVM 源码分析之 Java 类的加载过程 JVM 源码分析之 Java 对象的创建过程 JVM 源码分析之 JVM 启动流程 JVM 源码分析之堆内存的初始化 JVM 源码分析之 Java 对象的内存分配 JVM 源码分析之如何触发并执行 GC 线程 JVM 源码分析之垃圾收集的执行过程 JVM 源码分析之新生代 DefNewGeneration 的实现 JVM 源码分析之老年代 TenuredGeneration 的垃圾回收算法实现 JVM 源码分析之安全点 safepointJVM 源码分析之线程局部缓存 TLAB JVM 源码分析之不要被 GC 日志的表面现象迷惑 JVM 源码分析之 YGC 的来龙去脉 JVM 源码分析之跨代引用 CardTable JVM 源码分析之 System.gc() JVM 源码分析之 GC locker 深度分析 JVM 源码分析之由 JNI 操作引起的迷惑性 GC 从 JVM 角度看看 Java 的 clone 操作 JVM学习目录1. 【JVM】JVM系列之JVM体系（一） 2. 【JVM】JVM系列之垃圾回收（二） 3. 【JVM】JVM系列之Class文件（三） 4. 【JVM】JVM系列之类加载机制（四） 5. 【JVM】JVM系列之执行引擎（五） 6. 【JVM】JVM系列之内存模型（六）","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"一体化环境搭建","slug":"devops/docker/prometheus-grafana","date":"2021-08-02T07:31:24.150Z","updated":"2021-09-10T03:15:37.865Z","comments":true,"path":"2021/08/02/devops/docker/prometheus-grafana/","link":"","permalink":"https://wuhaocn.github.io/2021/08/02/devops/docker/prometheus-grafana/","excerpt":"","text":"prometheus+grafana安装 默认配置 123456789docker stop prometheusdocker rm prometheusdocker run -d --name=prometheus -p 9090:9090 prom/prometheusdocker update prometheus --restart=alwaysdocker stop grafanadocker rm grafanadocker run -d --name=grafana -p 3000:3000 grafana/grafanadocker update grafana --restart=always 修改配置 1234docker stop prometheusdocker rm prometheusdocker run -d --name=prometheus -p 9090:9090 -v /home/rcloud/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheusdocker update prometheus --restart=always 1234567891011121314global: # 默认情况下，每15s拉取一次目标采样点数据。 scrape_interval: 15s # 我们可以附加一些指定标签到采样点度量标签列表中, 用于和第三方系统进行通信, 包括：federation, remote storage, Alertmanager external_labels: # 下面就是拉取自身服务采样点数据配置 monitor: &#x27;codelab-monitor&#x27;scrape_configs: # job名称会增加到拉取到的所有采样点上，同时还有一个instance目标服务的host：port标签也会增加到采样点上 - job_name: &#x27;prometheus&#x27; # 覆盖global的采样点，拉取时间间隔5s scrape_interval: 5s static_configs: - targets: [&#x27;localhost:9090&#x27;] 登录配置 登录 http://127.0.0.1:3000 修改密码 默认 admin admin 配置 DataSource 127.0.0.1:9090 添加面板 app(metrics)–data–&gt; (?) + prometheus + grafana","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"grafana","slug":"grafana","permalink":"https://wuhaocn.github.io/tags/grafana/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wuhaocn.github.io/tags/prometheus/"}]},{"title":"hexo-安装","slug":"tool/hexo-install","date":"2021-07-26T01:33:15.069Z","updated":"2021-07-26T01:33:15.069Z","comments":true,"path":"2021/07/26/tool/hexo-install/","link":"","permalink":"https://wuhaocn.github.io/2021/07/26/tool/hexo-install/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info.If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/ubuntu/im/readme","date":"2021-06-18T10:54:51.877Z","updated":"2021-06-18T10:54:51.877Z","comments":true,"path":"2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/im/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/im/readme/","excerpt":"","text":"java appjava im 应用","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/ubuntu/web/readme","date":"2021-06-18T10:54:51.868Z","updated":"2021-06-18T10:54:51.868Z","comments":true,"path":"2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/web/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/web/readme/","excerpt":"","text":"java appjava web 应用","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/armjava/readme","date":"2021-06-17T11:02:52.042Z","updated":"2021-06-17T11:02:52.042Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/armjava/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/armjava/readme/","excerpt":"","text":"执行步骤1. ./build-clean.shdockerfile 解析12345678910111213141516171819202122FROM java:8MAINTAINER wuhaotx&lt;wuhaotx@feinno.com&gt;RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN cat /etc/apt/sources.list//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/fastdfs/readme","date":"2021-06-17T11:02:52.036Z","updated":"2021-06-17T11:02:52.036Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/fastdfs/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/fastdfs/readme/","excerpt":"","text":"FastDFS 集群 docker 构建1. docker 源1.1.使用season/fastdfs作为FastDFS源! season/fastdfs 1.2.Run as shell启动client做相关测试和镜像文件查看 docker run -ti --name fdfs_sh --net=host season/fastdfs sh 1.3.源镜像中会执行entrypoint.sh脚本进行FastDFS初始化工作 dockerfile 解析123456789101112131415161718192021222324252627282930# FastDFS基础镜像FROM season/fastdfs# MAINTAINERMAINTAINER wuhaocn@126.comVOLUME [&quot;/tmp&quot;]RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN mkdir -p /data/fastdfs/RUN mkdir -p /data/fastdfs/permfile//将自定义storage.conf拷贝到镜像中替换源镜像中/fdfs_conf/storage.confCOPY conf/storage.conf /fdfs_conf/storage.conf//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools 3.FastDFS 补充3.1.通过storage.conf指定不同store_path store_path0=/data/fastdfs store_path1=/data/fastdfs/permfile 3.2.通过storage.conf设置tracker_server地址 3.3.fastdfs的storage server的状态查询 # FDFS_STORAGE_STATUS：INIT :初始化，尚未得到同步已有数据的源服务器 # FDFS_STORAGE_STATUS：WAIT_SYNC :等待同步，已得到同步已有数据的源服务器 # FDFS_STORAGE_STATUS：SYNCING :同步中 # FDFS_STORAGE_STATUS：DELETED :已删除，该服务器从本组中摘除 # FDFS_STORAGE_STATUS：OFFLINE :离线 # FDFS_STORAGE_STATUS：ONLINE :在线，尚不能提供服务 # FDFS_STORAGE_STATUS：ACTIVE :在线，可以提供服务 使用命令：[root@localhost bin]# fdfs_monitor /etc/fdfs/client.conf 4.注意事项4.1.生产环境FastDFS部署必须要进行数据挂载至硬盘 4.2.先部署tracker,再进行storage部署 4.3.检查状态 可以使用 fdfs_monitor 来查看一下storage的状态，看是否已经成功注册到了tracker [......]# fdfs_monitor /etc/fdfs/storage.conf #也可以以下命令来监控服务器的状态： [......]# fdfs_monitor /etc/fdfs/client.conf","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/java/readme","date":"2021-06-17T11:02:52.029Z","updated":"2021-06-17T11:02:52.029Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/java/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/java/readme/","excerpt":"","text":"执行步骤1. ./build-clean.shdockerfile 解析12345678910111213141516171819202122FROM java:8MAINTAINER wuhaotx&lt;wuhaotx@feinno.com&gt;RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN cat /etc/apt/sources.list//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/nginx/readme","date":"2021-06-17T11:02:52.021Z","updated":"2021-06-17T11:02:52.021Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/nginx/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/nginx/readme/","excerpt":"","text":"参照：https://github.com/openresty/docker-openresty/blob/1.9.15.1/centos/Dockerfile 默认版本不支持 TCP，需要查看 git 源码 centos：为官方源码,二次打包 nginx-fusion.conf","categories":[],"tags":[]},{"title":"一体化环境搭建","slug":"devops/docker/一体化环境搭建","date":"2021-06-17T11:02:52.012Z","updated":"2021-08-31T08:18:33.461Z","comments":true,"path":"2021/06/17/devops/docker/一体化环境搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/%E4%B8%80%E4%BD%93%E5%8C%96%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"基础 jar123docker stop jappdocker rm jappdocker run --name japp --privileged=true -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.7.19 安装扩展 java redis123456789101112131415161718apt-key del 5072E1F5apt-get updateapt-key adv --keyserver keyserver.ubuntu.com --recv 8C718D3B5072E1F5apt-get updatelscd /rootlscd jdk1.8.0_251/lscd ..vim /etc/profileapt-get install vimvim /etc/profilesource /etc/profilejava -vjava -versionapt-get install redis-serverls 打包推送12345docker commit e9c1ad83b80a wuhaocn/javaapp:8docker tag wuhaocn/javaapp:8 wuhaocn/javaapp:8docker push wuhaocn/javaapp:8 运行123docker stop jappdocker rm jappdocker run --name japp --privileged=true -p 3337:3306 16379:6379 -d wuhaocn/javaapp:8","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/tags/java/"}]},{"title":"Shell关闭防火墙","slug":"language/shell/linux防火墙","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.359Z","comments":true,"path":"2021/06/15/language/shell/linux防火墙/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/linux%E9%98%B2%E7%81%AB%E5%A2%99/","excerpt":"","text":"Redhat6.x 关闭防火墙的方法关闭防火墙的方法为： 1. 永久性生效 开启：chkconfig iptables on 关闭：chkconfig iptables off 2. 即时生效，重启后失效 开启：service iptables start 关闭：service iptables stop 需要说明的是对于 Linux 下的其它服务都可以用以上命令执行开启和关闭操作 补充： a. 防火墙还需要关闭ipv6的防火墙： chkconfig ip6tables off 并且可以通过如下命令查看状态： chkconfig --list iptables b. selinux状态可以通过以下命令查看： sestatus","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"修改服务端IP","slug":"language/shell/修改机器服务端IP","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.363Z","comments":true,"path":"2021/06/15/language/shell/修改机器服务端IP/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E4%BF%AE%E6%94%B9%E6%9C%BA%E5%99%A8%E6%9C%8D%E5%8A%A1%E7%AB%AFIP/","excerpt":"","text":"1.查看并修改vim /etc/sysconfig/network-scripts/ifcfg-bond0 123456789[root@xxx-001 ~]# cat /etc/sysconfig/network-scripts/ifcfg-bond0DEVICE=bond0ONBOOT=yesBOOTPROTO=noneIPADDR=172.21.77.1NETMASK=255.255.255.192GATEWAY=172.21.77.62BONDING_OPTS=&quot;mode=1 miimon=100 primary=eth0&quot;USERCTL=no 2.重启service network restart 3.备注---修改ip地址--- 即时生效:# ifconfig eth0 192.168.1.155 netmask 255.255.255.0 重启生效:修改vi /etc/sysconfig/network-scripts/ifcfg-eth0 ---修改default gateway--- 即时生效:# route add default gw 192.168.1.1 重启生效:修改vi /etc/sysconfig/network-scripts/ifcfg-eth0 ---修改dns--- 修改vi /etc/resolv.conf #修改后即时生效，重启同样有效 ---修改host name--- 即时生效:# hostname test1 重启生效:修改vi /etc/sysconfig/network","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"工具脚本","slug":"language/shell/工具脚本","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-26T02:20:23.975Z","comments":true,"path":"2021/06/15/language/shell/工具脚本/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E5%B7%A5%E5%85%B7%E8%84%9A%E6%9C%AC/","excerpt":"","text":"定时任务123crontab -e*/1 * * * * /home/5g-doc/doc-update.sh 请参考：https://www.runoob.com/linux/linux-comm-crontab.html","categories":[{"name":"编程语言 - shell","slug":"编程语言-shell","permalink":"https://wuhaocn.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-shell/"}],"tags":[]},{"title":"常用shell命令","slug":"language/shell/常用shell命令","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.329Z","comments":true,"path":"2021/06/15/language/shell/常用shell命令/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4/","excerpt":"","text":"查找指定文件并返回结果dbhost=`grep -c &quot;nihao&quot; servicesetting.properties` echo $dbres if [ $dbres -eq &#39;0&#39; ]; then echo &quot;nihao Not Found&quot; else echo &quot;nihao Found!&quot; fi 判断变量为空加上引号判断 if [ ! -n &quot;$para1&quot; ]; then echo &quot;IS NULL&quot; else echo &quot;NOT NULL&quot; fi 【输出结果】&quot;IS NULL&quot; 直接通过变量判断 para1= if [ ! $para1 ]; then echo &quot;IS NULL&quot; else echo &quot;NOT NULL&quot; fi 【输出结果】&quot;IS NULL&quot; 使用 test 判断 dmin= if test -z &quot;$dmin&quot; then echo &quot;dmin is not set!&quot; else echo &quot;dmin is set !&quot; fi 【输出结果】&quot;dmin is not set!&quot; 使用””判断 dmin= if [ &quot;$dmin&quot; = &quot;&quot; ] then echo &quot;dmin is not set!&quot; else echo &quot;dmin is set !&quot; fi 【输出结果】&quot;dmin is not set!&quot;","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"系统日志","slug":"language/shell/日志相关","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.348Z","comments":true,"path":"2021/06/15/language/shell/日志相关/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E6%97%A5%E5%BF%97%E7%9B%B8%E5%85%B3/","excerpt":"","text":"####系统日志/var/log 为系统日志/var/log/supervisor/","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"权限设置shell命令","slug":"language/shell/权限设置shell命令","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.337Z","comments":true,"path":"2021/06/15/language/shell/权限设置shell命令/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E6%9D%83%E9%99%90%E8%AE%BE%E7%BD%AEshell%E5%91%BD%E4%BB%A4/","excerpt":"","text":"权限篇 chmod chgrp chownchmod 777 文件名 chgrp 用户名 文件名 -R chown 用户名 文件名 -R -R表示递归目录下所有文件 一、修改文件所属组群——chgrp 修改文件所属组群很简单-chgrp命令，就是change group的缩写（我们可以利用这些来记忆命令） 语法：chgrp 组群 文件名/目录 举例： [root@redhat ~]# groupadd groupa [root@redhat ~]# groupadd groupb [root@redhat ~]# useradd -g groupa zgz [root@redhat ~]# su - zgz [zgz@redhat ~]$ touch filea [zgz@redhat ~]$ touch fileb [zgz@redhat ~]$ ls -l total 8 -rw-r--r-- 1 zgz groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 0 Sep 26 05:50 fileb -- [root@redhat zgz]# chgrp groupb filea --改变filea所属群组 [root@redhat zgz]# ls -l total 8 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 0 Sep 26 05:50 fileb 二、修改文件拥有者——chown 修改组群的命令使chgrp，即change group，那么修改文件拥有者的命令自然就是chown，即change owner。chown功能很多，不仅仅能更改文件拥有者，还可以修改文件所属组群。如果需要将某一目录下的所有文件都改变其拥有者，可以使用-R参数。 语法如下： chown [-R] 账号名称 文件/目录 chown [-R] 账号名称:组群 文件/目录 举例： [root@redhat zgz]# ls -l total 20 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown myy fileb --修改fileb的拥有者为myy [root@redhat zgz]# ls -l total 20 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown myy:groupa filea --修改filea的拥有者为myy，并且同 [root@redhat zgz]# ls -l时修改组群为groupa total 20 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown -R myy zgzdir 同时改变其下所有文件拥有者 total 20 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# cd zgzdir/ [root@redhat zgzdir]# ls -l total 8 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed 三、改变文件权限——chmod 1.用数字来改变文件权限 我们已经了解了-rw-r--r-- 所表示含义，linux为每一个权限分配一个固定的数字： r： 4（读权限） w： 2（写权限） x： 1（执行权限） 我们再将这些数字相加，就得到每一组的权限值，例如 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed 第一组（user）：rw- = 4+2+0 = 6 第二组（group）：r-- = 4+0+0 = 4 第三组（others）：r-- = 4+0+0 = 4 那么644就是fileb权限的数字表示值。 如果我们想改变某一个文件的权限，首先需要将权限转化为数字组合，例如我们想得到-rwxrw-r--，那么就应该得到数字组合：[4+2+1][4+2+0][4+0+0]=764,然后再用chmod命令去修改 chmod语法： chmod xyz 文件/目录 举例： [root@redhat zgzdir]# ls -l total 8 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod 777 filec--将filec的权限改变为777 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod 750 filed--将filed的权限改变为750 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-x--- 1 myy groupa 0 Sep 26 06:07 filed 2、用字符来改变文件权限 还有一种改变权限的方法，我们已经了解到，文件权限分为三组，分别是user，group，others，那么我们可以用u，g,o分别代表三组，另外，a（all）代表全部，而权限属性即可用r，w，x三个字符来表示，那么请看下面的语法： chmod u/g/o/a +(加入)/-(除去)/=(设定) r/w/x 文件或者目录 举例： 我们想使filed文件得到：u：可读，可写，可执行 g，o：可读，可执行 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-x--- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod u=rwx,go=rx filed--修改filed的文件属性 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-xr-x 1 myy groupa 0 Sep 26 06:07 filed 其中g和o也可以用“，”分开来分别设定。 假设目前我不知道各组权限如何，只是想让所有组都增加“x”权限，那么我们可以用chmod a+x filename来实现， 举例： [root@redhat zgz]# ls -l total 24 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chmod a+x filea--修改filea的文件属性，所有组都增加“x”权限 [root@redhat zgz]# ls -l total 24 -rwxr-xr-x 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir 如果想除去某一权限，可以用“-”来操作， 举例： [root@redhat zgz]# ls -l total 24 -rwxr-xr-x 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chmod a-x filea-修改filea文件属性所有组都除去“x”权限 [root@redhat zgz]# ls -l total 24 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# 友情提醒： chgrp，chown，chmod这些命令默认的情况下只有root有权限执行，大家有时可能会用普通账户去修改文件权限，linux会提示你没有这个权限。因此大家一定要注意当前用户，例如： [zgz@redhat ~]$ chgrp groupb filea chgrp: changing group of `filea&#39;: Operation not permitted --zgz没有权限来改变‘filea’的组群","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"查看系统属性","slug":"language/shell/系统属性相关","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.343Z","comments":true,"path":"2021/06/15/language/shell/系统属性相关/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E7%B3%BB%E7%BB%9F%E5%B1%9E%E6%80%A7%E7%9B%B8%E5%85%B3/","excerpt":"","text":"查看系统属性1.查看 Linux 内核版本命令1.uname -alinux-onss:~ # uname -a Linux linux-onss 4.4.73-5-default #1 SMP Tue Jul 4 15:33:39 UTC 2017 (b7ce4e4) x86_64 x86_64 x86_64 GNU/Linux 2.cat /proc/versioncat /proc/version Linux version 4.4.73-5-default (geeko@buildhost) (gcc version 4.8.5 (SUSE Linux) ) #1 SMP Tue Jul 4 15:33:39 UTC 2017 (b7ce4e4) 2.查看 Linux 系统版本的命令1.lsb_release -a即可列出所有版本信息，这个命令适用于所有的Linux发行版，包括RedHat、SUSE、Debian…等发行版 lsb_release -a LSB Version: n/a Distributor ID: SUSE Description: SUSE Linux Enterprise Server 12 SP3 Release: 12.3 Codename: n/a 2.cat /etc/issue此命令也适用于所有的Linux发行版。 cat /etc/issue Welcome to SUSE Linux Enterprise Server 12 SP3 (x86_64) - Kernel \\r (\\l). 3.cat /etc/redhat-release这种方法只适合Redhat系的Linux： cat /etc/redhat-release Red Hat Enterprise Linux Server release 6.2 (Santiago) 4.查看硬件信息请参考： https://www.cnblogs.com/cloudos/p/8416415.html","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"Shell远程执行命令","slug":"language/shell/远程执行","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.354Z","comments":true,"path":"2021/06/15/language/shell/远程执行/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C/","excerpt":"","text":"Linux Shell 远程执行命令（命令行与脚本方式）shell远程执行： 经常需要远程到其他节点上执行一些shell命令，如果分别ssh到每台主机上再去执行很麻烦，因此能有个集中管理的方式就好了。一下介绍两种shell命令远程执行的方法。 前提条件： 配置ssh免密码登陆 对于简单的命令： 如果是简单执行几个命令，则： ssh user@remoteNode &quot;cd /home ; ls&quot; ssh root@10.10.220.90 &quot;cd /home ; ls&quot; 基本能完成常用的对于远程节点的管理了，几个注意的点： 双引号，必须有。如果不加双引号，第二个ls命令在本地执行 分号，两个命令之间用分号隔开 对于脚本的方式： 有些远程执行的命令内容较多，单一命令无法完成，考虑脚本方式实现： 复制代码 #!/bin/bash ssh user@remoteNode &gt; /dev/null 2&gt;&amp;1 &lt;&lt; eeooff cd /home touch abcdefg.txt exit eeooff echo done! 复制代码 远程执行的内容在“&lt;&lt; eeooff ” 至“ eeooff ”之间，在远程机器上的操作就位于其中，注意的点： &lt;&lt; eeooff，ssh后直到遇到eeooff这样的内容结束，eeooff可以随便修改成其他形式。 重定向目的在于不显示远程的输出了 在结束前，加exit退出远程节点","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"基础环境","slug":"devops/docker/基础环境","date":"2021-05-15T04:08:19.160Z","updated":"2021-08-31T12:00:21.650Z","comments":true,"path":"2021/05/15/devops/docker/基础环境/","link":"","permalink":"https://wuhaocn.github.io/2021/05/15/devops/docker/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/","excerpt":"","text":"docker 环境搭建ubuntu1234567891011121314151617181920docker 安装sudo apt-get updatesudo apt install docker.iosudo groupadd dockerdocker pssudo usermod -aG docker $USERsudo vim /etc/docker/daemon.json root@user1-virtual-machine:~# cat /etc/docker/daemon.json&#123; &quot;storage-driver&quot;:&quot;overlay&quot;, &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;]&#125;sudo service docker restart centos123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960简单安装：curl -sSL https://get.daocloud.io/docker | sh其他详细：1. 安装docker-yum 【centos7】 sudo yum install docker 【centos6】 修改yum源：参考/centos-6-yum源 # yum install device-mapper-libs yum upgrade device-mapper-libs yum update--skip-broke rpm -Uvh http://ftp.riken.jp/Linux/fedora/epel/6Server/x86_64/epel-release-6-8.noarch.rpm yum install docker-io ubuntu: apt-get update apt-get install apt-transport-https ca-certificates wget -qO- https://get.docker.com/ | sh service docker start2. 指定私库 修改/etc/docker/daemon.json文件 #vi /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] &#125; #这个现网使用出错 #&#123; # &quot;storage-driver&quot;:&quot;overlay&quot;, # &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] #&#125; cent-os-6 /etc/sysconfig/docker other_args=&#x27;--insecure-registry 10.10.208.193:5000&#x27; DOCKER_CERT_PATH=/etc/docker ADD_REGISTRY=&#x27;--add-registry 10.10.208.193:5000&#x27; # Resolves: rhbz#1176302 (docker issue #407) DOCKER_NOWARN_KERNEL_VERSION=13. 修改存储位置 修改docker.service文件，使用-g参数指定存储位置 vi /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --graph /data/docker4.配置生效 #reload配置文件 systemctl daemon-reload #重启docker systemctl restart docker #查看 Docker Root Dir: /var/lib/docker是否改成设定的目录/new-path/docker docker info Docker Root Dir: /data/docker #10.10.208.193 #systemctl daemon-reload # docker registry1.映射开发环境使用 12345678910docker run -itd --name registry --restart=always -p 5000:5000 -v /registry:/var/lib/registry registry:2docker stop registrydocker rm registrydocker run -itd --name registry --restart=always -p 5000:5000 registry:2docker stop registry-webdocker rm registry-webdocker run -d -p 15000:8080 --name registry-web --link registry -e REGISTRY_URL=http://registry:5000/v2 -e REGISTRY_NAME=localhost:5000 hyper/docker-registry-webdocker run -p 8080:8080 -e REG1=http://10.3.4.111:5000/v2/ atcol/docker-registry-ui 2.无映射本机测试临时使用 123docker stop registrydocker rm registrydocker run -d --name registry --restart=always -p 5000:5000 registry:2 基础环境备注1234567891，在运行容器的时候，给容器加特权：示例：docker run -i -t --privileged=true -v /home/docs:/src waterchestnut/nodejs:0.12.02，临时关闭selinux：示例：su -c &quot;setenforce 0&quot;之后执行：docker run -i -t -v /home/docs:/src waterchestnut/nodejs:0.12.0注意：之后要记得重新开启selinux，命令：su -c &quot;setenforce 1&quot;3，添加selinux规则，将要挂载的目录添加到白名单：示例：chcon -Rt svirt_sandbox_file_t /home/docs之后执行：docker run -i -t -v /home/docs:/src waterchestnut/nodejs:0.12.0","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"","slug":"devops/docker/docker-package/docker-build-java","date":"2021-01-05T12:05:13.000Z","updated":"2021-01-05T12:05:13.000Z","comments":true,"path":"2021/01/05/devops/docker/docker-package/docker-build-java/","link":"","permalink":"https://wuhaocn.github.io/2021/01/05/devops/docker/docker-package/docker-build-java/","excerpt":"","text":"docker 打包运行参照1. 目录结构 2. 打包流程2.1. docker 本地打包规范参照docker常用套路,需具备以下基本条件 1. docker基础环境 1. Dockerfile：用于打包特定镜像 2. run.sh：用于启动服务 3. build.gradle (java服务必须) 4. docker-clean-build.sh (快捷打包) 5. docker-xxx-dev.sh （快捷运行） 2.2. docker 基础环境2.2.1 安装（可自行搜索） yum install docker (centos7) apt-get install docker (ubuntu) 下载安装包（windows 、mac） 2.2.2.1 配置私服【linux】 修改/etc/docker/daemon.json文件 #vi /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] &#125; 重启docker 2.2.2.2 配置私服【mac】 2.3. DockerfileDockerfile 示例 1 1234567891011//官方基础镜像，打包之后目录未分开#基础镜像FROM java:8VOLUME [&quot;/tmp&quot;]ADD ./* /home/servicename/#指定时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneENTRYPOINT [&quot;/home/servicename/run.sh&quot;] Dockerfile 示例 2 12345678910111213141516171819202122//基于官方镜像二次封装，包含基础工具，打包之后目录分开#基础镜像FROM 10.10.208.193:5000/urcs/java:8#ARG是Docker1.9 版本才新加入的指令,如果不支持该命令则直接赋值ARG appName=urcs-service-groupVOLUME [&quot;/tmp&quot;]#ADD ./* /home/$appName/#docker打包时配置文件分离/和helium目录结构保持一致ADD config /home/$appName/config/ADD *.jar /home/$appName/lib/ADD ./*.xml /home/$appName/ADD ./*.sh /home/$appName/#指定时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneENTRYPOINT [&quot;/home/$appName/run.sh&quot;] 2.4 run.sh启动脚本 1234567891011121314151617#!/bin/bashulimit -c unlimitedulimit -n 32768basePath=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)SERVICE_HOME=$basePathSERVICE_LIBS=&quot;$SERVICE_HOME/&quot;SERVICE_MAIN=&quot;mainClass&quot;declare -a JAVA_ARGSJAVA_ARGS[0]=&quot;-Xmx256m&quot;JAVA_ARGS[1]=&quot;-Xms256m&quot;exec $JAVA_HOME/bin/java -Duser.dir=$SERVICE_HOME $&#123;JAVA_ARGS[@]&#125; -classpath $SERVICE_HOME:$SERVICE_LIBS/* $SERVICE_MAIN 2.5 build.gradle启动脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849buildscript &#123; repositories &#123; mavenCentral() &#125; dependencies &#123; //添加依赖jar包 classpath &#x27;se.transmode.gradle:gradle-docker:1.2&#x27; &#125;&#125;apply plugin: &#x27;docker&#x27;//build构造jar文件jar &#123; manifest &#123; attributes &#x27;Manifest-Version&#x27;: 1.0 attributes &#x27;Main-Class&#x27;: &#x27;mainClass&#x27; &#125; enabled = true&#125;//打包可运行jar包task buildRunJar(type:Copy, dependsOn: build) &#123; from configurations.runtime from &#x27;src/main/resources&#x27; into &#x27;build/libs&#x27; // 目标位置&#125;//打包dockertask buildDocker(type: Docker, dependsOn: buildRunJar) &#123; push = true //TODO 前面为服务器期名 + 后面为服务名【以后修改最好不把服务器名打进去】 tag = &quot;10.10.208.193:5000/&quot; + &quot;servicename&quot; applicationName = jar.baseName dockerfile = file(&#x27;src/main/docker/Dockerfile&#x27;) doFirst &#123; copy &#123; from &#x27;build/libs&#x27; into stageDir &#125; &#125;&#125;dependencies &#123; ....&#125; 2.6. docker-clean-build.sh1234docker rm `docker ps -a -q`docker rmi --force `docker images | grep servicename | awk &#x27;&#123;print $3&#125;&#x27;`gradle cleangradle buildDocker -x test 2.7. docker-run.sh123456789101112131415161718192021docker stop servicenamedocker rm `docker ps -a -q`docker run \\ --env PRIVATE_IP=0.0.0.0 \\ --env REG_IP=10.10.208.194 \\ --env ZK_HOSTS=10.10.208.194:7998 \\ --env HTTP_PORT=8011 \\ --env HTTP_DASH_PORT=8111 \\ --env RPC_PORT=6011 \\ --env RPC_STACK=rpc-stack \\ --env HTTP_STACK=http-stack \\ --env HTTP_DASH_STACK=http-dash-stack \\ --env KAFKA_HOST=10.10.208.194 \\ --privileged=true \\ -p 8011:8011 \\ -p 8111:8111 \\ -p 6011:6011 \\ -d --name servicename1.0 \\ 10.10.208.193:5000/servicename1.0.0-1902151423 3 常见问题1.docker容器时间与宿主机时间不一至,容器时间为UTC时间 1.1.解决：Dockerfile增加 #指定时区 RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone 2.docker基础镜像中安装常用功能,例如vim 4 常用命令 docker run -p 8888:8888 $name tag docker stop $name docker rm $name docker inspect $name docker ps -a | -l docker logs [-f] [-t] [-tail] $name -f –follows=true | false，默认是false，显示更新 -t –timestamps=true | false，默认是false，显示时间戳 –tail=“all” | 行数，显示最新行数的日志","categories":[],"tags":[]}],"categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"},{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"},{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"},{"name":"短信","slug":"短信","permalink":"https://wuhaocn.github.io/categories/%E7%9F%AD%E4%BF%A1/"},{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"},{"name":"编程语言 - shell","slug":"编程语言-shell","permalink":"https://wuhaocn.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-shell/"}],"tags":[{"name":"brew","slug":"brew","permalink":"https://wuhaocn.github.io/tags/brew/"},{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"},{"name":"design","slug":"design","permalink":"https://wuhaocn.github.io/tags/design/"},{"name":"动态调试技术","slug":"动态调试技术","permalink":"https://wuhaocn.github.io/tags/%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/"},{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"},{"name":"ai","slug":"ai","permalink":"https://wuhaocn.github.io/tags/ai/"},{"name":"jenkins","slug":"jenkins","permalink":"https://wuhaocn.github.io/tags/jenkins/"},{"name":"cmpp","slug":"cmpp","permalink":"https://wuhaocn.github.io/tags/cmpp/"},{"name":"ftp","slug":"ftp","permalink":"https://wuhaocn.github.io/tags/ftp/"},{"name":"nexus","slug":"nexus","permalink":"https://wuhaocn.github.io/tags/nexus/"},{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"NGAP","slug":"NGAP","permalink":"https://wuhaocn.github.io/tags/NGAP/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"},{"name":"MEC","slug":"MEC","permalink":"https://wuhaocn.github.io/tags/MEC/"},{"name":"网络切片","slug":"网络切片","permalink":"https://wuhaocn.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%87%E7%89%87/"},{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"AOP","slug":"AOP","permalink":"https://wuhaocn.github.io/tags/AOP/"},{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"},{"name":"grafana","slug":"grafana","permalink":"https://wuhaocn.github.io/tags/grafana/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wuhaocn.github.io/tags/prometheus/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/tags/java/"}]}